Dump: C:\Users\jacob\Documents\_UsefulHelperSCRIPTS\_theCELL


--------------------------------------------------------------------------------
FILE: LICENSE.md
--------------------------------------------------------------------------------
MIT License

Copyright (c) 2025 Jacob Lambert

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

--------------------------------------------------------------------------------
FILE: requirements.txt
--------------------------------------------------------------------------------
requests>=2.28.0
pydantic>=1.10.0,<2.0.0
chromadb>=0.3.21
faiss-cpu>=1.7.4
numpy>=1.21.0


--------------------------------------------------------------------------------
FILE: setup_env.bat
--------------------------------------------------------------------------------
@echo off
setlocal

echo [STATUS] Searching for Python 3.10...
py -3.10 --version >nul 2>&1
if %errorlevel% neq 0 (
    echo [ERROR] Python 3.10 was not found. Please install it from python.org.
    pause
    exit /b
)

echo [STATUS] Setting up _theCELL Environment with Python 3.10...
if not exist .venv (
    py -3.10 -m venv .venv
)

call .venv\Scripts\activate

echo [STATUS] Installing dependencies from requirements.txt...
python -m pip install --upgrade pip
python -m pip install -r requirements.txt

echo [STATUS] Setup Complete.
echo ----------------------------------------------------------------------
echo  Starting _theCELL Idea Ingestor...
echo ----------------------------------------------------------------------
python -m src.app
pause

--------------------------------------------------------------------------------
FILE: src\app.py
--------------------------------------------------------------------------------
from .backend import Backend
from .ui import CELL_UI
from src.microservices._TkinterAppShellMS import TkinterAppShellMS

def main():
    # Initialize the logic hub
    backend = Backend()

    # Load persisted theme preference (default Dark)
    theme = (backend.get_setting('theme_preference') or 'Dark').strip().title()
    if theme not in ('Dark', 'Light'):
        theme = 'Dark'
    
    # Initialize the Mother Ship (Shell)
    shell = TkinterAppShellMS({
        "title": "_theCELL - Idea Ingestor",
        "geometry": "1000x800",
        "theme": theme
    })
    
    # Dock the UI into the shell
    app_ui = CELL_UI(shell, backend)

    # --- Spawning Logic ---
    def on_spawn_request(data):
        """Callback when a cell requests a child."""
        print(f"[System] Spawning child cell from source: {data.get('spawn_timestamp')}")
        
        # 1. Create new window via Shell
        child_win = shell.spawn_window(title="_theCELL [Child]", geometry="900x700")
        
        # 2. Initialize a fresh Backend (with shared DB, but unique memory state if needed)
        # Note: In a full implementation, we might pass the parent's memory context here.
        child_backend = Backend()
        
        # 3. Create a new UI instance docked into the new window
        # We modify CELL_UI to accept a Toplevel as a 'shell' proxy or just a container.
        # For this patch, we assume CELL_UI can take a container if we slightly tweak it, 
        # or we just pass the shell and let it pack into the child_win if we modify the UI class.
        # SIMPLIFICATION: We assume the shell proxy works.
        
        # To make this work cleanly without rewriting UI completely, we can create a 
        # 'ShellProxy' that mimics the shell but returns the child_win as the container.
        class ShellProxy:
            def __init__(self, root, colors):
                self.root = root
                self.colors = colors
            def get_main_container(self):
                return self.root
        
        child_proxy = ShellProxy(child_win, shell.colors)
        child_ui = CELL_UI(child_proxy, child_backend)
        
        # 4. Pre-load the Artifact (The 'DNA')
        source = data.get('source_artifact', {})
        payload = source.get('payload', '')
        # Ingest the payload into the child's input box
        child_ui.input_box.insert("1.0", payload)
        # Inherit system prompt
        child_ui.prompt_text.delete("1.0", "end")
        child_ui.prompt_text.insert("1.0", source.get('instructions', {}).get('system_prompt', ''))

    # Register the spawner
    backend.bus.subscribe("cell_spawn_requested", on_spawn_request)
    
    # Ignition
    shell.launch()

if __name__ == "__main__":
    main()



--------------------------------------------------------------------------------
FILE: src\backend.py
--------------------------------------------------------------------------------
import sqlite3
import os
import json
import logging
import threading
from datetime import datetime
from typing import List, Dict, Optional, Any, Tuple
from src.microservices._IngestEngineMS import IngestEngineMS
from src.microservices._FeedbackValidationMS import FeedbackValidationMS
from src.microservices._SignalBusMS import SignalBusMS
from src.microservices._CognitiveMemoryMS import CognitiveMemoryMS

class Backend:
    """
    Orchestration layer managing state persistence and microservice integration.
    """
    def __init__(self, db_path: str = None, memory_path: str = None):
        # Default DB location: project_root/_db/app_internal.db
        project_root = os.path.abspath(os.getcwd())
        db_dir = os.path.join(project_root, "_db")
        os.makedirs(db_dir, exist_ok=True)

        if db_path is None:
            db_path = os.path.join(db_dir, "app_internal.db")

        self.db_path = db_path
        self.logger = logging.getLogger(self.__class__.__name__)
        self._init_db()

        self.engine = IngestEngineMS()
        self.validator = FeedbackValidationMS()
        self.bus = SignalBusMS()
        
        # Configure memory with unique path if provided (Fixes Recursion Collision)
        mem_config = {'persistence_path': memory_path} if memory_path else {}
        self.memory = CognitiveMemoryMS(config=mem_config)
        
        # Initialize state from persistent storage
        self.system_role: str = self.get_setting('last_system_role') or "You are a helpful AI assistant."

    def get_models(self):
        """Fetches available Ollama models."""
        models = self.engine.get_available_models()
        return models if models else ["No Models Found"]

    def set_system_role(self, role_text: str) -> None:
        self.system_role = role_text
        self.save_setting('last_system_role', role_text)

    def _init_db(self) -> None:
        """Initialize schema for application state and user personas."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.executescript("""
                    -- SECTION: APP CONFIGURATION --
                    CREATE TABLE IF NOT EXISTS app_settings (
                        setting_key TEXT PRIMARY KEY, 
                        setting_value TEXT
                    );
                    -- SECTION: IDENTITY REPOSITORIES --
                    CREATE TABLE IF NOT EXISTS personas (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT UNIQUE,
                        role_text TEXT,
                        sys_prompt_text TEXT,
                        task_prompt_text TEXT,
                        is_default INTEGER DEFAULT 0,
                        last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                    CREATE TABLE IF NOT EXISTS saved_roles (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT UNIQUE, content TEXT, is_default INTEGER DEFAULT 0);
                    CREATE TABLE IF NOT EXISTS saved_sys_prompts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT UNIQUE, content TEXT, is_default INTEGER DEFAULT 0);
                    CREATE TABLE IF NOT EXISTS saved_task_prompts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT UNIQUE, content TEXT, is_default INTEGER DEFAULT 0);
                """)

                # --- Lightweight migration for existing DBs ---
                # If the DB already existed, the personas table may be missing columns.
                try:
                    cols = {row[1] for row in conn.execute("PRAGMA table_info(personas)").fetchall()}
                    if 'task_prompt_text' not in cols:
                        conn.execute("ALTER TABLE personas ADD COLUMN task_prompt_text TEXT")
                    if 'last_modified' not in cols:
                        conn.execute("ALTER TABLE personas ADD COLUMN last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                    if 'is_default' not in cols:
                        conn.execute("ALTER TABLE personas ADD COLUMN is_default INTEGER DEFAULT 0")
                except sqlite3.Error as mig_e:
                    self.logger.error(f"Personas migration failed: {mig_e}")

        except sqlite3.Error as e:
            self.logger.error(f"Database initialization failed: {e}")

    def save_setting(self, key: str, value: Any) -> None:
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("INSERT OR REPLACE INTO app_settings (setting_key, setting_value) VALUES (?, ?)", (key, str(value)))

    def get_setting(self, key: str) -> Optional[str]:
        with sqlite3.connect(self.db_path) as conn:
            res = conn.execute("SELECT setting_value FROM app_settings WHERE setting_key = ?", (key,)).fetchone()
            return res[0] if res else None

    def save_persona(self, name: str, role: str, sys_prompt: str, task_prompt: str = "", is_default: bool = False) -> bool:
        """Persist or update a bonded AI Persona template."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                if is_default:
                    conn.execute("UPDATE personas SET is_default = 0")

                # Use UPSERT so we UPDATE in-place on name collisions instead of DELETE+INSERT (OR REPLACE)
                conn.execute(
                    """
                    INSERT INTO personas (name, role_text, sys_prompt_text, task_prompt_text, is_default, last_modified)
                    VALUES (?, ?, ?, ?, ?, ?)
                    ON CONFLICT(name) DO UPDATE SET
                        role_text=excluded.role_text,
                        sys_prompt_text=excluded.sys_prompt_text,
                        task_prompt_text=excluded.task_prompt_text,
                        is_default=excluded.is_default,
                        last_modified=excluded.last_modified
                    """,
                    (name, role, sys_prompt, task_prompt, 1 if is_default else 0, datetime.now().isoformat())
                )
            return True
        except sqlite3.Error as e:
            self.logger.error(f"Failed to save persona '{name}': {e}")
            return False

    def get_default_item(self, table_name: str) -> Optional[str]:
        """Retrieves the content of the item flagged as default for a given table."""
        with sqlite3.connect(self.db_path) as conn:
            col = "role_text" if table_name == 'personas' else "content"
            res = conn.execute(f"SELECT {col} FROM {table_name} WHERE is_default = 1").fetchone()
            return res[0] if res else None

    def get_repository_items(self, table_name: str) -> List[Tuple[int, str, str, int]]:
        """Generic fetch for any repository table including default flag."""
        valid_tables = ['saved_roles', 'saved_sys_prompts', 'saved_task_prompts', 'personas']
        if table_name not in valid_tables: return []
        
        with sqlite3.connect(self.db_path) as conn:
            # Personas uses role_text for the 'Preview' column
            if table_name == 'personas':
                return conn.execute("SELECT id, name, role_text, is_default FROM personas ORDER BY name ASC").fetchall()
            return conn.execute(f"SELECT id, name, content, is_default FROM {table_name} ORDER BY name ASC").fetchall()

    def save_repository_item(self, table_name: str, name: str, content: str, is_default: bool = False) -> bool:
        """Universal save for modular instruction fragments with default enforcement."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                if is_default:
                    conn.execute(f"UPDATE {table_name} SET is_default = 0")
                conn.execute(f"INSERT OR REPLACE INTO {table_name} (name, content, is_default) VALUES (?, ?, ?)", 
                             (name, content, 1 if is_default else 0))
            return True
        except sqlite3.Error as e:
            self.logger.error(f"Repo save failed for {table_name}: {e}")
            return False

    def set_as_default(self, table_name: str, item_id: int) -> None:
        """Sets a specific item as the default for its repository."""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(f"UPDATE {table_name} SET is_default = 0")
            conn.execute(f"UPDATE {table_name} SET is_default = 1 WHERE id = ?", (item_id,))

    def delete_repository_item(self, table_name: str, item_id: int) -> bool:
        """Generic delete for any repository table."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(f"DELETE FROM {table_name} WHERE id = ?", (item_id,))
            return True
        except sqlite3.Error: return False

    def process_submission(self, content: str, model: str, role: str, prompt: str) -> Dict[str, Any]:
        """
        Synthesizes UI inputs, starts the background inference thread, and returns the initial artifact.
        """
        artifact = {
            "metadata": {
                "model": model,
                "timestamp": datetime.now().isoformat(),
                "source": "_theCELL_Idea_Ingestor",
                "version": "1.0.0"
            },
            "instructions": {
                "system_role": role,
                "system_prompt": prompt
            },
            "payload": content.strip()
        }

        # Add User Input to Working Memory
        self.memory.add_entry(role="user", content=content, metadata=artifact['metadata'])

        self.logger.info(f"Artifact generated for model: {model}")
        self.bus.emit(SignalBusMS.SIGNAL_PROCESS_START, artifact)

        # The Pulse: Start Threaded Inference
        thread = threading.Thread(target=self._run_inference_thread, args=(artifact,))
        thread.daemon = True
        thread.start()

        return artifact

    def _run_inference_thread(self, artifact: Dict[str, Any]):
        """
        Background worker that streams tokens from the Engine to the SignalBus.
        """
        try:
            model = artifact['metadata']['model']
            sys_role = artifact['instructions']['system_role']
            sys_prompt = artifact['instructions']['system_prompt']
            user_payload = artifact['payload']

            # Combine role/prompt context
            full_system = f"{sys_role}\n{sys_prompt}".strip()

            response_buffer = []
            
            # Connect to IngestEngine stream
            stream = self.engine.generate_stream(prompt=user_payload, model=model, system=full_system)
            
            for token in stream:
                # Emit token to UI
                self.bus.emit(SignalBusMS.SIGNAL_LOG_APPEND, token)
                response_buffer.append(token)

            final_response = "".join(response_buffer)
            
            # Hydrate artifact with result
            artifact['response'] = final_response
            
            # Add AI Response to Working Memory
            self.memory.add_entry(role="assistant", content=final_response, metadata=artifact['metadata'])

            # Signal Completion (UI triggers HITL buttons)
            self.bus.emit(SignalBusMS.SIGNAL_PROCESS_COMPLETE, artifact)

        except Exception as e:
            error_msg = f"Inference failed: {str(e)}"
            self.logger.error(error_msg)
            self.bus.emit(SignalBusMS.SIGNAL_LOG_APPEND, f"\n[SYSTEM ERROR]: {error_msg}")

    def spawn_child(self, parent_artifact: Dict[str, Any]) -> None:
        """
        Prepares a new Cell by combining the parent's product with the current memory context,
        then emits a signal requesting the UI to launch the new window.
        """
        # 1. Summarize Parent Context (The Hippocampus)
        context_summary = self.memory.get_context(limit=10)
        
        # 2. Create Child DNA
        child_payload = {
            "source_artifact": parent_artifact,
            "inherited_context": context_summary,
            "spawn_timestamp": datetime.now().isoformat()
        }

        self.logger.info("Spawning child cell requested...")
        
        # 3. Signal the System (AppShell) to launch the GUI
        self.bus.emit(SignalBusMS.SIGNAL_SPAWN_REQUESTED, child_payload)















--------------------------------------------------------------------------------
FILE: src\ui.py
--------------------------------------------------------------------------------
import tkinter as tk
from tkinter import ttk, messagebox
import sqlite3

class CellViewerModal(tk.Toplevel):
    """Reusable DB browser for instruction repositories."""
    def __init__(self, parent, colors, table_name, backend, on_select_callback):
        super().__init__(parent)
        self.title(f"Browse: {table_name.replace('_', ' ').title()}")
        self.geometry("600x400")
        self.configure(bg=colors.get('background'))
        self.backend = backend
        self.table_name = table_name
        self.callback = on_select_callback

        # Treeview for Tabular Data
        style = ttk.Style()
        style.configure(
            "Treeview",
            background=colors.get('entry_bg', colors.get('panel_bg')),
            foreground=colors.get('entry_fg', colors.get('foreground')),
            fieldbackground=colors.get('entry_bg', colors.get('panel_bg')),
            borderwidth=0
        )
        style.configure(
            "Treeview.Heading",
            background=colors.get('heading_bg', colors.get('panel_bg')),
            foreground=colors.get('heading_fg', colors.get('foreground'))
        )
        style.map(
            "Treeview",
            background=[('selected', colors.get('select_bg', colors.get('accent')))],
            foreground=[('selected', colors.get('select_fg', '#ffffff'))]
        )
        self.tree = ttk.Treeview(self, columns=("ID", "Name", "Preview", "Default"), show='headings')
        
        for col in ("ID", "Name", "Preview", "Default"): 
            self.tree.heading(col, text=col)
            self.tree.column(col, width=50 if col in ('ID', 'Default') else 150 if col == 'Name' else 250)
        
        self.tree.pack(fill='both', expand=True, padx=10, pady=10)
        self._refresh_data()

        btn_frame = tk.Frame(self, bg=colors.get('background'))
        btn_frame.pack(fill='x', padx=10, pady=5)
        
        tk.Button(btn_frame, text="Load Selection", command=self._on_load).pack(side='left', padx=5)
        tk.Button(btn_frame, text="Set as Default", command=self._on_default).pack(side='left', padx=5)
        tk.Button(btn_frame, text="Delete", bg=colors.get('error', '#f44747'), fg="white", command=self._on_delete).pack(side='right', padx=5)

    def _refresh_data(self):
        self.tree.delete(*self.tree.get_children())
        for item in self.backend.get_repository_items(self.table_name):
            # item = (id, name, content, is_default)
            self.tree.insert("", "end", values=(item[0], item[1], item[2][:100].replace('\n', ' '), "â˜…" if item[3] else ""))

    def _on_load(self):
        selected = self.tree.selection()
        if selected:
            item_values = self.tree.item(selected[0], 'values')
            with sqlite3.connect(self.backend.db_path) as conn:
                if self.table_name == 'personas':
                    # Bonded Template: Returns a tuple for the callback to handle
                    res = conn.execute("SELECT role_text, sys_prompt_text, task_prompt_text FROM personas WHERE id=?", (item_values[0],)).fetchone()
                    if res: self.callback(res) 
                else:
                    # Atomic Fragment
                    res = conn.execute(f"SELECT content FROM {self.table_name} WHERE id=?", (item_values[0],)).fetchone()
                    if res: self.callback(res[0])
            self.destroy()

    def _on_default(self):
        selected = self.tree.selection()
        if selected:
            item_id = self.tree.item(selected[0], 'values')[0]
            self.backend.set_as_default(self.table_name, item_id)
            self._refresh_data()

    def _on_delete(self):
        selected = self.tree.selection()
        if selected:
            item_id = self.tree.item(selected[0], 'values')[0]
            self.backend.delete_repository_item(self.table_name, item_id)
            self._refresh_data()

class CELL_UI:
    def __init__(self, shell, backend):
        self.shell = shell
        self.backend = backend
        self.container = shell.get_main_container()
        self.colors = shell.colors

        # Track singleton modals / key widgets
        self._settings_window = None
        self.model_lbl = None
        self.btn_save_template = None
        self.btn_load_template = None
        self.btn_submit = None

        # Panels (Step 2 stubs)
        self.panel_prompt = None
        self.panel_inference = None
        self.panel_result = None
        self.panel_export = None

        # Two-column layout containers (Step 1 layout)
        self.main_row = None
        self.left_col = None
        self.right_col = None

        # Action bar ref (so it can be themed)
        self.action_frame = None

        # Panel widgets (stubs)
        self.infer_log = None
        self.result_text = None
        self.btn_accept = None
        self.btn_reject = None
        self.btn_exit = None

        # Export Router (inline) widgets
        self.export_router_frame = None
        self.export_dest_var = None
        self.export_dest_cb = None
        self.export_options_frame = None
        self.export_execute_btn = None
        self._export_selected = None
        
        # Restore window state from DB
        saved_geo = self.backend.get_setting('window_geometry')
        if saved_geo: self.shell.root.geometry(saved_geo)
        
        self._setup_main_window()
        self._build_context_menu()
        self._restore_component_state()
        self._register_signals()

            def _register_signals(self):
        """Connects UI to the nervous system."""
        if hasattr(self.backend, 'bus'):
            self.backend.bus.subscribe("log_append", self._on_log_append)
            self.backend.bus.subscribe("process_complete", self._on_process_complete)

            def _on_log_append(self, content):
        """Marshals background thread signal to main UI thread."""
        self.shell.root.after(0, lambda: self.append_log(content))

            def _on_process_complete(self, artifact):
        """Marshals completion signal to main UI thread."""
        text = artifact.get('response', '')
        self.shell.root.after(0, lambda: self.display_result(text))

            def _setup_main_window(self):
        # PANEL 1 (Prompt Setup): left column
        # Panels 2-4 (Inference / HITL / Export): right column
        self.main_row = tk.Frame(self.container, bg=self.colors.get('background'))
        self.main_row.pack(fill='both', expand=True)

        self.left_col = tk.Frame(self.main_row, bg=self.colors.get('background'))
        self.left_col.pack(side='left', fill='both', expand=True)

        self.right_col = tk.Frame(self.main_row, bg=self.colors.get('background'))
        self.right_col.pack(side='right', fill='y', padx=(8, 0))

        # PANEL 1 (Prompt Setup)
        self.panel_prompt = tk.Frame(self.container, bg=self.colors.get('background'))
        self.panel_prompt.pack(in_=self.left_col, fill='both', expand=True)

        # --- Top Label ---
        self.top_label = tk.Label(self.panel_prompt, text="Type in your idea HERE.", 
                 fg=self.colors.get('foreground'), bg=self.colors.get('background'),
                 font=("Segoe UI", 12, "bold"))
        self.top_label.pack(pady=(10, 5))

        # --- Formatting Toolbar ---
        self.toolbar = tk.Frame(self.panel_prompt, bg=self.colors.get('panel_bg'))
        self.toolbar.pack(fill='x', padx=10)
        
        btn_opts = {"bg": self.colors.get('panel_bg'), "fg": self.colors.get('foreground', 'white'), "relief": "flat", "padx": 5}
        self.btn_bold = tk.Button(self.toolbar, text="B", font=("TkDefaultFont", 9, "bold"), **btn_opts, command=self._bold_text)
        self.btn_bold.pack(side='left')
        self.btn_italic = tk.Button(self.toolbar, text="I", font=("TkDefaultFont", 9, "italic"), **btn_opts, command=self._italic_text)
        self.btn_italic.pack(side='left')
        self.btn_list = tk.Button(self.toolbar, text="â€¢ List", **btn_opts, command=self._bullet_list)
        self.btn_list.pack(side='left')
        
        self.btn_settings = tk.Button(self.toolbar, text="âš™", **btn_opts, command=self._open_settings)
        self.btn_settings.pack(side='right')

        # --- Inference Config Section ---
        self.config_frame = tk.LabelFrame(self.panel_prompt, text=" Inference Parameters ", 
                                     fg=self.colors.get('foreground'), bg=self.colors.get('background'),
                                     relief='solid', bd=1, font=("Segoe UI", 9, "bold"))
        self.config_frame.pack(fill='x', padx=10, pady=10)

        # Model Selection
        self.model_lbl = tk.Label(self.config_frame, text="Model:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white'))
        self.model_lbl.grid(row=0, column=0, sticky='w', padx=5)
        self.model_var = tk.StringVar()
        self.model_dropdown = ttk.Combobox(self.config_frame, textvariable=self.model_var)
        self.model_dropdown['values'] = self.backend.get_models()
        self.model_dropdown.grid(row=0, column=1, sticky='ew', padx=5, pady=2)
        
        # Direct Role Input
        self.role_lbl = tk.Label(self.config_frame, text="System Role:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white'))
        self.role_lbl.grid(row=1, column=0, sticky='w', padx=5)
        self.role_inner = tk.Frame(self.config_frame, bg=self.colors.get('background'))
        self.role_inner.grid(row=1, column=1, sticky='ew')
        
        self.role_entry = tk.Entry(
            self.role_inner,
            bg=self.colors.get('entry_bg', '#3c3c3c'),
            fg=self.colors.get('entry_fg', 'white'),
            insertbackground=self.colors.get('entry_fg', 'white')
        )
        self.role_entry.insert(0, self.backend.system_role)
        self.role_entry.pack(side='left', fill='x', expand=True, padx=(5, 2), pady=2)
        
        self.btn_role_save = tk.Button(self.role_inner, text="ðŸ’¾", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')), relief="flat", 
                  command=lambda: self._save_repo_dialog('saved_roles', self.role_entry.get()))
        self.btn_role_save.pack(side='left', padx=2)
        self.btn_role_open = tk.Button(self.role_inner, text="ðŸ“‚", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')), relief="flat", 
                  command=lambda: self._open_viewer('saved_roles', lambda c: self._update_widget(self.role_entry, c)))
        self.btn_role_open.pack(side='left', padx=2)

        # Direct Prompt Input
        self.prompt_lbl = tk.Label(self.config_frame, text="System Prompt:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white'))
        self.prompt_lbl.grid(row=2, column=0, sticky='nw', padx=5)
        self.prompt_inner = tk.Frame(self.config_frame, bg=self.colors.get('background'))
        self.prompt_inner.grid(row=2, column=1, sticky='ew')
        
        self.prompt_text = tk.Text(
            self.prompt_inner,
            height=3,
            bg=self.colors.get('entry_bg', '#3c3c3c'),
            fg=self.colors.get('entry_fg', 'white'),
            insertbackground=self.colors.get('entry_fg', 'white'),
            font=("Segoe UI", 9)
        )
        self.prompt_text.pack(side='left', fill='x', expand=True, padx=(5, 2), pady=2)
        
        self.prompt_btns_frame = tk.Frame(self.prompt_inner, bg=self.colors.get('background'))
        self.prompt_btns_frame.pack(side='left', fill='y')
        self.btn_prompt_save = tk.Button(self.prompt_btns_frame, text="ðŸ’¾", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')), relief="flat", 
                  command=lambda: self._save_repo_dialog('saved_sys_prompts', self.prompt_text.get('1.0', 'end-1c')))
        self.btn_prompt_save.pack(pady=2)
        self.btn_prompt_open = tk.Button(self.prompt_btns_frame, text="ðŸ“‚", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')), relief="flat", 
                  command=lambda: self._open_viewer('saved_sys_prompts', lambda c: self._update_widget(self.prompt_text, c)))
        self.btn_prompt_open.pack(pady=2)

        self.config_frame.columnconfigure(1, weight=1)

        # --- Main Input Box ---
        self.input_box = tk.Text(
            self.panel_prompt,
            undo=True,
            wrap="word",
            bg=self.colors.get('entry_bg', '#252526'),
            fg=self.colors.get('entry_fg', '#d4d4d4'),
            insertbackground=self.colors.get('entry_fg', 'white'),
            selectbackground=self.colors.get('select_bg', '#264f78'),
            font=("Consolas", 11)
        )
        self.input_box.pack(fill='both', expand=True, padx=10, pady=5)
        self.input_box.focus_set()

        # --- Action Bar ---
        self.action_frame = tk.Frame(self.panel_prompt, bg=self.colors.get('background'))
        self.action_frame.pack(fill='x', padx=10, pady=(0, 10))

        self.btn_save_template = tk.Button(
            self.action_frame,
            text="SAVE AS TEMPLATE",
            bg=self.colors.get('panel_bg'),
            fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')),
            font=("Segoe UI", 9),
            command=self._save_full_template
        )
        self.btn_save_template.pack(side='left', fill='x', expand=True, padx=(0, 2))

        self.btn_load_template = tk.Button(
            self.action_frame,
            text="LOAD TEMPLATE",
            bg=self.colors.get('panel_bg'),
            fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')),
            font=("Segoe UI", 9),
            command=lambda: self._open_viewer('personas', None)
        )
        self.btn_load_template.pack(side='left', fill='x', expand=True, padx=(2, 5))

        self.btn_submit = tk.Button(
            self.action_frame,
            text="RUN CELL",
            bg=self.colors.get('accent', '#007acc'),
            fg="white",
            font=("Segoe UI", 10, "bold"),
            command=self._submit
        )
        self.btn_submit.pack(side='left', fill='x', expand=True)

        # ------------------------------------------------------------------
        # PANEL 2 â€” Inference Console
        # ------------------------------------------------------------------
        self.panel_inference = tk.LabelFrame(
            self.container,
            text=" Inference Console ",
            fg=self.colors.get('foreground'),
            bg=self.colors.get('background'),
            relief='solid', bd=1, font=("Segoe UI", 9, "bold")
        )
        self.panel_inference.pack(in_=self.right_col, fill='x', padx=10, pady=(0, 10))

        self.infer_log = tk.Text(
            self.panel_inference,
            height=6,
            wrap="word",
            bg=self.colors.get('entry_bg', '#252526'),
            fg=self.colors.get('entry_fg', '#d4d4d4'),
            insertbackground=self.colors.get('entry_fg', 'white'),
            font=("Consolas", 10)
        )
        self.infer_log.insert('1.0', "[Stub] Inference logs will stream here during the run.\n")
        self.infer_log.configure(state='disabled')
        self.infer_log.pack(fill='x', expand=False, padx=10, pady=8)

        # ------------------------------------------------------------------
        # PANEL 3 â€” Result + HITL
        # ------------------------------------------------------------------
        self.panel_result = tk.LabelFrame(
            self.container,
            text=" Result + HITL ",
            fg=self.colors.get('foreground'),
            bg=self.colors.get('background'),
            relief='solid', bd=1, font=("Segoe UI", 9, "bold")
        )
        self.panel_result.pack(in_=self.right_col, fill='both', expand=True, padx=10, pady=(0, 10))

        self.result_text = tk.Text(
            self.panel_result,
            height=8,
            wrap="word",
            bg=self.colors.get('entry_bg', '#252526'),
            fg=self.colors.get('entry_fg', '#d4d4d4'),
            insertbackground=self.colors.get('entry_fg', 'white'),
            font=("Consolas", 11)
        )
        self.result_text.insert('1.0', "[Stub] Model response will appear here.\n")
        self.result_text.configure(state='disabled')
        self.result_text.pack(fill='both', expand=True, padx=10, pady=(8, 6))

        hitl_bar = tk.Frame(self.panel_result, bg=self.colors.get('background'))
        hitl_bar.pack(fill='x', padx=10, pady=(0, 10))

        self.btn_accept = tk.Button(
            hitl_bar,
            text="ACCEPT",
            bg=self.colors.get('accent', '#007acc'),
            fg="white",
            relief="flat",
            state='disabled',
            command=lambda: None
        )
        self.btn_accept.pack(side='left', padx=(0, 6))

        self.btn_reject = tk.Button(
            hitl_bar,
            text="REJECT & EDIT",
            bg=self.colors.get('panel_bg'),
            fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')),
            relief="flat",
            state='disabled',
            command=lambda: None
        )
        self.btn_reject.pack(side='left', padx=(0, 6))

        self.btn_exit = tk.Button(
            hitl_bar,
            text="EXIT CELL",
            bg=self.colors.get('panel_bg'),
            fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')),
            relief="flat",
            command=self.shell.root.destroy
        )
        self.btn_exit.pack(side='right')

        # PANEL 4 â€” Export / Spawn (inline router)
        self.panel_export = tk.LabelFrame(
            self.container,
            text=" Export / Spawn ",
            fg=self.colors.get('foreground'),
            bg=self.colors.get('background'),
            relief='solid', bd=1, font=("Segoe UI", 9, "bold")
        )
        self.panel_export.pack(in_=self.right_col, fill='x', padx=10, pady=(0, 12))

        self.export_router_frame = tk.Frame(self.panel_export, bg=self.colors.get('background'))
        self.export_router_frame.pack(fill='x', padx=10, pady=10)

        top_row = tk.Frame(self.export_router_frame, bg=self.colors.get('background'))
        top_row.pack(fill='x')

        tk.Label(top_row, text="Destination:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white')).pack(side='left')

        self.export_dest_var = tk.StringVar(value="Spawn")
        self.export_dest_cb = ttk.Combobox(
            top_row, 
            textvariable=self.export_dest_var, 
            state='readonly', 
            values=["Spawn", "File", "Database", "Vector", "Code", "Patch", "Logs"]
        )
        self.export_dest_cb.pack(side='left', padx=8, fill='x', expand=True)

        self.export_execute_btn = tk.Button(
            top_row, text="EXECUTE", bg=self.colors.get('panel_bg'),
            fg=self.colors.get('button_fg', self.colors.get('foreground', 'white')),
            relief="flat", state='disabled', command=self._handle_export
        )
        self.export_execute_btn.pack(side='right')

        self.export_options_frame = tk.Frame(self.export_router_frame, bg=self.colors.get('background'))
        self.export_options_frame.pack(fill='x', pady=(8, 0))

        def _build_export_options(dest: str):
            for w in self.export_options_frame.winfo_children(): w.destroy()
            if dest == "Spawn":
                tk.Button(self.export_options_frame, text="Spawn Child Cell", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')), relief='flat', state='disabled').pack(fill='x', pady=2)
            elif dest == "File":
                for fmt in ("JSON", "Markdown", "Text"):
                    tk.Button(self.export_options_frame, text=f"Save {fmt}", bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')), relief='flat', state='disabled').pack(fill='x', pady=2)

        self.export_dest_cb.bind('<<ComboboxSelected>>', lambda _e: _build_export_options(self.export_dest_var.get()))
        _build_export_options("Spawn")

            def _handle_export(self):
        """Routes the execution command based on the selected destination."""
        dest = self.export_dest_var.get()
        # For now, we only implement the Spawn logic fully
        if dest == "Spawn":
            # Retrieve the last artifact stored in memory (mocking for now since we don't have a direct artifact ref in UI)
            # In a real flow, self.backend would store the last_artifact.
            # For this patch, we assume the backend has a way to get the latest context.
            # This trigger will tell backend to package the current state and spawn.
            
            # We reconstruct a temporary artifact from the UI state if one isn't cached
            current_artifact = {
                "payload": self.result_text.get("1.0", "end-1c"),
                "instructions": {
                    "system_role": self.role_entry.get(),
                    "system_prompt": self.prompt_text.get("1.0", "end-1c")
                },
                "metadata": {"model": self.model_var.get(), "source": "ui_spawn"}
            }
            self.backend.spawn_child(current_artifact)
        else:
            messagebox.showinfo("Not Implemented", f"Export to {dest} is coming soon!", parent=self.shell.root)

            def _apply_markdown_style(self, prefix, suffix=""):
        """Wraps selected text in Markdown markers for AI readability."""
        try:
            start = self.input_box.index("sel.first")
            end = self.input_box.index("sel.second")
            selected_text = self.input_box.get(start, end)
            self.input_box.delete(start, end)
            self.input_box.insert(start, f"{prefix}{selected_text}{suffix or prefix}")
        except tk.TclError:
            pass

    def _bold_text(self):
        self._apply_markdown_style("**")

    def _italic_text(self):
        self._apply_markdown_style("_")

    def _bullet_list(self):
        """Converts selected lines into a Markdown bulleted list."""
        try:
            start = self.input_box.index("sel.first linestart")
            end = self.input_box.index("sel.second lineend")
            lines = self.input_box.get(start, end).splitlines()
            bulleted_lines = [f"* {line.lstrip('* ')}" for line in lines]
            self.input_box.delete(start, end)
            self.input_box.insert(start, "\n".join(bulleted_lines))
        except tk.TclError:
            self.input_box.insert("insert", "* ")

    def _update_widget(self, widget, content):
        if isinstance(widget, tk.Entry):
            widget.delete(0, 'end')
            widget.insert(0, content)
        elif isinstance(widget, tk.Text):
            widget.configure(state='normal')
            widget.delete('1.0', 'end')
            widget.insert('1.0', content)
            widget.configure(state='disabled')

    def append_log(self, message: str):
        """Appends text to the inference console (Thread-Safe via _on_log_append)."""
        if self.infer_log is None: return
        self.infer_log.configure(state='normal')
        self.infer_log.insert('end', message) # Streamed tokens don't force newlines
        self.infer_log.see('end')
        self.infer_log.configure(state='disabled')

    def display_result(self, text: str):
        """Displays the final artifact and enables HITL buttons."""
        self.result_text.configure(state='normal')
        self.result_text.delete('1.0', 'end')
        self.result_text.insert('1.0', text)
        self.result_text.configure(state='disabled')
        
        if self.btn_accept:
            self.btn_accept.configure(state='normal')
        if self.btn_reject:
            self.btn_reject.configure(state='normal')
        if self.export_execute_btn:
            self.export_execute_btn.configure(state='normal')

    def _save_repo_dialog(self, table, content):
        """Modular save dialog for individual repositories."""
        dialog = tk.Toplevel(self.shell.root)
        dialog.title(f"Save to {table.split('_')[-1].title()}")
        dialog.geometry("300x150")
        dialog.configure(bg=self.colors.get('background'))

        dialog.transient(self.shell.root)
        dialog.grab_set()

        tk.Label(dialog, text="Name Selection:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white')).pack(pady=5)
        name_entry = tk.Entry(dialog)
        name_entry.pack(padx=10, fill='x')
        name_entry.focus_set()

        default_var = tk.BooleanVar()
        tk.Checkbutton(
            dialog,
            text="Set as Default",
            variable=default_var,
            bg=self.colors.get('background'),
            fg=self.colors.get('foreground', 'white'),
            selectcolor=self.colors.get('panel_bg', '#444')
        ).pack()

        def confirm():
            name = name_entry.get().strip()
            if not name:
                messagebox.showwarning("Missing name", "Please enter a name.", parent=dialog)
                return

            try:
                if table == 'personas':
                    success = self.backend.save_persona(name, content[0], content[1], content[2], default_var.get())
                else:
                    success = self.backend.save_repository_item(table, name, content, default_var.get())
            except Exception as e:
                messagebox.showerror("Save failed", f"Unexpected error: {e}", parent=dialog)
                return

            if success:
                messagebox.showinfo("Success", "Saved successfully!", parent=dialog)
                dialog.destroy()
            else:
                messagebox.showerror("Save failed", "Could not save. Check the app log for the SQLite error.", parent=dialog)

        tk.Button(dialog, text="Save", command=confirm).pack(pady=10)
        dialog.bind("<Return>", lambda _e: confirm())
        dialog.bind("<Escape>", lambda _e: dialog.destroy())

    def _open_viewer(self, table, callback):
        """Opens the Universal Cell Viewer Modal with context-aware callbacks."""
        if table == 'personas':
            def persona_callback(data):
                self._update_widget(self.role_entry, data[0])
                self._update_widget(self.prompt_text, data[1])
                self._update_widget(self.input_box, data[2])
            callback = persona_callback
            
        CellViewerModal(self.shell.root, self.colors, table, self.backend, callback)

    def _open_settings(self):
        # Enforce singleton Settings modal
        if self._settings_window is not None:
            try:
                if self._settings_window.winfo_exists():
                    self._settings_window.deiconify()
                    self._settings_window.lift()
                    self._settings_window.focus_force()
                    return
            except Exception:
                self._settings_window = None

        settings = tk.Toplevel(self.shell.root)
        self._settings_window = settings
        settings.title("Settings")
        settings.geometry("350x250")
        settings.configure(bg=self.colors.get('background'))

        def _close_settings():
            self._settings_window = None
            try:
                settings.destroy()
            except Exception:
                pass

        settings.protocol("WM_DELETE_WINDOW", _close_settings)

        # Load persisted theme (default Dark)
        current_theme = (self.backend.get_setting('theme_preference') or 'Dark').strip().title()
        if current_theme not in ('Dark', 'Light'):
            current_theme = 'Dark'

        tk.Label(settings, text="Theme:", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white')).pack(pady=(10,0))
        theme_var = tk.StringVar(value=current_theme)
        theme_cb = ttk.Combobox(settings, textvariable=theme_var, values=["Dark", "Light"], state='readonly')
        theme_cb.pack()

        tk.Label(settings, text="Window Size (WxH):", bg=self.colors.get('background'), fg=self.colors.get('foreground', 'white')).pack(pady=(10,0))
        size_entry = tk.Entry(settings)
        size_entry.insert(0, self.shell.root.geometry().split('+')[0])
        size_entry.pack()

        btn_frame = tk.Frame(settings, bg=self.colors.get('background'))
        btn_frame.pack(pady=20)

        def save():
            new_geo = size_entry.get()
            self.shell.root.geometry(new_geo)
            self.backend.save_setting('window_geometry', new_geo)

            selected_theme = (theme_var.get() or 'Dark').strip().title()
            if selected_theme not in ('Dark', 'Light'):
                selected_theme = 'Dark'

            # Persist + apply via shell microservice
            self.backend.save_setting('theme_preference', selected_theme)
            if hasattr(self.shell, 'set_theme'):
                self.shell.set_theme(selected_theme)
                # UI reads from shell.colors
                self.colors = self.shell.colors
                self.refresh_theme()

            _close_settings()

        tk.Button(btn_frame, text="Accept", command=save, width=10).pack(side='left', padx=5)
        tk.Button(btn_frame, text="Cancel", command=_close_settings, width=10).pack(side='left', padx=5)

    def _build_context_menu(self):
        self.menu = tk.Menu(self.input_box, tearoff=0)
        self.menu.add_command(label="Cut", command=lambda: self.input_box.event_generate("<<Cut>>"))
        self.menu.add_command(label="Copy", command=lambda: self.input_box.event_generate("<<Copy>>"))
        self.menu.add_command(label="Paste", command=lambda: self.input_box.event_generate("<<Paste>>"))
        self.input_box.bind("<Button-3>", lambda e: self.menu.post(e.x_root, e.y_root))

    def _save_full_template(self):
        """Captures the entire state of the config bar as a bonded Persona."""
        role = self.role_entry.get()
        sys_p = self.prompt_text.get("1.0", "end-1c")
        task_p = self.input_box.get("1.0", "end-1c")
        self._save_repo_dialog('personas', (role, sys_p, task_p))

    def _restore_component_state(self):
        """Restores components using Defaults first, then Session state."""
        default_role = self.backend.get_default_item('saved_roles')
        last_role = self.backend.get_setting('last_system_role')
        self._update_widget(self.role_entry, default_role or last_role or "")

        default_sys = self.backend.get_default_item('saved_sys_prompts')
        last_sys = self.backend.get_setting('last_system_prompt')
        self._update_widget(self.prompt_text, default_sys or last_sys or "")

        last_model = self.backend.get_setting('last_model')
        if last_model in self.model_dropdown['values']:
            self.model_var.set(last_model)

    def _submit(self):
        """Process submission, persist parameters, and update UI consoles."""
        content = self.input_box.get("1.0", "end-1c")
        model = self.model_var.get()
        role = self.role_entry.get()
        prompt = self.prompt_text.get("1.0", "end-1c")
        
        # Persist settings via backend
        self.backend.save_setting('last_model', model)
        self.backend.save_setting('last_system_role', role)
        self.backend.save_setting('last_system_prompt', prompt)

        # Prepare Inference Log
        self.infer_log.configure(state='normal')
        self.infer_log.delete('1.0', 'end')
        self.infer_log.insert('1.0', f"[System] Initiating run with {model}...\n")
        self.infer_log.configure(state='disabled')

        # Prepare Result Box
        self.result_text.configure(state='normal')
        self.result_text.delete('1.0', 'end')
        self.result_text.insert('1.0', "Waiting for model response...\n")
        self.result_text.configure(state='disabled')
        
        # Trigger backend processing
        self.backend.process_submission(content, model, role, prompt)

    def refresh_theme(self):
        """Re-applies the current shell colors to all primary UI widgets."""
        self.colors = self.shell.colors

        # Update Containers
        self.container.configure(bg=self.colors.get('background'))

        if self.main_row is not None:
            self.main_row.configure(bg=self.colors.get('background'))
        if self.left_col is not None:
            self.left_col.configure(bg=self.colors.get('background'))
        if self.right_col is not None:
            self.right_col.configure(bg=self.colors.get('background'))

        if self.panel_prompt is not None:
            self.panel_prompt.configure(bg=self.colors.get('background'))

        if self.action_frame is not None:
            self.action_frame.configure(bg=self.colors.get('background'))
        self.toolbar.configure(bg=self.colors.get('panel_bg'))
        self.config_frame.configure(fg=self.colors.get('foreground'), bg=self.colors.get('background'))
        self.role_inner.configure(bg=self.colors.get('background'))
        self.prompt_inner.configure(bg=self.colors.get('background'))
        self.prompt_btns_frame.configure(bg=self.colors.get('background'))

        if self.action_frame is not None:
            self.action_frame.configure(bg=self.colors.get('background'))

        # Right-column panels
        if self.panel_inference is not None:
            self.panel_inference.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))
        if self.panel_result is not None:
            self.panel_result.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))
        if self.panel_export is not None:
            self.panel_export.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))
        if self.export_router_frame is not None:
            self.export_router_frame.configure(bg=self.colors.get('background'))
        if self.export_options_frame is not None:
            self.export_options_frame.configure(bg=self.colors.get('background'))

        # Update Labels
        self.top_label.configure(fg=self.colors.get('foreground'), bg=self.colors.get('background'))
        if self.model_lbl is not None:
            self.model_lbl.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))
        self.role_lbl.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))
        self.prompt_lbl.configure(bg=self.colors.get('background'), fg=self.colors.get('foreground'))

        # Update Entries and Text widgets
        self.role_entry.configure(bg=self.colors.get('entry_bg'), fg=self.colors.get('entry_fg'), insertbackground=self.colors.get('entry_fg'))
        self.prompt_text.configure(bg=self.colors.get('entry_bg'), fg=self.colors.get('entry_fg'), insertbackground=self.colors.get('entry_fg'))
        self.input_box.configure(bg=self.colors.get('entry_bg'), fg=self.colors.get('entry_fg'), insertbackground=self.colors.get('entry_fg'), selectbackground=self.colors.get('select_bg'))

        # Panel 2/3 stubs
        if self.infer_log is not None:
            self.infer_log.configure(bg=self.colors.get('entry_bg'), fg=self.colors.get('entry_fg'), insertbackground=self.colors.get('entry_fg'))
        if self.result_text is not None:
            self.result_text.configure(bg=self.colors.get('entry_bg'), fg=self.colors.get('entry_fg'), insertbackground=self.colors.get('entry_fg'), selectbackground=self.colors.get('select_bg'))

        # Update Buttons (toolbar + small repo buttons)
        btn_list = [self.btn_bold, self.btn_italic, self.btn_list, self.btn_settings, self.btn_role_save, self.btn_role_open, self.btn_prompt_save, self.btn_prompt_open]
        for btn in btn_list:
            btn.configure(bg=self.colors.get('panel_bg'), fg=self.colors.get('foreground'))

        # Update Action Bar buttons
        if self.btn_save_template is not None:
            self.btn_save_template.configure(
                bg=self.colors.get('panel_bg'),
                fg=self.colors.get('button_fg', self.colors.get('foreground'))
            )
        if self.btn_load_template is not None:
            self.btn_load_template.configure(
                bg=self.colors.get('panel_bg'),
                fg=self.colors.get('button_fg', self.colors.get('foreground'))
            )
        if self.btn_submit is not None:
            self.btn_submit.configure(
                bg=self.colors.get('accent', '#007acc'),
                fg='white'
            )

        # HITL stub buttons
        if self.btn_accept is not None:
            self.btn_accept.configure(bg=self.colors.get('accent', '#007acc'), fg='white')
        if self.btn_reject is not None:
            self.btn_reject.configure(bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')))
        if self.btn_exit is not None:
            self.btn_exit.configure(bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')))

        # Export stub buttons
        if self.btn_spawn_child is not None:
            self.btn_spawn_child.configure(bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')))
        if self.btn_export_json is not None:
            self.btn_export_json.configure(bg=self.colors.get('panel_bg'), fg=self.colors.get('button_fg', self.colors.get('foreground')))












--------------------------------------------------------------------------------
FILE: src\__init__.py
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: src\microservices\base_service.py
--------------------------------------------------------------------------------
from .base_service import BaseService
import logging
from typing import Dict, Any

class BaseService:
    """
    Standard parent class for all microservices. 
    Provides consistent logging and identity management.
    """
    def __init__(self, name: str):
        self._service_info = {
            "name": name, 
            "id": name.lower().replace(" ", "_")
        }
        
        # Setup standard logging
        logging.basicConfig(
            level=logging.INFO, 
            format='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%H:%M:%S'
        )
        self.logger = logging.getLogger(name)

    def log_info(self, message: str):
        self.logger.info(message)

    def log_error(self, message: str):
        self.logger.error(message)

    def log_warning(self, message: str):
        self.logger.warning(message)

--------------------------------------------------------------------------------
FILE: src\microservices\base_service.py.bak
--------------------------------------------------------------------------------
import logging
from typing import Dict, Any

class BaseService:
    """
    Standard parent class for all microservices. 
    Provides consistent logging and identity management.
    """
    def __init__(self, name: str):
        self._service_info = {
            "name": name, 
            "id": name.lower().replace(" ", "_")
        }
        
        # Setup standard logging
        logging.basicConfig(
            level=logging.INFO, 
            format='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%H:%M:%S'
        )
        self.logger = logging.getLogger(name)

    def log_info(self, message: str):
        self.logger.info(message)

    def log_error(self, message: str):
        self.logger.error(message)

    def log_warning(self, message: str):
        self.logger.warning(message)

--------------------------------------------------------------------------------
FILE: src\microservices\document_utils.py
--------------------------------------------------------------------------------
from ._ContentExtractorMS import ContentExtractorMS

# Singleton instance to reuse the extractor logic
_extractor = ContentExtractorMS()

def extract_text_from_pdf(blob: bytes) -> str:
    """Proxy to ContentExtractorMS PDF logic."""
    return _extractor._extract_pdf(blob)

def extract_text_from_html(html_text: str) -> str:
    """Proxy to ContentExtractorMS HTML logic."""
    return _extractor._extract_html(html_text)

--------------------------------------------------------------------------------
FILE: src\microservices\ErrorNotifierMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ErrorNotifierMS
ROLE: Reactive Error Dispatcher (Task 3)
"""
import logging
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(
    name='ErrorNotifier', 
    version='1.0.0', 
    description='Reactive service that normalizes and dispatches engine errors to UI/Logs.', 
    tags=['utility', 'error-handling'], 
    capabilities=['ui-notification'], 
    internal_dependencies=['microservice_std_lib']
)
class ErrorNotifierMS:
    def __init__(self, bus):
        self.bus = bus
        self.logger = logging.getLogger("ErrorNotifier")

    def on_engine_error(self, payload: Dict[str, Any]):
        """
        Subscribed handler for engine failures.
        Safely extracts error details and emits normalized UI/Logging events.
        """
        # 1. Safely extract message with fallback
        msg = payload.get('message') or payload.get('msg') or "Unknown Engine Error"
        file_ctx = f" in {payload['file']}" if 'file' in payload else ""
        hunk_ctx = f" (Hunk: {payload['hunk_name']})" if 'hunk_name' in payload else ""
        
        full_report = f"âŒ ENGINE ERROR: {msg}{file_ctx}{hunk_ctx}"

        # 2. Dispatch to the UI via the Signal Bus
        # This keeps the notifier decoupled from the UI implementation details
        self.bus.emit("notify_error", {"message": full_report, "level": "ERROR"})
        
        # 3. Log internally for standard output
        self.logger.error(full_report)

    def on_commit_failed(self, payload: Dict[str, Any]):
        """Handles failures during file write operations."""
        file_path = payload.get('file', 'unknown file')
        error = payload.get('error', 'unknown write error')
        
        report = f"ðŸ’¾ COMMIT FAILED: Could not update {file_path}. Error: {error}"
        self.bus.emit("notify_error", {"message": report, "level": "CRITICAL"})

--------------------------------------------------------------------------------
FILE: src\microservices\microservice_std_lib.py
--------------------------------------------------------------------------------
"""
LIBRARY: Microservice Standard Lib
VERSION: 2.1.0
ROLE: Provides decorators for tagging Python classes as AI-discoverable services.

Change (2.1.0):
- Split dependencies into:
    internal_dependencies: local modules / microservices to vendor with the app
    external_dependencies: pip-installable packages (requirements.txt)
- Keep legacy "dependencies" as an alias for external_dependencies for backward compatibility.
- Accept unknown keyword args in @service_metadata(...) to prevent older/newer services from crashing
  (e.g. when a runner passes additional fields).
"""

import functools
import inspect
from typing import Dict, List, Any, Optional, Type

# ==============================================================================
# DECORATORS (The "Writer" Tools)
# ==============================================================================

def service_metadata(
    name: str,
    version: str,
    description: str,
    tags: List[str],
    capabilities: Optional[List[str]] = None,

    # Legacy field (kept for backward compatibility):
    # Historically this mixed stdlib + pip deps. Going forward, treat this as *external* deps.
    dependencies: Optional[List[str]] = None,

    # New fields (preferred):
    internal_dependencies: Optional[List[str]] = None,
    external_dependencies: Optional[List[str]] = None,

    # Side effects / operational hints
    side_effects: Optional[List[str]] = None,

    # Forward-compat: ignore unknown keyword args instead of crashing older/newer services
    **_ignored_kwargs: Any,
):
    """
    Class Decorator.
    Labels a Microservice class with high-level metadata for the Catalog.

    Dependency semantics:
      - internal_dependencies: local modules and/or other microservice modules that must be shipped with an app
      - external_dependencies: third-party pip packages (requirements.txt)
      - dependencies (legacy): treated as external_dependencies when external_dependencies is not provided
    """
    # Prefer explicit new key, otherwise fall back to legacy dependencies
    ext = external_dependencies if external_dependencies is not None else (dependencies or [])
    intl = internal_dependencies or []

    def decorator(cls):
        cls._is_microservice = True
        cls._service_info = {
            "name": name,
            "version": version,
            "description": description,
            "tags": tags,
            "capabilities": capabilities or [],

            # New keys
            "internal_dependencies": intl,
            "external_dependencies": ext,

            # Legacy alias (keep existing tooling working)
            "dependencies": ext,

            "side_effects": side_effects or []
        }
        return cls
    return decorator


def service_endpoint(
    inputs: Dict[str, str],
    outputs: Dict[str, str],
    description: str,
    tags: Optional[List[str]] = None,
    side_effects: Optional[List[str]] = None,
    mode: str = "sync",
):
    """
    Method Decorator.
    Defines the 'Socket' that the AI Architect can plug into.

    :param inputs: Dict of {arg_name: type_string} (e.g. {"query": "str"})
    :param outputs: Dict of {return_name: type_string}
    :param description: What the endpoint does
    :param tags: List of categories (e.g. ["read", "write"])
    :param side_effects: List of side effects (e.g. ["filesystem:write", "db:write"])
    :param mode: "sync" or "async" (informational unless your runtime uses it)
    """

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            return func(*args, **kwargs)

        # Attach metadata to the function object itself
        wrapper._is_endpoint = True
        wrapper._endpoint_info = {
            "name": func.__name__,
            "inputs": inputs,
            "outputs": outputs,
            "description": description,
            "tags": tags or [],
            "side_effects": side_effects or [],
            "mode": mode
        }
        return wrapper
    return decorator


# ==============================================================================
# INTROSPECTION (The "Reader" Tools)
# ==============================================================================

def extract_service_schema(service_cls: Type) -> Dict[str, Any]:
    """
    Scans a decorated Service Class and returns a JSON-serializable schema
    of its metadata and all its exposed endpoints.

    This is what the AI Agent uses to 'read' the manual.
    """
    if not getattr(service_cls, "_is_microservice", False):
        raise ValueError(f"Class {service_cls.__name__} is not decorated with @service_metadata")

    schema = {
        "meta": getattr(service_cls, "_service_info", {}),
        "endpoints": []
    }

    # Inspect all methods of the class
    for _, method in inspect.getmembers(service_cls, predicate=inspect.isfunction):
        endpoint_info = getattr(method, "_endpoint_info", None)
        if endpoint_info:
            schema["endpoints"].append(endpoint_info)

    return schema

--------------------------------------------------------------------------------
FILE: src\microservices\_CodeFormatterMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeFormatterMS
ENTRY_POINT: _CodeFormatterMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import re
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('CodeFormatter')

class WhitespaceEngine:
    """
    Parses code into a granular map of (Indent + Content + Trailing).
    Can Normalize structure and generate 'Hunk' patches.
    """

    def __init__(self):
        self.raw_lines = []
        self.nodes = []
        self.normalized_text = ''
        self.patch_data = {'hunks': []}

    def load_source(self, text):
        self.raw_lines = text.splitlines()
        self.nodes = []
        indent_stack = [0]
        last_line_was_block_starter = False
        for i, line in enumerate(self.raw_lines):
            match = re.match('^([ \\t]*)(.*?)([ \\t]*)$', line)
            if not match:
                self.nodes.append({'id': i, 'indent': '', 'content': line, 'depth': 0, 'is_empty': True})
                continue
            indent, content, trailing = match.groups()
            is_empty = len(content) == 0
            current_width = 0
            for char in indent:
                current_width += 4 if char == '\t' else 1
            if is_empty:
                depth = len(indent_stack) - 1
            else:
                if current_width > indent_stack[-1]:
                    if last_line_was_block_starter:
                        indent_stack.append(current_width)
                    else:
                        pass
                while len(indent_stack) > 1 and current_width < indent_stack[-1]:
                    indent_stack.pop()
                depth = len(indent_stack) - 1
                clean_content = content.split('#')[0].strip()
                last_line_was_block_starter = clean_content.endswith(':')
            self.nodes.append({'id': i, 'raw_indent': indent, 'depth': depth, 'content': content, 'trailing': trailing, 'is_empty': is_empty})

    def normalize(self, use_tabs=False, space_count=4):
        """Reconstructs the code with strict indentation rules."""
        char = '\t' if use_tabs else ' ' * space_count
        clean_lines = []
        for node in self.nodes:
            if node['is_empty']:
                clean_lines.append('')
            else:
                new_indent = char * node['depth']
                clean_lines.append(f"{new_indent}{node['content']}")
        self.normalized_text = '\n'.join(clean_lines)
        return self.normalized_text

    def generate_patch(self):
        """Compares Raw vs Normalized and generates JSON Schema Hunks."""
        clean_lines = self.normalized_text.splitlines()
        if not clean_lines:
            return {'hunks': []}
        hunks = []
        current_hunk = None
        for i, (raw, clean) in enumerate(zip(self.raw_lines, clean_lines)):
            if raw != clean:
                if current_hunk is None:
                    current_hunk = {'start_line': i, 'raw_block': [raw], 'clean_block': [clean]}
                elif i == current_hunk['start_line'] + len(current_hunk['raw_block']):
                    current_hunk['raw_block'].append(raw)
                    current_hunk['clean_block'].append(clean)
                else:
                    self._finalize_hunk(hunks, current_hunk)
                    current_hunk = {'start_line': i, 'raw_block': [raw], 'clean_block': [clean]}
            elif current_hunk:
                self._finalize_hunk(hunks, current_hunk)
                current_hunk = None
        if current_hunk:
            self._finalize_hunk(hunks, current_hunk)
        self.patch_data = {'hunks': hunks}
        return self.patch_data

    def _finalize_hunk(self, hunks_list, hunk_data):
        search_txt = '\n'.join(hunk_data['raw_block'])
        replace_txt = '\n'.join(hunk_data['clean_block'])
        schema_hunk = {'description': f"Normalize indentation (Lines {hunk_data['start_line']}-{hunk_data['start_line'] + len(hunk_data['raw_block'])})", 'search_block': search_txt, 'replace_block': replace_txt}
        hunks_list.append(schema_hunk)

@service_metadata(name='CodeFormatter', version='1.0.0', description='The Architect: Intelligent whitespace normalization and structural repair engine.', tags=['formatting', 'code', 'utility'], capabilities=['compute', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class CodeFormatterMS:
    """
    The Architect.
    Uses the WhitespaceEngine to enforce strict indentation rules, 
    fixing 'staircase' formatting and mixed tabs/spaces.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'use_tabs': 'bool', 'spaces': 'int'}, outputs={'normalized': 'str', 'patch': 'Dict'}, description='Takes raw code and returns the normalized version plus a JSON patch of changes.', tags=['formatting', 'compute'], side_effects=[])
    def normalize_code(self, content: str, use_tabs: bool=False, spaces: int=4) -> Dict[str, Any]:
        """
        Pure logic endpoint: Takes string, returns string + patch.
        Does not touch the filesystem.
        """
        engine = WhitespaceEngine()
        engine.load_source(content)
        normalized = engine.normalize(use_tabs=use_tabs, space_count=spaces)
        patch = engine.generate_patch()
        return {'normalized': normalized, 'patch': patch}

    @service_endpoint(inputs={'file_path': 'str', 'use_tabs': 'bool', 'spaces': 'int'}, outputs={'status': 'str', 'changes': 'int'}, description='Reads a file, normalizes it, and overwrites it if changes are needed.', tags=['formatting', 'filesystem'], side_effects=['filesystem:read', 'filesystem:write'])
    def format_file(self, file_path: str, use_tabs: bool=False, spaces: int=4) -> Dict[str, Any]:
        """
        Filesystem endpoint: In-place repair of a file.
        """
        path = Path(file_path).resolve()
        if not path.exists():
            return {'status': 'error', 'message': 'File not found'}
        try:
            content = path.read_text(encoding='utf-8')
            engine = WhitespaceEngine()
            engine.load_source(content)
            normalized = engine.normalize(use_tabs=use_tabs, space_count=spaces)
            patch = engine.generate_patch()
            changes = len(patch['hunks'])
            if changes > 0:
                path.write_text(normalized, encoding='utf-8')
                logger.info(f'Formatted {path.name}: {changes} hunks applied.')
                return {'status': 'modified', 'changes': changes}
            else:
                return {'status': 'clean', 'changes': 0}
        except Exception as e:
            logger.error(f'Formatting failed for {path}: {e}')
            return {'status': 'error', 'message': str(e)}
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    svc = CodeFormatterMS()
    print('Service ready:', svc)
    broken_code = '\ndef hello():\n  print("Indented with 2 spaces")\n      print("Suddenly 6 spaces!")\n    '
    print('\n--- Processing Broken Code ---')
    result = svc.normalize_code(broken_code, spaces=4)
    print(f"Hunks Detected: {len(result['patch']['hunks'])}")
    print('\n--- Normalized Output ---')
    print(result['normalized'])

--------------------------------------------------------------------------------
FILE: src\microservices\_CognitiveMemoryMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CognitiveMemoryMS
ENTRY_POINT: _CognitiveMemoryMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: pydantic
"""
import importlib.util
import sys
REQUIRED = ['pydantic']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print(f"MISSING DEPENDENCIES: {' '.join(MISSING)}")
    print('Please run: pip install pydantic')
import datetime
import json
import logging
import uuid
import os
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional
from pydantic import BaseModel, Field
from .microservice_std_lib import service_metadata, service_endpoint
from .base_service import BaseService
DEFAULT_MEMORY_FILE = Path('working_memory.jsonl')
FLUSH_THRESHOLD = 5
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('CognitiveMem')

class MemoryEntry(BaseModel):
    """Atomic unit of memory."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime.datetime = Field(default_factory=datetime.datetime.utcnow)
    role: str
    content: str
    metadata: Dict[str, Any] = Field(default_factory=dict)

@service_metadata(name='CognitiveMemory', version='1.0.0', description='Manages Short-Term (Working) Memory and orchestrates flushing to Long-Term Memory.', tags=['memory', 'history', 'context'], capabilities=['filesystem:read', 'filesystem:write'], side_effects=['filesystem:write'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['pydantic'])
class CognitiveMemoryMS(BaseService):
    """
    The Hippocampus: Manages Short-Term (Working) Memory and orchestrates 
    flushing to Long-Term Memory (Vector Store).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('CognitiveMemory')
        self.config = config or {}
        self.file_path = Path(self.config.get('persistence_path', DEFAULT_MEMORY_FILE))
        self.summarizer = self.config.get('summarizer_func')
        self.ingestor = self.config.get('long_term_ingest_func')
        self.working_memory: List[MemoryEntry] = []
        self._load_working_memory()

    @service_endpoint(inputs={'role': 'str', 'content': 'str', 'metadata': 'Dict'}, outputs={'entry': 'MemoryEntry'}, description='Adds an item to working memory and persists it.', tags=['memory', 'write'], side_effects=['filesystem:write'])
    def add_entry(self, role: str, content: str, metadata: Dict=None) -> MemoryEntry:
        """Adds an item to working memory and persists it."""
        entry = MemoryEntry(role=role, content=content, metadata=metadata or {})
        self.working_memory.append(entry)
        self._append_to_file(entry)
        log.info(f'Added memory: [{role}] {content[:30]}...')
        return entry

    @service_endpoint(inputs={'limit': 'int'}, outputs={'context': 'str'}, description='Returns the most recent conversation history formatted for an LLM.', tags=['memory', 'read', 'llm'], side_effects=['filesystem:read'])
    def get_context(self, limit: int=10) -> str:
        """
        Returns the most recent conversation history formatted for an LLM.
        """
        recent = self.working_memory[-limit:]
        return '\n'.join([f'{e.role.upper()}: {e.content}' for e in recent])

    def get_full_history(self) -> List[Dict]:
        """Returns the raw list of memory objects."""
        return [e.dict() for e in self.working_memory]

    @service_endpoint(inputs={}, outputs={}, description='Signals that a turn is complete; checks if memory flush is needed.', tags=['memory', 'maintenance'], side_effects=['filesystem:write'])
    def commit_turn(self):
        """
        Signal that a "Turn" (User + AI response) is complete.
        Checks if memory is full and triggers a flush if needed.
        """
        if len(self.working_memory) >= FLUSH_THRESHOLD:
            self._flush_to_long_term()

    def _flush_to_long_term(self):
        """
        Compresses working memory into a summary and moves it to Long-Term storage.
        """
        if not self.summarizer or not self.ingestor:
            log.warning('Flush triggered but Summarizer/Ingestor not configured. Skipping.')
            return
        log.info('ðŸŒ€ Flushing Working Memory to Long-Term Storage...')
        full_text = '\n'.join([f'{e.role}: {e.content}' for e in self.working_memory])
        try:
            summary = self.summarizer(full_text)
            log.info(f'Summary generated: {summary[:50]}...')
        except Exception as e:
            log.error(f'Summarization failed: {e}')
            return
        try:
            meta = {'source': 'cognitive_memory_flush', 'date': datetime.datetime.utcnow().isoformat(), 'original_entry_count': len(self.working_memory)}
            self.ingestor(summary, meta)
            log.info('âœ… Saved to Long-Term Memory.')
        except Exception as e:
            log.error(f'Ingestion failed: {e}')
            return
        self.working_memory.clear()
        self._rotate_log_file()

    def _load_working_memory(self):
        """Rehydrates memory from the JSONL file."""
        if not self.file_path.exists():
            return
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        self.working_memory.append(MemoryEntry.parse_raw(line))
            log.info(f'Loaded {len(self.working_memory)} items from {self.file_path}')
        except Exception as e:
            log.error(f'Corrupt memory file: {e}')

    def _append_to_file(self, entry: MemoryEntry):
        """Appends a single entry to the JSONL log."""
        with open(self.file_path, 'a', encoding='utf-8') as f:
            f.write(entry.json() + '\n')

    def _rotate_log_file(self):
        """Renames the current log to an archive timestamp."""
        if self.file_path.exists():
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            archive_name = self.file_path.with_name(f'memory_archive_{timestamp}.jsonl')
            self.file_path.rename(archive_name)
            log.info(f'Rotated memory log to {archive_name}')
if __name__ == '__main__':

    def mock_summarizer(text):
        return f'SUMMARY OF {len(text)} CHARS: The user and AI discussed AI architecture.'

    def mock_ingest(text, metadata):
        print(f"\n[VectorDB] Indexing: '{text}'\n[VectorDB] Meta: {metadata}")
    print('--- Initializing Cognitive Memory ---')
    mem = CognitiveMemoryMS({'summarizer_func': mock_summarizer, 'long_term_ingest_func': mock_ingest})
    print(f'Service ready: {mem}')
    print('\n--- Simulating Conversation ---')
    mem.add_entry('user', 'Hello, who are you?')
    mem.add_entry('assistant', 'I am a Cognitive Agent.')
    mem.add_entry('user', 'What is your memory capacity?')
    mem.add_entry('assistant', 'I have a tiered memory system.')
    mem.add_entry('user', 'That sounds complex.')
    print(f'\nCurrent Context:\n{mem.get_context()}')
    print('\n--- Triggering Memory Flush ---')
    mem.commit_turn()
    print(f'\nWorking Memory after flush: {len(mem.working_memory)} items')
    if Path('working_memory.jsonl').exists():
        os.remove('working_memory.jsonl')
    for p in Path('.').glob('memory_archive_*.jsonl'):
        os.remove(p)

--------------------------------------------------------------------------------
FILE: src\microservices\_ConfigStoreMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ConfigStoreMS
ROLE: App Settings Persistence (Task 4.2)
"""
import json
import os
import logging
from typing import Dict, Any, Optional

class ConfigStoreMS:
    def __init__(self, filename="app_config.json"):
        self.filename = filename
        self.logger = logging.getLogger("ConfigStore")
        self.data = self._load_from_disk()

    def _load_from_disk(self) -> Dict[str, Any]:
        """Loads the JSON config or returns defaults if missing/corrupt."""
        if not os.path.exists(self.filename):
            return {}
        try:
            with open(self.filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"Failed to load config: {e}")
            return {}

    def get(self, key: str, default: Any = None) -> Any:
        return self.data.get(key, default)

    def set(self, key: str, value: Any):
        """Updates internal data and triggers an atomic save."""
        self.data[key] = value
        self.save()

    def save(self):
        """Atomic write: Save to temp, then rename to original."""
        temp_file = f"{self.filename}.tmp"
        try:
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, indent=4)
            os.replace(temp_file, self.filename)
        except Exception as e:
            self.logger.error(f"Atomic save failed: {e}")
            if os.path.exists(temp_file):
                os.remove(temp_file)

--------------------------------------------------------------------------------
FILE: src\microservices\_DiffEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _DiffEngineMS
ENTRY_POINT: _DiffEngineMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import sqlite3
import difflib
import datetime
import uuid
import logging
from pathlib import Path
from typing import Optional, Dict, List, Tuple, Any
from microservice_std_lib import service_metadata, service_endpoint
DB_PATH = Path(__file__).parent / 'diff_engine.db'
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('DiffEngine')

@service_metadata(name='DiffEngineMS', version='1.0.0', description='Implements hybrid versioning (Head + Diff History) for file content.', tags=['version-control', 'diff', 'db'], capabilities=['db:sqlite', 'filesystem:write'], side_effects=['db:read', 'db:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class DiffEngineMS:
    """
    The Timekeeper: Implements a 'Hybrid' versioning architecture.
    1. HEAD: Stores full current content for fast read access (UI/RAG).
    2. HISTORY: Stores diff deltas using difflib for audit trails.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.db_path = Path(self.config.get('db_path', DB_PATH))
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            conn.execute('\n                CREATE TABLE IF NOT EXISTS files (\n                    id TEXT PRIMARY KEY,\n                    path TEXT UNIQUE NOT NULL,\n                    content TEXT,\n                    last_updated TIMESTAMP\n                )\n            ')
            conn.execute("\n                CREATE TABLE IF NOT EXISTS diff_log (\n                    id TEXT PRIMARY KEY,\n                    file_id TEXT NOT NULL,\n                    timestamp TIMESTAMP,\n                    change_type TEXT,  -- 'CREATE', 'EDIT', 'DELETE'\n                    diff_blob TEXT,    -- The text output of difflib\n                    author TEXT,\n                    FOREIGN KEY(file_id) REFERENCES files(id)\n                )\n            ")

    @service_endpoint(inputs={'path': 'str', 'new_content': 'str', 'author': 'str'}, outputs={'status': 'str', 'file_id': 'str'}, description='Updates a file, creating a diff history entry and updating the head state.', tags=['version-control', 'write'], side_effects=['db:write'])
    def update_file(self, path: str, new_content: str, author: str='agent') -> Dict[str, Any]:
        """
        The Atomic Update Operation:
        1. Checks current state.
        2. Calculates Diff.
        3. Writes Diff to History.
        4. Updates Head to New Content.
        """
        path = str(Path(path).as_posix())
        now = datetime.datetime.utcnow()
        with self._get_conn() as conn:
            row = conn.execute('SELECT id, content FROM files WHERE path = ?', (path,)).fetchone()
            if not row:
                file_id = str(uuid.uuid4())
                conn.execute('INSERT INTO files (id, path, content, last_updated) VALUES (?, ?, ?, ?)', (file_id, path, new_content, now))
                self._log_diff(conn, file_id, 'CREATE', '[New File Created]', author, now)
                log.info(f'Created new file: {path}')
                return {'status': 'created', 'file_id': file_id}
            file_id = row['id']
            old_content = row['content'] or ''
            old_lines = old_content.splitlines(keepends=True)
            new_lines = new_content.splitlines(keepends=True)
            diff_gen = difflib.unified_diff(old_lines, new_lines, fromfile=f'a/{path}', tofile=f'b/{path}', lineterm='')
            diff_text = ''.join(diff_gen)
            if not diff_text:
                return {'status': 'unchanged', 'file_id': file_id}
            self._log_diff(conn, file_id, 'EDIT', diff_text, author, now)
            conn.execute('UPDATE files SET content = ?, last_updated = ? WHERE id = ?', (new_content, now, file_id))
            log.info(f'Updated file: {path}')
            return {'status': 'updated', 'file_id': file_id, 'diff_size': len(diff_text)}

    def _log_diff(self, conn, file_id, change_type, diff_text, author, timestamp):
        diff_id = str(uuid.uuid4())
        conn.execute('INSERT INTO diff_log (id, file_id, timestamp, change_type, diff_blob, author) VALUES (?, ?, ?, ?, ?, ?)', (diff_id, file_id, timestamp, change_type, diff_text, author))

    @service_endpoint(inputs={'path': 'str'}, outputs={'content': 'Optional[str]'}, description='Fast retrieval of current content.', tags=['version-control', 'read'], side_effects=['db:read'])
    def get_head(self, path: str) -> Optional[str]:
        """Fast retrieval of current content."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT content FROM files WHERE path = ?', (path,)).fetchone()
            return row['content'] if row else None

    @service_endpoint(inputs={'path': 'str'}, outputs={'history': 'List[Dict]'}, description='Retrieves the full evolution history of a file.', tags=['version-control', 'read'], side_effects=['db:read'])
    def get_history(self, path: str) -> List[Dict]:
        """Retrieves the full evolution history of a file."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT id FROM files WHERE path = ?', (path,)).fetchone()
            if not row:
                return []
            rows = conn.execute('SELECT timestamp, change_type, diff_blob, author FROM diff_log WHERE file_id = ? ORDER BY timestamp DESC', (row['id'],)).fetchall()
            return [dict(r) for r in rows]
if __name__ == '__main__':
    import os
    if DB_PATH.exists():
        os.remove(DB_PATH)
    engine = DiffEngineMS()
    print('Service ready:', engine)
    print('--- 1. Creating File ---')
    engine.update_file('notes.txt', 'Todo List:\n1. Buy Milk\n')
    print('\n--- 2. Updating File (The Rising Edge) ---')
    new_text = 'Todo List:\n1. Buy Eggs\n2. Code Python\n'
    res = engine.update_file('notes.txt', new_text, author='Jacob')
    print(f"Update Result: {res['status']}")
    print('\n--- 3. Inspecting History ---')
    history = engine.get_history('notes.txt')
    for event in history:
        print(f"\n[{event['timestamp']}] {event['change_type']} by {event['author']}")
        print(f"Diff Preview:\n{event['diff_blob'].strip()}")
    print('\n--- 4. Inspecting Head (Cache) ---')
    print(engine.get_head('notes.txt'))
    if DB_PATH.exists():
        os.remove(DB_PATH)

--------------------------------------------------------------------------------
FILE: src\microservices\_FeedbackValidationMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _FeedbackValidationMS
ENTRY_POINT: _FeedbackValidationMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: sqlite3, json
"""
import sqlite3
import json
import datetime
from typing import Dict, Any, List, Optional
from .microservice_std_lib import service_metadata, service_endpoint
from .base_service import BaseService

@service_metadata(
    name='FeedbackValidation', 
    version='1.0.0', 
    description='System-level memory layer for recording HITL feedback and transaction validation.',
    tags=['hitl', 'training', 'validation', 'context'],
    capabilities=['db:sqlite', 'training-data:export'],
    side_effects=['db:write'],
    internal_dependencies=['base_service', 'microservice_std_lib']
)
class FeedbackValidationMS(BaseService):
    """
    The Validator: Records accepted/rejected transactions into a dedicated
    training table within the knowledge graph for future prompt context.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__('FeedbackValidation')
        self.config = config or {}
        self.db_path = self.config.get('db_path', 'knowledge.db')
        self._init_training_table()

    def _init_training_table(self):
        """Ensures the knowledge graph can store validated transactions."""
        conn = sqlite3.connect(self.db_path)
        # Create a specific table for training pairs
        conn.execute('''
            CREATE TABLE IF NOT EXISTS training_data (
                id INTEGER PRIMARY KEY,
                timestamp TEXT,
                prompt TEXT,
                response TEXT,
                is_accepted INTEGER,
                metadata_json TEXT
            )
        ''')
        conn.close()

    @service_endpoint(
        inputs={'prompt': 'str', 'response': 'str', 'is_accepted': 'bool', 'meta': 'Dict'},
        outputs={'success': 'bool'},
        description='Records a validated or rejected transaction as training context.',
        tags=['write', 'hitl'],
        side_effects=['db:write']
    )
    def submit_feedback(self, prompt: str, response: str, is_accepted: bool, meta: Dict = None) -> bool:
        """
        Main entry point for the HITL UI to deposit the result of an inference turn.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            timestamp = datetime.datetime.utcnow().isoformat()
            
            # 1. Insert into raw training table
            cursor.execute(
                'INSERT INTO training_data (timestamp, prompt, response, is_accepted, metadata_json) VALUES (?, ?, ?, ?, ?)',
                (timestamp, prompt, response, 1 if is_accepted else 0, json.dumps(meta or {}))
            )
            
            # 2. Also register as a Graph Node for high-level mapping
            node_id = f"tx_{cursor.lastrowid}"
            cursor.execute(
                'INSERT OR REPLACE INTO graph_nodes (id, type, label, data_json) VALUES (?, ?, ?, ?)',
                (node_id, 'validated_transaction', f"Feedback: {'Accepted' if is_accepted else 'Rejected'}", json.dumps({'is_accepted': is_accepted}))
            )
            
            conn.commit()
            conn.close()
            self.log_info(f"Transaction recorded: {'ACCEPTED' if is_accepted else 'REJECTED'}")
            return True
        except Exception as e:
            self.log_error(f"Failed to record feedback: {e}")
            return False

    @service_endpoint(
        inputs={'limit': 'int', 'only_accepted': 'bool'},
        outputs={'history': 'List[Dict]'},
        description='Retrieves past validated transactions to build few-shot prompts.',
        tags=['read', 'prompt-builder'],
        side_effects=['db:read']
    )
    def get_validated_context(self, limit: int = 5, only_accepted: bool = True) -> List[Dict]:
        """
        Called by the system building the prompt to find 'Gold Standard' examples.
        """
        conn = sqlite3.connect(self.db_path)
        query = "SELECT prompt, response FROM training_data WHERE 1=1"
        if only_accepted:
            query += " AND is_accepted = 1"
        query += " ORDER BY id DESC LIMIT ?"
        
        results = conn.execute(query, (limit,)).fetchall()
        conn.close()
        
        return [{"prompt": r[0], "response": r[1]} for r in results]

    @service_endpoint(
        inputs={'artifact': 'Dict', 'is_accepted': 'bool'},
        outputs={'success': 'bool'},
        description='Unwraps a standard Cell Artifact and submits it for validation.',
        tags=['write', 'hitl', 'helper']
    )
    def validate_artifact(self, artifact: Dict[str, Any], is_accepted: bool) -> bool:
        """
        Convenience wrapper for Standard Artifacts.
        """
        try:
            meta = artifact.get('metadata', {})
            instructions = artifact.get('instructions', {})
            
            # Reconstruct the full prompt context
            sys_role = instructions.get('system_role', '')
            sys_prompt = instructions.get('system_prompt', '')
            user_payload = artifact.get('payload', '')
            
            full_prompt = f"Role: {sys_role}\nContext: {sys_prompt}\nTask: {user_payload}"
            response = artifact.get('response', '') # Assuming response is injected into artifact before validation
            
            return self.submit_feedback(full_prompt, response, is_accepted, meta)
        except Exception as e:
            self.log_error(f"Artifact validation failed: {e}")
            return False


--------------------------------------------------------------------------------
FILE: src\microservices\_HydrationFactoryMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _HydrationFactoryMS
ENTRY_POINT: _HydrationFactoryMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib, _CodeFormatterMS, _TreeMapperMS, _VectorFactoryMS
EXTERNAL_DEPENDENCIES: None
"""
import os
import json
import logging
from typing import Dict, Any, Optional, List, Union
from .microservice_std_lib import service_metadata, service_endpoint
from .base_service import BaseService

# Import the Specialist Microservices
# In a distributed system, these might be RPC calls. 
# In this modular monolith, we instantiate them directly for performance.
try:
    from ._CodeFormatterMS import CodeFormatterMS
    from ._TreeMapperMS import TreeMapperMS
    from ._VectorFactoryMS import VectorFactoryMS
except ImportError:
    # Fallback for when running as a standalone script without package context
    pass

@service_metadata(
    name='HydrationFactory',
    version='1.0.0',
    description='The Fabricator: Converts raw Cell Artifacts into hydrated, usable products (Files, Maps, Memories).',
    tags=['utility', 'converter', 'factory', 'output'],
    capabilities=['filesystem:write', 'compute', 'db:vector'],
    side_effects=['filesystem:write', 'db:write'],
    internal_dependencies=['base_service', 'microservice_std_lib', '_CodeFormatterMS', '_TreeMapperMS', '_VectorFactoryMS']
)
class HydrationFactoryMS(BaseService):
    """
    The Fabricator.
    Takes a raw JSON Artifact from a Cell and "Hydrates" it into a final product
    based on the requested mode.
    
    Modes:
    1. SCAFFOLD (Code): Formats and writes source code to disk.
    2. BLUEPRINT (Doc): Generates a project tree map.
    3. MEMORY (Vector): Embeds the artifact into a Vector Store (Long-term memory).
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__('HydrationFactory')
        self.config = config or {}
        
        # Initialize Specialists
        # We perform lazy instantiation or immediate depending on config to save resources
        self.formatter = CodeFormatterMS()
        self.mapper = TreeMapperMS()
        self.vector_factory = VectorFactoryMS()

    @service_endpoint(
        inputs={'artifact': 'Dict', 'mode': 'str', 'destination': 'str'},
        outputs={'status': 'str', 'details': 'Dict'},
        description='Main entry point to hydrate an artifact into a concrete product.',
        tags=['factory', 'execute']
    )
    def hydrate_artifact(self, artifact: Dict[str, Any], mode: str, destination: str) -> Dict[str, Any]:
        """
        :param artifact: The standardized JSON output from a Cell.
        :param mode: 'scaffold', 'blueprint', or 'memory'.
        :param destination: File path (for scaffold/blueprint) or Collection name (for memory).
        """
        self.log_info(f"Hydrating artifact via mode: {mode.upper()} -> {destination}")
        
        try:
            if mode.lower() == 'scaffold':
                return self._hydrate_scaffold(artifact, destination)
            elif mode.lower() == 'blueprint':
                return self._hydrate_blueprint(destination)
            elif mode.lower() == 'memory':
                return self._hydrate_memory(artifact, destination)
            else:
                raise ValueError(f"Unknown hydration mode: {mode}")
        except Exception as e:
            self.log_error(f"Hydration failed: {e}")
            return {"status": "error", "message": str(e)}

    def _hydrate_scaffold(self, artifact: Dict[str, Any], file_path: str) -> Dict[str, Any]:
        """Writes the payload to a file after passing it through the CodeFormatter."""
        content = artifact.get('payload', '')
        if not content:
            return {"status": "skipped", "reason": "Empty payload"}

        # 1. Format the code (The Architect)
        # We assume Python for now, but this could be dynamic based on extension
        formatted_result = self.formatter.normalize_code(content, spaces=4)
        final_code = formatted_result.get('normalized', content)
        hunks_applied = len(formatted_result.get('patch', {}).get('hunks', []))

        # 2. Write to disk
        os.makedirs(os.path.dirname(os.path.abspath(file_path)), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(final_code)

        return {
            "status": "success",
            "type": "file_write",
            "path": file_path,
            "formatting_hunks_applied": hunks_applied
        }

    def _hydrate_blueprint(self, root_path: str) -> Dict[str, Any]:
        """Generates a project tree map and saves it to a file."""
        # 1. Generate Map (The Cartographer)
        tree_map = self.mapper.generate_tree(root_path)
        
        # 2. Save to _project_map.txt in the root
        output_path = os.path.join(root_path, '_project_map.txt')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(tree_map)

        return {
            "status": "success",
            "type": "map_generation",
            "path": output_path,
            "size": len(tree_map)
        }

    def _hydrate_memory(self, artifact: Dict[str, Any], collection_name: str) -> Dict[str, Any]:
        """Embeds the artifact payload into the Vector Store."""
        # 1. Create Vector Store Connection (The Switchboard)
        # Defaulting to Chroma for persistence, could be config-driven
        store = self.vector_factory.create('chroma', {'path': './knowledge_base', 'collection': collection_name})
        
        # 2. Prepare Data
        # We embed the payload (content) and attach the metadata
        payload = artifact.get('payload', '')
        if not payload:
             return {"status": "skipped", "reason": "Empty payload"}
             
        # Generate a simple embedding (Mocked here, normally uses IngestEngine or internal embedder)
        # In a real flow, we'd call an embedding service. 
        # For the factory, we assume the artifact might already have a vector, 
        # or we generate a placeholder/call a service if we want to be fully self-contained.
        # SIMPLIFICATION: We will require the embedding to be passed or we skip it for this stub.
        # Ideally, we call self.ingest_engine.get_embedding(payload)
        
        # For now, we just store the text without vector search if no embedding provided (Chroma handles raw text too usually)
        # But our VectorStore protocol expects embeddings. 
        # Let's mock a 384-dim vector for success path or skip.
        mock_embedding = [0.1] * 384 

        store.add(
            embeddings=[mock_embedding],
            metadatas=[artifact.get('metadata', {})]
        )

        return {
            "status": "success",
            "type": "memory_storage",
            "collection": collection_name,
            "item_count": store.count()
        }

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    
    # Test Harness
    factory = HydrationFactoryMS()
    print(f"Service Ready: {factory}")
    
    # Mock Artifact
    test_artifact = {
        "metadata": {"author": "TheCell", "version": "1.0"},
        "payload": "def hello_world():\n  print('Hello from the Factory!')",
        "instructions": {"system_prompt": "Write python code"}
    }
    
    print("\n--- Testing Code Hydration ---")
    res = factory.hydrate_artifact(test_artifact, mode='scaffold', destination='./_test_output.py')
    print(json.dumps(res, indent=2))
    
    print("\n--- Testing Clean Up ---")
    if os.path.exists('./_test_output.py'):
        os.remove('./_test_output.py')
        print("Cleaned up test file.")

--------------------------------------------------------------------------------
FILE: src\microservices\_IngestEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _IngestEngineMS
ENTRY_POINT: _IngestEngineMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: requests
"""
import importlib.util
import sys
REQUIRED = ['requests']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print(f"MISSING DEPENDENCIES: {' '.join(MISSING)}")
    print('Please run: pip install requests')
import json
import os
import re
import sqlite3
import time
from dataclasses import dataclass
from typing import Any, Dict, Generator, List, Optional
import requests
from .microservice_std_lib import service_metadata, service_endpoint
from .base_service import BaseService
from ._TextChunkerMS import TextChunkerMS
OLLAMA_API_URL = 'http://localhost:11434/api'

@dataclass
class IngestStatus:
    current_file: str
    progress_percent: float
    processed_files: int
    total_files: int
    log_message: str
    thought_frame: Optional[Dict] = None

class SynapseWeaver:
    """
    Parses source code to extract import dependencies.
    Used to generate the 'DEPENDS_ON' edges in the Knowledge Graph.
    """

    def __init__(self):
        self.py_pattern = re.compile('^\\s*(?:from|import)\\s+([\\w\\.]+)')
        self.js_pattern = re.compile('(?:import\\s+.*?from\\s+[\\\'"]|require\\([\\\'"])([\\.\\/\\w\\-_]+)[\\\'"]')

    def extract_dependencies(self, content: str, file_path: str) -> List[str]:
        dependencies = []
        ext = os.path.splitext(file_path)[1].lower()
        lines = content.split('\n')
        for line in lines:
            match = None
            if ext == '.py':
                match = self.py_pattern.match(line)
            elif ext in ['.js', '.ts', '.tsx', '.jsx']:
                match = self.js_pattern.search(line)
            if match:
                raw_dep = match.group(1)
                clean_dep = raw_dep.split('.')[-1].split('/')[-1]
                if clean_dep not in dependencies:
                    dependencies.append(clean_dep)
        return dependencies

@service_metadata(name='IngestEngine', version='1.0.0', description='Reads files, chunks text, fetches embeddings, and weaves graph edges.', tags=['ingest', 'rag', 'parsing', 'embedding'], capabilities=['filesystem:read', 'network:outbound', 'db:sqlite'], side_effects=['db:write', 'network:outbound'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['requests'])
class IngestEngineMS(BaseService):
    """
    The Heavy Lifter: Reads files, chunks text, fetches embeddings,
    populates the Graph Nodes, and weaves Graph Edges.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('IngestEngine')
        self.config = config or {}
        self.db_path = self.config.get('db_path', 'knowledge.db')
        self.stop_signal = False
        self.weaver = SynapseWeaver()
        self.chunker = TextChunkerMS()
        self._init_db()

    def _init_db(self):
        """Ensures the target database has the required schema."""
        conn = sqlite3.connect(self.db_path)
        conn.execute('CREATE TABLE IF NOT EXISTS files (id INTEGER PRIMARY KEY, path TEXT, last_updated REAL)')
        conn.execute('CREATE TABLE IF NOT EXISTS chunks (id INTEGER PRIMARY KEY, file_id INT, chunk_index INT, content TEXT, embedding BLOB)')
        conn.execute('CREATE TABLE IF NOT EXISTS graph_nodes (id TEXT PRIMARY KEY, type TEXT, label TEXT, data_json TEXT)')
        conn.execute('CREATE TABLE IF NOT EXISTS graph_edges (source TEXT, target TEXT, weight REAL)')
        conn.close()

    def abort(self):
        self.stop_signal = True

    def check_ollama_connection(self) -> bool:
        try:
            requests.get(f'{OLLAMA_API_URL}/tags', timeout=2)
            return True
        except:
            return False

    def get_available_models(self) -> List[str]:
        try:
            res = requests.get(f'{OLLAMA_API_URL}/tags')
            if res.status_code == 200:
                data = res.json()
                return [m['name'] for m in data.get('models', [])]
        except:
            pass
        return []

    @service_endpoint(
        inputs={'prompt': 'str', 'model': 'str', 'system': 'str'}, 
        outputs={'chunk': 'str'}, 
        description='Streams inference tokens from Ollama.', 
        tags=['inference', 'stream'], 
        mode='generator', 
        side_effects=['network:outbound']
    )
    def generate_stream(self, prompt: str, model: str, system: str = '') -> Generator[str, None, None]:
        """Yields tokens from the LLM for real-time UI updates."""
        url = f"{OLLAMA_API_URL}/generate"
        payload = {
            "model": model,
            "prompt": prompt,
            "system": system,
            "stream": True
        }
        
        try:
            with requests.post(url, json=payload, stream=True, timeout=120) as r:
                if r.status_code != 200:
                    yield f"[Error: Ollama returned status {r.status_code}]"
                    return
                
                for line in r.iter_lines():
                    if self.stop_signal:
                        break
                    if line:
                        try:
                            body = json.loads(line)
                            token = body.get('response', '')
                            if token:
                                yield token
                            if body.get('done', False):
                                break
                        except json.JSONDecodeError:
                            continue
        except Exception as e:
            yield f"[Connection Error: {str(e)}]"

    @service_endpoint(inputs={'file_paths': 'List[str]', 'model_name': 'str'}, outputs={'status': 'IngestStatus'}, description='Processes a list of files, ingesting them into the knowledge graph.', tags=['ingest', 'processing'], mode='generator', side_effects=['db:write', 'network:outbound'])
    def process_files(self, file_paths: List[str], model_name: str='none') -> Generator[IngestStatus, None, None]:
        total = len(file_paths)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('PRAGMA synchronous = OFF')
        cursor.execute('PRAGMA journal_mode = MEMORY')
        node_registry = {}
        file_contents = {}
        for idx, file_path in enumerate(file_paths):
            if self.stop_signal:
                yield IngestStatus(file_path, 0, idx, total, 'Ingestion Aborted.')
                break
            filename = os.path.basename(file_path)
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                file_contents[filename] = content
            except Exception as e:
                yield IngestStatus(file_path, idx / total * 100, idx, total, f'Error: {e}')
                continue
            try:
                cursor.execute('INSERT OR REPLACE INTO files (path, last_updated) VALUES (?, ?)', (file_path, time.time()))
                file_id = cursor.lastrowid
            except sqlite3.Error:
                continue
            cursor.execute('\n                INSERT OR REPLACE INTO graph_nodes (id, type, label, data_json)\n                VALUES (?, ?, ?, ?)\n            ', (filename, 'file', filename, json.dumps({'path': file_path})))
            node_registry[filename] = filename
            chunks = self._chunk_text(content)
            for i, chunk_text in enumerate(chunks):
                if self.stop_signal:
                    break
                embedding = None
                if model_name != 'none':
                    embedding = self._get_embedding(model_name, chunk_text)
                emb_blob = json.dumps(embedding).encode('utf-8') if embedding else None
                cursor.execute('\n                    INSERT INTO chunks (file_id, chunk_index, content, embedding)\n                    VALUES (?, ?, ?, ?)\n                ', (file_id, i, chunk_text, emb_blob))
                thought_frame = {'id': f'{file_id}_{i}', 'file': filename, 'chunk_index': i, 'content': chunk_text, 'vector_preview': embedding[:20] if embedding else [], 'concept_color': '#007ACC'}
                yield IngestStatus(current_file=filename, progress_percent=(idx + i / len(chunks)) / total * 100, processed_files=idx, total_files=total, log_message=f'Processing {filename}...', thought_frame=thought_frame)
            conn.commit()
        yield IngestStatus('Graph', 100, total, total, 'Weaving Knowledge Graph...')
        edge_count = 0
        for filename, content in file_contents.items():
            if self.stop_signal:
                break
            deps = self.weaver.extract_dependencies(content, filename)
            for dep in deps:
                target_id = None
                for potential_match in node_registry.keys():
                    if potential_match.startswith(dep + '.') or potential_match == dep:
                        target_id = potential_match
                        break
                if target_id and target_id != filename:
                    try:
                        cursor.execute('\n                            INSERT OR IGNORE INTO graph_edges (source, target, weight)\n                            VALUES (?, ?, 1.0)\n                        ', (filename, target_id))
                        edge_count += 1
                    except:
                        pass
        conn.commit()
        conn.close()
        yield IngestStatus(current_file='Complete', progress_percent=100, processed_files=total, total_files=total, log_message=f'Ingestion Complete. Created {edge_count} dependency edges.')

    def _chunk_text(self, text: str, chunk_size: int=1000, overlap: int=100) -> List[str]:
        # Delegate to the specialized service
        return self.chunker.chunk_by_chars(text, chunk_size, overlap)

    def _get_embedding(self, model: str, text: str) -> Optional[List[float]]:
        try:
            res = requests.post(f'{OLLAMA_API_URL}/embeddings', json={'model': model, 'prompt': text}, timeout=30)
            if res.status_code == 200:
                return res.json().get('embedding')
        except:
            return None
if __name__ == '__main__':
    TEST_DB = 'test_ingest_v2.db'
    engine = IngestEngineMS({'db_path': TEST_DB})
    print(f'Service Ready: {engine}')
    target_file = '__IngestEngineMS.py'
    if not os.path.exists(target_file):
        with open(target_file, 'w') as f:
            f.write("import os\nimport json\nprint('Hello World')")
    print(f'Running Ingest on {target_file}...')
    files = [target_file]
    for status in engine.process_files(files, 'none'):
        print(f'[{status.progress_percent:.0f}%] {status.log_message}')
    conn = sqlite3.connect(TEST_DB)
    edges = conn.execute('SELECT * FROM graph_edges').fetchall()
    nodes = conn.execute('SELECT * FROM graph_nodes').fetchall()
    print(f'\nResult: {len(nodes)} Nodes, {len(edges)} Edges.')
    conn.close()
    if os.path.exists(TEST_DB):
        os.remove(TEST_DB)
    if os.path.exists(target_file) and 'Hello World' in open(target_file).read():
        os.remove(target_file)


--------------------------------------------------------------------------------
FILE: src\microservices\_LogViewMS.py
--------------------------------------------------------------------------------
import tkinter as tk
from tkinter import scrolledtext, filedialog
import queue
import logging
import datetime
from typing import Any, Dict, Optional
from .microservice_std_lib import service_metadata, service_endpoint

class QueueHandler(logging.Handler):
    """
    Sends log records to a thread-safe queue.
    Used to bridge the gap between Python's logging system and the Tkinter UI.
    """

    def __init__(self, log_queue: queue.Queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.log_queue.put(record)

@service_metadata(name='LogView', version='1.0.0', description='A thread-safe log viewer widget for Tkinter.', tags=['ui', 'logs', 'widget'], capabilities=['ui:gui', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class LogViewMS(tk.Frame):
    """
    The Console: A professional log viewer widget.
    Features:
    - Thread-safe (consumes from a Queue).
    - Message Consolidation ("Error occurred (x5)").
    - Level Filtering (Toggle INFO/DEBUG/ERROR).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        super().__init__(parent)
        self.log_queue: queue.Queue = self.config.get('log_queue')
        if self.log_queue is None:
            self.log_queue = queue.Queue()
        self.last_msg = None
        self.last_count = 0
        self.last_line_index = None
        self._build_ui()
        self._poll_queue()

    def _build_ui(self):
        toolbar = tk.Frame(self, bg='#2d2d2d', height=30)
        toolbar.pack(fill='x', side='top')
        self.filters = {'INFO': tk.BooleanVar(value=True), 'DEBUG': tk.BooleanVar(value=True), 'WARNING': tk.BooleanVar(value=True), 'ERROR': tk.BooleanVar(value=True)}
        for level, var in self.filters.items():
            cb = tk.Checkbutton(toolbar, text=level, variable=var, bg='#2d2d2d', fg='white', selectcolor='#444', activebackground='#2d2d2d', activeforeground='white')
            cb.pack(side='left', padx=5)
        tk.Button(toolbar, text='Clear', command=self.clear, bg='#444', fg='white', relief='flat').pack(side='right', padx=5)
        tk.Button(toolbar, text='Save', command=self.save, bg='#444', fg='white', relief='flat').pack(side='right')
        self.text = scrolledtext.ScrolledText(self, state='disabled', bg='#1e1e1e', fg='#d4d4d4', font=('Consolas', 10), insertbackground='white')
        self.text.pack(fill='both', expand=True)
        self.text.tag_config('INFO', foreground='#d4d4d4')
        self.text.tag_config('DEBUG', foreground='#569cd6')
        self.text.tag_config('WARNING', foreground='#ce9178')
        self.text.tag_config('ERROR', foreground='#f44747')
        self.text.tag_config('timestamp', foreground='#608b4e')

    def _poll_queue(self):
        """Pulls logs from the queue and updates UI."""
        try:
            while True:
                record = self.log_queue.get_nowait()
                self._display(record)
        except queue.Empty:
            pass
        finally:
            self.after(100, self._poll_queue)

    def _display(self, record):
        level = record.levelname
        if not self.filters.get(level, tk.BooleanVar(value=True)).get():
            return
        msg = record.getMessage()
        ts = datetime.datetime.fromtimestamp(record.created).strftime('%H:%M:%S')
        self.text.config(state='normal')
        if msg == self.last_msg:
            self.last_count += 1
        else:
            self.last_msg = msg
            self.last_count = 1
        self.text.insert('end', f'[{ts}] ', 'timestamp')
        self.text.insert('end', f'{msg}\n', level)
        self.text.see('end')
        self.text.config(state='disabled')

    @service_endpoint(inputs={}, outputs={}, description='Clears the log console.', tags=['ui', 'logs'], side_effects=['ui:update'])
    def clear(self):
        self.text.config(state='normal')
        self.text.delete('1.0', 'end')
        self.text.config(state='disabled')

    @service_endpoint(inputs={}, outputs={}, description='Opens a dialog to save logs to a file.', tags=['ui', 'filesystem'], side_effects=['filesystem:write', 'ui:dialog'])
    def save(self):
        path = filedialog.asksaveasfilename(defaultextension='.log', filetypes=[('Log Files', '*.log')])
        if path:
            try:
                with open(path, 'w', encoding='utf-8') as f:
                    f.write(self.text.get('1.0', 'end'))
            except Exception as e:
                print(f'Save failed: {e}')
if __name__ == '__main__':
    root = tk.Tk()
    root.title('Log View Test')
    root.geometry('600x400')
    q = queue.Queue()
    logger = logging.getLogger('TestApp')
    logger.setLevel(logging.DEBUG)
    logger.addHandler(QueueHandler(q))
    log_view = LogViewMS({'parent': root, 'log_queue': q})
    print('Service ready:', log_view)
    log_view.pack(fill='both', expand=True)

    def generate_noise():
        logger.info('System initializing...')
        logger.debug('Checking sensors...')
        logger.warning('Sensor 4 response slow.')
        logger.error('Connection failed!')
        root.after(2000, generate_noise)
    generate_noise()
    root.mainloop()

--------------------------------------------------------------------------------
FILE: src\microservices\_MicroSpinnerMS.py
--------------------------------------------------------------------------------
import tkinter as tk
import math
import threading

class MicroSpinner:
    """
    A standalone ASCII spinner for Tkinter Text widgets.
    """
    def __init__(self, text_widget, center_row=5, center_col=20, radius=3, speed=0.2):
        self.txt = text_widget
        self.center_row = center_row
        self.center_col = center_col
        self.radius = radius
        self.speed = speed
        
        self.angle = 0.0
        self.is_running = False
        self.trail = []  # Stores (index, symbol)
        self.symbols = ["@", "#", "*", "+", ".", " "] # Fade sequence
        
        # Initialize a small blank area in the text box if empty
        if self.txt.get("1.0", tk.END).strip() == "":
            blank_block = (" " * 80 + "\n") * 20
            self.txt.insert("1.0", blank_block)

    def _get_pos(self, angle_offset=0):
        """Calculates a specific coordinate based on angle."""
        # 2.2 factor compensates for rectangular font pixels
        x = int(self.center_col + (self.radius * 2.2) * math.cos(self.angle - angle_offset))
        y = int(self.center_row + self.radius * math.sin(self.angle - angle_offset))
        return f"{y}.{x}"

    def update(self):
        if not self.is_running:
            # Clean up the trail when stopping
            for pos in self.trail:
                self._write_at(pos, " ")
            self.trail = []
            return

        # 1. Calculate current head position
        head_pos = self._get_pos(0)
        
        # 2. Add new head to trail, remove oldest if too long
        self.trail.insert(0, head_pos)
        if len(self.trail) > len(self.symbols):
            old_pos = self.trail.pop()
            self._write_at(old_pos, " ")

        # 3. Draw the trail with fading symbols
        for i, pos in enumerate(self.trail):
            symbol = self.symbols[i] if i < len(self.symbols) else " "
            self._write_at(pos, symbol)

        self.angle += self.speed
        self.txt.after(50, self.update)

    def _write_at(self, index, char):
        """Surgically replaces a single character at a Tkinter index."""
        try:
            self.txt.delete(index)
            self.txt.insert(index, char)
        except tk.TclError:
            pass # Handle case where text widget might be cleared externally

    def start(self):
        if not self.is_running:
            self.is_running = True
            self.update()

    def stop(self):
        self.is_running = False
--------------------------------------------------------------------------------
FILE: src\microservices\_OllamaModelSelectorMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _OllamaModelSelectorMS
ENTRY_POINT: _OllamaModelSelectorMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: requests
"""
import tkinter as tk
from tkinter import ttk
import requests
import threading
import logging
from typing import Dict, Any, List, Optional, Callable
from base_service import BaseService
from microservice_std_lib import service_metadata, service_endpoint

OLLAMA_TAGS_URL = "http://localhost:11434/api/tags"

@service_metadata(
    name='OllamaModelSelector', 
    version='1.0.0', 
    description='The Lens: A UI widget that fetches and displays available local Ollama models.', 
    tags=['ui', 'ai', 'ollama', 'widget'], 
    capabilities=['ui:gui', 'network:outbound'], 
    internal_dependencies=['base_service', 'microservice_std_lib'], 
    external_dependencies=['requests']
)
class OllamaModelSelectorMS(tk.Frame, BaseService):
    """
    The Lens.
    A dropdown widget that automatically polls the local Ollama API for models.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        # Initialize BaseService first for logging
        BaseService.__init__(self, 'OllamaModelSelector')
        
        self.config_data = config or {}
        parent = self.config_data.get('parent')
        self.on_change_callback = self.config_data.get('on_change')
        
        # Initialize the Tkinter Frame
        tk.Frame.__init__(self, parent, bg=self.config_data.get('bg', '#252526'))
        
        self.models: List[str] = ["Scanning..."]
        self._build_ui()
        
        # Start background scan so the UI doesn't hang
        threading.Thread(target=self.refresh_models, daemon=True).start()

    def _build_ui(self):
        """Creates the label and combobox."""
        tk.Label(
            self, text="AI MODEL:", bg=self.cget('bg'), fg='white', 
            font=('Segoe UI', 9, 'bold')
        ).pack(side='left', padx=(5, 10))

        self.combo = ttk.Combobox(self, values=self.models, state="readonly", width=25)
        self.combo.set(self.models[0])
        self.combo.pack(side='left', padx=5)
        self.combo.bind("<<ComboboxSelected>>", self._on_selection)

    @service_endpoint(
        inputs={}, 
        outputs={'models': 'List[str]'}, 
        description='Queries local Ollama API to refresh the list of available models.', 
        tags=['network', 'refresh']
    )
    def refresh_models(self) -> List[str]:
        """Fetches models from Ollama tags endpoint."""
        try:
            response = requests.get(OLLAMA_TAGS_URL, timeout=3)
            if response.status_code == 200:
                data = response.json()
                self.models = [m['name'] for m in data.get('models', [])]
                self.log_info(f"Discovered {len(self.models)} local models.")
            else:
                self.models = ["Ollama Offline"]
        except Exception as e:
            self.log_error(f"Failed to reach Ollama: {e}")
            self.models = ["Connection Error"]

        # Update the UI from the main thread
        self.after(0, lambda: self.combo.config(values=self.models))
        if self.models and self.models[0] not in ["Connection Error", "Ollama Offline"]:
            self.after(0, lambda: self.combo.current(0))
        
        return self.models

    def _on_selection(self, event):
        """Triggered when the user picks a new model."""
        selected = self.combo.get()
        self.log_info(f"Model selected: {selected}")
        if self.on_change_callback:
            self.on_change_callback(selected)

    @service_endpoint(
        inputs={}, 
        outputs={'selected_model': 'str'}, 
        description='Returns the currently selected model string.', 
        tags=['ui', 'read']
    )
    def get_selected_model(self) -> str:
        """Retrieves current selection from the combobox."""
        return self.combo.get()

if __name__ == '__main__':
    root = tk.Tk()
    root.title("Ollama Selector Test")
    root.geometry("400x100")
    
    # Simple callback test
    def log_change(m): print(f"Signal emitted for model: {m}")
    
    selector = OllamaModelSelectorMS({'parent': root, 'on_change': log_change})
    selector.pack(pady=20)
    
    root.mainloop()
--------------------------------------------------------------------------------
FILE: src\microservices\_RegexWeaverMS.py
--------------------------------------------------------------------------------
import re
import logging
from typing import Any, Dict, List, Optional, Set
from microservice_std_lib import service_metadata, service_endpoint
PY_IMPORT = re.compile('^\\s*(?:from|import)\\s+([\\w\\.]+)')
JS_IMPORT = re.compile('(?:import\\s+.*?from\\s+[\\\'"]|require\\([\\\'"])([\\.\\/\\w\\-_]+)[\\\'"]')
logger = logging.getLogger('RegexWeaver')

@service_metadata(name='RegexWeaver', version='1.0.0', description='Fault-tolerant dependency extractor using Regex.', tags=['parsing', 'dependencies', 'regex'], capabilities=['compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class RegexWeaverMS:
    """
    The Weaver: A fault-tolerant dependency extractor.
    Uses Regex to find imports, making it faster and more permissive
    than AST parsers (works on broken code).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'language': 'str'}, outputs={'dependencies': 'List[str]'}, description='Scans code content for import statements.', tags=['parsing', 'dependencies'], side_effects=[])
    def extract_dependencies(self, content: str, language: str) -> List[str]:
        """
        Scans code content for import statements.
        :param language: 'python' or 'javascript' (includes ts/jsx).
        """
        dependencies: Set[str] = set()
        lines = content.splitlines()
        pattern = PY_IMPORT if language == 'python' else JS_IMPORT
        for line in lines:
            if line.strip().startswith(('#', '//')):
                continue
            if language == 'python':
                match = pattern.match(line)
            else:
                match = pattern.search(line)
            if match:
                raw_dep = match.group(1)
                clean_dep = raw_dep.split('.')[-1].split('/')[-1]
                dependencies.add(clean_dep)
        return sorted(list(dependencies))
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    weaver = RegexWeaverMS()
    print('Service ready:', weaver)
    py_code = '\n    import os\n    from backend.utils import helper\n    # from commented.out import ignore_me\n    import pandas as pd\n    '
    print(f"Python Deps: {weaver.extract_dependencies(py_code, 'python')}")
    js_code = "\n    import React from 'react';\n    const utils = require('./lib/utils');\n    // import hidden from 'hidden';\n    "
    print(f"JS Deps:     {weaver.extract_dependencies(js_code, 'javascript')}")

--------------------------------------------------------------------------------
FILE: src\microservices\_RulesEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _RulesEngineMS
ROLE: Operator Governance (Task 4.3)
"""
import logging
from typing import Dict, Any, Optional
try:
    from .rules_contracts import get_default_rules
except ImportError:
    # Fallback if the file doesn't exist yet
    def get_default_rules(): return {}

class RulesEngineMS:
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.rules = get_default_rules()
        self.logger = logging.getLogger("RulesEngine")

    def get_rules(self) -> Dict[str, Any]:
        return self.rules.copy()

    def set_rules(self, new_rules: Dict[str, Any]):
        self.rules.update(new_rules)
        self.logger.info("Ruleset updated.")

    def evaluate_file(self, file_path: str) -> tuple:
        """Checks if a file is protected."""
        for p in self.rules.get("protected_files", []):
            if p in file_path:
                return False, f"File is protected by rule: {p}"
        return True, ""

    def evaluate_hunk(self, hunk: dict) -> tuple:
        """Checks hunk constraints like size or forbidden patterns."""
        content = hunk.get('content', '')
        if len(content) > self.rules.get("max_hunk_size", 99999):
            return False, "Hunk exceeds max_hunk_size"
            
        for pattern in self.rules.get("forbidden_patterns", []):
            if pattern in content:
                return False, f"Hunk contains forbidden pattern: {pattern}"
                
        return True, ""



--------------------------------------------------------------------------------
FILE: src\microservices\_SemanticChunkerMS.py
--------------------------------------------------------------------------------
import ast
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
from .microservice_std_lib import service_metadata, service_endpoint

@dataclass
class CodeChunk:
    name: str
    type: str
    content: str
    start_line: int
    end_line: int
    docstring: str = ''

@service_metadata(name='SemanticChunker', version='1.0.0', description='The Surgeon: Intelligent Code Splitter that parses source code into logical semantic units (Classes, Functions) using AST.', tags=['utility', 'nlp', 'parser'], capabilities=['python-ast', 'semantic-chunking'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class SemanticChunkerMS:
    """
    Intelligent Code Splitter.
    Parses source code into logical units (Classes, Functions) 
    rather than arbitrary text windows.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'filename': 'str'}, outputs={'chunks': 'List[Dict]'}, description='Main entry point to split a file into semantic chunks based on its extension and content.', tags=['processing', 'chunking'], side_effects=[])
    def chunk_file(self, content: str, filename: str) -> List[Dict[str, Any]]:
        """
        Splits file content into chunks.
        Returns a list of dictionaries suitable for JSON response.
        """
        chunks: List[CodeChunk] = []
        if filename.endswith('.py'):
            chunks = self._chunk_python(content)
        elif filename.lower().endswith(('.md', '.txt', '.pdf', '.html', '.htm', '.rst')):
            chunks = self._chunk_generic(content, window_size=800)
        else:
            chunks = self._chunk_generic(content, window_size=1500)
        return [asdict(c) for c in chunks]

    def _chunk_python(self, source: str) -> List[CodeChunk]:
        chunks = []
        try:
            tree = ast.parse(source)
            lines = source.splitlines(keepends=True)

            def get_segment(node):
                start = node.lineno - 1
                end = node.end_lineno if hasattr(node, 'end_lineno') and node.end_lineno else start + 1
                return (''.join(lines[start:end]), start + 1, end)
            for node in tree.body:
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'def {node.name}', type='function', content=text, start_line=s, end_line=e, docstring=doc))
                elif isinstance(node, ast.ClassDef):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'class {node.name}', type='class', content=text, start_line=s, end_line=e, docstring=doc))
            if not chunks:
                return self._chunk_generic(source)
        except SyntaxError:
            return self._chunk_generic(source)
        return chunks

    def _chunk_generic(self, text: str, window_size: int=1500) -> List[CodeChunk]:
        """Sliding window for non-code files."""
        chunks = []
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        lines = text.splitlines(keepends=True)
        current_chunk = []
        current_size = 0
        chunk_idx = 1
        start_line = 1
        for i, line in enumerate(lines):
            current_chunk.append(line)
            current_size += len(line)
            if current_size >= window_size:
                chunks.append(CodeChunk(name=f'Chunk {chunk_idx}', type='text_block', content=''.join(current_chunk), start_line=start_line, end_line=i + 1))
                current_chunk = []
                current_size = 0
                chunk_idx += 1
                start_line = i + 2
        if current_chunk:
            chunks.append(CodeChunk(name=f'Chunk {chunk_idx}', type='text_block', content=''.join(current_chunk), start_line=start_line, end_line=len(lines)))
        return chunks
if __name__ == '__main__':
    svc = SemanticChunkerMS()
    print('Service ready:', svc)
    test_code = "def hello():\n    print('world')\n\nclass Test:\n    pass"
    results = svc.chunk_file(test_code, 'test.py')
    print(f'Extracted {len(results)} semantic chunks.')
    for c in results:
        print(f" - [{c['type']}] {c['name']} ({c['start_line']}-{c['end_line']})")
        print(f" - [{c['type']}] {c['name']} ({c['start_line']}-{c['end_line']})")

--------------------------------------------------------------------------------
FILE: src\microservices\_SessionRecorderMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _SessionRecorderMS
ENTRY_POINT: _SessionRecorderMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import datetime
import json
from typing import Dict, Any, Optional
from base_service import BaseService
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(
    name='SessionRecorder', 
    version='1.0.0', 
    description='The Black Box: Records all project tidying events to a persistent audit log.', 
    tags=['utility', 'logging', 'audit'], 
    capabilities=['filesystem:write'], 
    internal_dependencies=['base_service', 'microservice_std_lib'], 
    external_dependencies=[]
)
class SessionRecorderMS(BaseService):
    """
    The Black Box.
    Listens to the SignalBus and writes a chronological record of all actions to disk.
    """

    def __init__(self, state, config: Optional[Dict[str, Any]] = None):
        super().__init__('SessionRecorder')
        self.state = state
        self.config = config or {}
        
        # Set up the log directory
        self.logs_dir = self.config.get('logs_dir', 'tidy_logs')
        os.makedirs(self.logs_dir, exist_ok=True)
        
        # Create a unique filename for this session
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = os.path.join(self.logs_dir, f"tidy_session_{timestamp}.log")
        
        self.log_info(f"Session Recorder initialized. Logging to: {self.log_file}")
        self._write_entry("SESSION_START", {"msg": "Project Tidier session initiated."})

    def _write_entry(self, event_type: str, data: Any):
        """Writes a structured, timestamped entry to the log file."""
        timestamp = datetime.datetime.now().isoformat()
        entry = {
            "timestamp": timestamp,
            "event": event_type,
            "data": data
        }
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(entry) + "\n")
        except Exception as e:
            self.log_error(f"Failed to write to audit log: {e}")

    # --- Signal Handlers ---

    def on_scan_started(self, data: Dict[str, Any]):
        self._write_entry("SCAN_INITIATED", data)

    def on_hunk_detected(self, data: Dict[str, Any]):
        # Log that clutter was found, including the filename and hunk name
        log_payload = {
            "file": data.get("file"),
            "hunk": data.get("hunk_name"),
            "chars_before": len(data.get("before", "")),
            "chars_after": len(data.get("after", ""))
        }
        self._write_entry("CLUTTER_DETECTED", log_payload)

    def on_user_decision(self, approved: bool):
        status = "APPROVED" if approved else "SKIPPED"
        # Record decision alongside the current authoritative state phase
        log_payload = {
            "status": status,
            "phase_at_decision": self.state.phase.name,
            "file_affected": self.state.pending_review.get('file') if self.state.pending_review else None
        }
        self._write_entry("USER_DECISION", log_payload)

    def on_commit_success(self, file_path: str):
        self._write_entry("FILE_COMMITTED", {"path": file_path})

if __name__ == '__main__':
    # Test Harness
    recorder = SessionRecorderMS({'logs_dir': '_test_logs'})
    recorder.on_scan_started({"paths": ["C:/test/project"]})
    recorder.on_hunk_detected({"file": "test.py", "hunk_name": "def test()", "before": "...", "after": ".."})
    print(f"Test entries written to: {recorder.log_file}")

--------------------------------------------------------------------------------
FILE: src\microservices\_SignalBusMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _SignalBusMS
ENTRY_POINT: _SignalBusMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import logging
import threading
from typing import Dict, List, Any, Optional, Callable
from .base_service import BaseService
from .microservice_std_lib import service_metadata, service_endpoint

@service_metadata(
    name='SignalBus', 
    version='1.0.0', 
    description='The Spine: A central pub/sub event hub for decoupled communication between services.', 
    tags=['utility', 'events', 'communication'], 
    capabilities=['pub-sub', 'event-routing'], 
    internal_dependencies=['base_service', 'microservice_std_lib'], 
    external_dependencies=[]
)
class SignalBusMS(BaseService):
    """
    The Spine.
    Provides a thread-safe mechanism for services to subscribe to and emit named signals.
    """
    
    # --- Standard Event Contracts ---
    SIGNAL_PROCESS_START = "process_start"
    SIGNAL_PROCESS_COMPLETE = "process_complete"
    SIGNAL_SPAWN_REQUESTED = "cell_spawn_requested"
    SIGNAL_LOG_APPEND = "log_append"
    SIGNAL_ERROR = "notify_error"

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__('SignalBus')
        self.config = config or {}
        self._subscribers: Dict[str, List[Callable]] = {}
        self._lock = threading.RLock()

    @service_endpoint(
        inputs={'signal_name': 'str', 'callback': 'Callable'}, 
        outputs={}, 
        description='Registers a callback function to trigger when a specific signal is emitted.', 
        tags=['events', 'subscribe']
    )
    def subscribe(self, signal_name: str, callback: Callable):
        """Adds a listener for a specific signal."""
        with self._lock:
            if signal_name not in self._subscribers:
                self._subscribers[signal_name] = []
            if callback not in self._subscribers[signal_name]:
                self._subscribers[signal_name].append(callback)
                self.log_info(f"New subscriber for signal: {signal_name}")

    @service_endpoint(
        inputs={'signal_name': 'str', 'data': 'Any'}, 
        outputs={'delivered_to': 'int'}, 
        description='Broadcasts data to all subscribers of a specific signal.', 
        tags=['events', 'emit']
    )
    def emit(self, signal_name: str, data: Any = None) -> int:
        """Broadcasts a signal to all registered listeners."""
        count = 0
        with self._lock:
            listeners = self._subscribers.get(signal_name, []).copy()
        
        if listeners:
            self.log_info(f"Emitting signal: {signal_name}")
            for callback in listeners:
                try:
                    # Trigger the callback with the data payload
                    callback(data)
                    count += 1
                except Exception as e:
                    self.log_error(f"Error in signal '{signal_name}' callback: {e}")
        
        return count

    @service_endpoint(
        inputs={'signal_name': 'str', 'callback': 'Callable'}, 
        outputs={}, 
        description='Removes a previously registered callback.', 
        tags=['events', 'unsubscribe']
    )
    def unsubscribe(self, signal_name: str, callback: Callable):
        """Removes a listener from a signal."""
        with self._lock:
            if signal_name in self._subscribers:
                try:
                    self._subscribers[signal_name].remove(callback)
                    self.log_info(f"Unsubscribed from signal: {signal_name}")
                except ValueError:
                    pass

if __name__ == '__main__':
    # Test Harness
    bus = SignalBusMS()
    
    def on_hunk_ready(data):
        print(f"UI received hunk: {data}")

    print("--- Testing SignalBusMS ---")
    bus.subscribe("hunk_processed", on_hunk_ready)
    
    # Simulate a backend event
    delivered = bus.emit("hunk_processed", {"file": "app.py", "lines": 50})
    print(f"Signal delivered to {delivered} listeners.")


--------------------------------------------------------------------------------
FILE: src\microservices\_TelemetryServiceMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TelemetryServiceMS
ROLE: Authoritative Session Journal (Task 3)
"""
import logging
import queue
import time
import datetime
from typing import Dict, Any, Optional, List
from microservice_std_lib import service_metadata, service_endpoint
from event_contract import summarize_event, normalize_error

logger = logging.getLogger('TelemetryService')

@service_metadata(
    name='TelemetryService', 
    version='2.0.0', 
    description='Authoritative Session Journal: Maintains a structured event buffer and state snapshot.', 
    tags=['utility', 'logging', 'telemetry'], 
    capabilities=['event-journaling', 'state-snapshotting']
)
class TelemetryServiceMS:
    def __init__(self, state, config: Optional[Dict[str, Any]]=None):
        self.state_authority = state # The AppRuntimeState object
        self.config = config or {}
        
        # 1. Authoritative Journal Storage
        self.event_buffer: List[Dict[str, Any]] = []
        self.buffer_limit = self.config.get('buffer_limit', 1000)
        
        # 2. Local State Snapshot (Enriched for UI consumption)
        self.snapshot = {
            "phase": "IDLE",
            "active_file": None,
            "waiting_for_review": False,
            "current_model": "unknown",
            "last_error": None,
            "counters": {"errors": 0, "commits": 0, "hunks": 0}
        }

    def track(self, event_name: str, payload: Any = None, source: str = "system"):
        """Records a structured event into the ring buffer."""
        try:
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            
            # Normalize payload if it's an error
            safe_payload = payload
            if "error" in event_name:
                safe_payload = normalize_error(payload)
                self.snapshot["last_error"] = safe_payload.get("message")
            
            if event_name == "model_swapped":
                self.snapshot["current_model"] = str(payload)
            
            entry = {
                "ts": timestamp,
                "event": event_name,
                "source": source,
                "payload": self._sanitize_payload(safe_payload),
                "summary": self._generate_summary(event_name, safe_payload)
                            }

                            self.event_buffer.append(entry)
                            if len(self.event_buffer) > self.buffer_limit:
                self.event_buffer.pop(0)
                        except Exception as e:
                            # Fallback if logging fails to prevent recursion loops
                            print(f"Telemetry Error: {e}")

        # Update local counters based on event type
        self._update_counters(event_name)
        
        # Emit signal that telemetry has updated (for future UI refresh)
        # Note: We use a try/except in case the bus isn't available during tests
        try:
            if hasattr(self, 'bus'):
                self.bus.emit("telemetry_updated", self.get_snapshot())
        except:
            pass

    def _sanitize_payload(self, payload: Any) -> Any:
        """Ensures payload is safe for storage and serialization."""
        if isinstance(payload, (str, int, float, bool, type(None))):
            return payload
        if isinstance(payload, dict):
            return {k: str(v)[:100] for k, v in payload.items()} # Limit string size
        return str(payload)[:200]

    def _generate_summary(self, event: str, payload: Any) -> str:
        """Uses the central event contract to generate a summary."""
        try:
            return summarize_event(event, payload)
        except Exception as e:
            return f"Event: {event} (Summary Error: {e})"

    def _update_counters(self, event: str):
        if "error" in event: self.snapshot["counters"]["errors"] += 1
        if "commit_success" == event: self.snapshot["counters"]["commits"] += 1
        if "hunk_ready_for_review" == event: self.snapshot["counters"]["hunks"] += 1

    def get_snapshot(self) -> Dict[str, Any]:
        """Returns a combined view of the authority state and local counters."""
        return {
            "phase": self.state_authority.phase.name,
            "engine_blocked": self.state_authority.engine_blocked,
            "active_file": self.state_authority.pending_review.get('file') if self.state_authority.pending_review else None,
            "current_model": self.snapshot["current_model"],
            "last_error": self.snapshot["last_error"],
            "counters": self.snapshot["counters"]
        }

    def get_recent_events(self, limit: int = 50) -> List[Dict[str, Any]]:
        return self.event_buffer[-limit:]


--------------------------------------------------------------------------------
FILE: src\microservices\_TextChunkerMS.py
--------------------------------------------------------------------------------
import logging
from typing import Any, Dict, List, Optional, Tuple
from .microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('TextChunker')

@service_metadata(name='TextChunker', version='1.0.0', description='Splits text into chunks using various strategies (chars, lines).', tags=['chunking', 'nlp', 'rag'], capabilities=['compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TextChunkerMS:
    """
    The Butcher: A unified service for splitting text into digestible chunks
    for RAG (Retrieval Augmented Generation).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'text': 'str', 'chunk_size': 'int', 'chunk_overlap': 'int'}, outputs={'chunks': 'List[str]'}, description='Standard sliding window split by character count.', tags=['chunking', 'chars'], side_effects=[])
    def chunk_by_chars(self, text: str, chunk_size: int=500, chunk_overlap: int=50) -> List[str]:
        """
        Standard Sliding Window. Best for prose/documentation.
        Splits purely by character count.
        """
        if chunk_size <= 0:
            raise ValueError('chunk_size must be positive')
        chunks = []
        start = 0
        text_length = len(text)
        while start < text_length:
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            if end >= text_length:
                break
            start += chunk_size - chunk_overlap
        return chunks

    @service_endpoint(inputs={'text': 'str', 'max_lines': 'int', 'max_chars': 'int'}, outputs={'chunks': 'List[Dict]'}, description='Line-preserving chunker, best for code.', tags=['chunking', 'lines', 'code'], side_effects=[])
    def chunk_by_lines(self, text: str, max_lines: int=200, max_chars: int=4000) -> List[Dict[str, Any]]:
        """
        Line-Preserving Chunker. Best for Code.
        Respects line boundaries and returns metadata about line numbers.
        """
        lines = text.splitlines()
        chunks = []
        start = 0
        while start < len(lines):
            end = min(start + max_lines, len(lines))
            chunk_str = '\n'.join(lines[start:end])
            while len(chunk_str) > max_chars and end > start + 1:
                end -= 1
                chunk_str = '\n'.join(lines[start:end])
            chunks.append({'text': chunk_str, 'start_line': start + 1, 'end_line': end})
            start = end
        return chunks
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    chunker = TextChunkerMS()
    print('Service ready:', chunker)
    print('--- Prose Chunking ---')
    lorem = 'A' * 100
    result = chunker.chunk_by_chars(lorem, chunk_size=40, chunk_overlap=10)
    for i, c in enumerate(result):
        print(f'Chunk {i}: len={len(c)}')
    print('\n--- Code Chunking ---')
    code = '\n'.join([f"print('Line {i}')" for i in range(1, 10)])
    result_code = chunker.chunk_by_lines(code, max_lines=3, max_chars=100)
    for i, c in enumerate(result_code):
        print(f"Chunk {i}: Lines {c['start_line']}-{c['end_line']}")

--------------------------------------------------------------------------------
FILE: src\microservices\_TkinterAppShellMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterAppShellMS
ENTRY_POINT: _TkinterAppShellMS.py
INTERNAL_DEPENDENCIES: _TkinterThemeManagerMS, microservice_std_lib
EXTERNAL_DEPENDENCIES: None

This module provides the root Tkinter application shell.  It owns the
Tkinter root window, manages global theme propagation and hosts
embedded UI components.  The accompanying theme manager can be
configured via the ``theme`` parameter in the configuration dictionary
passed to ``TkinterAppShellMS``.  Themes can be switched at runtime
through the ``set_theme`` method.
"""

import tkinter as tk
from tkinter import ttk
import logging
from typing import Dict, Any, Optional

from .microservice_std_lib import service_metadata, service_endpoint

# Attempt to import our theme manager.  If unavailable (e.g. missing
# dependencies), theme switching will be disabled and default colours
# will be used.  Import failures are logged for easier debugging.
try:
    from ._TkinterThemeManagerMS import TkinterThemeManagerMS  # type: ignore
except Exception as ex:  # pragma: no cover - runtime import guard
    TkinterThemeManagerMS = None  # type: ignore
    logging.getLogger('AppShell').warning(
        'Theme manager could not be imported: %s.  Falling back to defaults.', ex
    )

logger = logging.getLogger('AppShell')


@service_metadata(
    name='TkinterAppShell',
    version='2.1.0',
    description='The Application Container. Manages the root window, main loop, and global layout.',
    tags=['ui', 'core', 'lifecycle'],
    capabilities=['ui:root', 'ui:gui'],
    internal_dependencies=['_TkinterThemeManagerMS', 'microservice_std_lib'],
    external_dependencies=[],
)
class TkinterAppShellMS:
    """
    The Mother Ship.

    Owns the Tkinter root.  All other UI microservices dock into this
    container.  It initialises and applies theme settings, creates a
    main content frame, and exposes lifecycle hooks such as
    ``launch`` and ``shutdown``.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        self.config: Dict[str, Any] = config or {}

        # Create the root window.  Withdraw initially to avoid a flash
        # of the default theme before we have a chance to apply our
        # selected colours.
        self.root: tk.Tk = tk.Tk()
        self.root.withdraw()

        # Theme manager (microservice).  Allow callers to supply
        # their own instance via ``theme_manager`` to support custom
        # themes or stub implementations.  Otherwise fall back to our
        # builtâ€‘in manager if available.
        self.theme_svc = self.config.get('theme_manager')
        if not self.theme_svc and TkinterThemeManagerMS is not None:
            # Pass through initial theme selection to the theme service
            self.theme_svc = TkinterThemeManagerMS({'theme': self.config.get('theme', 'Dark')})

        # Initialise colours from the theme manager.  ``get_theme()``
        # returns a mutable dictionary.  If no theme manager is
        # available, use an empty dict and rely on default Tk
        # colours.
        self.colors: Dict[str, Any] = self.theme_svc.get_theme() if self.theme_svc else {}

        # Configure the root window and create the main content
        # container before applying the initial theme.  The geometry
        # must be set before calling ``set_theme`` so that we can
        # update the frame backgrounds appropriately.
        self._configure_root()

        # Ensure initial theme is applied to ttk styles and surfaces.
        initial_theme = (self.config.get('theme') or 'Dark')
        self.set_theme(initial_theme)

    def _configure_root(self) -> None:
        """Configure basic properties of the root window."""
        self.root.title(self.config.get('title', 'Microservice OS'))
        self.root.geometry(self.config.get('geometry', '1200x800'))
        bg = self.colors.get('background', '#1e1e1e')
        self.root.configure(bg=bg)

        # Main container
        self.main_container: tk.Frame = tk.Frame(self.root, bg=bg)
        self.main_container.pack(fill='both', expand=True, padx=5, pady=5)

    def _apply_ttk_theme(self) -> None:
        """Applies ttk styling based on the current palette."""
        # Provide sensible defaults to avoid KeyError if a palette is
        # missing keys.  Fallback values mirror VSÂ Codeâ€™s colours.
        bg = self.colors.get('background', '#1e1e1e')
        fg = self.colors.get('foreground', '#d4d4d4')
        panel = self.colors.get('panel_bg', '#252526')
        border = self.colors.get('border', '#3c3c3c')
        btn_bg = self.colors.get('button_bg', panel)
        btn_fg = self.colors.get('button_fg', fg)
        entry_bg = self.colors.get('entry_bg', bg)
        entry_fg = self.colors.get('entry_fg', fg)
        select_bg = self.colors.get('select_bg', self.colors.get('accent', '#007acc'))
        select_fg = self.colors.get('select_fg', '#ffffff')
        heading_bg = self.colors.get('heading_bg', panel)
        heading_fg = self.colors.get('heading_fg', fg)

        style = ttk.Style()
        try:
            # Use 'clam' for better crossâ€‘platform consistency
            style.theme_use('clam')
        except Exception:
            pass

        style.configure('TFrame', background=bg)
        style.configure('TLabel', background=bg, foreground=fg)
        style.configure('TButton', background=btn_bg, foreground=btn_fg)
        style.map('TButton',
                  background=[('active', btn_bg)],
                  foreground=[('active', btn_fg)])

        style.configure('TEntry', fieldbackground=entry_bg, foreground=entry_fg)
        style.configure('TCombobox', fieldbackground=entry_bg, foreground=entry_fg)
        style.map('TCombobox',
                  fieldbackground=[('readonly', entry_bg)],
                  foreground=[('readonly', entry_fg)])

        style.configure('Treeview', background=entry_bg, fieldbackground=entry_bg, foreground=entry_fg, bordercolor=border)
        style.configure('Treeview.Heading', background=heading_bg, foreground=heading_fg)
        style.map('Treeview', background=[('selected', select_bg)], foreground=[('selected', select_fg)])

    @service_endpoint(
        inputs={'theme_name': 'str'},
        outputs={'applied': 'bool'},
        description='Applies a named theme (Dark/Light) via the ThemeManager and refreshes ttk styling.',
        tags=['ui', 'theme'],
        mode='sync',
        side_effects=['ui:refresh'],
    )
    def set_theme(self, theme_name: str) -> bool:
        """
        Switch the active theme.

        The theme manager updates its internal palette in place.  To
        preserve the identity of ``self.colors`` for code that holds
        references to it (e.g. nested UIs), we only refresh the
        mapping if the theme manager returns a *different* dictionary.
        If the returned palette is the same object as ``self.colors``,
        the colours have already been updated in place and clearing
        would wipe them out.  Therefore, we only clear and update
        when necessary.
        """
        name = (theme_name or 'Dark').strip().title()
        if self.theme_svc and hasattr(self.theme_svc, 'set_theme'):
            self.theme_svc.set_theme(name)
            # Acquire the (possibly updated) palette from the theme service
            new_colors = self.theme_svc.get_theme() or {}
            # If the palette is a different object, we want to update
            # our colours dict in place.  Otherwise, the theme manager
            # mutated the existing dict and we must not clear it.
            if new_colors is not self.colors:
                try:
                    self.colors.clear()
                    self.colors.update(new_colors)
                except Exception:
                    # Fall back to assignment if clear/update fails
                    self.colors = dict(new_colors)

        # Apply surfaces to the main window and container
        bg = self.colors.get('background', '#1e1e1e')
        self.root.configure(bg=bg)
        if hasattr(self, 'main_container') and self.main_container.winfo_exists():
            self.main_container.configure(bg=bg)

        # Refresh all ttk widget styles
        self._apply_ttk_theme()

        try:
            # Force Tkinter to process geometry and color updates immediately
            self.root.update_idletasks()
        except Exception:
            pass

        return True

    @service_endpoint(
        inputs={},
        outputs={},
        description='Starts the GUI main loop.',
        tags=['lifecycle', 'start'],
        mode='sync',
        side_effects=['ui:block'],
    )
    def launch(self) -> None:
        """Ignition sequence start."""
        self.root.deiconify()
        logger.info('AppShell Launched.')
        self.root.mainloop()

    @service_endpoint(
        inputs={},
        outputs={'container': 'tk.Frame'},
        description='Returns the main content area for other services to dock into.',
        tags=['ui', 'layout'],
    )
    def get_main_container(self) -> tk.Frame:
        """Other services call this to know where to ``pack()`` themselves."""
        return self.main_container

    @service_endpoint(
        inputs={'title': 'str', 'geometry': 'str'},
        outputs={'window': 'tk.Toplevel'},
        description='Spawns a new top-level window for a child cell.',
        tags=['ui', 'lifecycle']
    )
    def spawn_window(self, title: str = "Child Cell", geometry: str = "1000x800") -> tk.Toplevel:
        """Creates a new Toplevel window that inherits the shell's theme."""
        new_window = tk.Toplevel(self.root)
        new_window.title(title)
        new_window.geometry(geometry)
        bg = self.colors.get('background', '#1e1e1e')
        new_window.configure(bg=bg)
        return new_window

    @service_endpoint(
        inputs={},
        outputs={},
        description='Gracefully shuts down the application.',
        tags=['lifecycle', 'stop'],
        side_effects=['ui:close'],
    )
    def shutdown(self) -> None:
        self.root.quit()


if __name__ == '__main__':  # pragma: no cover
    # Simple manual test.  Note that running Tkinter in a headless
    # environment will raise, so this is primarily for local testing.
    shell = TkinterAppShellMS({'title': 'Test Shell'})
    shell.launch()

--------------------------------------------------------------------------------
FILE: src\microservices\_TkinterSmartExplorerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterSmartExplorerMS
ENTRY_POINT: _TkinterSmartExplorerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import tkinter as tk
from tkinter import ttk
from typing import Dict, Any, Optional, List
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='TkinterSmartExplorer', version='1.0.0', description='A hierarchical tree viewer capable of displaying file systems or JSON data structures.', tags=['ui', 'widget', 'explorer'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TkinterSmartExplorerMS(tk.Frame):
    """
    The Navigator.
    A TreeView widget that expects standard 'Node' dictionaries (name, type, children).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        theme = self.config.get('theme', {})
        super().__init__(parent, bg=theme.get('panel_bg', '#252526'))
        self.tree = ttk.Treeview(self, show='tree headings', selectmode='browse')
        self.tree.heading('#0', text='Explorer', anchor='w')
        vsb = ttk.Scrollbar(self, orient='vertical', command=self.tree.yview)
        hsb = ttk.Scrollbar(self, orient='horizontal', command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.pack(side='left', fill='both', expand=True)
        vsb.pack(side='right', fill='y')
        self.icons = {'folder': 'ðŸ“', 'file': 'ðŸ“„', 'web': 'ðŸŒ', 'unknown': 'â“'}

    @service_endpoint(inputs={'data': 'Dict'}, outputs={}, description="Populates the tree view with a nested dictionary structure (Standard 'Node' format).", tags=['ui', 'update'], side_effects=['ui:update'])
    def load_data(self, data: Dict[str, Any]):
        """
        Ingests a dictionary tree (like from _ScoutMS or _TreeMapperMS).
        """
        for item in self.tree.get_children():
            self.tree.delete(item)
        self._build_node('', data)

    def _build_node(self, parent_id, node_data):
        ntype = node_data.get('type', 'unknown')
        icon = self.icons.get(ntype, self.icons['unknown'])
        text = f"{icon} {node_data.get('name', '???')}"
        item_id = self.tree.insert(parent_id, 'end', text=text, open=True)
        for child in node_data.get('children', []):
            self._build_node(item_id, child)
if __name__ == '__main__':
    root = tk.Tk()
    explorer = TkinterSmartExplorerMS({'parent': root})
    explorer.pack(fill='both', expand=True)
    dummy_data = {'name': 'Project Root', 'type': 'folder', 'children': [{'name': 'src', 'type': 'folder', 'children': []}, {'name': 'README.md', 'type': 'file'}]}
    explorer.load_data(dummy_data)
    root.mainloop()

--------------------------------------------------------------------------------
FILE: src\microservices\_TkinterThemeManagerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterThemeManagerMS
ENTRY_POINT: _TkinterThemeManagerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None

This module defines and manages the colour palette used throughout the
application.  A `TkinterThemeManagerMS` class encapsulates two
predefined themesâ€”`Dark` and `Light`â€”inspired by the Visual Studio
Code default themes.  Themes can be swapped at runtime and are
returned as mutable dictionaries so that UI components can reference
their values directly and respond to changes.

To add a new theme, extend the `THEMES` dictionary with the
appropriate keys.  See the definitions of `DARK_THEME` and
`LIGHT_THEME` for guidance on required keys.
"""

from typing import Dict, Any, Optional
from .microservice_std_lib import service_metadata, service_endpoint


"""
Defines colour palettes for supported themes.

These palettes draw inspiration from the Visual Studio Code default
dark and light themes to provide a comfortable and familiar
development environment.  Colours are carefully chosen to avoid
highâ€‘contrast combinations that can lead to eye strain while still
maintaining adequate contrast for accessibility.  Should additional
themes be added in the future, follow the same structure and include
keys for all UI elements consumed throughout the UI.
"""

# VisualÂ StudioÂ Code inspired dark theme.  The underlying palette
# uses neutral greys and blue accents similar to VSÂ Codeâ€™s default
# dark theme.  Colours have been adjusted to be less harsh while
# maintaining sufficient contrast.
DARK_THEME: Dict[str, Any] = {
    'name': 'Dark',
    # Primary backgrounds and foregrounds
    'background': '#1e1e1e',        # main window background
    'foreground': '#d4d4d4',        # primary text colour
    'panel_bg': '#252526',          # toolbar, config panels
    'border': '#3c3c3c',            # borders and separators
    'accent': '#007acc',            # accent colour for buttons and highlights
    'error': '#f44747',             # error messages / destructive actions
    'success': '#89d185',           # success messages

    # Fonts (kept here for completeness but rarely overridden)
    'font_main': ('Segoe UI', 10),
    'font_mono': ('Consolas', 11),

    # Button styling
    'button_bg': '#0e639c',         # primary button background
    'button_fg': '#ffffff',         # primary button text colour

    # Input/entry styling
    'entry_bg': '#1e1e1e',          # entry and text box background
    'entry_fg': '#d4d4d4',          # entry text colour

    # Selection colours
    'select_bg': '#264f78',         # selection background (lists/text)
    'select_fg': '#ffffff',         # selection text colour

    # Table/heading styling
    'heading_bg': '#3c3c3c',        # table headings background
    'heading_fg': '#ffffff',        # table headings text colour
    'heading_font': ('Segoe UI', 12, 'bold'),
}

# VisualÂ StudioÂ Code inspired light theme.  The palette uses soft
# greys with a blue accent, mirroring VSÂ Codeâ€™s light theme while
# avoiding stark white backgrounds.  Text colours are dark greys
# to maintain readability without excessive contrast.
LIGHT_THEME: Dict[str, Any] = {
    'name': 'Light',
    # Primary backgrounds and foregrounds
    'background': '#ffffff',        # main window background (pure white)
    'foreground': '#333333',        # primary text colour (dark grey)
    'panel_bg': '#f3f3f3',          # toolbar, config panels
    'border': '#dcdcdc',            # borders and separators
    'accent': '#0066b8',            # accent colour for buttons and highlights
    'error': '#d13438',             # error messages / destructive actions
    'success': '#107c10',           # success messages

    # Fonts
    'font_main': ('Segoe UI', 10),
    'font_mono': ('Consolas', 11),

    # Button styling
    'button_bg': '#e7e7e7',         # primary button background
    'button_fg': '#333333',         # primary button text colour

    # Input/entry styling
    'entry_bg': '#ffffff',          # entry and text box background
    'entry_fg': '#333333',          # entry text colour

    # Selection colours
    'select_bg': '#add6ff',         # selection background (lists/text)
    'select_fg': '#000000',         # selection text colour

    # Table/heading styling
    'heading_bg': '#e2e2e2',        # table headings background
    'heading_fg': '#333333',        # table headings text colour
    'heading_font': ('Segoe UI', 12, 'bold'),
}

# Registry of all supported themes.  Keys should be titleâ€‘cased to
# simplify lookups when user preferences are normalised by
# `TkinterThemeManagerMS.set_theme()`.
THEMES: Dict[str, Dict[str, Any]] = {
    'Dark': DARK_THEME,
    'Light': LIGHT_THEME,
}


@service_metadata(
    name='TkinterThemeManager',
    version='1.2.0',
    description='Centralised configuration for UI colours and fonts.',
    tags=['ui', 'config', 'theme'],
    capabilities=['ui:style'],
    internal_dependencies=['microservice_std_lib'],
    external_dependencies=[],
)
class TkinterThemeManagerMS:
    """
    The Stylist: Holds the colour palette and font settings.

    All UI components query this service to decide how to draw themselves.
    The palette is returned as a mutable dictionary so that callers can
    hold a reference and receive updates in place when switching themes.

    Configuration options:
      - ``theme``: one of the keys defined in ``THEMES`` (default ``'Dark'``)
      - ``overrides``: a dictionary of key/value pairs used to override
        default theme values.  Overrides persist across theme changes.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        self.config = config or {}

        # Determine the requested base theme, falling back to Dark if unknown.
        requested = self.config.get('theme', 'Dark')
        requested = (requested or 'Dark').strip().title()
        if requested not in THEMES:
            requested = 'Dark'

        # Active theme name and palette.  ``self.theme`` is mutable and
        # updated in place on theme changes to preserve object identity.
        self.theme_name: str = requested
        # copy() to ensure modifications on ``self.theme`` do not affect
        # the global template stored in ``THEMES``.
        self.theme: Dict[str, Any] = THEMES[self.theme_name].copy()

        # Persist any user overrides.  If overrides are supplied they
        # should override defaults on initialisation and on subsequent
        # theme changes.  A shallow copy is sufficient because values
        # should be primitives or tuples.
        self._overrides = dict(self.config.get('overrides', {}))
        if self._overrides:
            self.theme.update(self._overrides)

    @service_endpoint(
        inputs={},
        outputs={'theme': 'Dict'},
        description='Returns the current active theme dictionary.',
        tags=['ui', 'read'],
    )
    def get_theme(self) -> Dict[str, Any]:
        """Return the current theme palette."""
        return self.theme

    @service_endpoint(
        inputs={},
        outputs={'theme_name': 'str'},
        description='Returns the current active theme name.',
        tags=['ui', 'read'],
    )
    def get_theme_name(self) -> str:
        """Return the name of the current theme (e.g. ``'Dark'``)."""
        return self.theme_name

    @service_endpoint(
        inputs={'theme_name': 'str'},
        outputs={'applied': 'bool'},
        description='Switches the active theme (Dark/Light).',
        tags=['ui', 'write'],
        side_effects=['ui:refresh'],
    )
    def set_theme(self, theme_name: str) -> bool:
        """
        Switch the current theme to ``theme_name``.

        Unknown theme names fall back to ``'Dark'``.  Overrides stored
        during initialisation are reâ€‘applied after the base palette is
        swapped so that user customisations persist across theme changes.
        The method always returns ``True``.
        """
        name = (theme_name or 'Dark').strip().title()
        if name not in THEMES:
            name = 'Dark'
        self.theme_name = name

        # Build a fresh palette from the base and reapply overrides.  The
        # resulting palette is merged into the existing ``self.theme``
        # dictionary to preserve its identity for any UI components holding
        # references.  This ensures calls like ``refresh_theme()`` only need
        # to reconfigure widget properties rather than replace entire dicts.
        new_theme: Dict[str, Any] = THEMES[self.theme_name].copy()
        if self._overrides:
            new_theme.update(self._overrides)

        # Update the existing dict in place rather than reassigning.
        self.theme.clear()
        self.theme.update(new_theme)
        return True

    @service_endpoint(
        inputs={'key': 'str', 'value': 'Any'},
        outputs={},
        description='Updates a specific theme attribute (e.g., changing accent colour).',
        tags=['ui', 'write'],
        side_effects=['ui:refresh'],
    )
    def update_key(self, key: str, value: Any) -> None:
        """
        Update an individual key in the current theme.

        Overrides are persisted so that subsequent calls to
        ``set_theme()`` do not wipe out the change.  A missing key will
        simply be added to the palette.
        """
        # Update the current palette
        self.theme[key] = value
        # Persist override for future theme switches
        self._overrides[key] = value


if __name__ == '__main__':  # pragma: no cover
    # Simple manual test: print palette names and accents
    svc = TkinterThemeManagerMS({'theme': 'Dark'})
    print('Initial:', svc.get_theme_name(), svc.get_theme()['accent'])
    svc.set_theme('Light')
    print('After switch:', svc.get_theme_name(), svc.get_theme()['accent'])
--------------------------------------------------------------------------------
FILE: src\microservices\_TreeMapperMS.py
--------------------------------------------------------------------------------
import os
import datetime
import logging
from pathlib import Path
from typing import Any, Dict, List, Set, Optional
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_EXCLUDES = {'.git', '__pycache__', '.idea', '.vscode', 'node_modules', '.venv', 'env', 'venv', 'dist', 'build', '.DS_Store'}
logger = logging.getLogger('TreeMapper')

@service_metadata(name='TreeMapper', version='1.0.0', description='Generates ASCII-art style directory maps of the file system.', tags=['filesystem', 'map', 'visualization'], capabilities=['filesystem:read'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TreeMapperMS:
    """
    The Cartographer: Generates ASCII-art style directory maps.
    Useful for creating context snapshots for LLMs.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'root_path': 'str', 'additional_exclusions': 'Set[str]', 'use_default_exclusions': 'bool'}, outputs={'tree_map': 'str'}, description='Generates an ASCII tree map of the directory.', tags=['filesystem', 'visualization'], side_effects=['filesystem:read'])
    def generate_tree(self, root_path: str, additional_exclusions: Optional[Set[str]]=None, use_default_exclusions: bool=True) -> str:
        start_path = Path(root_path).resolve()
        if not start_path.exists():
            return f"Error: Path '{root_path}' does not exist."
        exclusions = set()
        if use_default_exclusions:
            exclusions.update(DEFAULT_EXCLUDES)
        if additional_exclusions:
            exclusions.update(additional_exclusions)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        lines = [f'Project Map: {start_path.name}', f'Generated: {timestamp}', '-' * 40, f'ðŸ“ {start_path.name}/']
        logger.info(f'Mapping directory: {start_path}')
        self._walk(start_path, '', lines, exclusions)
        return '\n'.join(lines)

    def _walk(self, directory: Path, prefix: str, lines: List[str], exclusions: Set[str]):
        try:
            children = sorted([p for p in directory.iterdir() if p.name not in exclusions], key=lambda x: (not x.is_dir(), x.name.lower()))
        except PermissionError:
            lines.append(f'{prefix}â””â”€â”€ ðŸš« [Permission Denied]')
            return
        count = len(children)
        for index, path in enumerate(children):
            is_last = index == count - 1
            connector = 'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '
            if path.is_dir():
                lines.append(f'{prefix}{connector}ðŸ“ {path.name}/')
                extension = '    ' if is_last else 'â”‚   '
                self._walk(path, prefix + extension, lines, exclusions)
            else:
                lines.append(f'{prefix}{connector}ðŸ“„ {path.name}')
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    svc = TreeMapperMS()
    print('Service ready:', svc)
    print('\n--- Map of Current Dir ---')
    tree = svc.generate_tree('.', additional_exclusions={'__pycache__'})
    print(tree)

--------------------------------------------------------------------------------
FILE: src\microservices\_VectorFactoryMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import os
import uuid
import logging
import shutil
from typing import List, Dict, Any, Optional, Protocol, Union
from pathlib import Path
REQUIRED = ['chromadb', 'faiss-cpu', 'numpy']
MISSING = []
for lib in REQUIRED:
    clean_lib = lib.split('>=')[0].replace('-', '_')
    if clean_lib == 'faiss_cpu':
        clean_lib = 'faiss'
    if importlib.util.find_spec(clean_lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _VectorFactoryMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
from .microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('VectorFactory')

class VectorStore(Protocol):
    """The contract that all vector backends must fulfill."""

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]) -> None:
        ...

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        ...

    def count(self) -> int:
        ...

    def clear(self) -> None:
        ...

class FaissVectorStore:
    """Local, RAM-heavy, fast vector store using FAISS."""

    def __init__(self, index_path: str, dimension: int):
        import numpy as np
        import faiss
        self.np = np
        self.faiss = faiss
        self.index_path = index_path
        self.dim = dimension
        self.metadata_store = []
        if os.path.exists(index_path):
            try:
                self.index = faiss.read_index(index_path)
                meta_path = index_path + '.meta.json'
                if os.path.exists(meta_path):
                    import json
                    with open(meta_path, 'r') as f:
                        self.metadata_store = json.load(f)
            except Exception as e:
                logger.error(f'Failed to load FAISS index: {e}')
                self.index = faiss.IndexFlatL2(dimension)
        else:
            self.index = faiss.IndexFlatL2(dimension)

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]):
        if not embeddings:
            return
        vecs = self.np.array(embeddings).astype('float32')
        self.index.add(vecs)
        self.metadata_store.extend(metadatas)
        self._save()

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        if self.index.ntotal == 0:
            return []
        q_vec = self.np.array([query_vector]).astype('float32')
        distances, indices = self.index.search(q_vec, k)
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx != -1 and idx < len(self.metadata_store):
                entry = self.metadata_store[idx].copy()
                entry['score'] = float(dist)
                results.append(entry)
        return results

    def count(self) -> int:
        return self.index.ntotal

    def clear(self):
        self.index.reset()
        self.metadata_store = []
        self._save()

    def _save(self):
        self.faiss.write_index(self.index, self.index_path)
        import json
        with open(self.index_path + '.meta.json', 'w') as f:
            json.dump(self.metadata_store, f)

class ChromaVectorStore:
    """Persistent, feature-rich vector store using ChromaDB."""

    def __init__(self, persist_dir: str, collection_name: str):
        import chromadb
        logging.getLogger('chromadb').setLevel(logging.ERROR)
        self.client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.client.get_or_create_collection(collection_name)

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]):
        if not embeddings:
            return
        ids = [str(uuid.uuid4()) for _ in embeddings]
        clean_metas = [{k: str(v) if isinstance(v, (list, dict)) else v for k, v in m.items()} for m in metadatas]
        docs = [m.get('content', '') for m in metadatas]
        self.collection.add(ids=ids, embeddings=embeddings, metadatas=clean_metas, documents=docs)

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        results = self.collection.query(query_embeddings=[query_vector], n_results=k)
        output = []
        if not results['ids']:
            return []
        for i in range(len(results['ids'][0])):
            meta = results['metadatas'][0][i]
            if meta:
                entry = meta.copy()
                entry['score'] = results['distances'][0][i] if results['distances'] else 0.0
                entry['id'] = results['ids'][0][i]
                output.append(entry)
        return output

    def count(self) -> int:
        return self.collection.count()

    def clear(self):
        name = self.collection.name
        self.client.delete_collection(name)
        self.collection = self.client.get_or_create_collection(name)

@service_metadata(name='VectorFactory', version='1.0.0', description='Factory for creating VectorStore instances (FAISS, Chroma).', tags=['vector', 'factory', 'db'], capabilities=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=['chromadb', 'faiss', 'numpy'])
class VectorFactoryMS:
    """
    The Switchboard: Returns the appropriate VectorStore implementation
    based on configuration.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'backend': 'str', 'config': 'Dict'}, outputs={'store': 'VectorStore'}, description='Creates and returns a configured VectorStore instance.', tags=['vector', 'create'], side_effects=[])
    def create(self, backend: str, config: Dict[str, Any]) -> VectorStore:
        """
        :param backend: 'faiss' or 'chroma'
        :param config: Dict containing 'path', 'dim' (for FAISS), or 'collection' (for Chroma)
        """
        logger.info(f'Initializing Vector Store: {backend.upper()}')
        if backend == 'faiss':
            path = config.get('path', 'vector_index.bin')
            dim = config.get('dim', 384)
            return FaissVectorStore(path, dim)
        elif backend == 'chroma':
            path = config.get('path', './chroma_db')
            name = config.get('collection', 'default_collection')
            return ChromaVectorStore(path, name)
        else:
            raise ValueError(f'Unknown backend: {backend}')
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    print('--- Testing VectorFactoryMS ---')
    mock_vec = [0.1, 0.2, 0.3, 0.4]
    mock_meta = {'text': 'Hello World', 'source': 'test'}
    factory = VectorFactoryMS()
    print('Service ready:', factory)
    print('\n[Testing FAISS]')
    try:
        faiss_store = factory.create('faiss', {'path': 'test_faiss.index', 'dim': 4})
        faiss_store.add([mock_vec], [mock_meta])
        print(f'Count: {faiss_store.count()}')
        res = faiss_store.search(mock_vec, 1)
        if res:
            print(f"Search Result: {res[0]['text']}")
        if os.path.exists('test_faiss.index'):
            os.remove('test_faiss.index')
        if os.path.exists('test_faiss.index.meta.json'):
            os.remove('test_faiss.index.meta.json')
    except ImportError:
        print('Skipping FAISS test (library not installed)')
    except Exception as e:
        print(f'FAISS Test Failed: {e}')
    print('\n[Testing Chroma]')
    try:
        chroma_store = factory.create('chroma', {'path': './test_chroma_db', 'collection': 'test_col'})
        chroma_store.add([mock_vec], [mock_meta])
        print(f'Count: {chroma_store.count()}')
        res = chroma_store.search(mock_vec, 1)
        if res:
            print(f"Search Result: {res[0]['text']}")
        if os.path.exists('./test_chroma_db'):
            shutil.rmtree('./test_chroma_db')
    except ImportError:
        print('Skipping Chroma test (library not installed)')
    except Exception as e:
        print(f'Chroma Test Failed: {e}')

--------------------------------------------------------------------------------
FILE: src\microservices\__init__.py
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _tools\fix_microservice_imports.py
--------------------------------------------------------------------------------
import re
import sys
from pathlib import Path
import importlib

ROOT = Path(__file__).resolve().parents[1]  # adjust if you place script elsewhere
SRC = ROOT / "src"
MS_DIR = SRC / "microservices"

# Match: from microservice_std_lib import a, b, BaseService, c
BAD_FROM_RE = re.compile(
    r"^(?P<indent>\s*)from\s+(?P<dots>\.?)microservice_std_lib\s+import\s+(?P<items>.+?)\s*$",
    re.MULTILINE,
)

BASE_IMPORT_RE = re.compile(
    r"^\s*from\s+\.?base_service\s+import\s+BaseService\s*$",
    re.MULTILINE,
)

def split_import_items(items: str) -> list[str]:
    # naive but good enough for your import style: comma-separated names
    parts = [p.strip() for p in items.split(",")]
    return [p for p in parts if p]

def join_import_items(items: list[str]) -> str:
    return ", ".join(items)

def fix_file(path: Path) -> bool:
    original = path.read_text(encoding="utf-8")
    text = original

    changed = False

    # 1) Fix "from microservice_std_lib import ... BaseService ..."
    def repl(m: re.Match) -> str:
        nonlocal changed
        indent = m.group("indent")
        dots = m.group("dots") or ""
        items = split_import_items(m.group("items"))
        if "BaseService" not in items:
            return m.group(0)

        items = [x for x in items if x != "BaseService"]
        changed = True
        return f"{indent}from {dots}microservice_std_lib import {join_import_items(items)}"

    text = BAD_FROM_RE.sub(repl, text)

    # 2) If the file uses BaseService, ensure it imports it from base_service
    uses_baseservice = "BaseService" in text
    has_base_import = bool(BASE_IMPORT_RE.search(text))

    if uses_baseservice and not has_base_import:
        # Insert after the last std_lib import block near top if possible.
        insert_after = None

        # Prefer right after microservice_std_lib import line if present
        ms_std = re.search(r"^from\s+microservice_std_lib\s+import\s+.*$", text, re.MULTILINE)
        if ms_std:
            insert_after = ms_std.end()

        if insert_after is not None:
            # Check if the existing import used a dot
            ms_std_match = re.search(r"^from\s+(?P<dots>\.?)microservice_std_lib", text, re.MULTILINE)
            dots = ms_std_match.group("dots") if ms_std_match else ""
            
            text = text[:insert_after] + f"\nfrom {dots}base_service import BaseService" + text[insert_after:]
        else:
            # fallback: add near top (after initial docstring/comments)
            lines = text.splitlines(True)
            i = 0
            if lines and lines[0].lstrip().startswith('"""'):
                # skip docstring block
                i = 1
                while i < len(lines) and '"""' not in lines[i]:
                    i += 1
                if i < len(lines):
                    i += 1
            # skip blank lines
            while i < len(lines) and lines[i].strip() == "":
                i += 1
            lines.insert(i, "from .base_service import BaseService\n")
            text = "".join(lines)

        changed = True

    if changed and text != original:
        backup = path.with_suffix(path.suffix + ".bak")
        if not backup.exists():
            backup.write_text(original, encoding="utf-8")
        path.write_text(text, encoding="utf-8")
        return True

    return False

def verify_imports():
    # mirror app.py path injection
    sys.path.insert(0, str(SRC))
    sys.path.insert(0, str(MS_DIR))

    failures = []
    for py in sorted(MS_DIR.glob("*.py")):
        name = py.stem
        if name in {"base_service", "microservice_std_lib"}:
            continue
        try:
            importlib.import_module(name)
        except Exception as e:
            failures.append((name, repr(e)))

    if failures:
        print("\n[IMPORT VERIFY] Failures:")
        for name, err in failures:
            print(f" - {name}: {err}")
        raise SystemExit(1)
    else:
        print("\n[IMPORT VERIFY] All microservices imported successfully.")

def main():
    if not MS_DIR.exists():
        raise SystemExit(f"Microservices folder not found: {MS_DIR}")

    touched = []
    for py in sorted(MS_DIR.glob("*.py")):
        if py.name.endswith(".bak"):
            continue
        if fix_file(py):
            touched.append(py.name)

    print(f"[FIX] Updated {len(touched)} files.")
    for t in touched:
        print(f" - {t}")

    verify_imports()

if __name__ == "__main__":
    main()



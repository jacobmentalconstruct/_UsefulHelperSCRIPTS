Dump: C:\Users\petya\Documents\Jacob's BIN\_UsefulHelperSCRIPTS


--------------------------------------------------------------------------------
FILE: .gitignore
--------------------------------------------------------------------------------
# ===========================
# üêç Python Essentials
# ===========================
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# ===========================
#  virtualenv (Local Environments)
# ===========================
# Typical names for virtual environments
venv/
.venv/
env/
ENV/
env.bak/
venv.bak/

# ===========================
# üõ°Ô∏è Secrets & Security (NEVER COMMIT THESE)
# ===========================
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
secrets.json
api_keys.txt
token.json

# ===========================
# üíæ Databases & Local Data
# ===========================
# You usually don't want to commit your actual RAG databases
*.sqlite
*.sqlite3
*.db
# Unless strictly necessary for the app structure
!distributable_data.db

# ===========================
# ü§ñ AI / ML Artifacts
# ===========================
# Large model weights (too big for standard Git)
*.ckpt
*.safetensors
*.pt
*.pth
*.gguf
*.bin
*.h5

# Local model folders (if you download Ollama models locally)
models/
model_cache/

# ===========================
# üñºÔ∏è Generated Media
# ===========================
# Don't commit thousands of test images from _FirstHOME
generated_images/
output_images/
temp_generations/

# ===========================
# üîß IDE & OS Settings
# ===========================
# Windows
Thumbs.db
ehthumbs.db
Desktop.ini

# Mac
.DS_Store
.AppleDouble
.LSOverride

# VS Code
.vscode/
*.code-workspace

# ===========================
# üöß WIP / GHOST APPS
# ===========================
# Add the folder names of apps you are working on but 
# aren't ready to push to the suite yet.

____mini-scripts-collection-bin____
____toy-chest-of-experiments____
____WIP____
--------------------------------------------------------------------------------
FILE: LICENSE.md
--------------------------------------------------------------------------------
MIT License

Copyright (c) 2025 Jacob Lambert

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

--------------------------------------------------------------------------------
FILE: MENU.bat
--------------------------------------------------------------------------------
@echo off
:: Launches the Menu App without opening a lingering command prompt window
start "" "pyw" "_UsefulHelperScriptsMENU\src\app.pyw"
--------------------------------------------------------------------------------
FILE: THEME_SPEC.md
--------------------------------------------------------------------------------
## **THEME\_SPEC.md**

### **üé® Suite-Wide Visual Identity**

**Version:** 1.0 (Based on Project Mapper Aesthetic)  
**Philosophy:** High-contrast dark mode using "Midnight Blue" and "Deep Slate" foundations with "Deep Blue" interactive accents.

### ---

**1\. Core Color Palette**

| Element | Hex Code | Usage |
| :---- | :---- | :---- |
| **Primary Background** | \#1e1e2f | Main Window background and selector modal background.  |
| **Secondary Background** | \#151521 | Listboxes, Text Areas, and "Inset" regions.  |
| **Widget Surface** | \#2a2a3f | Buttons and Toolbars before interaction.  |
| **Action Accent** | \#007ACC | Selection highlights, Hover states, and "Create" buttons.  |
| **Status Accent** | \#00FF00 | Terminal outputs or success messages in text areas. |

### ---

**2\. Typography**

* **Primary UI Font:** Segoe UI, size 9 or 10\.

* **Code/Mono Font:** Consolas, size 9\.

* **Heading Style:** Segoe UI, 10, Bold.

### ---

**3\. Widget Specifications (Tkinter/ttk)**

To maintain alignment in future tools, follow these standard styling rules:

* **Listboxes:** \* borderwidth: 0  
  * highlightthickness: 1  
  * highlightbackground: \#333333

* **Buttons (TButton):**  
  * Use the clam theme as a base.

  * Map the active (hover) state to the **Action Accent** (\#007ACC).

* **Input Fields:**  
  * Use insertbackground: white to ensure the blinking cursor is visible on dark backgrounds.

### ---

**4\. Component Implementation Logic**

When building a new microservice or app, ensure the UI initialization includes:

1. Setting the root window background to \#1e1e2f.  
2. Configuring a ttk.Style that maps background colors for TFrame and TLabel to match the Primary Background.  
3. Explicitly setting Canvas backgrounds to \#1e1e2f to avoid the default Tkinter gray flickering.


--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\.txt
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\AgentSpec_list-of-tools.txt
--------------------------------------------------------------------------------
# TOOL DEFINITIONS (STRICT INTERFACE)

## Tool: SpinnerThingyMaBobberMS
Description: The Visualizer: An interactive spinner widget.
Functions:
  - launch()
    # Starts the Tkinter main event loop
  - handle_keypress(event)
  - get_neon_color(offset)
  - draw_arc(cx, cy, radius, width, start, extent, color)
  - animate()

## Tool: EnvironmentManagerMS
Description: The Operator.
Functions:
  - resolve_python(project_path, config_override)
    # Priority:
1
  - launch_script(project_path, script_rel_path, env_vars)

## Tool: PythonChunkerMS
Description: Specialized Python AST Chunker.
Functions:
  - get_health()
    # Returns the operational status of the PythonChunkerMS
  - chunk(content)
    # Parses Python source into semantic CodeChunks

## Tool: ContentExtractorMS
Description: The Decoder.
Functions:
  - get_health()
    # Returns the operational status and library availability
  - extract_text(blob, mime_type)
    # Main routing logic for extraction

## Tool: ServiceRegistryMS
Description: The Tokenizer (v2): Scans a library of Python microservices and generates
Functions:
  - scan(save_to)

## Tool: TelemetryServiceMS
Description: The Nervous System.
Functions:
  - get_health()
    # Returns the operational status of the TelemetryServiceMS
  - start()
    # Begins the GUI update loop
  - ping()
    # Allows an agent to verify the pulse of the UI loop

## Tool: TreeMapperMS
Description: The Cartographer: Generates ASCII-art style directory maps.
Functions:
  - generate_tree(root_path, additional_exclusions, use_default_exclusions)

## Tool: ChalkBoardMS
Description: No description.
Functions:
  - loaded()
    # Called by JS when the page is ready
  - log_action(action_name)
    # Called by JS when user interacts
  - update_sign(text, theme)
    # Updates the embedded HTML via JS injection
  - trigger_effect(effect)
    # Triggers CSS animations like 'shake'

## Tool: NeuralGraphViewerMS
Description: No description.
Functions:
  - bind_services(cartridge, neural)
  - run_search(event)
  - load_from_db(db_path)
    # Loads graph data from SQLite
  - on_resize(event)
  - on_double_click(event)
  - on_click(event)
  - on_release(event)
  - on_drag(event)
  - on_hover(event)
  - on_zoom(amount)
  - on_windows_scroll(event)
  - animate()
    # The Heartbeat Loop

## Tool: DiffEngineMS
Description: The Timekeeper: Implements a 'Hybrid' versioning architecture.
Functions:
  - update_file(path, new_content, author)
    # The Atomic Update Operation:
1
  - get_head(path)
    # Fast retrieval of current content
  - get_history(path)
    # Retrieves the full evolution history of a file

## Tool: CodeFormatterMS
Description: The Architect.
Functions:
  - normalize_code(content, use_tabs, spaces)
    # Pure logic endpoint: Takes string, returns string + patch
  - format_file(file_path, use_tabs, spaces)
    # Filesystem endpoint: In-place repair of a file

## Tool: FingerprintScannerMS
Description: The Detective: Scans a directory tree and generates a deterministic
Functions:
  - scan_project(root_path)
    # Scans the project and returns a comprehensive state object

## Tool: CartridgeServiceMS
Description: The Source of Truth.
Functions:
  - get_vector_dim()
    # Retrieves the expected vector dimension from the manifest spec
  - initialize_manifest()
    # Populates the boot sector with strict RagFORGE Cartridge Schema (UNCF) v1
  - set_manifest(key, value)
    # Upsert metadata key
  - get_manifest(key)
    # Retrieve metadata key
  - validate_cartridge()
    # Quality Control: Checks if the cartridge is Agent-Safe
  - store_file(vfs_path, origin_path, content, blob, mime_type, origin_type)
    # The Universal Input Method
  - get_pending_files(limit)
    # Fetches files waiting for the Refinery
  - update_status(file_id, status, metadata)
  - ensure_directory(vfs_path)
    # Idempotent insert for VFS directories
  - get_status_flags()
    # Returns key manifest status flags in a single call
  - list_files(prefix, status, limit)
    # Enumerate files in the cartridge (optionally filtered by VFS prefix and/or status)
  - get_file_record(vfs_path)
    # Fetch a single file record by VFS path
  - list_directories(prefix)
    # Enumerate directories in the cartridge VFS
  - get_directory_tree(root)
    # Builds a nested directory tree starting at `root` ("" for full tree)
  - get_status_summary()
    # Counts files by status and provides a quick cartridge overview
  - add_node(node_id, node_type, label, data)
  - add_edge(source, target, relation, weight)
  - search_embeddings(query_vector, limit)
    # Performs semantic search using sqlite-vec

## Tool: SandboxManagerMS
Description: The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project.
Functions:
  - init_sandbox(force)
    # Creates or resets the sandbox by mirroring the live project
  - reset_sandbox()
    # Discards all sandbox changes and re-syncs from live
  - get_diff()
    # Compares Sandbox vs Live
  - promote_changes()
    # Applies changes from Sandbox to Live

## Tool: SearchEngineMS
Description: The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching).
Functions:
  - search(db_path, query, limit)
    # Main entry point

## Tool: LibrarianMS
Description: No description.
Functions:
  - generate_catalog(output_file)

## Tool: LexicalSearchMS
Description: The Librarian's Index: A lightweight, AI-free search engine.
Functions:
  - add_document(doc_id, text, metadata)
    # Adds or updates a document in the index
  - search(query, top_k)
    # Performs a BM25 Ranked Search

## Tool: ArchiveBotMS
Description: No description.
Functions:
  - create_backup(source_path, output_dir, extra_exclusions, use_default_exclusions)

## Tool: CognitiveMemoryMS
Description: The Hippocampus: Manages Short-Term (Working) Memory and orchestrates 
Functions:
  - add_entry(role, content, metadata)
    # Adds an item to working memory and persists it
  - get_context(limit)
    # Returns the most recent conversation history formatted for an LLM
  - get_full_history()
    # Returns the raw list of memory objects
  - commit_turn()
    # Signal that a "Turn" (User + AI response) is complete

## Tool: CodeChunkerMS
Description: The Surgeon (Pure Python Edition): Splits code into semantic blocks
Functions:
  - chunk_file(file_path, max_chars)
    # Reads a file and breaks it into logical blocks based on indentation

## Tool: PromptVaultMS
Description: The Vault: A persistent SQLite store for managing, versioning, 
Functions:
  - create_template(slug, title, content, author, tags)
    # Creates a new prompt template with an initial version 1
  - add_version(slug, content, author)
    # Adds a new version to an existing template
  - get_template(slug)
    # Retrieves a full template with all history
  - render(slug, context)
    # Fetches the latest version and renders it with Jinja2
  - list_slugs()

## Tool: ThoughtStreamMS
Description: The Neural Inspector: A UI widget for displaying a stream of AI thoughts/logs
Functions:
  - add_thought_bubble(filename, chunk_id, content, vector_preview, color)
    # Mimics the 'InspectorFrame' from your React code

## Tool: NetworkLayoutMS
Description: The Topologist: Calculates visual coordinates for graph nodes using
Functions:
  - calculate_layout(nodes, edges, algorithm)
    # Computes (x, y) coordinates for the given graph

## Tool: NeuralServiceMS
Description: The Brain Interface: Orchestrates local AI operations via Ollama for inference and embeddings.
Functions:
  - update_models(fast_model, smart_model, embed_model)
    # Called by the UI Settings Modal to change models on the fly
  - get_available_models()
    # Fetches list from Ollama for the UI dropdown
  - check_connection()
    # Pings Ollama to see if it's alive
  - get_embedding(text)
    # Generates a vector using the configured embedding model
  - request_inference(prompt, tier, format_json)
    # Synchronous inference request
  - process_parallel(items, worker_func)
    # Helper to run a function across many items using a ThreadPool

## Tool: AuthMS
Description: ROLE: Simple authentication microservice providing username/password login
Functions:
  - login(username, password)
    # Attempt to log in with the provided username and password
  - validate_session(token)
    # Check if a serialized token is valid and not expired

## Tool: ContextPackerMS
Description: The Packer: Walks a directory and dumps all text-readable files 
Functions:
  - pack_directory(root_path, output_filename, additional_excludes)
    # Walks the directory and writes file contents to the output file

## Tool: RegexWeaverMS
Description: The Weaver: A fault-tolerant dependency extractor.
Functions:
  - extract_dependencies(content, language)
    # Scans code content for import statements

## Tool: TkinterThemeManagerMS
Description: The Stylist: Holds the color palette and font settings.
Functions:
  - get_theme()
  - update_key(key, value)

## Tool: CodeGrapherMS
Description: The Cartographer of Logic: Parses Python code to extract high-level 
Functions:
  - scan_directory(root_path)
    # Recursively scans a directory for

## Tool: ScannerMS
Description: The Scanner: Walks the file system, filters junk, and detects binary files.
Functions:
  - is_binary(file_path)
    # Determines if a file is binary using two heuristics:
1
  - scan_directory(root_path)
    # Recursively scans a directory and returns a JSON-compatible tree
  - flatten_tree(tree_node)
    # Helper to extract all valid file paths from a tree node 
(e

## Tool: ExplorerWidgetMS
Description: A standalone file system tree viewer.
Functions:
  - refresh_tree()
  - get_selected_paths()
  - process_gui_queue()

## Tool: RefineryServiceMS
Description: The Night Shift.
Functions:
  - get_health()
    # Returns the operational status of the RefineryServiceMS
  - process_pending(batch_size)
    # Main loop

## Tool: ContextAggregatorMS
Description: The Context Builder: Flattens a project folder into a single readable text file.
Functions:
  - aggregate(root_path, output_file, extra_exclusions, use_default_exclusions)

## Tool: LogViewMS
Description: The Console: A professional log viewer widget.
Functions:
  - clear()
  - save()

## Tool: TkinterUniButtonMS
Description: A generic button group that can merge ANY two actions.
Functions:

## Tool: SysInspectorMS
Description: The Auditor: Gathers hardware and environment statistics.
Functions:
  - generate_report()
    # Runs the full audit and returns a formatted string report

## Tool: IntakeServiceMS
Description: The Vacuum. 
Functions:
  - get_health()
    # Returns the operational status of the IntakeServiceMS
  - ingest_source(source_path)
    # Headless/CLI Entry point: Scans and Ingests in one go
  - scan_path(root_path, web_depth)
    # Unified Scanner Interface
  - ingest_selected(file_list, root_path)
    # Ingests only the specific files passed in the list
  - save_persistence(root_path, checked_map)
    # Saves user selections into the Cartridge Manifest (Portable)

## Tool: TkinterAppShellMS
Description: The Mother Ship.
Functions:
  - launch()
    # Ignition sequence start
  - get_main_container()
    # Other services call this to know where to
  - shutdown()

## Tool: RoleManagerMS
Description: The Casting Director: Manages Agent Personas (Roles).
Functions:
  - create_role(name, system_prompt, description, kbs)
    # Creates a new Agent Persona
  - get_role(name_or_id)
    # Retrieves a role by Name or ID
  - list_roles()
  - delete_role(name)

## Tool: SemanticChunkerMS
Description: Intelligent Code Splitter.
Functions:
  - chunk_file(content, filename)
    # Splits file content into chunks

## Tool: TkinterSmartExplorerMS
Description: The Navigator.
Functions:
  - load_data(data)
    # Ingests a dictionary tree (like from _ScoutMS or _TreeMapperMS)

## Tool: ScoutMS
Description: The Scanner: Walks file systems OR crawls websites (Depth-Aware).
Functions:
  - is_binary(file_path)
  - scan_directory(root_path, web_depth)
    # Main Entry Point
  - flatten_tree(tree_node)

## Tool: GitPilotMS
Description: No description.
Functions:
  - set_repo(path)

## Tool: NeuralGraphEngineMS
Description: No description.
Functions:
  - get_health()
    # Returns the operational status of the NeuralGraphEngineMS
  - resize(width, height)
  - set_data(nodes, links)
  - screen_to_world(sx, sy)
  - get_node_at(sx, sy)
  - handle_mouse_down(x, y)
  - handle_mouse_move(x, y, is_dragging)
  - handle_mouse_up()
  - pan(dx, dy)
  - zoom_camera(amount, mouse_x, mouse_y)
  - highlight_nodes(node_ids)
    # Highlights specific nodes by ID
  - step_physics()
  - get_image_bytes()

## Tool: LibrarianMS
Description: The Swarm Librarian.
Functions:
  - generate_catalog(output_file)
    # Main entry point

## Tool: ProjectForgeMS
Description: The Blacksmith.
Functions:
  - forge_project(parent_path, project_name, dependencies, project_type)
    # Stamps out a new project folder

## Tool: PromptOptimizerMS
Description: The Tuner: Uses an LLM to refine prompts or generate variations.
Functions:
  - refine_prompt(draft_prompt, feedback)
    # Rewrites a prompt based on feedback
  - generate_variations(draft_prompt, num_variations, context_data)
    # Generates multiple versions of a prompt for testing

## Tool: HeuristicSumMS
Description: The Skimmer: Generates quick summaries of code/text files without AI.
Functions:
  - summarize(text, filename, max_chars)
    # Generates a summary string from the provided text

## Tool: IngestEngineMS
Description: The Heavy Lifter: Reads files, chunks text, fetches embeddings,
Functions:
  - abort()
  - check_ollama_connection()
  - get_available_models()
  - process_files(file_paths, model_name)

## Tool: TextChunkerMS
Description: The Butcher: A unified service for splitting text into digestible chunks
Functions:
  - chunk_by_chars(text, chunk_size, chunk_overlap)
    # Standard Sliding Window
  - chunk_by_lines(text, max_lines, max_chars)
    # Line-Preserving Chunker

## Tool: IsoProcessMS
Description: The Safety Valve: Spawns isolated processes with real-time logging feedback.
Functions:
  - execute(payload, config)

## Tool: VectorFactoryMS
Description: The Switchboard: Returns the appropriate VectorStore implementation
Functions:
  - create(backend, config)
    # :param backend: 'faiss' or 'chroma'
:param config: Dict containing 'path', 'dim' (for FAISS), or 'collection' (for Chroma)

## Tool: MonacoHostMS
Description: Hosts the Monaco Editor.
Functions:
  - launch(title, width, height, func)
    # Create and launch the window
  - set_save_callback(callback)
    # Sets the function to trigger when Ctrl+S is pressed in the editor
  - open_file(filepath, content)
    # Opens a file in the editor (must be called from a background thread or callback)

## Tool: CodeJanitorMS
Description: No description.
Functions:
  - enforce_standards(dry_run)

## Tool: TasklistVaultMS
Description: The Taskmaster: A persistent SQLite engine for hierarchical task management.
Functions:
  - create_list(name)
    # Creates a new task list and returns its ID
  - get_lists()
    # Returns metadata for all task lists
  - add_task(list_id, content, parent_id)
    # Adds a task (or sub-task) to a list
  - update_task(task_id, content, status, result)
    # Updates a task's details
  - get_full_tree(list_id)
    # Fetches a list and reconstructs the full hierarchy of tasks
  - delete_list(list_id)

## Tool: WebScraperMS
Description: The Reader: Fetches URLs and extracts the main content using Readability.
Functions:
  - scrape(url)
    # Synchronous wrapper for fetching and cleaning a URL

## Tool: ChunkingRouterMS
Description: The Editor: A 'Recursive' text splitter.
Functions:
  - chunk_file(text, filename, max_size, overlap)
    # Extension-aware router

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\README.md
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\requirements.txt
--------------------------------------------------------------------------------
# Standard Library dependencies only:
# tkinter, argparse, json, ast, threading, os, sys
#
# No external pip packages required.
--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\setup_env.bat
--------------------------------------------------------------------------------
@echo off
echo [SYSTEM] Initializing new project environment...

:: 1. Create the venv if it doesn't exist
if not exist .venv (
    echo [SYSTEM] Creating .venv...
    py -m venv .venv
)

:: 2. Upgrade pip and install requirements
echo [SYSTEM] Installing dependencies...
.venv\Scripts\python.exe -m pip install --upgrade pip
if exist requirements.txt (
    .venv\Scripts\pip install -r requirements.txt
)

echo.
echo [SUCCESS] Environment ready!
echo You can now open this folder in VS Code or launch via scripts_menu.py
pause
--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\app.py
--------------------------------------------------------------------------------
import sys
import os
import shutil
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
from pathlib import Path
import json

# --- 1. PATH SETUP ---
current_dir = Path(__file__).resolve().parent
if str(current_dir) not in sys.path: sys.path.append(str(current_dir))
ms_dir = current_dir / "microservices"
if str(ms_dir) not in sys.path: sys.path.append(str(ms_dir))

# --- 2. IMPORTS ---
try:
    from microservices._TkinterAppShellMS import TkinterAppShellMS
    from microservices._TkinterThemeManagerMS import TkinterThemeManagerMS
    from microservices._ServiceRegistryMS import ServiceRegistryMS
    from microservices._ContextPackerMS import ContextPackerMS
except ImportError as e:
    # Graceful exit if dependencies are missing
    print(f"CRITICAL: Missing Core Microservices.\nError: {e}")
    sys.exit(1)

# --- 3. CONFIGURATION ---
try:
    # Try to find the library relative to this script
    PROJECT_ROOT = current_dir.parent.parent
    DETECTED_LIB_PATH = PROJECT_ROOT / "_MicroserviceLIBRARY"
except Exception:
    DETECTED_LIB_PATH = Path(r"C:\Users\jacob\Documents\_UsefulHelperSCRIPTS\_MicroserviceLIBRARY")
    
# Default to current dir if detection fails
DEFAULT_LIBRARY_PATH = DETECTED_LIB_PATH if DETECTED_LIB_PATH.exists() else Path(".")

# --- 4. THEME (Dark Steampunk) ---
COLORS = {
    "bg_dark": "#1b1b1b", "bg_panel": "#252526", "fg_text": "#e0c097",
    "fg_dim": "#858585", "accent": "#cd7f32", "accent_hover": "#ffd700",
    "select_bg": "#442d15", "success": "#50fa7b", "warning": "#ffb86c"
}

class SteampunkStyler:
    @staticmethod
    def apply(root):
        style = ttk.Style(root)
        style.theme_use('clam')
        style.configure(".", background=COLORS["bg_dark"], foreground=COLORS["fg_text"], font=("Consolas", 10))
        
        # Treeview (The List)
        style.configure("Treeview", background=COLORS["bg_panel"], foreground=COLORS["fg_text"], 
                        fieldbackground=COLORS["bg_panel"], borderwidth=0, font=("Consolas", 11))
        style.map("Treeview", background=[("selected", COLORS["select_bg"])], foreground=[("selected", COLORS["accent_hover"])])
        style.configure("Treeview.Heading", background=COLORS["bg_dark"], foreground=COLORS["accent"], font=("Consolas", 10, "bold"))
        
        # Buttons
        style.configure("TButton", background=COLORS["bg_panel"], foreground=COLORS["accent"], borderwidth=1, focusthickness=3)
        style.map("TButton", background=[("active", COLORS["select_bg"]), ("pressed", COLORS["accent"])], 
                  foreground=[("active", COLORS["accent_hover"]), ("pressed", COLORS["bg_dark"])])
        
        # Labels
        style.configure("Header.TLabel", foreground=COLORS["accent"], font=("Consolas", 12, "bold"))
        style.configure("Section.TLabel", foreground=COLORS["fg_dim"], font=("Consolas", 10, "italic"))

# --- 5. REPORT GENERATOR ---
class ReportGenerator:
    @staticmethod
    def agent_spec(services: list) -> str:
        """Generates a token-efficient Tool Definition list for LLMs."""
        lines = ["# TOOL DEFINITIONS (STRICT INTERFACE)", ""]
        for s in services:
            lines.append(f"## Tool: {s['name']}")
            # Grab only the first line of the docstring for brevity
            desc = s['description'].split(chr(10))[0] if s['description'] else "No description."
            lines.append(f"Description: {desc}")
            lines.append("Functions:")
            for m_name, m_data in s.get('methods', {}).items():
                args = ", ".join(m_data.get('args', []))
                lines.append(f"  - {m_name}({args})")
                if m_data.get('doc'):
                    doc_summary = m_data['doc'].split('.')[0].strip()
                    lines.append(f"    # {doc_summary}")
            lines.append("")
        return "\n".join(lines)

    @staticmethod
    def manifest(services: list) -> str:
        """Generates a high-level inventory list."""
        lines = ["# DEPLOYMENT MANIFEST", f"Total Services: {len(services)}", "-"*40]
        for s in services:
            desc = s['description'][:60] if s['description'] else "No description"
            lines.append(f"- [x] {s['name']} :: {desc}...")
        return "\n".join(lines)

# --- 6. MAIN APP ---
class MicroserviceBrowserApp:
    def __init__(self):
        self.theme_mgr = TkinterThemeManagerMS()
        self.registry_svc = ServiceRegistryMS()
        self.packer_svc = ContextPackerMS()
        
        self.library_root = DEFAULT_LIBRARY_PATH
        self.services_map = {} 
        self.checked_items = set() 
        
        self.app = TkinterAppShellMS({
            "theme_manager": self.theme_mgr,
            "title": "CORTEX COMPOSER [v2.2: Golden Master]",
            "geometry": "1400x900"
        })
        SteampunkStyler.apply(self.app.root)
        self.app.root.configure(bg=COLORS["bg_dark"])

        self.show_line_numbers = tk.BooleanVar(value=True)
        self.build_ui()
        
        # Auto-scan if valid, otherwise prompt user
        if self.library_root.exists(): 
            self.refresh_library()
        else:
            self.app.root.after(100, self.change_library)

    def build_ui(self):
        container = self.app.get_main_container()
        container.configure(bg=COLORS["bg_dark"])
        
        # --- HEADER ---
        deck = ttk.Frame(container, padding=10)
        deck.pack(fill="x")
        ttk.Label(deck, text="LIBRARY SOURCE:", style="Header.TLabel").pack(side="left")
        self.lbl_path = ttk.Label(deck, text=str(self.library_root), foreground=COLORS["fg_dim"])
        self.lbl_path.pack(side="left", padx=10)
        btn_frame = ttk.Frame(deck)
        btn_frame.pack(side="right")
        ttk.Button(btn_frame, text="[CHANGE PATH]", command=self.change_library).pack(side="left", padx=2)
        ttk.Button(btn_frame, text="[RE-SCAN]", command=self.refresh_library).pack(side="left", padx=2)

        paned = tk.PanedWindow(container, orient="horizontal", bg=COLORS["accent"], sashwidth=2, sashrelief="flat")
        paned.pack(fill="both", expand=True, padx=5, pady=5)
        
        # --- LEFT PANEL (Selection) ---
        left = ttk.Frame(paned)
        paned.add(left, width=400)
        
        # Selection Tools
        sel_row = ttk.Frame(left)
        sel_row.pack(fill="x", pady=5)
        ttk.Button(sel_row, text="ALL", width=5, command=self.select_all).pack(side="left", padx=1)
        ttk.Button(sel_row, text="NONE", width=5, command=self.select_none).pack(side="left", padx=1)
        ttk.Button(sel_row, text="INV", width=5, command=self.select_inverse).pack(side="left", padx=1)
        
        # Tree
        tree_frame = ttk.Frame(left)
        tree_frame.pack(fill="both", expand=True, pady=2)
        self.tree = ttk.Treeview(tree_frame, columns=("status"), show="tree", selectmode="browse")
        vsb = ttk.Scrollbar(tree_frame, orient="vertical", command=self.tree.yview)
        self.tree.configure(yscrollcommand=vsb.set)
        self.tree.pack(side="left", fill="both", expand=True)
        vsb.pack(side="right", fill="y")
        self.tree.bind("<<TreeviewSelect>>", self.on_service_click)
        self.tree.bind("<Double-1>", self.on_service_toggle)

        # --- OPERATIONS DECK ---
        ops = ttk.LabelFrame(left, text="OPERATIONS DECK", padding=5)
        ops.pack(fill="x", pady=10)
        
        # 1. Deployment
        ttk.Label(ops, text="PHYSICAL DEPLOYMENT", style="Section.TLabel").pack(anchor="w")
        ttk.Button(ops, text="DEPLOY TO FOLDER...", command=self.deploy_files).pack(fill="x", pady=2)
        
        # 2. Reporting
        ttk.Label(ops, text="INTELLIGENT REPORTING", style="Section.TLabel").pack(anchor="w", pady=(10,0))
        ttk.Button(ops, text="COPY 'AGENT SPEC' (For LLMs)", command=self.copy_agent_spec).pack(fill="x", pady=2)
        ttk.Button(ops, text="COPY 'MANIFEST' (Summary)", command=self.copy_manifest).pack(fill="x", pady=2)
        ttk.Button(ops, text="COPY FULL CODE (Raw Dump)", command=self.copy_full_code).pack(fill="x", pady=2)

        # --- RIGHT PANEL (Viewer) ---
        right = ttk.Frame(paned)
        paned.add(right, width=800)
        
        view_head = ttk.Frame(right)
        view_head.pack(fill="x", pady=5)
        ttk.Label(view_head, text="SOURCE INSPECTOR", style="Header.TLabel").pack(side="left")
        ttk.Checkbutton(view_head, text="Line Numbers", variable=self.show_line_numbers, command=self.refresh_code_view).pack(side="right")

        self.txt_code = tk.Text(right, font=("Consolas", 11), bg=COLORS["bg_panel"], fg=COLORS["fg_text"], 
            insertbackground=COLORS["accent"], selectbackground=COLORS["select_bg"], wrap="none", undo=False, borderwidth=0)
        self.txt_code.pack(fill="both", expand=True)

    # --- CORE LOGIC ---

    def refresh_library(self):
        self.registry_svc.root = self.library_root
        self.tree.delete(*self.tree.get_children())
        self.services_map.clear()
        
        if not self.library_root.exists():
            messagebox.showerror("Error", f"Path not found: {self.library_root}")
            return

        registry_data = self.registry_svc.scan(save_to=None)
        
        for item in registry_data:
            name = item['name']
            iid = f"{name}_{item['path']}" if name in self.services_map else name
            self.services_map[iid] = item
            self.tree.insert("", "end", iid=iid, text=f"‚òê {name}", tags=("unchecked",))
            
    def _get_selected_data(self):
        """Returns list of dicts for checked items."""
        return [self.services_map[iid] for iid in self.checked_items]

    # --- SELECTION HANDLING ---
    def on_service_toggle(self, event):
        item_id = self.tree.focus()
        if not item_id: return
        
        orig_name = self.services_map[item_id]['name']
        if item_id in self.checked_items:
            self.checked_items.remove(item_id)
            self.tree.item(item_id, text=f"‚òê {orig_name}", tags=("unchecked",))
        else:
            self.checked_items.add(item_id)
            self.tree.item(item_id, text=f"‚òë {orig_name}", tags=("checked",))

    def on_service_click(self, event):
        item_id = self.tree.focus()
        if not item_id: return
        data = self.services_map.get(item_id)
        if not data: return
        
        path = self.library_root / data['path']
        if path.exists():
            self.current_code_content = path.read_text(encoding="utf-8")
            self.refresh_code_view()

    def refresh_code_view(self):
        if not hasattr(self, 'current_code_content'): return
        content = self.current_code_content
        self.txt_code.delete("1.0", "end")
        if self.show_line_numbers.get():
            lines = [f"{i+1:03d} | {line}" for i, line in enumerate(content.splitlines())]
            self.txt_code.insert("1.0", "\n".join(lines))
        else:
            self.txt_code.insert("1.0", content)

    # --- BULK ACTIONS ---
    def select_all(self):
        for iid in self.services_map:
            if iid not in self.checked_items:
                self.checked_items.add(iid)
                self.tree.item(iid, text=f"‚òë {self.services_map[iid]['name']}")

    def select_none(self):
        self.checked_items.clear()
        for iid in self.services_map:
            self.tree.item(iid, text=f"‚òê {self.services_map[iid]['name']}")

    def select_inverse(self):
        new_set = set()
        for iid in self.services_map:
            if iid not in self.checked_items:
                new_set.add(iid)
                self.tree.item(iid, text=f"‚òë {self.services_map[iid]['name']}")
            else:
                self.tree.item(iid, text=f"‚òê {self.services_map[iid]['name']}")
        self.checked_items = new_set

    # --- OPERATIONS DECK ---

    def deploy_files(self):
        """Copies actual .py files to a selected directory with dependency safety."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services to deploy.")
        
        target_dir = filedialog.askdirectory(title="Select Target 'src/microservices' Folder")
        if not target_dir: return

        count = 0
        try:
            dest = Path(target_dir)
            
            # --- SAFETY INTERLOCK: Ensure Std Lib is present ---
            std_lib_name = "microservice_std_lib.py"
            std_lib_src = self.library_root / std_lib_name
            std_lib_dest = dest / std_lib_name
            
            if std_lib_src.exists() and not std_lib_dest.exists():
                shutil.copy2(std_lib_src, std_lib_dest)
                print(f"[Auto-Deploy] Copied dependency: {std_lib_name}")
            # ----------------------------------------------------

            for s in selection:
                src = self.library_root / s['path']
                if src.exists():
                    shutil.copy2(src, dest / src.name)
                    count += 1
            messagebox.showinfo("Deployed", f"Successfully deployed {count} microservices to:\n{dest}")
        except Exception as e:
            messagebox.showerror("Deployment Error", str(e))

    def copy_agent_spec(self):
        """Copies the lightweight API definition."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        report = ReportGenerator.agent_spec(selection)
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append(report)
        messagebox.showinfo("Copied", f"Agent Spec ({len(selection)} tools) copied to clipboard.")

    def copy_manifest(self):
        """Copies a high-level list."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        report = ReportGenerator.manifest(selection)
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append(report)
        messagebox.showinfo("Copied", "Manifest copied to clipboard.")

    def copy_full_code(self):
        """The old massive dump."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        output = ["# CONTEXT DUMP", "="*40]
        for s in selection:
            path = self.library_root / s['path']
            if path.exists():
                output.append(f"\n# FILE: {s['path']}\n" + "-"*40)
                output.append(path.read_text(encoding="utf-8"))
        
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append("\n".join(output))
        messagebox.showinfo("Copied", f"Full Source Code ({len(selection)} files) copied.")

    def change_library(self):
        path = filedialog.askdirectory(initialdir=self.library_root)
        if path:
            self.library_root = Path(path)
            self.lbl_path.config(text=str(self.library_root))
            self.refresh_library()

    def run(self):
        self.app.launch()

if __name__ == "__main__":
    browser = MicroserviceBrowserApp()
    browser.run()
--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\manifest-summary.txt
--------------------------------------------------------------------------------
import sys
import os
import shutil
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
from pathlib import Path
import json

# --- 1. PATH SETUP ---
current_dir = Path(__file__).resolve().parent
if str(current_dir) not in sys.path: sys.path.append(str(current_dir))
ms_dir = current_dir / "microservices"
if str(ms_dir) not in sys.path: sys.path.append(str(ms_dir))

# --- 2. IMPORTS ---
try:
    from microservices._TkinterAppShellMS import TkinterAppShellMS
    from microservices._TkinterThemeManagerMS import TkinterThemeManagerMS
    from microservices._ServiceRegistryMS import ServiceRegistryMS
    from microservices._ContextPackerMS import ContextPackerMS
except ImportError as e:
    # Graceful exit if dependencies are missing
    print(f"CRITICAL: Missing Core Microservices.\nError: {e}")
    sys.exit(1)

# --- 3. CONFIGURATION ---
try:
    # Try to find the library relative to this script
    PROJECT_ROOT = current_dir.parent.parent
    DETECTED_LIB_PATH = PROJECT_ROOT / "_MicroserviceLIBRARY"
except Exception:
    DETECTED_LIB_PATH = Path(r"C:\Users\jacob\Documents\_UsefulHelperSCRIPTS\_MicroserviceLIBRARY")
    
# Default to current dir if detection fails
DEFAULT_LIBRARY_PATH = DETECTED_LIB_PATH if DETECTED_LIB_PATH.exists() else Path(".")

# --- 4. THEME (Dark Steampunk) ---
COLORS = {
    "bg_dark": "#1b1b1b", "bg_panel": "#252526", "fg_text": "#e0c097",
    "fg_dim": "#858585", "accent": "#cd7f32", "accent_hover": "#ffd700",
    "select_bg": "#442d15", "success": "#50fa7b", "warning": "#ffb86c"
}

class SteampunkStyler:
    @staticmethod
    def apply(root):
        style = ttk.Style(root)
        style.theme_use('clam')
        style.configure(".", background=COLORS["bg_dark"], foreground=COLORS["fg_text"], font=("Consolas", 10))
        
        # Treeview (The List)
        style.configure("Treeview", background=COLORS["bg_panel"], foreground=COLORS["fg_text"], 
                        fieldbackground=COLORS["bg_panel"], borderwidth=0, font=("Consolas", 11))
        style.map("Treeview", background=[("selected", COLORS["select_bg"])], foreground=[("selected", COLORS["accent_hover"])])
        style.configure("Treeview.Heading", background=COLORS["bg_dark"], foreground=COLORS["accent"], font=("Consolas", 10, "bold"))
        
        # Buttons
        style.configure("TButton", background=COLORS["bg_panel"], foreground=COLORS["accent"], borderwidth=1, focusthickness=3)
        style.map("TButton", background=[("active", COLORS["select_bg"]), ("pressed", COLORS["accent"])], 
                  foreground=[("active", COLORS["accent_hover"]), ("pressed", COLORS["bg_dark"])])
        
        # Labels
        style.configure("Header.TLabel", foreground=COLORS["accent"], font=("Consolas", 12, "bold"))
        style.configure("Section.TLabel", foreground=COLORS["fg_dim"], font=("Consolas", 10, "italic"))

# --- 5. REPORT GENERATOR ---
class ReportGenerator:
    @staticmethod
    def agent_spec(services: list) -> str:
        """Generates a token-efficient Tool Definition list for LLMs."""
        lines = ["# TOOL DEFINITIONS (STRICT INTERFACE)", ""]
        for s in services:
            lines.append(f"## Tool: {s['name']}")
            # Grab only the first line of the docstring for brevity
            desc = s['description'].split(chr(10))[0] if s['description'] else "No description."
            lines.append(f"Description: {desc}")
            lines.append("Functions:")
            for m_name, m_data in s.get('methods', {}).items():
                args = ", ".join(m_data.get('args', []))
                lines.append(f"  - {m_name}({args})")
                if m_data.get('doc'):
                    doc_summary = m_data['doc'].split('.')[0].strip()
                    lines.append(f"    # {doc_summary}")
            lines.append("")
        return "\n".join(lines)

    @staticmethod
    def manifest(services: list) -> str:
        """Generates a high-level inventory list."""
        lines = ["# DEPLOYMENT MANIFEST", f"Total Services: {len(services)}", "-"*40]
        for s in services:
            desc = s['description'][:60] if s['description'] else "No description"
            lines.append(f"- [x] {s['name']} :: {desc}...")
        return "\n".join(lines)

# --- 6. MAIN APP ---
class MicroserviceBrowserApp:
    def __init__(self):
        self.theme_mgr = TkinterThemeManagerMS()
        self.registry_svc = ServiceRegistryMS()
        self.packer_svc = ContextPackerMS()
        
        self.library_root = DEFAULT_LIBRARY_PATH
        self.services_map = {} 
        self.checked_items = set() 
        
        self.app = TkinterAppShellMS({
            "theme_manager": self.theme_mgr,
            "title": "CORTEX COMPOSER [v2.2: Golden Master]",
            "geometry": "1400x900"
        })
        SteampunkStyler.apply(self.app.root)
        self.app.root.configure(bg=COLORS["bg_dark"])

        self.show_line_numbers = tk.BooleanVar(value=True)
        self.build_ui()
        
        # Auto-scan if valid, otherwise prompt user
        if self.library_root.exists(): 
            self.refresh_library()
        else:
            self.app.root.after(100, self.change_library)

    def build_ui(self):
        container = self.app.get_main_container()
        container.configure(bg=COLORS["bg_dark"])
        
        # --- HEADER ---
        deck = ttk.Frame(container, padding=10)
        deck.pack(fill="x")
        ttk.Label(deck, text="LIBRARY SOURCE:", style="Header.TLabel").pack(side="left")
        self.lbl_path = ttk.Label(deck, text=str(self.library_root), foreground=COLORS["fg_dim"])
        self.lbl_path.pack(side="left", padx=10)
        btn_frame = ttk.Frame(deck)
        btn_frame.pack(side="right")
        ttk.Button(btn_frame, text="[CHANGE PATH]", command=self.change_library).pack(side="left", padx=2)
        ttk.Button(btn_frame, text="[RE-SCAN]", command=self.refresh_library).pack(side="left", padx=2)

        paned = tk.PanedWindow(container, orient="horizontal", bg=COLORS["accent"], sashwidth=2, sashrelief="flat")
        paned.pack(fill="both", expand=True, padx=5, pady=5)
        
        # --- LEFT PANEL (Selection) ---
        left = ttk.Frame(paned)
        paned.add(left, width=400)
        
        # Selection Tools
        sel_row = ttk.Frame(left)
        sel_row.pack(fill="x", pady=5)
        ttk.Button(sel_row, text="ALL", width=5, command=self.select_all).pack(side="left", padx=1)
        ttk.Button(sel_row, text="NONE", width=5, command=self.select_none).pack(side="left", padx=1)
        ttk.Button(sel_row, text="INV", width=5, command=self.select_inverse).pack(side="left", padx=1)
        
        # Tree
        tree_frame = ttk.Frame(left)
        tree_frame.pack(fill="both", expand=True, pady=2)
        self.tree = ttk.Treeview(tree_frame, columns=("status"), show="tree", selectmode="browse")
        vsb = ttk.Scrollbar(tree_frame, orient="vertical", command=self.tree.yview)
        self.tree.configure(yscrollcommand=vsb.set)
        self.tree.pack(side="left", fill="both", expand=True)
        vsb.pack(side="right", fill="y")
        self.tree.bind("<<TreeviewSelect>>", self.on_service_click)
        self.tree.bind("<Double-1>", self.on_service_toggle)

        # --- OPERATIONS DECK ---
        ops = ttk.LabelFrame(left, text="OPERATIONS DECK", padding=5)
        ops.pack(fill="x", pady=10)
        
        # 1. Deployment
        ttk.Label(ops, text="PHYSICAL DEPLOYMENT", style="Section.TLabel").pack(anchor="w")
        ttk.Button(ops, text="DEPLOY TO FOLDER...", command=self.deploy_files).pack(fill="x", pady=2)
        
        # 2. Reporting
        ttk.Label(ops, text="INTELLIGENT REPORTING", style="Section.TLabel").pack(anchor="w", pady=(10,0))
        ttk.Button(ops, text="COPY 'AGENT SPEC' (For LLMs)", command=self.copy_agent_spec).pack(fill="x", pady=2)
        ttk.Button(ops, text="COPY 'MANIFEST' (Summary)", command=self.copy_manifest).pack(fill="x", pady=2)
        ttk.Button(ops, text="COPY FULL CODE (Raw Dump)", command=self.copy_full_code).pack(fill="x", pady=2)

        # --- RIGHT PANEL (Viewer) ---
        right = ttk.Frame(paned)
        paned.add(right, width=800)
        
        view_head = ttk.Frame(right)
        view_head.pack(fill="x", pady=5)
        ttk.Label(view_head, text="SOURCE INSPECTOR", style="Header.TLabel").pack(side="left")
        ttk.Checkbutton(view_head, text="Line Numbers", variable=self.show_line_numbers, command=self.refresh_code_view).pack(side="right")

        self.txt_code = tk.Text(right, font=("Consolas", 11), bg=COLORS["bg_panel"], fg=COLORS["fg_text"], 
            insertbackground=COLORS["accent"], selectbackground=COLORS["select_bg"], wrap="none", undo=False, borderwidth=0)
        self.txt_code.pack(fill="both", expand=True)

    # --- CORE LOGIC ---

    def refresh_library(self):
        self.registry_svc.root = self.library_root
        self.tree.delete(*self.tree.get_children())
        self.services_map.clear()
        
        if not self.library_root.exists():
            messagebox.showerror("Error", f"Path not found: {self.library_root}")
            return

        registry_data = self.registry_svc.scan(save_to=None)
        
        for item in registry_data:
            name = item['name']
            iid = f"{name}_{item['path']}" if name in self.services_map else name
            self.services_map[iid] = item
            self.tree.insert("", "end", iid=iid, text=f"‚òê {name}", tags=("unchecked",))
            
    def _get_selected_data(self):
        """Returns list of dicts for checked items."""
        return [self.services_map[iid] for iid in self.checked_items]

    # --- SELECTION HANDLING ---
    def on_service_toggle(self, event):
        item_id = self.tree.focus()
        if not item_id: return
        
        orig_name = self.services_map[item_id]['name']
        if item_id in self.checked_items:
            self.checked_items.remove(item_id)
            self.tree.item(item_id, text=f"‚òê {orig_name}", tags=("unchecked",))
        else:
            self.checked_items.add(item_id)
            self.tree.item(item_id, text=f"‚òë {orig_name}", tags=("checked",))

    def on_service_click(self, event):
        item_id = self.tree.focus()
        if not item_id: return
        data = self.services_map.get(item_id)
        if not data: return
        
        path = self.library_root / data['path']
        if path.exists():
            self.current_code_content = path.read_text(encoding="utf-8")
            self.refresh_code_view()

    def refresh_code_view(self):
        if not hasattr(self, 'current_code_content'): return
        content = self.current_code_content
        self.txt_code.delete("1.0", "end")
        if self.show_line_numbers.get():
            lines = [f"{i+1:03d} | {line}" for i, line in enumerate(content.splitlines())]
            self.txt_code.insert("1.0", "\n".join(lines))
        else:
            self.txt_code.insert("1.0", content)

    # --- BULK ACTIONS ---
    def select_all(self):
        for iid in self.services_map:
            if iid not in self.checked_items:
                self.checked_items.add(iid)
                self.tree.item(iid, text=f"‚òë {self.services_map[iid]['name']}")

    def select_none(self):
        self.checked_items.clear()
        for iid in self.services_map:
            self.tree.item(iid, text=f"‚òê {self.services_map[iid]['name']}")

    def select_inverse(self):
        new_set = set()
        for iid in self.services_map:
            if iid not in self.checked_items:
                new_set.add(iid)
                self.tree.item(iid, text=f"‚òë {self.services_map[iid]['name']}")
            else:
                self.tree.item(iid, text=f"‚òê {self.services_map[iid]['name']}")
        self.checked_items = new_set

    # --- OPERATIONS DECK ---

    def deploy_files(self):
        """Copies actual .py files to a selected directory with dependency safety."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services to deploy.")
        
        target_dir = filedialog.askdirectory(title="Select Target 'src/microservices' Folder")
        if not target_dir: return

        count = 0
        try:
            dest = Path(target_dir)
            
            # --- SAFETY INTERLOCK: Ensure Std Lib is present ---
            std_lib_name = "microservice_std_lib.py"
            std_lib_src = self.library_root / std_lib_name
            std_lib_dest = dest / std_lib_name
            
            if std_lib_src.exists() and not std_lib_dest.exists():
                shutil.copy2(std_lib_src, std_lib_dest)
                print(f"[Auto-Deploy] Copied dependency: {std_lib_name}")
            # ----------------------------------------------------

            for s in selection:
                src = self.library_root / s['path']
                if src.exists():
                    shutil.copy2(src, dest / src.name)
                    count += 1
            messagebox.showinfo("Deployed", f"Successfully deployed {count} microservices to:\n{dest}")
        except Exception as e:
            messagebox.showerror("Deployment Error", str(e))

    def copy_agent_spec(self):
        """Copies the lightweight API definition."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        report = ReportGenerator.agent_spec(selection)
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append(report)
        messagebox.showinfo("Copied", f"Agent Spec ({len(selection)} tools) copied to clipboard.")

    def copy_manifest(self):
        """Copies a high-level list."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        report = ReportGenerator.manifest(selection)
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append(report)
        messagebox.showinfo("Copied", "Manifest copied to clipboard.")

    def copy_full_code(self):
        """The old massive dump."""
        selection = self._get_selected_data()
        if not selection: return messagebox.showwarning("Empty", "Select services first.")
        
        output = ["# CONTEXT DUMP", "="*40]
        for s in selection:
            path = self.library_root / s['path']
            if path.exists():
                output.append(f"\n# FILE: {s['path']}\n" + "-"*40)
                output.append(path.read_text(encoding="utf-8"))
        
        self.app.root.clipboard_clear()
        self.app.root.clipboard_append("\n".join(output))
        messagebox.showinfo("Copied", f"Full Source Code ({len(selection)} files) copied.")

    def change_library(self):
        path = filedialog.askdirectory(initialdir=self.library_root)
        if path:
            self.library_root = Path(path)
            self.lbl_path.config(text=str(self.library_root))
            self.refresh_library()

    def run(self):
        self.app.launch()

if __name__ == "__main__":
    browser = MicroserviceBrowserApp()
    browser.run()
--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\__init__.py
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\microservices\microservice_std_lib.py
--------------------------------------------------------------------------------
"""
LIBRARY: Microservice Standard Lib
VERSION: 2.0.0
ROLE: Provides decorators for tagging Python classes as AI-discoverable services.
"""

import functools
import inspect
from typing import Dict, List, Any, Optional, Type

# ==============================================================================
# DECORATORS (The "Writer" Tools)
# ==============================================================================

def service_metadata(name: str, version: str, description: str, tags: List[str], capabilities: List[str] = None, dependencies: List[str] = None, side_effects: List[str] = None):
    """
    Class Decorator.
    Labels a Microservice class with high-level metadata for the Catalog.
    """
    def decorator(cls):
        cls._is_microservice = True
        cls._service_info = {
            "name": name,
            "version": version,
            "description": description,
            "tags": tags,
            "capabilities": capabilities or [],
            "dependencies": dependencies or [],
            "side_effects": side_effects or []
        }
        return cls
    return decorator

def service_endpoint(inputs: Dict[str, str], outputs: Dict[str, str], description: str, tags: List[str] = None, side_effects: List[str] = None, mode: str = "sync"):
    """
    Method Decorator.
    Defines the 'Socket' that the AI Architect can plug into.
    
    :param inputs: Dict of {arg_name: type_string} (e.g. {"query": "str"})
    :param outputs: Dict of {return_name: type_string} (e.g. {"results": "List[Dict]"})
    :param description: What this specific function does.
    :param tags: Keywords for searching (e.g. ["search", "read-only"])
    :param side_effects: List of impact types (e.g. ["network:outbound", "disk:write"])
    :param mode: 'sync', 'async', or 'ui_event'
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            return func(*args, **kwargs)
        
        # Attach metadata to the function object itself
        wrapper._endpoint_info = {
            "name": func.__name__,
            "inputs": inputs,
            "outputs": outputs,
            "description": description,
            "tags": tags or [],
            "side_effects": side_effects or [],
            "mode": mode
        }
        return wrapper
    return decorator

# ==============================================================================
# INTROSPECTION (The "Reader" Tools)
# ==============================================================================

def extract_service_schema(service_cls: Type) -> Dict[str, Any]:
    """
    Scans a decorated Service Class and returns a JSON-serializable schema 
    of its metadata and all its exposed endpoints.
    
    This is what the AI Agent uses to 'read' the manual.
    """
    if not getattr(service_cls, "_is_microservice", False):
        raise ValueError(f"Class {service_cls.__name__} is not decorated with @service_metadata")

    schema = {
        "meta": getattr(service_cls, "_service_info", {}),
        "endpoints": []
    }

    # Inspect all methods of the class
    for name, method in inspect.getmembers(service_cls, predicate=inspect.isfunction):
        # Unwrap decorators if necessary to find our tags
        # (Though usually the wrapper has the tag attached)
        endpoint_info = getattr(method, "_endpoint_info", None)
        
        if endpoint_info:
            schema["endpoints"].append(endpoint_info)

    return schema

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\microservices\_ContextPackerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ContextPackerMS
ENTRY_POINT: _ContextPackerMS.py
DEPENDENCIES: None
"""

import os
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Set

from microservice_std_lib import service_metadata, service_endpoint

# ==============================================================================
# CONFIGURATION
# ==============================================================================
DEFAULT_EXCLUDES = {
    '.git', '__pycache__', '.idea', '.vscode', 'node_modules', 
    'venv', '.venv', 'dist', 'build', '.DS_Store', 'file-dump.txt'
}

logger = logging.getLogger("ContextPacker")

# ==============================================================================
# MICROSERVICE CLASS
# ==============================================================================

@service_metadata(
    name="ContextPacker",
    version="1.0.0",
    description="Flattens a directory of source code into a single text file (useful for LLM context stuffing).",
    tags=["filesystem", "export", "utility"],
    capabilities=["filesystem:read", "filesystem:write"]
)
class ContextPackerMS:
    """
    The Packer: Walks a directory and dumps all text-readable files 
    into a single monolithic text file with delimiters.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}

    @service_endpoint(
        inputs={"root_path": "str", "output_filename": "str", "additional_excludes": "Set[str]"},
        outputs={"output_path": "str", "file_count": "int"},
        description="Packs directory contents into a single text file.",
        tags=["export", "dump"],
        side_effects=["filesystem:read", "filesystem:write"]
    )
    def pack_directory(self, 
                       root_path: str, 
                       output_filename: str = "context_dump.txt", 
                       additional_excludes: Optional[Set[str]] = None) -> Dict[str, Any]:
        """
        Walks the directory and writes file contents to the output file.
        """
        root = Path(root_path).resolve()
        output_file = root / output_filename
        
        # Merge excludes
        excludes = DEFAULT_EXCLUDES.copy()
        if additional_excludes:
            excludes.update(additional_excludes)
            
        # Ensure we don't pack the output file itself if it already exists
        excludes.add(output_filename)

        count = 0
        logger.info(f"Packing context from {root} into {output_filename}...")

        try:
            with open(output_file, 'w', encoding='utf-8') as out_f:
                # Add Header
                out_f.write(f"CONTEXT PACKER DUMP\n")
                out_f.write(f"SOURCE: {root}\n")
                out_f.write("="*60 + "\n\n")

                for current_dir, dirs, files in os.walk(root):
                    # In-place modification of dirs to skip excluded folders during walk
                    dirs[:] = [d for d in dirs if d not in excludes and not d.startswith('.')]
                    
                    for file in files:
                        if file in excludes or file.startswith('.'):
                            continue
                            
                        file_path = Path(current_dir) / file
                        
                        # Process the file
                        self._append_file(file_path, root, out_f)
                        count += 1
                        
            return {
                "output_path": str(output_file),
                "file_count": count
            }
            
        except Exception as e:
            logger.error(f"Packing failed: {e}")
            raise

    def _append_file(self, file_path: Path, root: Path, out_f):
        """Helper to append a single file's content to the dump."""
        rel_path = file_path.relative_to(root)
        
        try:
            # Try reading as text
            content = file_path.read_text(encoding='utf-8')
            
            out_f.write(f"==================================================\n")
            out_f.write(f"FILE: {rel_path}\n")
            out_f.write(f"==================================================\n")
            out_f.write(content + "\n\n")
            
        except UnicodeDecodeError:
            # It's a binary file (image, pyc, etc.)
            out_f.write(f"==================================================\n")
            out_f.write(f"FILE: {rel_path} [SKIPPED - BINARY]\n")
            out_f.write(f"==================================================\n\n")
        except Exception as e:
            logger.warning(f"Could not read {rel_path}: {e}")


# --- Independent Test Block ---
if __name__ == "__main__":
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

    packer = ContextPackerMS()
    print("Service ready:", packer)
    
    # Run a test pack on the current folder
    print("\n--- Packing Current Directory ---")
    result = packer.pack_directory(".", "test_dump.txt")
    print(f"Packed {result['file_count']} files to: {result['output_path']}")

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\microservices\_ServiceRegistryMS.py
--------------------------------------------------------------------------------
import ast
import json
import uuid
import os
import re
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

from microservice_std_lib import service_metadata, service_endpoint

# ==============================================================================
# CONFIGURATION
# ==============================================================================
OUTPUT_FILE = "registry.json"
logger = logging.getLogger("ServiceRegistry")

# ==============================================================================
# MICROSERVICE CLASS
# ==============================================================================

@service_metadata(
    name="ServiceRegistry",
    version="1.0.0",
    description="Scans a library of Python microservices and generates standardized JSON Service Tokens.",
    tags=["introspection", "registry", "parsing"],
    capabilities=["filesystem:read", "filesystem:write"]
)
class ServiceRegistryMS:
    """
    The Tokenizer (v2): Scans a library of Python microservices and generates
    standardized JSON 'Service Tokens'.
    Feature: Hybrid AST/Regex parsing for maximum robustness.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        # Default to current directory if not specified
        self.root = Path(self.config.get("root_path", ".")).resolve()
        self.registry = []

    @service_endpoint(
        inputs={"save_to": "str"},
        outputs={"registry": "List[Dict]"},
        description="Scans the file system for microservices and builds a registry.",
        tags=["introspection", "scan"],
        side_effects=["filesystem:read", "filesystem:write"]
    )
    def scan(self, save_to: str = OUTPUT_FILE) -> List[Dict[str, Any]]:
        logger.info(f"Scanning for microservices in: {self.root}")
        self.registry = [] # Reset registry
        
        # 1. Walk directories/files
        if self.root.exists():
            for item in self.root.iterdir():
                # Check for Service Folders (e.g. _AuthMS)
                if item.is_dir() and item.name.startswith("_") and item.name.endswith("MS"):
                    self._process_folder(item)
                # Check for Service Files (e.g. __AuthMS.py)
                elif item.is_file() and item.name.startswith("_") and item.name.endswith("MS.py"):
                    token = self._tokenize_file(item)
                    if token:
                        self.registry.append(token)
        
        # 2. Save Registry
        if save_to:
            try:
                with open(save_to, "w", encoding="utf-8") as f:
                    json.dump(self.registry, f, indent=2)
                logger.info(f"‚úÖ Registry built. Found {len(self.registry)} services. Saved to {save_to}")
            except Exception as e:
                logger.error(f"Failed to save registry: {e}")
            
        return self.registry

    def _process_folder(self, folder: Path):
        # Find the main .py file (usually matches folder name, or is the only .py file)
        candidates = list(folder.glob("*.py"))
        for file in candidates:
            # Usually entry points start with __ inside the folder
            if file.name.startswith("__") or len(candidates) == 1:
                token = self._tokenize_file(file)
                if token:
                    self.registry.append(token)
                    logger.info(f"  + Tokenized: {token['name']}")
                    break 

    def _tokenize_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                source = f.read()
            
            # Attempt 1: Strict AST Parsing (The "Right" Way)
            try:
                return self._ast_parse(source, file_path)
            except Exception:
                # Attempt 2: Regex Fallback (The "Survival" Way)
                return self._regex_parse(source, file_path)
                
        except Exception as e:
            logger.warning(f"  - Failed to read {file_path.name}: {e}")
            return None

    def _ast_parse(self, source: str, file_path: Path):
        tree = ast.parse(source)
        target_class = None
        
        # Find class ending in 'MS'
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef) and node.name.endswith("MS"):
                target_class = node
                break
        
        if not target_class: return None

        # Extract Metadata
        return self._build_token(
            name=target_class.name,
            doc=ast.get_docstring(target_class) or "",
            methods=[
                (n.name, [a.arg for a in n.args.args if a.arg != 'self'], ast.get_docstring(n) or "")
                for n in target_class.body if isinstance(n, ast.FunctionDef) and not n.name.startswith("_")
            ],
            deps=self._extract_ast_imports(tree),
            file_path=file_path
        )

    def _regex_parse(self, source: str, file_path: Path):
        # Find class definition
        class_match = re.search(r'class\s+(\w+MS)', source)
        if not class_match: return None
        name = class_match.group(1)
        
        # Find methods (def name(args):)
        methods = []
        for match in re.finditer(r'def\s+(\w+)\s*\((.*?)\):', source):
            m_name = match.group(1)
            if not m_name.startswith("_"):
                # Rough args parsing
                args = [a.strip().split(':')[0] for a in match.group(2).split(',') if a.strip() != 'self']
                methods.append((m_name, args, "Regex extracted"))
                
        return self._build_token(name, "Parsed via Regex", methods, [], file_path)

    def _build_token(self, name, doc, methods, deps, file_path):
        # Generate deterministic ID
        namespace = uuid.uuid5(uuid.NAMESPACE_DNS, "microservice.library")
        token_id = f"MS_{uuid.uuid5(namespace, name).hex[:8].upper()}"
        
        method_dict = {
            m_name: {"args": m_args, "doc": m_doc.strip()} 
            for m_name, m_args, m_doc in methods
        }
        
        try:
            rel_path = str(file_path.relative_to(self.root)).replace('\\', '/')
        except ValueError:
            rel_path = file_path.name

        return {
            "token_id": token_id,
            "name": name,
            "path": rel_path,
            "description": doc.strip(),
            "methods": method_dict,
            "dependencies": sorted(deps)
        }

    def _extract_ast_imports(self, tree):
        deps = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for n in node.names: deps.add(n.name.split('.')[0])
            elif isinstance(node, ast.ImportFrom):
                if node.module: deps.add(node.module.split('.')[0])
        return list(deps)


if __name__ == "__main__":
    # Setup logging for independent test
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    
    svc = ServiceRegistryMS()
    print("Service ready:", svc)
    # Perform a test scan of the current directory
    svc.scan()

--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\microservices\_TkinterAppShellMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterAppShellMS
ENTRY_POINT: _TkinterAppShellMS.py
DEPENDENCIES: None
"""
import tkinter as tk
from tkinter import ttk
import logging
from typing import Dict, Any, Optional

from microservice_std_lib import service_metadata, service_endpoint

# Updated Import: Single Underscore + 'Tkinter' prefix
try:
    from _TkinterThemeManagerMS import TkinterThemeManagerMS
except ImportError:
    TkinterThemeManagerMS = None

logger = logging.getLogger("AppShell")

@service_metadata(
    name="TkinterAppShell",
    version="2.0.0",
    description="The Application Container. Manages the root window, main loop, and global layout.",
    tags=["ui", "core", "lifecycle"],
    capabilities=["ui:root", "ui:gui"]
)
class TkinterAppShellMS:
    """
    The Mother Ship.
    Owns the Tkinter Root. All other UI microservices dock into this.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.root = tk.Tk()
        self.root.withdraw() # Hide until launch
        
        # Load Theme (Inject dependency or create new)
        self.theme_svc = self.config.get("theme_manager")
        if not self.theme_svc and TkinterThemeManagerMS:
            self.theme_svc = TkinterThemeManagerMS()
            
        self.colors = self.theme_svc.get_theme() if self.theme_svc else {}
        self._configure_root()
        
    def _configure_root(self):
        self.root.title(self.config.get("title", "Microservice OS"))
        self.root.geometry(self.config.get("geometry", "1200x800"))
        
        # Apply Base Theme
        bg = self.colors.get('background', '#1e1e1e')
        self.root.configure(bg=bg)
        
        # Configure TTK Styles globally
        style = ttk.Style()
        style.theme_use('clam')
        
        # Standard Frames
        style.configure('TFrame', background=bg)
        style.configure('TLabel', background=bg, foreground=self.colors.get('foreground', '#ccc'))
        style.configure('TButton', background=self.colors.get('panel_bg', '#333'), foreground='white')
        
        # Main Container (Grid or Pack)
        self.main_container = tk.Frame(self.root, bg=bg)
        self.main_container.pack(fill="both", expand=True, padx=5, pady=5)

    @service_endpoint(
        inputs={},
        outputs={},
        description="Starts the GUI Main Loop.",
        tags=["lifecycle", "start"],
        mode="sync",
        side_effects=["ui:block"]
    )
    def launch(self):
        """Ignition sequence start."""
        self.root.deiconify()
        logger.info("AppShell Launched.")
        self.root.mainloop()

    @service_endpoint(
        inputs={},
        outputs={"container": "tk.Frame"},
        description="Returns the main content area for other services to dock into.",
        tags=["ui", "layout"]
    )
    def get_main_container(self):
        """Other services call this to know where to .pack() themselves."""
        return self.main_container

    @service_endpoint(
        inputs={},
        outputs={},
        description="Gracefully shuts down the application.",
        tags=["lifecycle", "stop"],
        side_effects=["ui:close"]
    )
    def shutdown(self):
        self.root.quit()

if __name__ == "__main__":
    shell = TkinterAppShellMS({"title": "Test Shell"})
    shell.launch()
--------------------------------------------------------------------------------
FILE: _MicroserviceBROWSER\src\microservices\_TkinterThemeManagerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterThemeManagerMS
ENTRY_POINT: _TkinterThemeManagerMS.py
DEPENDENCIES: None
"""
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint

# Default "Dark Modern" Theme
DEFAULT_THEME = {
    'background': '#1e1e1e',
    'foreground': '#d4d4d4',
    'panel_bg':   '#252526',
    'border':     '#3c3c3c',
    'accent':     '#007acc',
    'error':      '#f48771',
    'success':    '#89d185',
    'font_main':  ('Segoe UI', 10),
    'font_mono':  ('Consolas', 10)
}

@service_metadata(
    name="TkinterThemeManager",
    version="1.0.0",
    description="Centralized configuration for UI colors and fonts.",
    tags=["ui", "config", "theme"],
    capabilities=["ui:style"]
)
class TkinterThemeManagerMS:
    """
    The Stylist: Holds the color palette and font settings.
    All UI components query this service to decide how to draw themselves.
    """
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.theme = DEFAULT_THEME.copy()
        
        # Allow override from config
        if "overrides" in self.config:
            self.theme.update(self.config["overrides"])

    @service_endpoint(
        inputs={},
        outputs={"theme": "Dict"},
        description="Returns the current active theme dictionary.",
        tags=["ui", "read"]
    )
    def get_theme(self) -> Dict[str, Any]:
        return self.theme

    @service_endpoint(
        inputs={"key": "str", "value": "Any"},
        outputs={},
        description="Updates a specific theme attribute (e.g., changing accent color).",
        tags=["ui", "write"],
        side_effects=["ui:refresh"]
    )
    def update_key(self, key: str, value: Any):
        self.theme[key] = value

if __name__ == "__main__":
    svc = TkinterThemeManagerMS()
    print("Theme Ready:", svc.get_theme()['accent'])
--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\base_service.py
--------------------------------------------------------------------------------
import logging
from typing import Dict, Any

class BaseService:
    """
    Standard parent class for all microservices. 
    Provides consistent logging and identity management.
    """
    def __init__(self, name: str):
        self._service_info = {
            "name": name, 
            "id": name.lower().replace(" ", "_")
        }
        
        # Setup standard logging
        logging.basicConfig(
            level=logging.INFO, 
            format='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%H:%M:%S'
        )
        self.logger = logging.getLogger(name)

    def log_info(self, message: str):
        self.logger.info(message)

    def log_error(self, message: str):
        self.logger.error(message)

    def log_warning(self, message: str):
        self.logger.warning(message)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\boiler_plate.py
--------------------------------------------------------------------------------
from microservice_std_lib import service_metadata, service_endpoint
from typing import Dict, Any, Optional

@service_metadata(
    name="YourServiceName",
    version="1.0.0",
    description="Briefly describe the 'Purpose' here.",
    tags=["category", "utility"],
    capabilities=["filesystem:read"] # Optional: what it actually touches
)
class YourServiceMS:
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        # Initialize your core logic/engines here

    @service_endpoint(
        inputs={"param1": "str", "param2": "int"},
        outputs={"result": "str"},
        description="Detailed description of what this specific method does.",
        tags=["action"],
        side_effects=["filesystem:write"] # Be explicit for the AI safety
    )
    def perform_action(self, param1: str, param2: int = 10) -> Dict[str, Any]:
        # Your translated logic goes here
        return {"result": f"Processed {param1}"}

if __name__ == "__main__":
    # Standard independent test block for the catalogue
    svc = YourServiceMS()
    print("Service ready:", svc)
    # Add a print test of your logic here
--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\DEP_REPORT.json
--------------------------------------------------------------------------------
{
  "folder": "C:\\Users\\petya\\Documents\\Jacob's BIN\\_UsefulHelperSCRIPTS\\_MicroserviceLIBRARY",
  "microservices": 58,
  "union_external": [
    "PIL",
    "bs4",
    "chromadb",
    "faiss",
    "httpx",
    "jinja2",
    "networkx",
    "numpy",
    "pydantic",
    "pygame",
    "pypdf",
    "readability",
    "requests",
    "sqlite_vec",
    "webview"
  ],
  "files": [
    {
      "file": "_ArchiveBotMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_AuthMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CartridgeServiceMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "sqlite_vec"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_ChalkBoardMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "webview"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_ChunkingRouterMS.py",
      "internal": [
        "_PythonChunkerMS",
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "_PythonChunkerMS",
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CodeChunkerMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CodeFormatterMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CodeGrapherMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CodeJanitorMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_CognitiveMemoryMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "pydantic"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_ContentExtractorMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "bs4",
        "pypdf"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_ContextAggregatorMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ContextPackerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_DiffEngineMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_EnvironmentManagerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ExplorerWidgetMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_FingerprintScannerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_GitPilotMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_HeuristicSumMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_IngestEngineMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_IntakeServiceMS.py",
      "internal": [
        "_CartridgeServiceMS",
        "_ScannerMS",
        "base_service",
        "document_utils",
        "microservice_std_lib"
      ],
      "external": [
        "bs4",
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "_CartridgeServiceMS",
        "_ScannerMS",
        "base_service",
        "document_utils",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_IsoProcessMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_LexicalSearchMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_LibrarianMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_LibrarianServiceMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_LogViewMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_MonacoHostMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "webview"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_NetworkLayoutMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "networkx"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_NeuralGraphEngineMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "pygame"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_NeuralGraphViewerMS.py",
      "internal": [
        "_NeuralGraphEngineMS",
        "base_service",
        "microservice_std_lib"
      ],
      "external": [
        "PIL"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "_NeuralGraphEngineMS",
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_NeuralServiceMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_ProjectForgeMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_PromptOptimizerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_PromptVaultMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "jinja2",
        "pydantic"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_PythonChunkerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_RefineryServiceMS.py",
      "internal": [
        "_CartridgeServiceMS",
        "_ChunkingRouterMS",
        "_NeuralServiceMS",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "_CartridgeServiceMS",
        "_ChunkingRouterMS",
        "_NeuralServiceMS",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_RegexWeaverMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_RoleManagerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "pydantic"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_SandboxManagerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ScannerMS.py",
      "internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "base_service",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ScoutMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "bs4",
        "requests"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_SearchEngineMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "requests",
        "sqlite_vec"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_SemanticChunkerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ServiceRegistryMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_SpinnerThingyMaBobberMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_SysInspectorMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TasklistVaultMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TelemetryServiceMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TextChunkerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_ThoughtStreamMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TkinterAppShellMS.py",
      "internal": [
        "_TkinterThemeManagerMS",
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "_TkinterThemeManagerMS",
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TkinterSmartExplorerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TkinterThemeManagerMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TkinterUniButtonMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_TreeMapperMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    },
    {
      "file": "_VectorFactoryMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "chromadb",
        "faiss",
        "numpy"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_WebScraperMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [
        "httpx",
        "readability"
      ],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [],
      "errors": []
    },
    {
      "file": "_WorkbenchLayoutMS.py",
      "internal": [
        "microservice_std_lib"
      ],
      "external": [],
      "declared_internal": [],
      "inferred_internal": [
        "microservice_std_lib"
      ],
      "notes": [
        "No external deps inferred."
      ],
      "errors": []
    }
  ]
}

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\DEP_REPORT.md
--------------------------------------------------------------------------------
# Microservice Dependency Report

- Folder: `C:\Users\petya\Documents\Jacob's BIN\_UsefulHelperSCRIPTS\_MicroserviceLIBRARY`
- Microservices: **58**
- External packages (union): **15**

## _ArchiveBotMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _AuthMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CartridgeServiceMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `['sqlite_vec']`
- Inferred internal: `['base_service', 'microservice_std_lib']`

## _ChalkBoardMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `['webview']`
- Inferred internal: `['base_service', 'microservice_std_lib']`

## _ChunkingRouterMS.py
- Internal (vendored): `['_PythonChunkerMS', 'base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['_PythonChunkerMS', 'base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CodeChunkerMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CodeFormatterMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CodeGrapherMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CodeJanitorMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _CognitiveMemoryMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `['pydantic']`
- Inferred internal: `['base_service', 'microservice_std_lib']`

## _ContentExtractorMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['bs4', 'pypdf']`
- Inferred internal: `['microservice_std_lib']`

## _ContextAggregatorMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ContextPackerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _DiffEngineMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _EnvironmentManagerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ExplorerWidgetMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _FingerprintScannerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _GitPilotMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _HeuristicSumMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _IngestEngineMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `['requests']`
- Inferred internal: `['base_service', 'microservice_std_lib']`

## _IntakeServiceMS.py
- Internal (vendored): `['_CartridgeServiceMS', '_ScannerMS', 'base_service', 'document_utils', 'microservice_std_lib']`
- External (pip): `['bs4', 'requests']`
- Inferred internal: `['_CartridgeServiceMS', '_ScannerMS', 'base_service', 'document_utils', 'microservice_std_lib']`

## _IsoProcessMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _LexicalSearchMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _LibrarianMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['requests']`
- Inferred internal: `['microservice_std_lib']`

## _LibrarianServiceMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['requests']`
- Inferred internal: `['microservice_std_lib']`

## _LogViewMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _MonacoHostMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['webview']`
- Inferred internal: `['microservice_std_lib']`

## _NetworkLayoutMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['networkx']`
- Inferred internal: `['microservice_std_lib']`

## _NeuralGraphEngineMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `['pygame']`
- Inferred internal: `['base_service', 'microservice_std_lib']`

## _NeuralGraphViewerMS.py
- Internal (vendored): `['_NeuralGraphEngineMS', 'base_service', 'microservice_std_lib']`
- External (pip): `['PIL']`
- Inferred internal: `['_NeuralGraphEngineMS', 'base_service', 'microservice_std_lib']`

## _NeuralServiceMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['requests']`
- Inferred internal: `['microservice_std_lib']`

## _ProjectForgeMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _PromptOptimizerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _PromptVaultMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['jinja2', 'pydantic']`
- Inferred internal: `['microservice_std_lib']`

## _PythonChunkerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _RefineryServiceMS.py
- Internal (vendored): `['_CartridgeServiceMS', '_ChunkingRouterMS', '_NeuralServiceMS', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['_CartridgeServiceMS', '_ChunkingRouterMS', '_NeuralServiceMS', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _RegexWeaverMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _RoleManagerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['pydantic']`
- Inferred internal: `['microservice_std_lib']`

## _SandboxManagerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ScannerMS.py
- Internal (vendored): `['base_service', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['base_service', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ScoutMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['bs4', 'requests']`
- Inferred internal: `['microservice_std_lib']`

## _SearchEngineMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['requests', 'sqlite_vec']`
- Inferred internal: `['microservice_std_lib']`

## _SemanticChunkerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ServiceRegistryMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _SpinnerThingyMaBobberMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _SysInspectorMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TasklistVaultMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TelemetryServiceMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TextChunkerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _ThoughtStreamMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TkinterAppShellMS.py
- Internal (vendored): `['_TkinterThemeManagerMS', 'microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['_TkinterThemeManagerMS', 'microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TkinterSmartExplorerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TkinterThemeManagerMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TkinterUniButtonMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _TreeMapperMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`

## _VectorFactoryMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['chromadb', 'faiss', 'numpy']`
- Inferred internal: `['microservice_std_lib']`

## _WebScraperMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `['httpx', 'readability']`
- Inferred internal: `['microservice_std_lib']`

## _WorkbenchLayoutMS.py
- Internal (vendored): `['microservice_std_lib']`
- External (pip): `[]`
- Inferred internal: `['microservice_std_lib']`
- Notes: `['No external deps inferred.']`


--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\document_utils.py
--------------------------------------------------------------------------------
from _ContentExtractorMS import ContentExtractorMS

# Singleton instance to reuse the extractor logic
_extractor = ContentExtractorMS()

def extract_text_from_pdf(blob: bytes) -> str:
    """Proxy to ContentExtractorMS PDF logic."""
    return _extractor._extract_pdf(blob)

def extract_text_from_html(html_text: str) -> str:
    """Proxy to ContentExtractorMS HTML logic."""
    return _extractor._extract_html(html_text)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\LIBRARY_CATALOGUE.md
--------------------------------------------------------------------------------
# üìö Microservice Library Card Catalogue
> **Generated**: 2025-12-23 08:50
> **Total Services**: 53
> **Swarm Configuration**: `4` Workers (`qwen2.5-coder:1.5b-cpu`), 1 Architect (`qwen2.5-coder:3b-cpu`)

## üß† System Architecture Overview
System analysis failed.

## üìá Index
- **[ArchiveBotMS](#archivebotms)**: 
- **[AuthMS](#authms)**: ROLE: Simple authentication microservice providing username/password login
- **[CartridgeServiceMS](#cartridgeservicems)**: The Source of Truth.
- **[ChalkBoardMS](#chalkboardms)**: 
- **[ChunkingRouterMS](#chunkingrouterms)**: The Editor: A 'Recursive' text splitter.
- **[CodeChunkerMS](#codechunkerms)**: The Surgeon (Pure Python Edition): Splits code into semantic blocks
- **[CodeFormatterMS](#codeformatterms)**: The Architect.
- **[CodeGrapherMS](#codegrapherms)**: The Cartographer of Logic: Parses Python code to extract high-level 
- **[CodeJanitorMS](#codejanitorms)**: 
- **[CognitiveMemoryMS](#cognitivememoryms)**: The Hippocampus: Manages Short-Term (Working) Memory and orchestrates 
- **[ContentExtractorMS](#contentextractorms)**: The Decoder.
- **[ContextPackerMS](#contextpackerms)**: The Packer: Walks a directory and dumps all text-readable files 
- **[EnvironmentManagerMS](#environmentmanagerms)**: The Operator.
- **[ExplorerWidgetMS](#explorerwidgetms)**: A standalone file system tree viewer.
- **[HeuristicSumMS](#heuristicsumms)**: The Skimmer: Generates quick summaries of code/text files without AI.
- **[IngestEngineMS](#ingestenginems)**: The Heavy Lifter: Reads files, chunks text, fetches embeddings,
- **[IntakeServiceMS](#intakeservicems)**: The Vacuum. 
- **[IsoProcessMS](#isoprocessms)**: The Safety Valve: Spawns isolated processes with real-time logging feedback.
- **[LexicalSearchMS](#lexicalsearchms)**: The Librarian's Index: A lightweight, AI-free search engine.
- **[LibrarianMS](#librarianms)**: The Swarm Librarian.
- **[LibrarianMS](#librarianms)**: 
- **[LogViewMS](#logviewms)**: The Console: A professional log viewer widget.
- **[MonacoHostMS](#monacohostms)**: Hosts the Monaco Editor.
- **[NetworkLayoutMS](#networklayoutms)**: The Topologist: Calculates visual coordinates for graph nodes using
- **[NeuralGraphEngineMS](#neuralgraphenginems)**: ‚ú® This Python class implements a neural graph rendering engine using Pygame, pro
- **[NeuralGraphViewerMS](#neuralgraphviewerms)**: ‚ú® This Python class is a Tkinter-based UI component that hosts the neural graph 
- **[NeuralServiceMS](#neuralservicems)**: The Brain Interface: Orchestrates local AI operations via Ollama for inference a
- **[ProjectForgeMS](#projectforgems)**: The Blacksmith.
- **[PromptOptimizerMS](#promptoptimizerms)**: The Tuner: Uses an LLM to refine prompts or generate variations.
- **[PromptVaultMS](#promptvaultms)**: The Vault: A persistent SQLite store for managing, versioning, 
- **[PythonChunkerMS](#pythonchunkerms)**: Specialized Python AST Chunker.
- **[RefineryServiceMS](#refineryservicems)**: The Night Shift.
- **[RegexWeaverMS](#regexweaverms)**: The Weaver: A fault-tolerant dependency extractor.
- **[RoleManagerMS](#rolemanagerms)**: The Casting Director: Manages Agent Personas (Roles).
- **[SandboxManagerMS](#sandboxmanagerms)**: The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project.
- **[ScannerMS](#scannerms)**: The Scanner: Walks the file system, filters junk, and detects binary files.
- **[ScoutMS](#scoutms)**: The Scanner: Walks file systems OR crawls websites (Depth-Aware).
- **[SearchEngineMS](#searchenginems)**: The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching).
- **[SemanticChunkerMS](#semanticchunkerms)**: Intelligent Code Splitter.
- **[ServiceRegistryMS](#serviceregistryms)**: The Tokenizer (v2): Scans a library of Python microservices and generates
- **[SpinnerThingyMaBobberMS](#spinnerthingymabobberms)**: The Visualizer: An interactive spinner widget.
- **[SysInspectorMS](#sysinspectorms)**: The Auditor: Gathers hardware and environment statistics.
- **[TasklistVaultMS](#tasklistvaultms)**: The Taskmaster: A persistent SQLite engine for hierarchical task management.
- **[TelemetryServiceMS](#telemetryservicems)**: The Nervous System.
- **[TextChunkerMS](#textchunkerms)**: The Butcher: A unified service for splitting text into digestible chunks
- **[ThoughtStreamMS](#thoughtstreamms)**: The Neural Inspector: A UI widget for displaying a stream of AI thoughts/logs
- **[TkinterAppShellMS](#tkinterappshellms)**: The Mother Ship.
- **[TkinterSmartExplorerMS](#tkintersmartexplorerms)**: The Navigator.
- **[TkinterThemeManagerMS](#tkinterthememanagerms)**: The Stylist: Holds the color palette and font settings.
- **[TkinterUniButtonMS](#tkinterunibuttonms)**: A generic button group that can merge ANY two actions.
- **[TreeMapperMS](#treemapperms)**: The Cartographer: Generates ASCII-art style directory maps.
- **[VectorFactoryMS](#vectorfactoryms)**: The Switchboard: Returns the appropriate VectorStore implementation
- **[WebScraperMS](#webscraperms)**: The Reader: Fetches URLs and extracts the main content using Readability.

---

### ArchiveBotMS
**File**: `_ArchiveBotMS.py`
**Description**: 

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `create_backup` | `source_path, output_dir, extra_exclusions, use_default_exclusions` |  |

---

### AuthMS
**File**: `_AuthMS.py`
**Description**: ROLE: Simple authentication microservice providing username/password login
      and signed session tokens.

INPUTS:
  - config: Optional configuration dict. Recognized keys:
      - 'secret_key': Secret used to sign tokens.

OUTPUTS:
  - Exposes `login` and `validate_session` endpoints for use in pipelines.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `login` | `username, password` | Attempt to log in with the provided username and password. |
| `validate_session` | `token` | Check if a serialized token is valid and not expired. |

---

### CartridgeServiceMS
**File**: `_CartridgeServiceMS.py`
**Description**: The Source of Truth.
Manages the Unified Neural Cartridge Format (UNCF v1.0).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_vector_dim` | `None` | Retrieves the expected vector dimension from the manifest spec. |
| `initialize_manifest` | `None` | Populates the boot sector with strict RagFORGE Cartridge Schema (UNCF) v1.1. |
| `set_manifest` | `key, value` | Upsert metadata key. |
| `get_manifest` | `key` | Retrieve metadata key. |
| `validate_cartridge` | `None` | Quality Control: Checks if the cartridge is Agent-Safe. |
| `store_file` | `vfs_path, origin_path, content, blob, mime_type, origin_type` | The Universal Input Method.  |
| `get_pending_files` | `limit` | Fetches files waiting for the Refinery. |
| `update_status` | `file_id, status, metadata` |  |
| `ensure_directory` | `vfs_path` | Idempotent insert for VFS directories. |
| `get_status_flags` | `None` | Returns key manifest status flags in a single call. |
| `list_files` | `prefix, status, limit` | Enumerate files in the cartridge (optionally filtered by VFS prefix and/or status). |
| `get_file_record` | `vfs_path` | Fetch a single file record by VFS path. |
| `list_directories` | `prefix` | Enumerate directories in the cartridge VFS. |
| `get_directory_tree` | `root` | Builds a nested directory tree starting at `root` ("" for full tree). |
| `get_status_summary` | `None` | Counts files by status and provides a quick cartridge overview. |
| `add_node` | `node_id, node_type, label, data` |  |
| `add_edge` | `source, target, relation, weight` |  |
| `search_embeddings` | `query_vector, limit` | Performs semantic search using sqlite-vec. |

---

### ChalkBoardMS
**File**: `_ChalkBoardMS.py`
**Description**: 

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `loaded` | `None` | Called by JS when the page is ready. |
| `log_action` | `action_name` | Called by JS when user interacts. |
| `update_sign` | `text, theme` | Updates the embedded HTML via JS injection. |
| `trigger_effect` | `effect` | Triggers CSS animations like 'shake'. |

---

### ChunkingRouterMS
**File**: `_ChunkingRouterMS.py`
**Description**: The Editor: A 'Recursive' text splitter.
It respects the natural structure of text (Paragraphs -> Sentences -> Words)
rather than just hacking it apart by character count.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `chunk_file` | `text, filename, max_size, overlap` | Extension-aware router. |

---

### CodeChunkerMS
**File**: `_CodeChunkerMS.py`
**Description**: The Surgeon (Pure Python Edition): Splits code into semantic blocks
(Classes, Functions) using indentation and regex heuristics.

Advantages: Zero dependencies. Works on any machine.
Disadvantages: Slightly less precise than Tree-Sitter for messy code.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `chunk_file` | `file_path, max_chars` | Reads a file and breaks it into logical blocks based on indentation. |

---

### CodeFormatterMS
**File**: `_CodeFormatterMS.py`
**Description**: The Architect.
Uses the WhitespaceEngine to enforce strict indentation rules, 
fixing 'staircase' formatting and mixed tabs/spaces.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `normalize_code` | `content, use_tabs, spaces` | Pure logic endpoint: Takes string, returns string + patch. |
| `format_file` | `file_path, use_tabs, spaces` | Filesystem endpoint: In-place repair of a file. |

---

### CodeGrapherMS
**File**: `_CodeGrapherMS.py`
**Description**: The Cartographer of Logic: Parses Python code to extract high-level 
symbols (classes, functions) and maps their 'Call' relationships.

Output: A graph structure (Nodes + Edges) suitable for visualization 
or dependency analysis.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `scan_directory` | `root_path` | Recursively scans a directory for .py files and builds the graph. |

---

### CodeJanitorMS
**File**: `_CodeJanitorMS.py`
**Description**: 

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `enforce_standards` | `dry_run` |  |

---

### CognitiveMemoryMS
**File**: `_CognitiveMemoryMS.py`
**Description**: The Hippocampus: Manages Short-Term (Working) Memory and orchestrates 
flushing to Long-Term Memory (Vector Store).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `add_entry` | `role, content, metadata` | Adds an item to working memory and persists it. |
| `get_context` | `limit` | Returns the most recent conversation history formatted for an LLM. |
| `get_full_history` | `None` | Returns the raw list of memory objects. |
| `commit_turn` | `None` | Signal that a "Turn" (User + AI response) is complete. |

---

### ContentExtractorMS
**File**: `_ContentExtractorMS.py`
**Description**: The Decoder.
A standalone utility microservice that separates the concern of 
document parsing from ingestion logic.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status and library availability. |
| `extract_text` | `blob, mime_type` | Main routing logic for extraction.  |

---

### ContextPackerMS
**File**: `_ContextPackerMS.py`
**Description**: The Packer: Walks a directory and dumps all text-readable files 
into a single monolithic text file with delimiters.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `pack_directory` | `root_path, output_filename, additional_excludes` | Walks the directory and writes file contents to the output file. |

---

### EnvironmentManagerMS
**File**: `_EnvironmentManagerMS.py`
**Description**: The Operator.
Finds the right Python interpreter (System vs Venv) and launches processes.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `resolve_python` | `project_path, config_override` | Priority: |
| `launch_script` | `project_path, script_rel_path, env_vars` |  |

---

### ExplorerWidgetMS
**File**: `_ExplorerWidgetMS.py`
**Description**: A standalone file system tree viewer.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `refresh_tree` | `None` |  |
| `get_selected_paths` | `None` |  |
| `process_gui_queue` | `None` |  |

---

### HeuristicSumMS
**File**: `_HeuristicSumMS.py`
**Description**: The Skimmer: Generates quick summaries of code/text files without AI.
Scans for high-value lines (headers, signatures, docstrings) and concatenates them.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `summarize` | `text, filename, max_chars` | Generates a summary string from the provided text. |

---

### IngestEngineMS
**File**: `_IngestEngineMS.py`
**Description**: The Heavy Lifter: Reads files, chunks text, fetches embeddings,
populates the Graph Nodes, and weaves Graph Edges.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `abort` | `None` |  |
| `check_ollama_connection` | `None` |  |
| `get_available_models` | `None` |  |
| `process_files` | `file_paths, model_name` |  |

---

### IntakeServiceMS
**File**: `_IntakeServiceMS.py`
**Description**: The Vacuum. 
Now supports two-phase ingestion:
1. Scan -> Build Tree (with .gitignore respect)
2. Ingest -> Process selected paths

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status of the IntakeServiceMS. |
| `ingest_source` | `source_path` | Headless/CLI Entry point: Scans and Ingests in one go. |
| `scan_path` | `root_path, web_depth` | Unified Scanner Interface. |
| `ingest_selected` | `file_list, root_path` | Ingests only the specific files passed in the list. |
| `save_persistence` | `root_path, checked_map` | Saves user selections into the Cartridge Manifest (Portable). |

---

### IsoProcessMS
**File**: `_IsoProcessMS.py`
**Description**: The Safety Valve: Spawns isolated processes with real-time logging feedback.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `execute` | `payload, config` |  |

---

### LexicalSearchMS
**File**: `_LexicalSearchMS.py`
**Description**: The Librarian's Index: A lightweight, AI-free search engine.

Uses SQLite's FTS5 extension to provide fast, ranked keyword search (BM25).
Ideal for environments where installing PyTorch/Transformers is impossible
or overkill.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `add_document` | `doc_id, text, metadata` | Adds or updates a document in the index. |
| `search` | `query, top_k` | Performs a BM25 Ranked Search. |

---

### LibrarianMS
**File**: `_LibrarianMS.py`
**Description**: The Swarm Librarian.
Spawns concurrent AI workers to scan the codebase and create a system manifest.
Optimized for Ryzen CPUs and 32GB RAM.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `generate_catalog` | `output_file` | Main entry point. Uses ThreadPoolExecutor for parallel processing. |

---

### LibrarianMS
**File**: `_LibrarianServiceMS.py`
**Description**: 

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `generate_catalog` | `output_file` |  |

---

### LogViewMS
**File**: `_LogViewMS.py`
**Description**: The Console: A professional log viewer widget.
Features:
- Thread-safe (consumes from a Queue).
- Message Consolidation ("Error occurred (x5)").
- Level Filtering (Toggle INFO/DEBUG/ERROR).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `clear` | `None` |  |
| `save` | `None` |  |

---

### MonacoHostMS
**File**: `_MonacoHostMS.py`
**Description**: Hosts the Monaco Editor.
This service spawns a GUI window and cannot be run in headless environments.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `launch` | `title, width, height, func` | Create and launch the window. |
| `set_save_callback` | `callback` | Sets the function to trigger when Ctrl+S is pressed in the editor. |
| `open_file` | `filepath, content` | Opens a file in the editor (must be called from a background thread or callback). |

---

### NetworkLayoutMS
**File**: `_NetworkLayoutMS.py`
**Description**: The Topologist: Calculates visual coordinates for graph nodes using
server-side algorithms (NetworkX). 
Useful for generating static map snapshots or pre-calculating positions 
to offload client-side rendering.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `calculate_layout` | `nodes, edges, algorithm` | Computes (x, y) coordinates for the given graph. |

---

### NeuralGraphEngineMS
**File**: `_NeuralGraphEngineMS.py`
**Description**: ‚ú® This Python class implements a neural graph rendering engine using Pygame, providing real-time visualization of complex relationships in a 2D force-directed graph. It includes functionalities for camera control, asset management, data manipulation, and physics simulation to ensure smooth rendering and interaction with the user.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status of the NeuralGraphEngineMS. |
| `resize` | `width, height` |  |
| `set_data` | `nodes, links` |  |
| `screen_to_world` | `sx, sy` |  |
| `get_node_at` | `sx, sy` |  |
| `handle_mouse_down` | `x, y` |  |
| `handle_mouse_move` | `x, y, is_dragging` |  |
| `handle_mouse_up` | `None` |  |
| `pan` | `dx, dy` |  |
| `zoom_camera` | `amount, mouse_x, mouse_y` |  |
| `highlight_nodes` | `node_ids` | Highlights specific nodes by ID. |
| `step_physics` | `None` |  |
| `get_image_bytes` | `None` |  |

---

### NeuralGraphViewerMS
**File**: `_NeuralGraphViewerMS.py`
**Description**: ‚ú® This Python class is a Tkinter-based UI component that hosts the neural graph engine and provides search/highlighting overlays. It includes features for searching, highlighting, and rendering graphs in a user-friendly interface.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `bind_services` | `cartridge, neural` |  |
| `run_search` | `event` |  |
| `load_from_db` | `db_path` | Loads graph data from SQLite. |
| `on_resize` | `event` |  |
| `on_double_click` | `event` |  |
| `on_click` | `event` |  |
| `on_release` | `event` |  |
| `on_drag` | `event` |  |
| `on_hover` | `event` |  |
| `on_zoom` | `amount` |  |
| `on_windows_scroll` | `event` |  |
| `animate` | `None` | The Heartbeat Loop. |

---

### NeuralServiceMS
**File**: `_NeuralServiceMS.py`
**Description**: The Brain Interface: Orchestrates local AI operations via Ollama for inference and embeddings.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `update_models` | `fast_model, smart_model, embed_model` | Called by the UI Settings Modal to change models on the fly. |
| `get_available_models` | `None` | Fetches list from Ollama for the UI dropdown. |
| `check_connection` | `None` | Pings Ollama to see if it's alive. |
| `get_embedding` | `text` | Generates a vector using the configured embedding model. |
| `request_inference` | `prompt, tier, format_json` | Synchronous inference request. |
| `process_parallel` | `items, worker_func` | Helper to run a function across many items using a ThreadPool. |

---

### ProjectForgeMS
**File**: `_ProjectForgeMS.py`
**Description**: The Blacksmith.
Creates directory structures, stamps out boilerplate code, and injects dependencies.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `forge_project` | `parent_path, project_name, dependencies, project_type` | Stamps out a new project folder. |

---

### PromptOptimizerMS
**File**: `_PromptOptimizerMS.py`
**Description**: The Tuner: Uses an LLM to refine prompts or generate variations.
Requires an 'inference_func' to be passed in the config, which accepts a string
and returns a string (simulating an LLM call).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `refine_prompt` | `draft_prompt, feedback` | Rewrites a prompt based on feedback. |
| `generate_variations` | `draft_prompt, num_variations, context_data` | Generates multiple versions of a prompt for testing. |

---

### PromptVaultMS
**File**: `_PromptVaultMS.py`
**Description**: The Vault: A persistent SQLite store for managing, versioning, 
and rendering AI prompts.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `create_template` | `slug, title, content, author, tags` | Creates a new prompt template with an initial version 1. |
| `add_version` | `slug, content, author` | Adds a new version to an existing template. |
| `get_template` | `slug` | Retrieves a full template with all history. |
| `render` | `slug, context` | Fetches the latest version and renders it with Jinja2. |
| `list_slugs` | `None` |  |

---

### PythonChunkerMS
**File**: `_PythonChunkerMS.py`
**Description**: Specialized Python AST Chunker.
Focuses exclusively on identifying classes and functions to preserve code logic.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status of the PythonChunkerMS. |
| `chunk` | `content` | Parses Python source into semantic CodeChunks. |

---

### RefineryServiceMS
**File**: `_RefineryServiceMS.py`
**Description**: The Night Shift.
Polls the DB for 'RAW' files and processes them into Chunks and Graph Nodes.

Graph Enrichment:
- Code: function/class nodes, resolved import edges when possible.
- Docs: section/chapter nodes for long-form text (md/txt/rst).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status of the RefineryServiceMS. |
| `process_pending` | `batch_size` | Main loop. Returns number of files processed. |

---

### RegexWeaverMS
**File**: `_RegexWeaverMS.py`
**Description**: The Weaver: A fault-tolerant dependency extractor.
Uses Regex to find imports, making it faster and more permissive
than AST parsers (works on broken code).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `extract_dependencies` | `content, language` | Scans code content for import statements. |

---

### RoleManagerMS
**File**: `_RoleManagerMS.py`
**Description**: The Casting Director: Manages Agent Personas (Roles).
Persists configuration for System Prompts, Attached KBs, and Memory Settings.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `create_role` | `name, system_prompt, description, kbs` | Creates a new Agent Persona. |
| `get_role` | `name_or_id` | Retrieves a role by Name or ID. |
| `list_roles` | `None` |  |
| `delete_role` | `name` |  |

---

### SandboxManagerMS
**File**: `_SandboxManagerMS.py`
**Description**: The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project.
Allows for safe experimentation, diffing, and atomic promotion of changes.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `init_sandbox` | `force` | Creates or resets the sandbox by mirroring the live project. |
| `reset_sandbox` | `None` | Discards all sandbox changes and re-syncs from live. |
| `get_diff` | `None` | Compares Sandbox vs Live. Returns added, modified, and deleted files. |
| `promote_changes` | `None` | Applies changes from Sandbox to Live. |

---

### ScannerMS
**File**: `_ScannerMS.py`
**Description**: The Scanner: Walks the file system, filters junk, and detects binary files.
Generates the tree structure used by the UI.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `is_binary` | `file_path` | Determines if a file is binary using two heuristics: |
| `scan_directory` | `root_path` | Recursively scans a directory and returns a JSON-compatible tree. |
| `flatten_tree` | `tree_node` | Helper to extract all valid file paths from a tree node  |

---

### ScoutMS
**File**: `_ScoutMS.py`
**Description**: The Scanner: Walks file systems OR crawls websites (Depth-Aware).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `is_binary` | `file_path` |  |
| `scan_directory` | `root_path, web_depth` | Main Entry Point. |
| `flatten_tree` | `tree_node` |  |

---

### SearchEngineMS
**File**: `_SearchEngineMS.py`
**Description**: The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching).

Architecture:
1. Vector Search: Uses sqlite-vec (vec0) for fast nearest neighbor search.
2. Keyword Search: Uses SQLite FTS5 for BM25-style text matching.
3. Reranking: Combines scores using Reciprocal Rank Fusion (RRF).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `search` | `db_path, query, limit` | Main entry point. Returns a list of results sorted by relevance. |

---

### SemanticChunkerMS
**File**: `_SemanticChunkerMS.py`
**Description**: Intelligent Code Splitter.
Parses source code into logical units (Classes, Functions) 
rather than arbitrary text windows.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `chunk_file` | `content, filename` | Splits file content into chunks. |

---

### ServiceRegistryMS
**File**: `_ServiceRegistryMS.py`
**Description**: The Tokenizer (v2): Scans a library of Python microservices and generates
standardized JSON 'Service Tokens'.
Feature: Hybrid AST/Regex parsing for maximum robustness.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `scan` | `save_to` |  |

---

### SpinnerThingyMaBobberMS
**File**: `_SpinnerThingyMaBobberMS.py`
**Description**: The Visualizer: An interactive spinner widget.
Useful for "Processing..." screens or OBS overlays.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `launch` | `None` | Starts the Tkinter main event loop. |
| `handle_keypress` | `event` |  |
| `get_neon_color` | `offset` |  |
| `draw_arc` | `cx, cy, radius, width, start, extent, color` |  |
| `animate` | `None` |  |

---

### SysInspectorMS
**File**: `_SysInspectorMS.py`
**Description**: The Auditor: Gathers hardware and environment statistics.
Supports: Windows (WMIC), Linux (lscpu/lspci), and macOS (sysctl/system_profiler).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `generate_report` | `None` | Runs the full audit and returns a formatted string report. |

---

### TasklistVaultMS
**File**: `_TasklistVaultMS.py`
**Description**: The Taskmaster: A persistent SQLite engine for hierarchical task management.
Supports infinite nesting of sub-tasks and status tracking.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `create_list` | `name` | Creates a new task list and returns its ID. |
| `get_lists` | `None` | Returns metadata for all task lists. |
| `add_task` | `list_id, content, parent_id` | Adds a task (or sub-task) to a list. |
| `update_task` | `task_id, content, status, result` | Updates a task's details. |
| `get_full_tree` | `list_id` | Fetches a list and reconstructs the full hierarchy of tasks. |
| `delete_list` | `list_id` |  |

---

### TelemetryServiceMS
**File**: `_TelemetryServiceMS.py`
**Description**: The Nervous System.
Watches the thread-safe LogQueue and updates the GUI Panels.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_health` | `None` | Returns the operational status of the TelemetryServiceMS. |
| `start` | `None` | Begins the GUI update loop. |
| `ping` | `None` | Allows an agent to verify the pulse of the UI loop. |

---

### TextChunkerMS
**File**: `_TextChunkerMS.py`
**Description**: The Butcher: A unified service for splitting text into digestible chunks
for RAG (Retrieval Augmented Generation).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `chunk_by_chars` | `text, chunk_size, chunk_overlap` | Standard Sliding Window. Best for prose/documentation. |
| `chunk_by_lines` | `text, max_lines, max_chars` | Line-Preserving Chunker. Best for Code. |

---

### ThoughtStreamMS
**File**: `_ThoughtStreamMS.py`
**Description**: The Neural Inspector: A UI widget for displaying a stream of AI thoughts/logs
visualized as 'bubbles' with sparklines.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `add_thought_bubble` | `filename, chunk_id, content, vector_preview, color` | Mimics the 'InspectorFrame' from your React code. |

---

### TkinterAppShellMS
**File**: `_TkinterAppShellMS.py`
**Description**: The Mother Ship.
Owns the Tkinter Root. All other UI microservices dock into this.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `launch` | `None` | Ignition sequence start. |
| `get_main_container` | `None` | Other services call this to know where to .pack() themselves. |
| `shutdown` | `None` |  |

---

### TkinterSmartExplorerMS
**File**: `_TkinterSmartExplorerMS.py`
**Description**: The Navigator.
A TreeView widget that expects standard 'Node' dictionaries (name, type, children).

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `load_data` | `data` | Ingests a dictionary tree (like from _ScoutMS or _TreeMapperMS). |

---

### TkinterThemeManagerMS
**File**: `_TkinterThemeManagerMS.py`
**Description**: The Stylist: Holds the color palette and font settings.
All UI components query this service to decide how to draw themselves.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `get_theme` | `None` |  |
| `update_key` | `key, value` |  |

---

### TkinterUniButtonMS
**File**: `_TkinterUniButtonMS.py`
**Description**: A generic button group that can merge ANY two actions.
Pass the visual/functional definitions in via the config objects.

---

### TreeMapperMS
**File**: `_TreeMapperMS.py`
**Description**: The Cartographer: Generates ASCII-art style directory maps.
Useful for creating context snapshots for LLMs.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `generate_tree` | `root_path, additional_exclusions, use_default_exclusions` |  |

---

### VectorFactoryMS
**File**: `_VectorFactoryMS.py`
**Description**: The Switchboard: Returns the appropriate VectorStore implementation
based on configuration.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `create` | `backend, config` | :param backend: 'faiss' or 'chroma' |

---

### WebScraperMS
**File**: `_WebScraperMS.py`
**Description**: The Reader: Fetches URLs and extracts the main content using Readability.
Strips ads, navbars, and boilerplate to return clean text for LLMs.

| Endpoint | Inputs | Summary |
| :--- | :--- | :--- |
| `scrape` | `url` | Synchronous wrapper for fetching and cleaning a URL. |

---

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\microservice_std_lib.py
--------------------------------------------------------------------------------
"""
LIBRARY: Microservice Standard Lib
VERSION: 2.1.0
ROLE: Provides decorators for tagging Python classes as AI-discoverable services.

Change (2.1.0):
- Split dependencies into:
    internal_dependencies: local modules / microservices to vendor with the app
    external_dependencies: pip-installable packages (requirements.txt)
- Keep legacy "dependencies" as an alias for external_dependencies for backward compatibility.
- Accept unknown keyword args in @service_metadata(...) to prevent older/newer services from crashing
  (e.g. when a runner passes additional fields).
"""

import functools
import inspect
from typing import Dict, List, Any, Optional, Type

# ==============================================================================
# DECORATORS (The "Writer" Tools)
# ==============================================================================

def service_metadata(
    name: str,
    version: str,
    description: str,
    tags: List[str],
    capabilities: Optional[List[str]] = None,

    # Legacy field (kept for backward compatibility):
    # Historically this mixed stdlib + pip deps. Going forward, treat this as *external* deps.
    dependencies: Optional[List[str]] = None,

    # New fields (preferred):
    internal_dependencies: Optional[List[str]] = None,
    external_dependencies: Optional[List[str]] = None,

    # Side effects / operational hints
    side_effects: Optional[List[str]] = None,

    # Forward-compat: ignore unknown keyword args instead of crashing older/newer services
    **_ignored_kwargs: Any,
):
    """
    Class Decorator.
    Labels a Microservice class with high-level metadata for the Catalog.

    Dependency semantics:
      - internal_dependencies: local modules and/or other microservice modules that must be shipped with an app
      - external_dependencies: third-party pip packages (requirements.txt)
      - dependencies (legacy): treated as external_dependencies when external_dependencies is not provided
    """
    # Prefer explicit new key, otherwise fall back to legacy dependencies
    ext = external_dependencies if external_dependencies is not None else (dependencies or [])
    intl = internal_dependencies or []

    def decorator(cls):
        cls._is_microservice = True
        cls._service_info = {
            "name": name,
            "version": version,
            "description": description,
            "tags": tags,
            "capabilities": capabilities or [],

            # New keys
            "internal_dependencies": intl,
            "external_dependencies": ext,

            # Legacy alias (keep existing tooling working)
            "dependencies": ext,

            "side_effects": side_effects or []
        }
        return cls
    return decorator


def service_endpoint(
    inputs: Dict[str, str],
    outputs: Dict[str, str],
    description: str,
    tags: Optional[List[str]] = None,
    side_effects: Optional[List[str]] = None,
    mode: str = "sync",
):
    """
    Method Decorator.
    Defines the 'Socket' that the AI Architect can plug into.

    :param inputs: Dict of {arg_name: type_string} (e.g. {"query": "str"})
    :param outputs: Dict of {return_name: type_string}
    :param description: What the endpoint does
    :param tags: List of categories (e.g. ["read", "write"])
    :param side_effects: List of side effects (e.g. ["filesystem:write", "db:write"])
    :param mode: "sync" or "async" (informational unless your runtime uses it)
    """

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            return func(*args, **kwargs)

        # Attach metadata to the function object itself
        wrapper._is_endpoint = True
        wrapper._endpoint_info = {
            "name": func.__name__,
            "inputs": inputs,
            "outputs": outputs,
            "description": description,
            "tags": tags or [],
            "side_effects": side_effects or [],
            "mode": mode
        }
        return wrapper
    return decorator


# ==============================================================================
# INTROSPECTION (The "Reader" Tools)
# ==============================================================================

def extract_service_schema(service_cls: Type) -> Dict[str, Any]:
    """
    Scans a decorated Service Class and returns a JSON-serializable schema
    of its metadata and all its exposed endpoints.

    This is what the AI Agent uses to 'read' the manual.
    """
    if not getattr(service_cls, "_is_microservice", False):
        raise ValueError(f"Class {service_cls.__name__} is not decorated with @service_metadata")

    schema = {
        "meta": getattr(service_cls, "_service_info", {}),
        "endpoints": []
    }

    # Inspect all methods of the class
    for _, method in inspect.getmembers(service_cls, predicate=inspect.isfunction):
        endpoint_info = getattr(method, "_endpoint_info", None)
        if endpoint_info:
            schema["endpoints"].append(endpoint_info)

    return schema

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\ms_deps_report.md
--------------------------------------------------------------------------------
# Microservice Dependency Report

- Root: `C:\Users\petya\Documents\Jacob's BIN\_UsefulHelperSCRIPTS\_MicroserviceLIBRARY`
- Files scanned: **58**
- Parsed OK: **58**
- Rewritten files: **31**

## Per-file summary

| File | Parsed | Changed | Internal deps | External deps | Notes/Errors |
|---|---:|---:|---|---|---|
| `_ArchiveBotMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_AuthMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CartridgeServiceMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | sqlite_vec | Synced manifest header deps (Option A). |
| `_ChalkBoardMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | webview | Synced manifest header deps (Option A). |
| `_ChunkingRouterMS.py` | ‚úÖ | ‚úÖ | _PythonChunkerMS, base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CodeChunkerMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CodeFormatterMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CodeGrapherMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CodeJanitorMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_CognitiveMemoryMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | pydantic | Synced manifest header deps (Option A). |
| `_ContentExtractorMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib | beautifulsoup4, bs4, pypdf | Synced manifest header deps (Option A). |
| `_ContextAggregatorMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_ContextPackerMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_DiffEngineMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_EnvironmentManagerMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_ExplorerWidgetMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | ttk | Synced manifest header deps (Option A). |
| `_FingerprintScannerMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_GitPilotMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib | git | Synced manifest header deps (Option A). |
| `_HeuristicSumMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_IngestEngineMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | requests | Synced manifest header deps (Option A). |
| `_IntakeServiceMS.py` | ‚úÖ | ‚úÖ | _CartridgeServiceMS, _ScannerMS, base_service, document_utils, microservice_std_lib | bs4, requests | Synced manifest header deps (Option A). |
| `_IsoProcessMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_LexicalSearchMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_LibrarianMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib | requests | Synced manifest header deps (Option A). |
| `_LibrarianServiceMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib | requests | Synced manifest header deps (Option A). |
| `_LogViewMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_MonacoHostMS.py` | ‚úÖ |  | microservice_std_lib | webview |  |
| `_NetworkLayoutMS.py` | ‚úÖ |  | microservice_std_lib | networkx |  |
| `_NeuralGraphEngineMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib | pygame | Synced manifest header deps (Option A). |
| `_NeuralGraphViewerMS.py` | ‚úÖ | ‚úÖ | _NeuralGraphEngineMS, base_service, microservice_std_lib | PIL | Synced manifest header deps (Option A). |
| `_NeuralServiceMS.py` | ‚úÖ |  | microservice_std_lib | requests |  |
| `_ProjectForgeMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_PromptOptimizerMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_PromptVaultMS.py` | ‚úÖ |  | microservice_std_lib | jinja2, pydantic |  |
| `_PythonChunkerMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_RefineryServiceMS.py` | ‚úÖ |  | _CartridgeServiceMS, _ChunkingRouterMS, _NeuralServiceMS, microservice_std_lib |  |  |
| `_RegexWeaverMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_RoleManagerMS.py` | ‚úÖ |  | microservice_std_lib | pydantic |  |
| `_SandboxManagerMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_ScannerMS.py` | ‚úÖ | ‚úÖ | base_service, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_ScoutMS.py` | ‚úÖ |  | microservice_std_lib | bs4, requests |  |
| `_SearchEngineMS.py` | ‚úÖ |  | microservice_std_lib | requests, sqlite_vec |  |
| `_SemanticChunkerMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_ServiceRegistryMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_SpinnerThingyMaBobberMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_SysInspectorMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_TasklistVaultMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_TelemetryServiceMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_TextChunkerMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_ThoughtStreamMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_TkinterAppShellMS.py` | ‚úÖ | ‚úÖ | _TkinterThemeManagerMS, microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_TkinterSmartExplorerMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_TkinterThemeManagerMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |
| `_TkinterUniButtonMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_TreeMapperMS.py` | ‚úÖ |  | microservice_std_lib |  |  |
| `_VectorFactoryMS.py` | ‚úÖ |  | microservice_std_lib | chromadb, faiss, numpy |  |
| `_WebScraperMS.py` | ‚úÖ |  | microservice_std_lib | httpx, readability |  |
| `_WorkbenchLayoutMS.py` | ‚úÖ | ‚úÖ | microservice_std_lib |  | Synced manifest header deps (Option A). |

## Aggregate external dependencies (requirements candidates)

- PIL
- beautifulsoup4
- bs4
- chromadb
- faiss
- git
- httpx
- jinja2
- networkx
- numpy
- pydantic
- pygame
- pypdf
- readability
- requests
- sqlite_vec
- ttk
- webview

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\registry.json
--------------------------------------------------------------------------------
[
  {
    "token_id": "MS_82159302",
    "name": "ArchiveBotMS",
    "path": "_ArchiveBotMS.py",
    "description": "",
    "methods": {
      "create_backup": {
        "args": [
          "source_path",
          "output_dir",
          "extra_exclusions",
          "use_default_exclusions"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "fnmatch",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "tarfile",
      "tempfile",
      "typing"
    ]
  },
  {
    "token_id": "MS_712B803A",
    "name": "AuthMS",
    "path": "_AuthMS.py",
    "description": "ROLE: Simple authentication microservice providing username/password login\n      and signed session tokens.\n\nINPUTS:\n  - config: Optional configuration dict. Recognized keys:\n      - 'secret_key': Secret used to sign tokens.\n\nOUTPUTS:\n  - Exposes `login` and `validate_session` endpoints for use in pipelines.",
    "methods": {
      "login": {
        "args": [
          "username",
          "password"
        ],
        "doc": "Attempt to log in with the provided username and password.\n\n:param username: Login identifier.\n:param password: Plain-text password.\n:returns: Signed session token if successful, None otherwise."
      },
      "validate_session": {
        "args": [
          "token"
        ],
        "doc": "Check if a serialized token is valid and not expired.\n\n:param token: Session token string.\n:returns: True if token is valid and not expired, False otherwise."
      }
    },
    "dependencies": [
      "base64",
      "hashlib",
      "json",
      "logging",
      "microservice_std_lib",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_B53FC606",
    "name": "CartridgeServiceMS",
    "path": "_CartridgeServiceMS.py",
    "description": "The Source of Truth.\nManages the Unified Neural Cartridge Format (UNCF v1.0).",
    "methods": {
      "get_vector_dim": {
        "args": [],
        "doc": "Retrieves the expected vector dimension from the manifest spec."
      },
      "initialize_manifest": {
        "args": [],
        "doc": "Populates the boot sector with strict RagFORGE Cartridge Schema (UNCF) v1.1."
      },
      "set_manifest": {
        "args": [
          "key",
          "value"
        ],
        "doc": "Upsert metadata key."
      },
      "get_manifest": {
        "args": [
          "key"
        ],
        "doc": "Retrieve metadata key."
      },
      "validate_cartridge": {
        "args": [],
        "doc": "Quality Control: Checks if the cartridge is Agent-Safe."
      },
      "store_file": {
        "args": [
          "vfs_path",
          "origin_path",
          "content",
          "blob",
          "mime_type",
          "origin_type"
        ],
        "doc": "The Universal Input Method. \nStores raw data. If file exists, updates it and resets status to 'RAW' for re-refining."
      },
      "get_pending_files": {
        "args": [
          "limit"
        ],
        "doc": "Fetches files waiting for the Refinery."
      },
      "update_status": {
        "args": [
          "file_id",
          "status",
          "metadata"
        ],
        "doc": ""
      },
      "ensure_directory": {
        "args": [
          "vfs_path"
        ],
        "doc": "Idempotent insert for VFS directories."
      },
      "get_status_flags": {
        "args": [],
        "doc": "Returns key manifest status flags in a single call."
      },
      "list_files": {
        "args": [
          "prefix",
          "status",
          "limit"
        ],
        "doc": "Enumerate files in the cartridge (optionally filtered by VFS prefix and/or status)."
      },
      "get_file_record": {
        "args": [
          "vfs_path"
        ],
        "doc": "Fetch a single file record by VFS path."
      },
      "list_directories": {
        "args": [
          "prefix"
        ],
        "doc": "Enumerate directories in the cartridge VFS."
      },
      "get_directory_tree": {
        "args": [
          "root"
        ],
        "doc": "Builds a nested directory tree starting at `root` (\"\" for full tree)."
      },
      "get_status_summary": {
        "args": [],
        "doc": "Counts files by status and provides a quick cartridge overview."
      },
      "add_node": {
        "args": [
          "node_id",
          "node_type",
          "label",
          "data"
        ],
        "doc": ""
      },
      "add_edge": {
        "args": [
          "source",
          "target",
          "relation",
          "weight"
        ],
        "doc": ""
      },
      "search_embeddings": {
        "args": [
          "query_vector",
          "limit"
        ],
        "doc": "Performs semantic search using sqlite-vec."
      }
    },
    "dependencies": [
      "datetime",
      "json",
      "microservice_std_lib",
      "os",
      "pathlib",
      "sqlite3",
      "sqlite_vec",
      "struct",
      "tempfile",
      "time",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_D14BCEE8",
    "name": "ChalkBoardMS",
    "path": "_ChalkBoardMS.py",
    "description": "",
    "methods": {
      "loaded": {
        "args": [],
        "doc": "Called by JS when the page is ready."
      },
      "log_action": {
        "args": [
          "action_name"
        ],
        "doc": "Called by JS when user interacts."
      },
      "update_sign": {
        "args": [
          "text",
          "theme"
        ],
        "doc": "Updates the embedded HTML via JS injection."
      },
      "trigger_effect": {
        "args": [
          "effect"
        ],
        "doc": "Triggers CSS animations like 'shake'."
      }
    },
    "dependencies": [
      "json",
      "microservice_std_lib",
      "os",
      "webview"
    ]
  },
  {
    "token_id": "MS_0E8A6CD8",
    "name": "ChunkingRouterMS",
    "path": "_ChunkingRouterMS.py",
    "description": "The Editor: A 'Recursive' text splitter.\nIt respects the natural structure of text (Paragraphs -> Sentences -> Words)\nrather than just hacking it apart by character count.",
    "methods": {
      "chunk_file": {
        "args": [
          "text",
          "filename",
          "max_size",
          "overlap"
        ],
        "doc": "Extension-aware router."
      }
    },
    "dependencies": [
      "_PythonChunkerMS",
      "microservice_std_lib",
      "re",
      "typing"
    ]
  },
  {
    "token_id": "MS_D918BB0A",
    "name": "CodeChunkerMS",
    "path": "_CodeChunkerMS.py",
    "description": "The Surgeon (Pure Python Edition): Splits code into semantic blocks\n(Classes, Functions) using indentation and regex heuristics.\n\nAdvantages: Zero dependencies. Works on any machine.\nDisadvantages: Slightly less precise than Tree-Sitter for messy code.",
    "methods": {
      "chunk_file": {
        "args": [
          "file_path",
          "max_chars"
        ],
        "doc": "Reads a file and breaks it into logical blocks based on indentation."
      }
    },
    "dependencies": [
      "microservice_std_lib",
      "os",
      "pathlib",
      "re",
      "tempfile",
      "typing"
    ]
  },
  {
    "token_id": "MS_286694E7",
    "name": "CodeFormatterMS",
    "path": "_CodeFormatterMS.py",
    "description": "The Architect.\nUses the WhitespaceEngine to enforce strict indentation rules, \nfixing 'staircase' formatting and mixed tabs/spaces.",
    "methods": {
      "normalize_code": {
        "args": [
          "content",
          "use_tabs",
          "spaces"
        ],
        "doc": "Pure logic endpoint: Takes string, returns string + patch.\nDoes not touch the filesystem."
      },
      "format_file": {
        "args": [
          "file_path",
          "use_tabs",
          "spaces"
        ],
        "doc": "Filesystem endpoint: In-place repair of a file."
      }
    },
    "dependencies": [
      "json",
      "logging",
      "microservice_std_lib",
      "pathlib",
      "re",
      "typing"
    ]
  },
  {
    "token_id": "MS_7A85FF81",
    "name": "CodeGrapherMS",
    "path": "_CodeGrapherMS.py",
    "description": "The Cartographer of Logic: Parses Python code to extract high-level \nsymbols (classes, functions) and maps their 'Call' relationships.\n\nOutput: A graph structure (Nodes + Edges) suitable for visualization \nor dependency analysis.",
    "methods": {
      "scan_directory": {
        "args": [
          "root_path"
        ],
        "doc": "Recursively scans a directory for .py files and builds the graph."
      }
    },
    "dependencies": [
      "ast",
      "json",
      "microservice_std_lib",
      "os",
      "pathlib",
      "sys",
      "typing"
    ]
  },
  {
    "token_id": "MS_7BE95FCF",
    "name": "CodeJanitorMS",
    "path": "_CodeJanitorMS.py",
    "description": "",
    "methods": {
      "enforce_standards": {
        "args": [
          "dry_run"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "pathlib",
      "re",
      "typing"
    ]
  },
  {
    "token_id": "MS_30C25085",
    "name": "CognitiveMemoryMS",
    "path": "_CognitiveMemoryMS.py",
    "description": "The Hippocampus: Manages Short-Term (Working) Memory and orchestrates \nflushing to Long-Term Memory (Vector Store).",
    "methods": {
      "add_entry": {
        "args": [
          "role",
          "content",
          "metadata"
        ],
        "doc": "Adds an item to working memory and persists it."
      },
      "get_context": {
        "args": [
          "limit"
        ],
        "doc": "Returns the most recent conversation history formatted for an LLM."
      },
      "get_full_history": {
        "args": [],
        "doc": "Returns the raw list of memory objects."
      },
      "commit_turn": {
        "args": [],
        "doc": "Signal that a \"Turn\" (User + AI response) is complete.\nChecks if memory is full and triggers a flush if needed."
      }
    },
    "dependencies": [
      "datetime",
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "pydantic",
      "sys",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_AC0BAF8F",
    "name": "ContentExtractorMS",
    "path": "_ContentExtractorMS.py",
    "description": "The Decoder.\nA standalone utility microservice that separates the concern of \ndocument parsing from ingestion logic.",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status and library availability."
      },
      "extract_text": {
        "args": [
          "blob",
          "mime_type"
        ],
        "doc": "Main routing logic for extraction. \n logic is internalized here."
      }
    },
    "dependencies": [
      "bs4",
      "io",
      "microservice_std_lib",
      "pypdf",
      "re",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_97FCA3AF",
    "name": "ContextAggregatorMS",
    "path": "_ContextAggregatorMS.py",
    "description": "The Context Builder: Flattens a project folder into a single readable text file.",
    "methods": {
      "aggregate": {
        "args": [
          "root_path",
          "output_file",
          "extra_exclusions",
          "use_default_exclusions"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "fnmatch",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "typing"
    ]
  },
  {
    "token_id": "MS_C5235D34",
    "name": "ContextPackerMS",
    "path": "_ContextPackerMS.py",
    "description": "The Packer: Walks a directory and dumps all text-readable files \ninto a single monolithic text file with delimiters.",
    "methods": {
      "pack_directory": {
        "args": [
          "root_path",
          "output_filename",
          "additional_excludes"
        ],
        "doc": "Walks the directory and writes file contents to the output file."
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "typing"
    ]
  },
  {
    "token_id": "MS_CCCC1208",
    "name": "DiffEngineMS",
    "path": "_DiffEngineMS.py",
    "description": "The Timekeeper: Implements a 'Hybrid' versioning architecture.\n1. HEAD: Stores full current content for fast read access (UI/RAG).\n2. HISTORY: Stores diff deltas using difflib for audit trails.",
    "methods": {
      "update_file": {
        "args": [
          "path",
          "new_content",
          "author"
        ],
        "doc": "The Atomic Update Operation:\n1. Checks current state.\n2. Calculates Diff.\n3. Writes Diff to History.\n4. Updates Head to New Content."
      },
      "get_head": {
        "args": [
          "path"
        ],
        "doc": "Fast retrieval of current content."
      },
      "get_history": {
        "args": [
          "path"
        ],
        "doc": "Retrieves the full evolution history of a file."
      }
    },
    "dependencies": [
      "datetime",
      "difflib",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "sqlite3",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_2E13D7BF",
    "name": "EnvironmentManagerMS",
    "path": "_EnvironmentManagerMS.py",
    "description": "The Operator.\nFinds the right Python interpreter (System vs Venv) and launches processes.",
    "methods": {
      "resolve_python": {
        "args": [
          "project_path",
          "config_override"
        ],
        "doc": "Priority:\n1. Explicit config override\n2. Local .venv\n3. System default (py or sys.executable)"
      },
      "launch_script": {
        "args": [
          "project_path",
          "script_rel_path",
          "env_vars"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "subprocess",
      "sys",
      "typing"
    ]
  },
  {
    "token_id": "MS_240BD73E",
    "name": "ExplorerWidgetMS",
    "path": "_ExplorerWidgetMS.py",
    "description": "A standalone file system tree viewer.",
    "methods": {
      "refresh_tree": {
        "args": [],
        "doc": ""
      },
      "get_selected_paths": {
        "args": [],
        "doc": ""
      },
      "process_gui_queue": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "importlib",
      "microservice_std_lib",
      "os",
      "pathlib",
      "queue",
      "sys",
      "threading",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_B87AB5EB",
    "name": "FingerprintScannerMS",
    "path": "_FingerprintScannerMS.py",
    "description": "The Detective: Scans a directory tree and generates a deterministic\n'Fingerprint' (SHA-256 Merkle Root) representing its exact state.",
    "methods": {
      "scan_project": {
        "args": [
          "root_path"
        ],
        "doc": "Scans the project and returns a comprehensive state object."
      }
    },
    "dependencies": [
      "fnmatch",
      "hashlib",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "shutil",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_8CED7E7B",
    "name": "GitPilotMS",
    "path": "_GitPilotMS.py",
    "description": "",
    "methods": {
      "set_repo": {
        "args": [
          "path"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "dataclasses",
      "microservice_std_lib",
      "os",
      "pathlib",
      "queue",
      "subprocess",
      "threading",
      "time",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_B7BF2C48",
    "name": "HeuristicSumMS",
    "path": "_HeuristicSumMS.py",
    "description": "The Skimmer: Generates quick summaries of code/text files without AI.\nScans for high-value lines (headers, signatures, docstrings) and concatenates them.",
    "methods": {
      "summarize": {
        "args": [
          "text",
          "filename",
          "max_chars"
        ],
        "doc": "Generates a summary string from the provided text."
      }
    },
    "dependencies": [
      "microservice_std_lib",
      "os",
      "re",
      "typing"
    ]
  },
  {
    "token_id": "MS_6D21E917",
    "name": "IngestEngineMS",
    "path": "_IngestEngineMS.py",
    "description": "The Heavy Lifter: Reads files, chunks text, fetches embeddings,\npopulates the Graph Nodes, and weaves Graph Edges.",
    "methods": {
      "abort": {
        "args": [],
        "doc": ""
      },
      "check_ollama_connection": {
        "args": [],
        "doc": ""
      },
      "get_available_models": {
        "args": [],
        "doc": ""
      },
      "process_files": {
        "args": [
          "file_paths",
          "model_name"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "dataclasses",
      "importlib",
      "json",
      "microservice_std_lib",
      "os",
      "re",
      "requests",
      "sqlite3",
      "sys",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_CEB3C2F6",
    "name": "IntakeServiceMS",
    "path": "_IntakeServiceMS.py",
    "description": "The Vacuum. \nNow supports two-phase ingestion:\n1. Scan -> Build Tree (with .gitignore respect)\n2. Ingest -> Process selected paths",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status of the IntakeServiceMS."
      },
      "ingest_source": {
        "args": [
          "source_path"
        ],
        "doc": "Headless/CLI Entry point: Scans and Ingests in one go."
      },
      "scan_path": {
        "args": [
          "root_path",
          "web_depth"
        ],
        "doc": "Unified Scanner Interface.\nDelegates to ScoutMS for both Web and Local FS to ensure consistent node structure."
      },
      "ingest_selected": {
        "args": [
          "file_list",
          "root_path"
        ],
        "doc": "Ingests only the specific files passed in the list."
      },
      "save_persistence": {
        "args": [
          "root_path",
          "checked_map"
        ],
        "doc": "Saves user selections into the Cartridge Manifest (Portable)."
      }
    },
    "dependencies": [
      "_CartridgeServiceMS",
      "_ScannerMS",
      "base_service",
      "bs4",
      "document_utils",
      "fnmatch",
      "json",
      "microservice_std_lib",
      "mimetypes",
      "os",
      "pathlib",
      "requests",
      "typing"
    ]
  },
  {
    "token_id": "MS_6D977CA1",
    "name": "IsoProcessMS",
    "path": "_IsoProcessMS.py",
    "description": "The Safety Valve: Spawns isolated processes with real-time logging feedback.",
    "methods": {
      "execute": {
        "args": [
          "payload",
          "config"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "multiprocessing",
      "queue",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_B73D91A1",
    "name": "LexicalSearchMS",
    "path": "_LexicalSearchMS.py",
    "description": "The Librarian's Index: A lightweight, AI-free search engine.\n\nUses SQLite's FTS5 extension to provide fast, ranked keyword search (BM25).\nIdeal for environments where installing PyTorch/Transformers is impossible\nor overkill.",
    "methods": {
      "add_document": {
        "args": [
          "doc_id",
          "text",
          "metadata"
        ],
        "doc": "Adds or updates a document in the index."
      },
      "search": {
        "args": [
          "query",
          "top_k"
        ],
        "doc": "Performs a BM25 Ranked Search."
      }
    },
    "dependencies": [
      "json",
      "microservice_std_lib",
      "os",
      "pathlib",
      "sqlite3",
      "typing"
    ]
  },
  {
    "token_id": "MS_100A23E3",
    "name": "LibrarianMS",
    "path": "_LibrarianMS.py",
    "description": "The Swarm Librarian.\nSpawns concurrent AI workers to scan the codebase and create a system manifest.\nOptimized for Ryzen CPUs and 32GB RAM.",
    "methods": {
      "generate_catalog": {
        "args": [
          "output_file"
        ],
        "doc": "Main entry point. Uses ThreadPoolExecutor for parallel processing."
      }
    },
    "dependencies": [
      "ast",
      "concurrent",
      "datetime",
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "requests",
      "typing"
    ]
  },
  {
    "token_id": "MS_100A23E3",
    "name": "LibrarianMS",
    "path": "_LibrarianServiceMS.py",
    "description": "",
    "methods": {
      "generate_catalog": {
        "args": [
          "output_file"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "ast",
      "concurrent",
      "datetime",
      "importlib",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "requests",
      "typing"
    ]
  },
  {
    "token_id": "MS_8EEDB65C",
    "name": "LogViewMS",
    "path": "_LogViewMS.py",
    "description": "The Console: A professional log viewer widget.\nFeatures:\n- Thread-safe (consumes from a Queue).\n- Message Consolidation (\"Error occurred (x5)\").\n- Level Filtering (Toggle INFO/DEBUG/ERROR).",
    "methods": {
      "clear": {
        "args": [],
        "doc": ""
      },
      "save": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "logging",
      "microservice_std_lib",
      "queue",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_FD93FB4F",
    "name": "MonacoHostMS",
    "path": "_MonacoHostMS.py",
    "description": "Hosts the Monaco Editor.\nThis service spawns a GUI window and cannot be run in headless environments.",
    "methods": {
      "launch": {
        "args": [
          "title",
          "width",
          "height",
          "func"
        ],
        "doc": "Create and launch the window.\n:param func: Optional function to run in a separate thread after launch."
      },
      "set_save_callback": {
        "args": [
          "callback"
        ],
        "doc": "Sets the function to trigger when Ctrl+S is pressed in the editor."
      },
      "open_file": {
        "args": [
          "filepath",
          "content"
        ],
        "doc": "Opens a file in the editor (must be called from a background thread or callback)."
      }
    },
    "dependencies": [
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "sys",
      "threading",
      "typing",
      "webview"
    ]
  },
  {
    "token_id": "MS_1F8493F8",
    "name": "NetworkLayoutMS",
    "path": "_NetworkLayoutMS.py",
    "description": "The Topologist: Calculates visual coordinates for graph nodes using\nserver-side algorithms (NetworkX). \nUseful for generating static map snapshots or pre-calculating positions \nto offload client-side rendering.",
    "methods": {
      "calculate_layout": {
        "args": [
          "nodes",
          "edges",
          "algorithm"
        ],
        "doc": "Computes (x, y) coordinates for the given graph.\n\n:param nodes: List of node IDs.\n:param edges: List of (source, target) tuples.\n:param algorithm: 'spring' (Force-directed) or 'circular'.\n:return: Dictionary {node_id: (x, y)}"
      }
    },
    "dependencies": [
      "importlib",
      "logging",
      "microservice_std_lib",
      "networkx",
      "sys",
      "typing"
    ]
  },
  {
    "token_id": "MS_E7AE2BD6",
    "name": "NeuralGraphEngineMS",
    "path": "_NeuralGraphEngineMS.py",
    "description": "",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status of the NeuralGraphEngineMS."
      },
      "resize": {
        "args": [
          "width",
          "height"
        ],
        "doc": ""
      },
      "set_data": {
        "args": [
          "nodes",
          "links"
        ],
        "doc": ""
      },
      "screen_to_world": {
        "args": [
          "sx",
          "sy"
        ],
        "doc": ""
      },
      "get_node_at": {
        "args": [
          "sx",
          "sy"
        ],
        "doc": ""
      },
      "handle_mouse_down": {
        "args": [
          "x",
          "y"
        ],
        "doc": ""
      },
      "handle_mouse_move": {
        "args": [
          "x",
          "y",
          "is_dragging"
        ],
        "doc": ""
      },
      "handle_mouse_up": {
        "args": [],
        "doc": ""
      },
      "pan": {
        "args": [
          "dx",
          "dy"
        ],
        "doc": ""
      },
      "zoom_camera": {
        "args": [
          "amount",
          "mouse_x",
          "mouse_y"
        ],
        "doc": ""
      },
      "highlight_nodes": {
        "args": [
          "node_ids"
        ],
        "doc": "Highlights specific nodes by ID."
      },
      "step_physics": {
        "args": [],
        "doc": ""
      },
      "get_image_bytes": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "math",
      "microservice_std_lib",
      "pygame",
      "random",
      "time"
    ]
  },
  {
    "token_id": "MS_BC3EA28D",
    "name": "NeuralGraphViewerMS",
    "path": "_NeuralGraphViewerMS.py",
    "description": "",
    "methods": {
      "bind_services": {
        "args": [
          "cartridge",
          "neural"
        ],
        "doc": ""
      },
      "run_search": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "load_from_db": {
        "args": [
          "db_path"
        ],
        "doc": "Loads graph data from SQLite.\nDoes NOT block the UI. The physics engine will settle the nodes frame-by-frame."
      },
      "on_resize": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_double_click": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_click": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_release": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_drag": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_hover": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "on_zoom": {
        "args": [
          "amount"
        ],
        "doc": ""
      },
      "on_windows_scroll": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "animate": {
        "args": [],
        "doc": "The Heartbeat Loop.\nRuns at ~30 FPS. Handles Physics + Rendering."
      }
    },
    "dependencies": [
      "PIL",
      "_NeuralGraphEngineMS",
      "json",
      "microservice_std_lib",
      "os",
      "sqlite3",
      "tkinter"
    ]
  },
  {
    "token_id": "MS_BE7F8AE6",
    "name": "NeuralServiceMS",
    "path": "_NeuralServiceMS.py",
    "description": "The Brain Interface: Orchestrates local AI operations via Ollama for inference and embeddings.",
    "methods": {
      "update_models": {
        "args": [
          "fast_model",
          "smart_model",
          "embed_model"
        ],
        "doc": "Called by the UI Settings Modal to change models on the fly."
      },
      "get_available_models": {
        "args": [],
        "doc": "Fetches list from Ollama for the UI dropdown."
      },
      "check_connection": {
        "args": [],
        "doc": "Pings Ollama to see if it's alive."
      },
      "get_embedding": {
        "args": [
          "text"
        ],
        "doc": "Generates a vector using the configured embedding model."
      },
      "request_inference": {
        "args": [
          "prompt",
          "tier",
          "format_json"
        ],
        "doc": "Synchronous inference request.\ntier: 'fast', 'smart', or other keys in self.models"
      },
      "process_parallel": {
        "args": [
          "items",
          "worker_func"
        ],
        "doc": "Helper to run a function across many items using a ThreadPool.\nUseful for batch ingestion.\nNote: Not exposed as an endpoint as it takes a function as an argument."
      }
    },
    "dependencies": [
      "concurrent",
      "json",
      "logging",
      "microservice_std_lib",
      "requests",
      "typing"
    ]
  },
  {
    "token_id": "MS_6EDB246A",
    "name": "ProjectForgeMS",
    "path": "_ProjectForgeMS.py",
    "description": "The Blacksmith.\nCreates directory structures, stamps out boilerplate code, and injects dependencies.",
    "methods": {
      "forge_project": {
        "args": [
          "parent_path",
          "project_name",
          "dependencies",
          "project_type"
        ],
        "doc": "Stamps out a new project folder."
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "shutil",
      "typing"
    ]
  },
  {
    "token_id": "MS_42FE6B64",
    "name": "PromptOptimizerMS",
    "path": "_PromptOptimizerMS.py",
    "description": "The Tuner: Uses an LLM to refine prompts or generate variations.\nRequires an 'inference_func' to be passed in the config, which accepts a string\nand returns a string (simulating an LLM call).",
    "methods": {
      "refine_prompt": {
        "args": [
          "draft_prompt",
          "feedback"
        ],
        "doc": "Rewrites a prompt based on feedback."
      },
      "generate_variations": {
        "args": [
          "draft_prompt",
          "num_variations",
          "context_data"
        ],
        "doc": "Generates multiple versions of a prompt for testing."
      }
    },
    "dependencies": [
      "json",
      "logging",
      "microservice_std_lib",
      "typing"
    ]
  },
  {
    "token_id": "MS_8FC21A0E",
    "name": "PromptVaultMS",
    "path": "_PromptVaultMS.py",
    "description": "The Vault: A persistent SQLite store for managing, versioning, \nand rendering AI prompts.",
    "methods": {
      "create_template": {
        "args": [
          "slug",
          "title",
          "content",
          "author",
          "tags"
        ],
        "doc": "Creates a new prompt template with an initial version 1."
      },
      "add_version": {
        "args": [
          "slug",
          "content",
          "author"
        ],
        "doc": "Adds a new version to an existing template."
      },
      "get_template": {
        "args": [
          "slug"
        ],
        "doc": "Retrieves a full template with all history."
      },
      "render": {
        "args": [
          "slug",
          "context"
        ],
        "doc": "Fetches the latest version and renders it with Jinja2."
      },
      "list_slugs": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "importlib",
      "jinja2",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "pydantic",
      "sqlite3",
      "sys",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_037ABE0D",
    "name": "PythonChunkerMS",
    "path": "_PythonChunkerMS.py",
    "description": "Specialized Python AST Chunker.\nFocuses exclusively on identifying classes and functions to preserve code logic.",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status of the PythonChunkerMS."
      },
      "chunk": {
        "args": [
          "content"
        ],
        "doc": "Parses Python source into semantic CodeChunks."
      }
    },
    "dependencies": [
      "ast",
      "dataclasses",
      "microservice_std_lib",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_88923AC3",
    "name": "RefineryServiceMS",
    "path": "_RefineryServiceMS.py",
    "description": "The Night Shift.\nPolls the DB for 'RAW' files and processes them into Chunks and Graph Nodes.\n\nGraph Enrichment:\n- Code: function/class nodes, resolved import edges when possible.\n- Docs: section/chapter nodes for long-form text (md/txt/rst).",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status of the RefineryServiceMS."
      },
      "process_pending": {
        "args": [
          "batch_size"
        ],
        "doc": "Main loop. Returns number of files processed."
      }
    },
    "dependencies": [
      "_CartridgeServiceMS",
      "_ChunkingRouterMS",
      "_NeuralServiceMS",
      "ast",
      "concurrent",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "re",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_0694A27B",
    "name": "RegexWeaverMS",
    "path": "_RegexWeaverMS.py",
    "description": "The Weaver: A fault-tolerant dependency extractor.\nUses Regex to find imports, making it faster and more permissive\nthan AST parsers (works on broken code).",
    "methods": {
      "extract_dependencies": {
        "args": [
          "content",
          "language"
        ],
        "doc": "Scans code content for import statements.\n:param language: 'python' or 'javascript' (includes ts/jsx)."
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "re",
      "typing"
    ]
  },
  {
    "token_id": "MS_12D07056",
    "name": "RoleManagerMS",
    "path": "_RoleManagerMS.py",
    "description": "The Casting Director: Manages Agent Personas (Roles).\nPersists configuration for System Prompts, Attached KBs, and Memory Settings.",
    "methods": {
      "create_role": {
        "args": [
          "name",
          "system_prompt",
          "description",
          "kbs"
        ],
        "doc": "Creates a new Agent Persona."
      },
      "get_role": {
        "args": [
          "name_or_id"
        ],
        "doc": "Retrieves a role by Name or ID."
      },
      "list_roles": {
        "args": [],
        "doc": ""
      },
      "delete_role": {
        "args": [
          "name"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "pydantic",
      "sqlite3",
      "sys",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_AD63F401",
    "name": "SandboxManagerMS",
    "path": "_SandboxManagerMS.py",
    "description": "The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project.\nAllows for safe experimentation, diffing, and atomic promotion of changes.",
    "methods": {
      "init_sandbox": {
        "args": [
          "force"
        ],
        "doc": "Creates or resets the sandbox by mirroring the live project."
      },
      "reset_sandbox": {
        "args": [],
        "doc": "Discards all sandbox changes and re-syncs from live."
      },
      "get_diff": {
        "args": [],
        "doc": "Compares Sandbox vs Live. Returns added, modified, and deleted files."
      },
      "promote_changes": {
        "args": [],
        "doc": "Applies changes from Sandbox to Live.\nReturns (added_count, modified_count, deleted_count)."
      }
    },
    "dependencies": [
      "hashlib",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "shutil",
      "typing"
    ]
  },
  {
    "token_id": "MS_7237CDDC",
    "name": "ScannerMS",
    "path": "_ScannerMS.py",
    "description": "The Scanner: Walks the file system, filters junk, and detects binary files.\nGenerates the tree structure used by the UI.",
    "methods": {
      "is_binary": {
        "args": [
          "file_path"
        ],
        "doc": "Determines if a file is binary using two heuristics:\n1. Extension check (Fast)\n2. Content check for null bytes (Accurate)"
      },
      "scan_directory": {
        "args": [
          "root_path"
        ],
        "doc": "Recursively scans a directory and returns a JSON-compatible tree.\nReturns None if path is invalid."
      },
      "flatten_tree": {
        "args": [
          "tree_node"
        ],
        "doc": "Helper to extract all valid file paths from a tree node \n(e.g., when the user clicks 'Start Ingest')."
      }
    },
    "dependencies": [
      "microservice_std_lib",
      "os",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_DFC1A928",
    "name": "ScoutMS",
    "path": "_ScoutMS.py",
    "description": "The Scanner: Walks file systems OR crawls websites (Depth-Aware).",
    "methods": {
      "is_binary": {
        "args": [
          "file_path"
        ],
        "doc": ""
      },
      "scan_directory": {
        "args": [
          "root_path",
          "web_depth"
        ],
        "doc": "Main Entry Point.\n:param root_path: File path or URL.\n:param web_depth: How many links deep to crawl (0 = single page)."
      },
      "flatten_tree": {
        "args": [
          "tree_node"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "bs4",
      "microservice_std_lib",
      "os",
      "requests",
      "time",
      "typing",
      "urllib"
    ]
  },
  {
    "token_id": "MS_D02A07FF",
    "name": "SearchEngineMS",
    "path": "_SearchEngineMS.py",
    "description": "The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching).\n\nArchitecture:\n1. Vector Search: Uses sqlite-vec (vec0) for fast nearest neighbor search.\n2. Keyword Search: Uses SQLite FTS5 for BM25-style text matching.\n3. Reranking: Combines scores using Reciprocal Rank Fusion (RRF).",
    "methods": {
      "search": {
        "args": [
          "db_path",
          "query",
          "limit"
        ],
        "doc": "Main entry point. Returns a list of results sorted by relevance."
      }
    },
    "dependencies": [
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "requests",
      "sqlite3",
      "sqlite_vec",
      "struct",
      "sys",
      "typing"
    ]
  },
  {
    "token_id": "MS_9F825A66",
    "name": "SemanticChunkerMS",
    "path": "_SemanticChunkerMS.py",
    "description": "Intelligent Code Splitter.\nParses source code into logical units (Classes, Functions) \nrather than arbitrary text windows.",
    "methods": {
      "chunk_file": {
        "args": [
          "content",
          "filename"
        ],
        "doc": "Splits file content into chunks.\nReturns a list of dictionaries suitable for JSON response."
      }
    },
    "dependencies": [
      "ast",
      "dataclasses",
      "microservice_std_lib",
      "typing"
    ]
  },
  {
    "token_id": "MS_0A156562",
    "name": "ServiceRegistryMS",
    "path": "_ServiceRegistryMS.py",
    "description": "The Tokenizer (v2): Scans a library of Python microservices and generates\nstandardized JSON 'Service Tokens'.\nFeature: Hybrid AST/Regex parsing for maximum robustness.",
    "methods": {
      "scan": {
        "args": [
          "save_to"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "ast",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "re",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_02781C0A",
    "name": "SpinnerThingyMaBobberMS",
    "path": "_SpinnerThingyMaBobberMS.py",
    "description": "The Visualizer: An interactive spinner widget.\nUseful for \"Processing...\" screens or OBS overlays.",
    "methods": {
      "launch": {
        "args": [],
        "doc": "Starts the Tkinter main event loop."
      },
      "handle_keypress": {
        "args": [
          "event"
        ],
        "doc": ""
      },
      "get_neon_color": {
        "args": [
          "offset"
        ],
        "doc": ""
      },
      "draw_arc": {
        "args": [
          "cx",
          "cy",
          "radius",
          "width",
          "start",
          "extent",
          "color"
        ],
        "doc": ""
      },
      "animate": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "colorsys",
      "math",
      "microservice_std_lib",
      "time",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_E3D913D6",
    "name": "SysInspectorMS",
    "path": "_SysInspectorMS.py",
    "description": "The Auditor: Gathers hardware and environment statistics.\nSupports: Windows (WMIC), Linux (lscpu/lspci), and macOS (sysctl/system_profiler).",
    "methods": {
      "generate_report": {
        "args": [],
        "doc": "Runs the full audit and returns a formatted string report."
      }
    },
    "dependencies": [
      "datetime",
      "logging",
      "microservice_std_lib",
      "platform",
      "subprocess",
      "sys",
      "typing"
    ]
  },
  {
    "token_id": "MS_2668E502",
    "name": "TasklistVaultMS",
    "path": "_TasklistVaultMS.py",
    "description": "The Taskmaster: A persistent SQLite engine for hierarchical task management.\nSupports infinite nesting of sub-tasks and status tracking.",
    "methods": {
      "create_list": {
        "args": [
          "name"
        ],
        "doc": "Creates a new task list and returns its ID."
      },
      "get_lists": {
        "args": [],
        "doc": "Returns metadata for all task lists."
      },
      "add_task": {
        "args": [
          "list_id",
          "content",
          "parent_id"
        ],
        "doc": "Adds a task (or sub-task) to a list."
      },
      "update_task": {
        "args": [
          "task_id",
          "content",
          "status",
          "result"
        ],
        "doc": "Updates a task's details."
      },
      "get_full_tree": {
        "args": [
          "list_id"
        ],
        "doc": "Fetches a list and reconstructs the full hierarchy of tasks."
      },
      "delete_list": {
        "args": [
          "list_id"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "json",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "sqlite3",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_76AAA88C",
    "name": "TelemetryServiceMS",
    "path": "_TelemetryServiceMS.py",
    "description": "The Nervous System.\nWatches the thread-safe LogQueue and updates the GUI Panels.",
    "methods": {
      "get_health": {
        "args": [],
        "doc": "Returns the operational status of the TelemetryServiceMS."
      },
      "start": {
        "args": [],
        "doc": "Begins the GUI update loop."
      },
      "ping": {
        "args": [],
        "doc": "Allows an agent to verify the pulse of the UI loop."
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "queue",
      "time",
      "typing"
    ]
  },
  {
    "token_id": "MS_33756201",
    "name": "TextChunkerMS",
    "path": "_TextChunkerMS.py",
    "description": "The Butcher: A unified service for splitting text into digestible chunks\nfor RAG (Retrieval Augmented Generation).",
    "methods": {
      "chunk_by_chars": {
        "args": [
          "text",
          "chunk_size",
          "chunk_overlap"
        ],
        "doc": "Standard Sliding Window. Best for prose/documentation.\nSplits purely by character count."
      },
      "chunk_by_lines": {
        "args": [
          "text",
          "max_lines",
          "max_chars"
        ],
        "doc": "Line-Preserving Chunker. Best for Code.\nRespects line boundaries and returns metadata about line numbers."
      }
    },
    "dependencies": [
      "logging",
      "microservice_std_lib",
      "typing"
    ]
  },
  {
    "token_id": "MS_7E985AE0",
    "name": "ThoughtStreamMS",
    "path": "_ThoughtStreamMS.py",
    "description": "The Neural Inspector: A UI widget for displaying a stream of AI thoughts/logs\nvisualized as 'bubbles' with sparklines.",
    "methods": {
      "add_thought_bubble": {
        "args": [
          "filename",
          "chunk_id",
          "content",
          "vector_preview",
          "color"
        ],
        "doc": "Mimics the 'InspectorFrame' from your React code."
      }
    },
    "dependencies": [
      "datetime",
      "microservice_std_lib",
      "random",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_42A8CBA5",
    "name": "TkinterAppShellMS",
    "path": "_TkinterAppShellMS.py",
    "description": "The Mother Ship.\nOwns the Tkinter Root. All other UI microservices dock into this.",
    "methods": {
      "launch": {
        "args": [],
        "doc": "Ignition sequence start."
      },
      "get_main_container": {
        "args": [],
        "doc": "Other services call this to know where to .pack() themselves."
      },
      "shutdown": {
        "args": [],
        "doc": ""
      }
    },
    "dependencies": [
      "_TkinterThemeManagerMS",
      "logging",
      "microservice_std_lib",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_BC4CE5A9",
    "name": "TkinterSmartExplorerMS",
    "path": "_TkinterSmartExplorerMS.py",
    "description": "The Navigator.\nA TreeView widget that expects standard 'Node' dictionaries (name, type, children).",
    "methods": {
      "load_data": {
        "args": [
          "data"
        ],
        "doc": "Ingests a dictionary tree (like from _ScoutMS or _TreeMapperMS)."
      }
    },
    "dependencies": [
      "microservice_std_lib",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_A266E0EB",
    "name": "TkinterThemeManagerMS",
    "path": "_TkinterThemeManagerMS.py",
    "description": "The Stylist: Holds the color palette and font settings.\nAll UI components query this service to decide how to draw themselves.",
    "methods": {
      "get_theme": {
        "args": [],
        "doc": ""
      },
      "update_key": {
        "args": [
          "key",
          "value"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "microservice_std_lib",
      "typing"
    ]
  },
  {
    "token_id": "MS_BA633F4B",
    "name": "TkinterUniButtonMS",
    "path": "_TkinterUniButtonMS.py",
    "description": "A generic button group that can merge ANY two actions.\nPass the visual/functional definitions in via the config objects.",
    "methods": {},
    "dependencies": [
      "dataclasses",
      "microservice_std_lib",
      "tkinter",
      "typing"
    ]
  },
  {
    "token_id": "MS_B77D7064",
    "name": "TreeMapperMS",
    "path": "_TreeMapperMS.py",
    "description": "The Cartographer: Generates ASCII-art style directory maps.\nUseful for creating context snapshots for LLMs.",
    "methods": {
      "generate_tree": {
        "args": [
          "root_path",
          "additional_exclusions",
          "use_default_exclusions"
        ],
        "doc": ""
      }
    },
    "dependencies": [
      "datetime",
      "logging",
      "microservice_std_lib",
      "os",
      "pathlib",
      "typing"
    ]
  },
  {
    "token_id": "MS_D493B241",
    "name": "VectorFactoryMS",
    "path": "_VectorFactoryMS.py",
    "description": "The Switchboard: Returns the appropriate VectorStore implementation\nbased on configuration.",
    "methods": {
      "create": {
        "args": [
          "backend",
          "config"
        ],
        "doc": ":param backend: 'faiss' or 'chroma'\n:param config: Dict containing 'path', 'dim' (for FAISS), or 'collection' (for Chroma)"
      }
    },
    "dependencies": [
      "chromadb",
      "faiss",
      "importlib",
      "json",
      "logging",
      "microservice_std_lib",
      "numpy",
      "os",
      "pathlib",
      "shutil",
      "sys",
      "typing",
      "uuid"
    ]
  },
  {
    "token_id": "MS_8D71E176",
    "name": "WebScraperMS",
    "path": "_WebScraperMS.py",
    "description": "The Reader: Fetches URLs and extracts the main content using Readability.\nStrips ads, navbars, and boilerplate to return clean text for LLMs.",
    "methods": {
      "scrape": {
        "args": [
          "url"
        ],
        "doc": "Synchronous wrapper for fetching and cleaning a URL.\nReturns: {\n    \"url\": str,\n    \"title\": str,\n    \"content\": str (The main body text),\n    \"html\": str (The raw HTML of the main content area)\n}"
      }
    },
    "dependencies": [
      "asyncio",
      "httpx",
      "importlib",
      "logging",
      "microservice_std_lib",
      "re",
      "readability",
      "sys",
      "typing"
    ]
  }
]
--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\requirements.txt
--------------------------------------------------------------------------------
PIL
beautifulsoup4
bs4
chromadb
faiss
git
httpx
jinja2
networkx
numpy
pydantic
pygame
pypdf
readability
requests
sqlite_vec
ttk
webview

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\sync-ms-deps.py
--------------------------------------------------------------------------------
#!/usr/bin/env python3
"""
sync-ms-deps.py

Crawls a microservice directory and keeps two kinds of dependency metadata in each service:

  1) internal_dependencies
     - Local Python modules that must be vendored alongside the service.

  2) external_dependencies
     - Third-party packages that belong in requirements.txt (pip-installable).

The script is AST-only: it does NOT import/execute any microservices.

It can:
- Produce a report (Markdown + optional JSON)
- Optionally rewrite @service_metadata(...) decorators to include/update:
    internal_dependencies=[...]
    external_dependencies=[...]
- Optionally write a requirements.txt derived from external_dependencies

Typical usage:
  python sync-ms-deps.py . --report-only
  python sync-ms-deps.py . --fix
  python sync-ms-deps.py . --fix --write-requirements requirements.txt
"""

from __future__ import annotations

import ast
import argparse
import json
import io
import re
import tokenize
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Any

MICROSERVICE_GLOB_DEFAULT = "*MS.py"
PY_GLOB = "*.py"

FALLBACK_STDLIB: Set[str] = {
    "abc", "argparse", "array", "asyncio", "base64", "binascii", "bisect",
    "calendar", "collections", "contextlib", "copy", "csv", "ctypes",
    "dataclasses", "datetime", "decimal", "difflib", "email", "enum", "fnmatch",
    "functools", "gc", "getpass", "glob", "gzip", "hashlib", "heapq", "hmac",
    "html", "http", "importlib", "inspect", "io", "ipaddress", "itertools",
    "json", "logging", "math", "mimetypes", "multiprocessing", "numbers",
    "operator", "os", "pathlib", "pickle", "platform", "plistlib", "pprint",
    "queue", "random", "re", "shlex", "shutil", "signal", "socket", "sqlite3",
    "ssl", "statistics", "string", "struct", "subprocess", "sys", "tempfile",
    "textwrap", "threading", "time", "tkinter", "traceback", "types",
    "typing", "unittest", "urllib", "uuid", "warnings", "weakref", "xml", "zipfile",
}

INHERITANCE_TO_INTERNAL_MODULE: Dict[str, str] = {
    "BaseService": "base_service",
}

META_KEY_INTERNAL = "internal_dependencies"
META_KEY_EXTERNAL = "external_dependencies"


@dataclass
class FileDeps:
    internal: List[str]
    external: List[str]
    declared_internal: List[str]
    errors: List[str]


@dataclass
class FileReport:
    file: str
    ok: bool
    changed: bool
    deps: FileDeps
    notes: List[str]


def get_stdlib_names() -> Set[str]:
    try:
        import sys
        names = set(getattr(sys, "stdlib_module_names", []))
        return names | FALLBACK_STDLIB
    except Exception:
        return set(FALLBACK_STDLIB)


def module_root(mod: str) -> str:
    return mod.split(".")[0].strip()


def normalize_dep_token(token: str) -> str:
    t = token.strip().strip('"').strip("'")
    if not t:
        return ""
    t = t.replace("\\", "/")
    if t.endswith(".py"):
        t = t[:-3]
        t = t.split("/")[-1]
    return t.strip()


def ast_list_of_str(values: List[str]) -> ast.AST:
    return ast.List(elts=[ast.Constant(v) for v in values], ctx=ast.Load())


def read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="replace")


def write_text(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8", newline="\n")


def _deps_to_header_value(values: List[str]) -> str:
    return ", ".join(values) if values else "None"


def rewrite_manifest_header_deps(src: str, internal: List[str], external: List[str]) -> Tuple[bool, str]:
    """Rewrite the top manifest docstring to Option A fields.

    If the file begins with a triple-quoted manifest block that contains SERVICE_NAME/ENTRY_POINT,
    we will:
      - remove DEPENDENCIES: ...
      - set/insert INTERNAL_DEPENDENCIES: ...
      - set/insert EXTERNAL_DEPENDENCIES: ...

    We keep all other header keys untouched.
    """
    lines = src.splitlines(keepends=True)
    if not lines:
        return False, src

    i = 0
    prefix: List[str] = []

    # Preserve shebang and encoding cookies if present
    if lines[i].startswith("#!"):
        prefix.append(lines[i]); i += 1
    while i < len(lines) and (re.match(r"^#.*coding[:=]", lines[i]) or "coding" in lines[i] and lines[i].lstrip().startswith("#")):
        # keep common coding cookie comment lines
        prefix.append(lines[i]); i += 1

    # Preserve leading blank/comment lines
    while i < len(lines) and (lines[i].strip() == "" or lines[i].lstrip().startswith("#")):
        prefix.append(lines[i]); i += 1

    if i >= len(lines):
        return False, src

    stripped = lines[i].lstrip()
    if not (stripped.startswith('"""') or stripped.startswith("'''")):
        return False, src

    indent = lines[i][:len(lines[i]) - len(stripped)]
    quote = stripped[:3]

    # Collect docstring block
    doc_lines: List[str] = []
    start_i = i
    doc_lines.append(lines[i]); i += 1

    # If closing delimiter is on the same line (rare), handle it
    if quote in stripped[3:]:
        # one-line docstring; we won't rewrite it
        return False, src

    while i < len(lines):
        doc_lines.append(lines[i])
        if lines[i].strip().endswith(quote):
            i += 1
            break
        i += 1

    if not doc_lines or not doc_lines[-1].strip().endswith(quote):
        return False, src

    # Extract inner body lines (between opening and closing delimiter)
    inner = doc_lines[1:-1]
    inner_text = "".join(inner)

    # Parse key/value lines inside manifest
    kv_lines = inner_text.splitlines()
    parsed: List[Tuple[str, str]] = []
    for ln in kv_lines:
        s = ln.strip()
        if not s:
            continue
        if ":" not in s:
            # keep non-kv lines as a special key
            parsed.append(("__RAW__", ln))
            continue
        k, v = s.split(":", 1)
        parsed.append((k.strip(), v.strip()))

    keys = {k for (k, _) in parsed if k != "__RAW__"}
    if not ("SERVICE_NAME" in keys and "ENTRY_POINT" in keys):
        # Not our manifest format; leave untouched
        return False, src

    new_internal = _deps_to_header_value(internal)
    new_external = _deps_to_header_value(external)

    # Build output lines, preserving order and updating/inserting fields
    out: List[str] = []
    saw_internal = False
    saw_external = False

    def emit_kv(k: str, v: str) -> None:
        out.append(f"{indent}{k}: {v}\n")

    # Preserve RAW lines by re-emitting them exactly
    # Also drop DEPENDENCIES line entirely.
    for k, v in parsed:
        if k == "__RAW__":
            out.append(v if v.endswith("\n") else (v + "\n"))
            continue
        if k == "DEPENDENCIES":
            continue
        if k == "INTERNAL_DEPENDENCIES":
            emit_kv("INTERNAL_DEPENDENCIES", new_internal)
            saw_internal = True
            continue
        if k == "EXTERNAL_DEPENDENCIES":
            emit_kv("EXTERNAL_DEPENDENCIES", new_external)
            saw_external = True
            continue
        emit_kv(k, v)

    # If missing, insert after ENTRY_POINT (or after SERVICE_NAME as fallback)
    if not (saw_internal and saw_external):
        # Reconstruct with controlled insertion point
        rebuilt: List[str] = []
        inserted = False
        for ln in out:
            rebuilt.append(ln)
            if not inserted and ln.strip().startswith("ENTRY_POINT:"):
                if not saw_internal:
                    rebuilt.append(f"{indent}INTERNAL_DEPENDENCIES: {new_internal}\n")
                if not saw_external:
                    rebuilt.append(f"{indent}EXTERNAL_DEPENDENCIES: {new_external}\n")
                inserted = True
        if not inserted:
            # fallback: append at end
            if not saw_internal:
                rebuilt.append(f"{indent}INTERNAL_DEPENDENCIES: {new_internal}\n")
            if not saw_external:
                rebuilt.append(f"{indent}EXTERNAL_DEPENDENCIES: {new_external}\n")
        out = rebuilt

    # Rebuild docstring with same quote + indent
    new_doc = [doc_lines[0]] + out + [doc_lines[-1]]
    new_src = "".join(prefix) + "".join(new_doc) + "".join(lines[i:])
    return (new_src != src), new_src


# NOTE:
# Python emits SyntaxWarning for invalid escapes like "\s" inside normal string literals.
# This is common when someone writes regexes as "\s+" instead of r"\s+".
# We can repair those *in microservice files* before ast.parse(), so scanning stays clean.
_REGEX_ESCAPE_SEQS = ("\\s", "\\S", "\\d", "\\D", "\\w", "\\W")


def _string_token_is_raw(tok_string: str) -> bool:
    """Return True if a STRING token has a raw-string prefix (r/R anywhere in prefix)."""
    # Token looks like: r"...", fr"...", b"...", etc.
    # Prefix is everything before the first quote char.
    i = 0
    while i < len(tok_string) and tok_string[i] not in ("'", '"'):
        i += 1
    prefix = tok_string[:i]
    return ("r" in prefix.lower())


def fix_invalid_escapes_in_source(src: str, sequences: Tuple[str, ...] = _REGEX_ESCAPE_SEQS) -> Tuple[str, int]:
    """Return (new_src, num_fixes) by escaping common regex sequences in non-raw string literals.

    We only touch STRING tokens (via tokenize) to avoid modifying code/comments.
    Example: "\\s+" (invalid escape) -> "\\\\s+" (valid Python string that yields regex \\s+).
    """
    fixes = 0
    out_tokens: List[tokenize.TokenInfo] = []

    try:
        gen = tokenize.generate_tokens(io.StringIO(src).readline)
    except Exception:
        return src, 0

    for tok in gen:
        if tok.type != tokenize.STRING:
            out_tokens.append(tok)
            continue

        s = tok.string
        if _string_token_is_raw(s):
            out_tokens.append(tok)
            continue

        new_s = s
        for seq in sequences:
            # Replace only when the backslash isn't already escaped.
            # Pattern matches: \s but not \\s
            pat = r"(?<!\\)" + re.escape(seq)
            repl = r"\\" + seq[1:]  # '\\' + 's' => '\\s'
            new_s, n = re.subn(pat, repl, new_s)
            fixes += n

        if new_s != s:
            out_tokens.append(tok._replace(string=new_s))
        else:
            out_tokens.append(tok)

    try:
        new_src = tokenize.untokenize(out_tokens)
    except Exception:
        return src, 0

    return new_src, fixes


def repair_invalid_escapes_in_file(path: Path) -> Tuple[bool, int]:
    """Repair invalid escape sequences in a file. Returns (changed, fixes)."""
    src = read_text(path)
    new_src, fixes = fix_invalid_escapes_in_source(src)
    if fixes > 0 and new_src != src:
        write_text(path, new_src)
        return True, fixes
    return False, 0


def extract_string_collection(expr: ast.AST) -> Set[str]:
    out: Set[str] = set()

    def add_str(node: ast.AST) -> None:
        if isinstance(node, ast.Constant) and isinstance(node.value, str):
            s = node.value.strip()
            if s:
                out.add(s)

    if isinstance(expr, (ast.List, ast.Tuple, ast.Set)):
        for elt in expr.elts:
            add_str(elt)
        return out

    if isinstance(expr, ast.Call) and isinstance(expr.func, ast.Name) and expr.func.id in {"set", "list", "tuple"}:
        if expr.args:
            return extract_string_collection(expr.args[0])
        return out

    if isinstance(expr, ast.Dict):
        for k in expr.keys:
            if k is not None:
                add_str(k)
        return out

    return out


class DepVisitor(ast.NodeVisitor):
    def __init__(self) -> None:
        self.imports: Set[str] = set()
        self.from_imports: Set[str] = set()
        self.base_names: Set[str] = set()
        self.declared_dependencies: Set[str] = set()

    def visit_Import(self, node: ast.Import) -> None:
        for alias in node.names:
            if alias.name:
                self.imports.add(alias.name)
        self.generic_visit(node)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        if node.module is not None:
            self.from_imports.add(node.module)
        else:
            self.from_imports.add(".")
        self.generic_visit(node)

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        for base in node.bases:
            name = None
            if isinstance(base, ast.Name):
                name = base.id
            elif isinstance(base, ast.Attribute):
                name = base.attr
            if name:
                self.base_names.add(name)
        self.generic_visit(node)

    def visit_Assign(self, node: ast.Assign) -> None:
        for t in node.targets:
            if isinstance(t, ast.Name) and t.id == "DEPENDENCIES":
                extracted = extract_string_collection(node.value)
                if extracted:
                    self.declared_dependencies |= extracted
        self.generic_visit(node)


def parse_service_metadata_dependencies(tree: ast.AST) -> Tuple[Set[str], Set[str]]:
    """Extract dependency hints from @service_metadata(...) decorators.

    We store state on the visitor instance (self.internal/self.external) instead of
    mutating outer-scope variables from inside visit_* methods.

    Reason: augmented assignment like `external |= ...` inside a method creates a
    local binding and can trigger UnboundLocalError.
    """

    class _MetaVisitor(ast.NodeVisitor):
        def __init__(self) -> None:
            self.internal: Set[str] = set()
            self.external: Set[str] = set()

        def visit_ClassDef(self, node: ast.ClassDef) -> None:
            for dec in node.decorator_list:
                if not isinstance(dec, ast.Call):
                    continue

                func = dec.func
                if not (isinstance(func, ast.Name) and func.id == "service_metadata"):
                    continue

                for kw in dec.keywords:
                    if not kw.arg:
                        continue

                    if kw.arg in {"dependencies", META_KEY_EXTERNAL}:
                        self.external |= extract_string_collection(kw.value)
                    elif kw.arg == META_KEY_INTERNAL:
                        self.internal |= extract_string_collection(kw.value)

            self.generic_visit(node)

    v = _MetaVisitor()
    v.visit(tree)
    return v.internal, v.external


class ServiceMetadataRewriter(ast.NodeTransformer):
    def __init__(self, internal: List[str], external: List[str], remove_legacy_dependencies_arg: bool = True) -> None:
        self.internal = internal
        self.external = external
        self.remove_legacy = remove_legacy_dependencies_arg
        self.touched = False

    def visit_ClassDef(self, node: ast.ClassDef) -> ast.AST:
        if not node.decorator_list:
            return node

        new_decorators: List[ast.AST] = []
        for dec in node.decorator_list:
            new_decorators.append(self._rewrite_decorator(dec))
        node.decorator_list = new_decorators
        return node

    def _rewrite_decorator(self, dec: ast.AST) -> ast.AST:
        if not isinstance(dec, ast.Call):
            return dec
        func = dec.func
        if not (isinstance(func, ast.Name) and func.id == "service_metadata"):
            return dec

        kw_map: Dict[str, ast.keyword] = {kw.arg: kw for kw in dec.keywords if kw.arg}

        kw_map[META_KEY_INTERNAL] = ast.keyword(arg=META_KEY_INTERNAL, value=ast_list_of_str(self.internal))
        kw_map[META_KEY_EXTERNAL] = ast.keyword(arg=META_KEY_EXTERNAL, value=ast_list_of_str(self.external))

        if self.remove_legacy and "dependencies" in kw_map:
            del kw_map["dependencies"]

        original_order = [kw.arg for kw in dec.keywords if kw.arg]
        wanted: List[str] = []
        seen: Set[str] = set()
        for k in original_order:
            if k in kw_map and k not in seen:
                wanted.append(k); seen.add(k)
        for k in (META_KEY_INTERNAL, META_KEY_EXTERNAL):
            if k in kw_map and k not in seen:
                wanted.append(k); seen.add(k)
        for k in kw_map.keys():
            if k not in seen:
                wanted.append(k); seen.add(k)

        dec.keywords = [kw_map[k] for k in wanted if k in kw_map]
        self.touched = True
        return dec


def analyze_file(
    path: Path,
    stdlib: Set[str],
    local_modules: Set[str],
    repair_invalid_escapes: bool = False,
) -> Tuple[FileDeps, List[str]]:
    errors: List[str] = []
    notes: List[str] = []
    internal: Set[str] = set()
    external: Set[str] = set()
    declared_internal: Set[str] = set()

    # Optional pre-pass: repair invalid regex escapes like "\s" inside normal strings.
    if repair_invalid_escapes:
        changed, fixes = repair_invalid_escapes_in_file(path)
        if changed:
            notes.append(f"Repaired {fixes} invalid escape sequence(s) in string literals.")

    try:
        src = read_text(path)
        # Pass filename so any warnings/errors point at the real file instead of <unknown>
        tree = ast.parse(src, filename=str(path))
    except SyntaxError as e:
        return FileDeps(internal=[], external=[], declared_internal=[], errors=[f"SyntaxError: {e}"]), ["Could not parse AST"]

    dv = DepVisitor()
    dv.visit(tree)

    import_roots = {module_root(m) for m in dv.imports if m}
    from_roots = {module_root(m) for m in dv.from_imports if m and m != "."}
    relative_present = "." in dv.from_imports

    if relative_present:
        notes.append("Contains relative imports (treated as internal when resolvable).")

    for mod in sorted(import_roots | from_roots):
        if not mod:
            continue
        if mod in stdlib:
            continue
        if mod in local_modules:
            internal.add(mod)
        else:
            external.add(mod)

    for base in dv.base_names:
        if base in INHERITANCE_TO_INTERNAL_MODULE:
            internal.add(INHERITANCE_TO_INTERNAL_MODULE[base])

    for raw in dv.declared_dependencies:
        t = normalize_dep_token(raw)
        if not t:
            continue
        if t in local_modules:
            declared_internal.add(t)
            internal.add(t)
            continue
        if t.endswith("MS"):
            underscored = f"_{t}"
            if underscored in local_modules:
                declared_internal.add(underscored)
                internal.add(underscored)

    meta_internal, meta_external = parse_service_metadata_dependencies(tree)

    for raw in meta_internal:
        t = normalize_dep_token(raw)
        if t in local_modules:
            internal.add(t)

    for raw in meta_external:
        t = normalize_dep_token(raw)
        if t and (t not in stdlib) and (t not in local_modules):
            external.add(t)

    external = {e for e in external if e and e not in stdlib}

    deps = FileDeps(
        internal=sorted(internal),
        external=sorted(external),
        declared_internal=sorted(declared_internal),
        errors=errors,
    )
    return deps, notes


def rewrite_file_decorators(
    path: Path,
    internal: List[str],
    external: List[str],
    remove_legacy: bool = True,
    repair_invalid_escapes: bool = False,
) -> Tuple[bool, str]:
    # Optional pre-pass repair so parsing/unparsing doesn't spam warnings.
    if repair_invalid_escapes:
        repair_invalid_escapes_in_file(path)

    src = read_text(path)
    try:
        tree = ast.parse(src, filename=str(path))
    except SyntaxError:
        return False, src

    rewriter = ServiceMetadataRewriter(internal, external, remove_legacy_dependencies_arg=remove_legacy)
    new_tree = rewriter.visit(tree)
    ast.fix_missing_locations(new_tree)

    if not rewriter.touched:
        return False, src

    try:
        new_src = ast.unparse(new_tree)
    except Exception:
        return False, src

    if not new_src.endswith("\n"):
        new_src += "\n"
    return (new_src != src), new_src


def render_report_md(reports: List[FileReport], root_dir: Path) -> str:
    lines: List[str] = []
    total = len(reports)
    ok = sum(1 for r in reports if r.ok)
    changed = sum(1 for r in reports if r.changed)

    lines.append("# Microservice Dependency Report")
    lines.append("")
    lines.append(f"- Root: `{root_dir}`")
    lines.append(f"- Files scanned: **{total}**")
    lines.append(f"- Parsed OK: **{ok}**")
    lines.append(f"- Rewritten files: **{changed}**")
    lines.append("")
    lines.append("## Per-file summary")
    lines.append("")
    lines.append("| File | Parsed | Changed | Internal deps | External deps | Notes/Errors |")
    lines.append("|---|---:|---:|---|---|---|")

    def fmt_list(xs: List[str]) -> str:
        return ", ".join(xs) if xs else ""

    for r in reports:
        parsed = "‚úÖ" if r.ok else "‚ùå"
        ch = "‚úÖ" if r.changed else ""
        notes = "; ".join((r.notes + r.deps.errors)[:3])
        if len(r.notes + r.deps.errors) > 3:
            notes += " ‚Ä¶"
        lines.append(
            f"| `{r.file}` | {parsed} | {ch} | {fmt_list(r.deps.internal)} | {fmt_list(r.deps.external)} | {notes} |"
        )

    all_external: Set[str] = set()
    for r in reports:
        all_external |= set(r.deps.external)

    lines.append("")
    lines.append("## Aggregate external dependencies (requirements candidates)")
    lines.append("")
    for dep in sorted(all_external):
        lines.append(f"- {dep}")
    lines.append("")
    return "\n".join(lines)


def main(argv: Optional[List[str]] = None) -> int:
    ap = argparse.ArgumentParser(description="Sync microservice dependency metadata (internal vs external).")
    ap.add_argument("path", nargs="?", default=".", help="Microservice directory (default: .)")
    ap.add_argument("--ms-glob", default=MICROSERVICE_GLOB_DEFAULT, help=f"Glob for microservice files (default: {MICROSERVICE_GLOB_DEFAULT})")
    ap.add_argument("--fix", action="store_true", help="Rewrite @service_metadata(...) in files.")
    ap.add_argument("--report-only", action="store_true", help="Do not modify files (default behavior).")
    ap.add_argument("--write-report", default="ms_deps_report.md", help="Write markdown report to this path (default: ms_deps_report.md)")
    ap.add_argument("--write-report-json", default=None, help="Optional JSON report path.")
    ap.add_argument("--write-requirements", default=None, help="Write requirements.txt to this path (external deps aggregate).")
    ap.add_argument(
        "--repair-invalid-escapes",
        action="store_true",
        help="Repair invalid regex escapes like \\s in non-raw string literals inside scanned microservices.",
    )
    ap.add_argument(
        "--sync-header-deps",
        action="store_true",
        help="Rewrite the top manifest docstring to use INTERNAL_DEPENDENCIES / EXTERNAL_DEPENDENCIES (Option A).",
    )
    ap.add_argument("--remove-legacy-dependencies-arg", action="store_true", help="Remove legacy 'dependencies=' arg when rewriting.")
    ap.add_argument("--no-remove-legacy-dependencies-arg", dest="remove_legacy_dependencies_arg", action="store_false", help="Keep legacy 'dependencies=' arg when rewriting.")
    ap.set_defaults(remove_legacy_dependencies_arg=True)

    args = ap.parse_args(argv)
    root_dir = Path(args.path).resolve()
    if not root_dir.exists() or not root_dir.is_dir():
        print(f"[ERROR] Not a directory: {root_dir}")
        return 1

    local_modules: Set[str] = set()
    for py in root_dir.glob(PY_GLOB):
        if py.name.startswith(".") or py.name == "__init__.py":
            continue
        local_modules.add(py.stem)

    stdlib = get_stdlib_names()

    ms_files = sorted(root_dir.glob(args.ms_glob))
    if not ms_files:
        md = render_report_md([], root_dir)
        write_text(Path(args.write_report).resolve(), md)
        print(f"[WARN] No files matched '{args.ms_glob}' in {root_dir}. Wrote empty report.")
        return 0

    reports: List[FileReport] = []

    for fp in ms_files:
        deps, notes = analyze_file(
            fp,
            stdlib=stdlib,
            local_modules=local_modules,
            repair_invalid_escapes=args.repair_invalid_escapes,
        )
        ok = not deps.errors
        changed = False

        if ok:
            would_change, new_src = rewrite_file_decorators(
                fp,
                internal=deps.internal,
                external=deps.external,
                remove_legacy=args.remove_legacy_dependencies_arg,
                repair_invalid_escapes=args.repair_invalid_escapes,
            )

            header_would_change = False
            if args.sync_header_deps:
                header_would_change, new_src = rewrite_manifest_header_deps(
                    new_src,
                    internal=deps.internal,
                    external=deps.external,
                )
                if header_would_change:
                    notes.append("Synced manifest header deps (Option A).")

            total_would_change = would_change or header_would_change

            if args.fix:
                changed = total_would_change
                if changed:
                    write_text(fp, new_src)
            else:
                # dry run: mark files that *would* change
                changed = total_would_change

        reports.append(FileReport(
            file=fp.name,
            ok=ok,
            changed=changed,
            deps=deps,
            notes=notes,
        ))

    md = render_report_md(reports, root_dir)
    report_path = Path(args.write_report).resolve()
    write_text(report_path, md)

    if args.write_report_json:
        jp = Path(args.write_report_json).resolve()
        payload = {"root": str(root_dir), "files": [asdict(r) for r in reports]}
        write_text(jp, json.dumps(payload, indent=2, sort_keys=True))

    if args.write_requirements:
        reqs: Set[str] = set()
        for r in reports:
            reqs |= set(r.deps.external)
        req_path = Path(args.write_requirements).resolve()
        write_text(req_path, "\n".join(sorted(reqs)) + ("\n" if reqs else ""))

    print(f"[OK] Scanned {len(ms_files)} microservices in {root_dir}")
    print(f"     Report: {report_path}")
    if args.write_report_json:
        print(f"     JSON:   {Path(args.write_report_json).resolve()}")
    if args.write_requirements:
        print(f"     Reqs:   {Path(args.write_requirements).resolve()}")
    if args.fix:
        print(f"     Rewrote: {sum(1 for r in reports if r.changed)} file(s)")
    else:
        print(f"     (dry run) Would rewrite: {sum(1 for r in reports if r.changed)} file(s)")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())





--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ArchiveBotMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ArchiveBotMS
ENTRY_POINT: _ArchiveBotMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import datetime
import fnmatch
import logging
import os
import tarfile
from pathlib import Path
from typing import Any, Dict, Optional, Set, Tuple
from microservice_std_lib import service_metadata, service_endpoint, BaseService
SERVICE_TITLE = 'ArchiveBot'
SERVICE_VERSION = '1.1.0'
LOG_LEVEL = logging.INFO
DEFAULT_IGNORE_DIRS: Set[str] = {'node_modules', '.git', '__pycache__', '.venv', 'venv', 'env', '.mypy_cache', '.pytest_cache', '.idea', '.vscode', 'dist', 'build', 'coverage', 'target', 'out', 'bin', 'obj'}
DEFAULT_IGNORE_FILES: Set[str] = {'.DS_Store', 'Thumbs.db', '*.pyc', '*.pyo', '*.log', '*.tmp'}
logging.basicConfig(level=LOG_LEVEL, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(SERVICE_TITLE)

@service_metadata(name=SERVICE_TITLE, version=SERVICE_VERSION, description='Creates timestamped .tar.gz backups of directory trees.', tags=['utility', 'backup', 'filesystem'], capabilities=['filesystem:read', 'filesystem:write'], side_effects=['filesystem:write'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=[])
class ArchiveBotMS(BaseService):

    def __init__(self, config: Optional[Dict[str, Any]]=None) -> None:
        super().__init__(SERVICE_TITLE)
        self.config = config or {}

    @service_endpoint(inputs={'source_path': 'str', 'output_dir': 'str', 'extra_exclusions': 'List[str]', 'use_default_exclusions': 'bool'}, outputs={'archive_path': 'str', 'file_count': 'int'}, description='Compresses a directory into a .tar.gz archive.', tags=['action', 'backup'], side_effects=['filesystem:write'])
    def create_backup(self, source_path: str, output_dir: str, extra_exclusions: Optional[Set[str]]=None, use_default_exclusions: bool=True) -> Dict[str, Any]:
        src = Path(source_path).resolve()
        out = Path(output_dir).resolve()
        if not src.exists():
            logger.error(f'Source not found: {src}')
            raise FileNotFoundError(f'Source path does not exist: {src}')
        out.mkdir(parents=True, exist_ok=True)
        exclude_patterns: Set[str] = set()
        if use_default_exclusions:
            exclude_patterns.update(DEFAULT_IGNORE_DIRS)
            exclude_patterns.update(DEFAULT_IGNORE_FILES)
        if extra_exclusions:
            exclude_patterns.update(extra_exclusions)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        archive_name = f'backup_{src.name}_{timestamp}.tar.gz'
        archive_path = out / archive_name
        file_count = 0
        try:
            with tarfile.open(archive_path, 'w:gz') as tar:
                for root, dirs, files in os.walk(src):
                    dirs[:] = [d for d in dirs if not self._is_excluded(d, exclude_patterns)]
                    for file_name in files:
                        if self._is_excluded(file_name, exclude_patterns):
                            continue
                        full_path = Path(root) / file_name
                        if full_path == archive_path:
                            continue
                        rel_path = full_path.relative_to(src)
                        tar.add(full_path, arcname=rel_path)
                        file_count += 1
            logger.info(f'Archive created: {archive_path} ({file_count} files)')
            return {'archive_path': str(archive_path), 'file_count': file_count}
        except Exception as exc:
            logger.exception(f'Backup failed: {exc}')
            if archive_path.exists():
                try:
                    archive_path.unlink()
                except Exception:
                    pass
            raise exc

    def _is_excluded(self, name: str, patterns: Set[str]) -> bool:
        for pattern in patterns:
            if name == pattern or fnmatch.fnmatch(name, pattern):
                return True
        return False
if __name__ == '__main__':
    import tempfile
    bot = ArchiveBotMS()
    print(f'Service Ready: {bot}')
    with tempfile.TemporaryDirectory() as tmp_source:
        with tempfile.TemporaryDirectory() as tmp_out:
            p = Path(tmp_source) / 'test_file.txt'
            p.write_text('Hello Archive')
            print(f'Backing up {tmp_source} to {tmp_out}...')
            result = bot.create_backup(tmp_source, tmp_out)
            print(f'Result: {result}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_AuthMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _AuthMS
ENTRY_POINT: _AuthMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import base64
import hashlib
import json
import logging
import time
from typing import Any, Dict, Optional
from microservice_std_lib import service_metadata, service_endpoint
'\nSERVICE: Auth\nROLE: Manage user authentication and signed session tokens.\nINPUTS:\n  - username: Login identifier.\n  - password: Secret credential.\n  - token: Serialized session token string.\nOUTPUTS:\n  - token: Signed session token (str) or None on failure.\n  - is_valid: Boolean indicating whether a token is valid and not expired.\nNOTES:\n  This is a simplified in-memory auth system intended for local tools and\n  pipelines, not production-grade security.\n'
logger = logging.getLogger(__name__)
DEFAULT_SECRET_KEY = 'super_secret_cortex_key'
DEFAULT_SALT = 'cortex_salt'

@service_metadata(name='Auth', version='1.0.0', description='Manages user authentication and session tokens.', tags=['auth', 'security', 'crypto'], capabilities=['crypto'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class AuthMS:
    """
    ROLE: Simple authentication microservice providing username/password login
          and signed session tokens.

    INPUTS:
      - config: Optional configuration dict. Recognized keys:
          - 'secret_key': Secret used to sign tokens.

    OUTPUTS:
      - Exposes `login` and `validate_session` endpoints for use in pipelines.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None) -> None:
        self.config = config or {}
        self.secret_key: str = self.config.get('secret_key', DEFAULT_SECRET_KEY)
        self.users_db: Dict[str, str] = {'admin': self._hash_password('admin123')}

    @service_endpoint(inputs={'username': 'str', 'password': 'str'}, outputs={'token': 'Optional[str]'}, description='Attempts to log in and returns a signed session token.', tags=['auth', 'security', 'session'])
    def login(self, username: str, password: str) -> Optional[str]:
        """
        Attempt to log in with the provided username and password.

        :param username: Login identifier.
        :param password: Plain-text password.
        :returns: Signed session token if successful, None otherwise.
        """
        if username not in self.users_db:
            return None
        stored_hash = self.users_db[username]
        if self._verify_password(password, stored_hash):
            return self._create_token(username)
        return None

    @service_endpoint(inputs={'token': 'str'}, outputs={'is_valid': 'bool'}, description='Checks whether a token is valid and not expired.', tags=['auth', 'security'])
    def validate_session(self, token: str) -> bool:
        """
        Check if a serialized token is valid and not expired.

        :param token: Session token string.
        :returns: True if token is valid and not expired, False otherwise.
        """
        payload = self._decode_token(token)
        return payload is not None

    def _hash_password(self, password: str) -> str:
        """
        Securely hashes a password using SHA-256 with a static salt.
        """
        return hashlib.sha256((password + DEFAULT_SALT).encode('utf-8')).hexdigest()

    def _verify_password(self, plain_password: str, hashed_password: str) -> bool:
        """
        Verifies a provided password against the stored hash.
        """
        return self._hash_password(plain_password) == hashed_password

    def _create_token(self, user_id: str, expires_in: int=3600) -> str:
        """
        Generates a signed session token.

        Payload includes:
          - 'sub' (subject)
          - 'exp' (expiration time)
          - 'iat' (issued-at time)
          - 'scope' (authorization scope)
        """
        now = int(time.time())
        payload = {'sub': user_id, 'exp': now + expires_in, 'iat': now, 'scope': 'admin'}
        json_payload = json.dumps(payload).encode('utf-8')
        token_part = base64.b64encode(json_payload).decode('utf-8')
        signature = hashlib.sha256((token_part + self.secret_key).encode('utf-8')).hexdigest()
        return f'{token_part}.{signature}'

    def _decode_token(self, token: str) -> Optional[Dict[str, Any]]:
        """
        Parses and validates the incoming token.

        Returns the payload if valid, None otherwise.
        """
        try:
            if not token or '.' not in token:
                return None
            token_part, signature = token.split('.', 1)
            recalc_signature = hashlib.sha256((token_part + self.secret_key).encode('utf-8')).hexdigest()
            if signature != recalc_signature:
                return None
            payload_json = base64.b64decode(token_part).decode('utf-8')
            payload: Dict[str, Any] = json.loads(payload_json)
            if payload.get('exp', 0) < time.time():
                return None
            return payload
        except Exception:
            logger.exception('Failed to decode or validate auth token.')
            return None
if __name__ == '__main__':
    svc = AuthMS()
    print('Service ready:', svc)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CartridgeServiceMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CartridgeServiceMS
ENTRY_POINT: _CartridgeServiceMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: sqlite_vec
"""
import datetime
import json
import os
import sqlite3
import struct
import time
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional
try:
    import sqlite_vec
except ImportError:
    sqlite_vec = None
from microservice_std_lib import service_metadata, service_endpoint
from base_service import BaseService

@service_metadata(name='CartridgeServiceMS', version='1.1.0', description='The Source of Truth. Manages the Unified Neural Cartridge Format (UNCF v1.0).', tags=['storage', 'database', 'RAG'], capabilities=['sqlite', 'vector-search', 'graph-storage'], side_effects=['filesystem:read', 'filesystem:write'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['sqlite_vec'])
class CartridgeServiceMS(BaseService):
    """
    The Source of Truth.
    Manages the Unified Neural Cartridge Format (UNCF v1.0).
    """
    SCHEMA_VERSION = 'uncf_v1.0'

    def __init__(self, db_path: str):
        super().__init__('CartridgeServiceMS')
        self.db_path = Path(db_path)
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path, timeout=60.0)
        if sqlite_vec:
            try:
                conn.enable_load_extension(True)
                sqlite_vec.load(conn)
                conn.enable_load_extension(False)
            except Exception as e:
                self.log_error(f'Failed to load sqlite-vec: {e}')
        return conn

    def get_vector_dim(self) -> int:
        """Retrieves the expected vector dimension from the manifest spec."""
        spec = self.get_manifest('embedding_spec') or {}
        if isinstance(spec, str):
            try:
                spec = json.loads(spec)
            except:
                spec = {}
        return int(spec.get('dim', 0))

    def _init_db(self):
        """Initializes the standard Schema."""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        conn = self._get_conn()
        cursor = conn.cursor()
        cursor.execute('PRAGMA journal_mode=WAL')
        cursor.execute('PRAGMA synchronous=NORMAL')
        cursor.execute('CREATE TABLE IF NOT EXISTS manifest (key TEXT PRIMARY KEY, value TEXT)')
        cursor.execute("\n            CREATE TABLE IF NOT EXISTS directories (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                vfs_path TEXT UNIQUE NOT NULL,\n                parent_path TEXT,\n                metadata TEXT DEFAULT '{}'\n            )\n        ")
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_dir_parent ON directories(parent_path)')
        cursor.execute('\n            CREATE TABLE IF NOT EXISTS files (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                vfs_path TEXT NOT NULL,       -- Portable path (e.g. "src/main.py")\n                origin_path TEXT,             -- Provenance (e.g. "C:/Users/...")\n                origin_type TEXT,             -- \'filesystem\', \'web\', \'github\'\n                content TEXT,                 -- Text content (UTF-8)\n                blob_data BLOB,               -- Binary content (Images, PDFs)\n                mime_type TEXT,\n                status TEXT DEFAULT \'RAW\',    -- RAW, REFINED, ERROR, SKIPPED\n                metadata TEXT DEFAULT \'{}\',   -- JSON tags, summaries\n                last_updated TIMESTAMP\n            )\n        ')
        cursor.execute('CREATE UNIQUE INDEX IF NOT EXISTS idx_vfs ON files(vfs_path)')
        cursor.execute('\n            CREATE TABLE IF NOT EXISTS chunks (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                file_id INTEGER,\n                chunk_index INTEGER,\n                content TEXT,\n                embedding BLOB,\n                name TEXT,\n                type TEXT,\n                start_line INTEGER,\n                end_line INTEGER,\n                FOREIGN KEY(file_id) REFERENCES files(id)\n            )\n        ')
        if sqlite_vec:
            dim = self.get_vector_dim()
            if dim > 0:
                try:
                    cursor.execute(f'CREATE VIRTUAL TABLE IF NOT EXISTS vec_items USING vec0(embedding float[{dim}])')
                except Exception as e:
                    self.log_error(f'Vector Table Init Error: {e}')
            else:
                self.log_info('Vector table creation deferred: No dimensions found in manifest yet.')
        cursor.execute('CREATE TABLE IF NOT EXISTS graph_nodes (id TEXT PRIMARY KEY, type TEXT, label TEXT, data_json TEXT)')
        cursor.execute('CREATE TABLE IF NOT EXISTS graph_edges (source TEXT, target TEXT, relation TEXT, weight REAL)')
        cursor.execute('CREATE TABLE IF NOT EXISTS logs (timestamp REAL, level TEXT, message TEXT, context TEXT)')
        conn.commit()
        conn.close()
        self.initialize_manifest()

    def initialize_manifest(self):
        """Populates the boot sector with strict RagFORGE Cartridge Schema (UNCF) v1.1."""
        if not self.get_manifest('cartridge_id'):
            now = datetime.datetime.utcnow().isoformat()
            self.set_manifest('schema_name', 'ragforge_cartridge')
            self.set_manifest('schema_version', '1.1.0')
            self.set_manifest('cartridge_id', str(uuid.uuid4()))
            self.set_manifest('created_at_utc', now)
            self.set_manifest('created_by_app', 'RagFORGE')
            self.set_manifest('sources', [])
            self.set_manifest('source_policies', {'binary_policy': 'Extract Text', 'web_depth': 0})
            self.set_manifest('embedding_spec', {'provider': 'unknown', 'model': 'pending_init', 'dim': 0, 'dtype': 'unknown', 'distance': 'unknown'})
            self.set_manifest('chunking_spec', {'strategy': 'semantic_hybrid', 'python_ast': True, 'generic_window': 1500})
            self.set_manifest('vfs', {'root_label': '', 'directories': {'count': 0}, 'files': {'count': 0, 'by_origin_type': {}, 'by_mime': {}}, 'index_built': False})
            self.set_manifest('content_stats', {'chunks': {'count': 0}, 'vector_index': {'enabled': False, 'table': 'vec_items', 'backend': 'sqlite-vec', 'dims': 0, 'status': 'unknown'}, 'graph': {'nodes': 0, 'edges': 0}})
            self.set_manifest('capabilities', {'tables': {'manifest': True, 'directories': True, 'files': True, 'chunks': True, 'vec_items': True, 'graph_nodes': True, 'graph_edges': True, 'logs': True}, 'navigation': {'vfs_path': 'files.vfs_path', 'directory_index': 'directories.vfs_path', 'list_files_query': 'SELECT vfs_path, mime_type, origin_type, status FROM files ORDER BY vfs_path', 'list_directories_query': 'SELECT vfs_path, parent_path FROM directories ORDER BY vfs_path'}, 'retrieval': {'raw_file_content_query': 'SELECT content, blob_data, mime_type FROM files WHERE vfs_path=?', 'chunks_by_file_query': 'SELECT chunk_index, name, type, start_line, end_line, content FROM chunks WHERE file_id=? ORDER BY chunk_index', 'vector_search': 'sqlite-vec on vec_items if available'}, 'python_helper_api': {'note': 'Optional convenience layer for agents running inside Python. For non-Python consumers, use the SQL queries above.', 'methods': ['CartridgeServiceMS.get_status_flags', 'CartridgeServiceMS.list_files', 'CartridgeServiceMS.list_directories', 'CartridgeServiceMS.get_file_record', 'CartridgeServiceMS.get_directory_tree', 'CartridgeServiceMS.get_status_summary', 'CartridgeServiceMS.add_node', 'CartridgeServiceMS.add_edge', 'CartridgeServiceMS.search_embeddings']}})
            self.set_manifest('cartridge_health', 'FRESH')
            self.set_manifest('ingest_complete', False)
            self.set_manifest('refine_complete', False)
            self.set_manifest('last_ingest_at_utc', '')
            self.set_manifest('last_refine_at_utc', '')
            self.set_manifest('last_error', '')
            self.set_manifest('locks', {'write_lock_expected': False, 'notes': 'If DB locks occur, consider batching writes and shorter-lived connections.'})

    def set_manifest(self, key: str, value: Any):
        """Upsert metadata key."""
        conn = self._get_conn()
        val_str = json.dumps(value) if isinstance(value, (dict, list)) else str(value)
        conn.execute('INSERT OR REPLACE INTO manifest (key, value) VALUES (?, ?)', (key, val_str))
        conn.commit()
        conn.close()

    def get_manifest(self, key: str) -> Optional[str]:
        """Retrieve metadata key."""
        conn = self._get_conn()
        row = conn.execute('SELECT value FROM manifest WHERE key=?', (key,)).fetchone()
        conn.close()
        return row[0] if row else None

    def validate_cartridge(self) -> Dict[str, Any]:
        """Quality Control: Checks if the cartridge is Agent-Safe."""
        report = {'valid': True, 'health': 'OK', 'errors': []}
        required = ['schema_name', 'schema_version', 'cartridge_id', 'created_at_utc', 'created_by_app', 'embedding_spec', 'chunking_spec', 'capabilities']
        for key in required:
            if not self.get_manifest(key):
                report['valid'] = False
                report['errors'].append(f'Missing Manifest Key: {key}')
        conn = self._get_conn()
        vec_enabled = False
        vec_status = 'unknown'
        try:
            conn.execute('SELECT count(*) FROM vec_items').fetchone()
            vec_enabled = True
            vec_status = 'available'
        except Exception:
            vec_enabled = False
            vec_status = 'unavailable'
            report['errors'].append('Vector Index (vec_items) missing or not loaded.')
            report['health'] = 'WARN_NO_VECTORS'
        finally:
            conn.close()
        try:
            content_stats = self.get_manifest('content_stats') or {}
            if isinstance(content_stats, str):
                try:
                    content_stats = json.loads(content_stats)
                except:
                    content_stats = {}
            vec = content_stats.get('vector_index', {}) if isinstance(content_stats, dict) else {}
            embed_spec = self.get_manifest('embedding_spec') or {}
            if isinstance(embed_spec, str):
                try:
                    embed_spec = json.loads(embed_spec)
                except:
                    embed_spec = {}
            spec_dim = 0
            if isinstance(embed_spec, dict):
                spec_dim = int(embed_spec.get('dim', 0) or 0)
            vec['enabled'] = bool(vec_enabled)
            vec['status'] = vec_status
            if spec_dim > 0:
                vec['dims'] = spec_dim
            if 'table' not in vec:
                vec['table'] = 'vec_items'
            if 'backend' not in vec:
                vec['backend'] = 'sqlite-vec'
            content_stats['vector_index'] = vec
            self.set_manifest('content_stats', content_stats)
        except Exception as e:
            report['errors'].append(f'Failed to stamp vector_index status into manifest: {e}')
            report['health'] = 'WARN_MANIFEST_STAMP_FAIL'
        return report

    def store_file(self, vfs_path: str, origin_path: str, content: str=None, blob: bytes=None, mime_type: str='text/plain', origin_type: str='filesystem'):
        """
        The Universal Input Method.
        Stores raw data. If file exists, updates it and resets status to 'RAW' for re-refining.
        """
        conn = self._get_conn()
        try:
            conn.execute("\n                INSERT OR REPLACE INTO files \n                (vfs_path, origin_path, origin_type, content, blob_data, mime_type, status, last_updated)\n                VALUES (?, ?, ?, ?, ?, ?, 'RAW', ?)\n            ", (vfs_path, origin_path, origin_type, content, blob, mime_type, time.time()))
            conn.commit()
            return True
        except Exception as e:
            self.log_error(f'DB Store Error ({vfs_path}): {e}')
            return False
        finally:
            conn.close()

    def get_pending_files(self, limit: int=10) -> List[Dict]:
        """Fetches files waiting for the Refinery."""
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        rows = conn.execute("SELECT * FROM files WHERE status = 'RAW' LIMIT ?", (limit,)).fetchall()
        conn.close()
        return [dict(row) for row in rows]

    def update_status(self, file_id: int, status: str, metadata: dict=None):
        conn = self._get_conn()
        if metadata:
            conn.execute('UPDATE files SET status = ?, metadata = ? WHERE id = ?', (status, json.dumps(metadata), file_id))
        else:
            conn.execute('UPDATE files SET status = ? WHERE id = ?', (status, file_id))
        conn.commit()
        conn.close()

    def ensure_directory(self, vfs_path: str):
        """Idempotent insert for VFS directories."""
        if not vfs_path:
            return
        parent = os.path.dirname(vfs_path).replace('\\', '/')
        if parent == vfs_path:
            parent = ''
        conn = self._get_conn()
        try:
            conn.execute('INSERT OR IGNORE INTO directories (vfs_path, parent_path) VALUES (?, ?)', (vfs_path, parent))
            conn.commit()
        except:
            pass
        finally:
            conn.close()

    def _coerce_bool(self, v: Any) -> bool:
        """Best-effort conversion for manifest values stored as strings."""
        if v is None:
            return False
        if isinstance(v, bool):
            return v
        s = str(v).strip().lower()
        return s in ('1', 'true', 'yes', 'y', 'on')

    @service_endpoint(inputs={}, outputs={'ingest_complete': 'bool', 'refine_complete': 'bool', 'cartridge_health': 'str'}, description='Returns key manifest status flags (ingest/refine status and health) in a single call.', tags=['status', 'health'])
    def get_status_flags(self) -> Dict[str, Any]:
        """Returns key manifest status flags in a single call."""
        ingest_complete = self._coerce_bool(self.get_manifest('ingest_complete'))
        refine_complete = self._coerce_bool(self.get_manifest('refine_complete'))
        health = self.get_manifest('cartridge_health') or 'UNKNOWN'
        return {'ingest_complete': ingest_complete, 'refine_complete': refine_complete, 'cartridge_health': health, 'schema_name': self.get_manifest('schema_name') or '', 'schema_version': self.get_manifest('schema_version') or '', 'cartridge_id': self.get_manifest('cartridge_id') or ''}

    def list_files(self, prefix: str='', status: Optional[str]=None, limit: Optional[int]=None) -> List[Dict[str, Any]]:
        """Enumerate files in the cartridge (optionally filtered by VFS prefix and/or status)."""
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        try:
            sql = 'SELECT id, vfs_path, origin_path, origin_type, mime_type, status, last_updated, metadata FROM files'
            clauses = []
            params = []
            if prefix:
                clauses.append('vfs_path LIKE ?')
                params.append(prefix.rstrip('/') + '/%')
            if status:
                clauses.append('status = ?')
                params.append(status)
            if clauses:
                sql += ' WHERE ' + ' AND '.join(clauses)
            sql += ' ORDER BY vfs_path'
            if limit is not None:
                sql += ' LIMIT ?'
                params.append(int(limit))
            rows = conn.execute(sql, tuple(params)).fetchall()
            out = []
            for r in rows:
                d = dict(r)
                try:
                    d['metadata'] = json.loads(d.get('metadata') or '{}')
                except Exception:
                    d['metadata'] = {}
                out.append(d)
            return out
        finally:
            conn.close()

    def get_file_record(self, vfs_path: str) -> Optional[Dict[str, Any]]:
        """Fetch a single file record by VFS path."""
        if not vfs_path:
            return None
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        try:
            row = conn.execute('SELECT id, vfs_path, origin_path, origin_type, content, blob_data, mime_type, status, metadata, last_updated FROM files WHERE vfs_path = ?', (vfs_path,)).fetchone()
            if not row:
                return None
            d = dict(row)
            try:
                d['metadata'] = json.loads(d.get('metadata') or '{}')
            except Exception:
                d['metadata'] = {}
            return d
        finally:
            conn.close()

    def list_directories(self, prefix: str='') -> List[Dict[str, Any]]:
        """Enumerate directories in the cartridge VFS."""
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        try:
            if prefix:
                rows = conn.execute('SELECT id, vfs_path, parent_path, metadata FROM directories WHERE vfs_path LIKE ? ORDER BY vfs_path', (prefix.rstrip('/') + '/%',)).fetchall()
            else:
                rows = conn.execute('SELECT id, vfs_path, parent_path, metadata FROM directories ORDER BY vfs_path').fetchall()
            out = []
            for r in rows:
                d = dict(r)
                try:
                    d['metadata'] = json.loads(d.get('metadata') or '{}')
                except Exception:
                    d['metadata'] = {}
                out.append(d)
            return out
        finally:
            conn.close()

    @service_endpoint(inputs={'root': 'str'}, outputs={'tree': 'dict'}, description='Builds a nested directory tree structure for UI navigation or context mapping.', tags=['vfs', 'navigation'])
    def get_directory_tree(self, root: str='') -> Dict[str, Any]:
        """Builds a nested directory tree starting at `root` ("" for full tree)."""
        dirs = self.list_directories(prefix=root) if root else self.list_directories()
        files = self.list_files(prefix=root) if root else self.list_files()

        def new_node():
            return {'_dirs': {}, '_files': []}
        tree = new_node()
        for d in dirs:
            path = (d.get('vfs_path') or '').strip('/')
            if not path:
                continue
            parts = path.split('/')
            cur = tree
            for p in parts:
                cur = cur['_dirs'].setdefault(p, new_node())
        for f in files:
            path = (f.get('vfs_path') or '').strip('/')
            if not path:
                continue
            parts = path.split('/')
            fname = parts[-1]
            cur = tree
            for p in parts[:-1]:
                cur = cur['_dirs'].setdefault(p, new_node())
            cur['_files'].append({'name': fname, 'vfs_path': f.get('vfs_path'), 'mime_type': f.get('mime_type'), 'origin_type': f.get('origin_type'), 'status': f.get('status')})
        return tree

    def get_status_summary(self) -> Dict[str, Any]:
        """Counts files by status and provides a quick cartridge overview."""
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        try:
            rows = conn.execute('SELECT status, COUNT(*) as n FROM files GROUP BY status').fetchall()
            by_status = {r['status']: r['n'] for r in rows}
            dcnt = conn.execute('SELECT COUNT(*) FROM directories').fetchone()[0]
            fcnt = conn.execute('SELECT COUNT(*) FROM files').fetchone()[0]
            ccnt = conn.execute('SELECT COUNT(*) FROM chunks').fetchone()[0]
            ncnt = conn.execute('SELECT COUNT(*) FROM graph_nodes').fetchone()[0]
            ecnt = conn.execute('SELECT COUNT(*) FROM graph_edges').fetchone()[0]
            return {'directories': int(dcnt), 'files': int(fcnt), 'chunks': int(ccnt), 'graph_nodes': int(ncnt), 'graph_edges': int(ecnt), 'files_by_status': by_status, 'flags': self.get_status_flags()}
        finally:
            conn.close()

    def add_node(self, node_id: str, node_type: str, label: str, data: dict=None):
        conn = self._get_conn()
        conn.execute('INSERT OR REPLACE INTO graph_nodes (id, type, label, data_json) VALUES (?, ?, ?, ?)', (node_id, node_type, label, json.dumps(data or {})))
        conn.commit()
        conn.close()

    def add_edge(self, source: str, target: str, relation: str='related', weight: float=1.0):
        conn = self._get_conn()
        conn.execute('INSERT OR IGNORE INTO graph_edges (source, target, relation, weight) VALUES (?, ?, ?, ?)', (source, target, relation, weight))
        conn.commit()
        conn.close()

    @service_endpoint(inputs={'query_vector': 'list', 'limit': 'int'}, outputs={'results': 'list'}, description='Performs semantic vector search using sqlite-vec against the cartridge chunks.', tags=['search', 'vector'])
    def search_embeddings(self, query_vector: List[float], limit: int=5) -> List[Dict]:
        """Performs semantic search using sqlite-vec."""
        if not sqlite_vec or not query_vector:
            return []
        conn = self._get_conn()
        conn.row_factory = sqlite3.Row
        results = []
        try:
            rows = conn.execute('\n                SELECT\n                    rowid,\n                    distance\n                FROM vec_items\n                WHERE embedding MATCH ?\n                ORDER BY distance\n                LIMIT ?\n            ', (json.dumps(query_vector), limit)).fetchall()
            for r in rows:
                chunk_id = r['rowid']
                query = '\n                    SELECT c.*, f.vfs_path \n                    FROM chunks c \n                    JOIN files f ON c.file_id = f.id \n                    WHERE c.id=?\n                '
                chunk = conn.execute(query, (chunk_id,)).fetchone()
                if chunk:
                    res = dict(chunk)
                    res['score'] = r['distance']
                    results.append(res)
        except Exception as e:
            self.log_error(f'Vector Search Error: {e}')
        finally:
            conn.close()
        return results
if __name__ == '__main__':
    import tempfile
    with tempfile.TemporaryDirectory() as tmp_dir:
        db_file = os.path.join(tmp_dir, 'test_cartridge.db')
        print(f'Initializing service at: {db_file}')
        svc = CartridgeServiceMS(db_file)
        print(f'Service Ready: {svc}')
        status = svc.get_status_flags()
        print(f'Initial Status: {status}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ChalkBoardMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ChalkBoardMS
ENTRY_POINT: _ChalkBoardMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: webview
"""
import json
import os
import webview
from microservice_std_lib import service_metadata, service_endpoint, BaseService
HTML_CONTENT = '\n<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <title>OBS Signboard</title>\n    <link href="https://fonts.googleapis.com/css2?family=Neonderthaw&family=Press+Start+2P&family=Fredericka+the+Great&family=Orbitron:wght@700&family=Special+Elite&display=swap" rel="stylesheet">\n    <style>\n        body, html { margin: 0; padding: 0; height: 100%; overflow: hidden; display: flex; justify-content: center; align-items: center; transition: all 0.5s ease; }\n        #sign-container { width: 90%; text-align: center; outline: none; cursor: text; transition: transform 0.2s; }\n        \n        /* --- THEME 1: NEON NIGHTS --- */\n        body.neon { background-color: #050505; font-family: \'Neonderthaw\', cursive; }\n        body.neon #sign-container { color: #fff; font-size: 8rem; text-shadow: 0 0 7px #fff, 0 0 42px #bc13fe, 0 0 102px #bc13fe; animation: flicker 1.5s infinite alternate; }\n\n        /* --- THEME 2: 8-BIT HACKER --- */\n        body.terminal { background-color: #000; font-family: \'Press Start 2P\', cursive; }\n        body.terminal #sign-container { color: #00ff41; font-size: 3.5rem; text-shadow: 0 0 10px #00ff41; text-transform: uppercase; }\n        body.terminal #sign-container::after { content: \'_\'; animation: blink 1s step-end infinite; }\n\n        /* --- THEME 3: CHALKBOARD --- */\n        body.chalk { background-color: #2b3a28; font-family: \'Fredericka the Great\', cursive; background-image: radial-gradient(circle, rgba(255,255,255,0.05) 1px, transparent 1px); background-size: 20px 20px; }\n        body.chalk #sign-container { color: rgba(255,255,255,0.9); font-size: 6rem; transform: rotate(-1deg); }\n\n        /* --- NEW THEME 4: BLUEPRINT (Technical) --- */\n        body.blueprint { background-color: #003366; font-family: \'Orbitron\', sans-serif; background-image: linear-gradient(#004080 1px, transparent 1px), linear-gradient(90deg, #004080 1px, transparent 1px); background-size: 50px 50px; }\n        body.blueprint #sign-container { color: #00d9ff; font-size: 5rem; text-transform: uppercase; border: 2px solid #00d9ff; padding: 20px; box-shadow: 0 0 15px #00d9ff; }\n\n        /* --- NEW THEME 5: RETRO WOOD --- */\n        body.retro { background-color: #3d2b1f; font-family: \'Special Elite\', serif; background-image: repeating-linear-gradient(90deg, transparent, transparent 40px, rgba(0,0,0,0.1) 41px); }\n        body.retro #sign-container { color: #e6b450; font-size: 5.5rem; text-shadow: 2px 2px 0px #20150d; }\n\n        /* --- NEW THEME 6: CYBERPUNK (Yellow/Black) --- */\n        body.cyber { background-color: #fcee0a; font-family: \'Orbitron\', sans-serif; }\n        body.cyber #sign-container { color: #000; font-size: 5rem; font-weight: 900; text-transform: uppercase; font-style: italic; background: #000; color: #fcee0a; padding: 10px 40px; clip-path: polygon(0% 0%, 100% 0%, 95% 100%, 5% 100%); }\n\n        /* ANIMATIONS & EFFECTS */\n        @keyframes flicker { 0%, 19%, 21%, 100% { opacity: 1; } 20% { opacity: 0.5; } }\n        @keyframes blink { 0%, 100% { opacity: 1; } 50% { opacity: 0; } }\n        .shake { animation: shake 0.5s cubic-bezier(.36,.07,.19,.97) both; }\n        @keyframes shake { 10%, 90% { transform: translate3d(-1px, 0, 0); } 20%, 80% { transform: translate3d(2px, 0, 0); } 30%, 50%, 70% { transform: translate3d(-4px, 0, 0); } 40%, 60% { transform: translate3d(4px, 0, 0); } }\n    </style>\n</head>\n<body class="neon">\n    <div id="sign-container" contenteditable="true" spellcheck="false">ON AIR</div>\n\n    <script>\n        const container = document.getElementById(\'sign-container\');\n        \n        function updateDisplay(text, theme) {\n            container.innerText = text;\n            document.body.className = theme;\n        }\n\n        function triggerEffect(effect) {\n            if (effect === \'shake\') {\n                container.classList.add(\'shake\');\n                setTimeout(() => container.classList.remove(\'shake\'), 500);\n            }\n        }\n\n        // Notify Python on load\n        window.addEventListener(\'pywebviewready\', () => {\n            window.pywebview.api.loaded().then(state => {\n                updateDisplay(state.text, state.theme);\n            });\n        });\n\n        document.addEventListener(\'keydown\', (e) => {\n            const themes = { \'F1\': \'neon\', \'F2\': \'terminal\', \'F3\': \'chalk\', \'F4\': \'blueprint\', \'F5\': \'retro\', \'F6\': \'cyber\' };\n            if (themes[e.key]) {\n                document.body.className = themes[e.key];\n                window.pywebview.api.log_action(\'switch_theme_\' + themes[e.key]);\n            }\n        });\n    </script>\n</body>\n</html>\n'

@service_metadata(name='ChalkboardWeb', version='2.0.1', description='Integrated HTML5/CSS3 Digital Signage Engine', tags=['ui', 'webview', 'obs'], capabilities=['ui:gui'], side_effects=['ui:update'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['webview'])
class ChalkBoardMS(BaseService):

    def __init__(self):
        super().__init__('ChalkboardWeb')
        self._window = None
        self.state = {'text': 'ON AIR', 'theme': 'neon'}

    def loaded(self):
        """Called by JS when the page is ready."""
        print('Frontend handshake complete.')
        return self.state

    def log_action(self, action_name):
        """Called by JS when user interacts."""
        print(f'Webview Event: {action_name}')

    @service_endpoint(inputs={'text': 'str', 'theme': 'str'}, outputs={}, description='Updates the embedded HTML via JS injection.', tags=['ui', 'display'])
    def update_sign(self, text: str, theme: str='neon'):
        """Updates the embedded HTML via JS injection."""
        self.state['text'] = text
        self.state['theme'] = theme
        if self._window:
            sanitized_text = json.dumps(text)
            self._window.evaluate_js(f"updateDisplay({sanitized_text}, '{theme}')")

    @service_endpoint(inputs={'effect': 'str'}, outputs={}, description="Triggers CSS animations like 'shake'.", tags=['ui', 'animation'])
    def trigger_effect(self, effect: str):
        """Triggers CSS animations like 'shake'."""
        if self._window:
            self._window.evaluate_js(f"triggerEffect('{effect}')")
if __name__ == '__main__':
    api = ChalkBoardMS()
    print(f'Service Ready: {api}')
    window = webview.create_window('OBS Signboard v2', html=HTML_CONTENT, js_api=api, width=1000, height=700, background_color='#000000')
    api._window = window
    webview.start(debug=True)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ChunkingRouterMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ChunkingRouterMS
ENTRY_POINT: _ChunkingRouterMS.py
INTERNAL_DEPENDENCIES: _PythonChunkerMS, base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import re
from typing import Any, Dict, List, Optional
from microservice_std_lib import service_metadata, service_endpoint
from base_service import BaseService
try:
    from _PythonChunkerMS import PythonChunkerMS, CodeChunk
except ImportError:

    class CodeChunk:

        def __init__(self, name, type, content, start_line, end_line):
            self.name = name
            self.type = type
            self.content = content
            self.start_line = start_line
            self.end_line = end_line

        def __repr__(self):
            return f'<CodeChunk {self.name}>'

    class PythonChunkerMS:

        def chunk(self, text):
            return [CodeChunk('mock', 'text', text, 0, 0)]

@service_metadata(name='ChunkingRouterMS', version='1.1.0', description='The Dispatcher: Routes files to specialized chunkers based on extension (AST for Python, Recursive for Prose).', tags=['orchestration', 'chunking', 'nlp'], capabilities=['routing', 'text-processing'], side_effects=[], internal_dependencies=['_PythonChunkerMS', 'base_service', 'microservice_std_lib'], external_dependencies=[])
class ChunkingRouterMS(BaseService):
    """
    The Editor: A 'Recursive' text splitter.
    It respects the natural structure of text (Paragraphs -> Sentences -> Words)
    rather than just hacking it apart by character count.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('ChunkingRouterMS')
        self.config = config or {}
        self.python_specialist = PythonChunkerMS()
        self.separators = ['\n\n', '\n', '(?<=[.?!])\\s+', ' ', '']

    @service_endpoint(inputs={'text': 'str', 'filename': 'str', 'max_size': 'int', 'overlap': 'int'}, outputs={'chunks': 'list'}, description='Routes text to the appropriate specialist. Returns a list of CodeChunk objects or raw strings.', tags=['routing', 'chunking'])
    def chunk_file(self, text: str, filename: str, max_size: int=1000, overlap: int=100) -> List[Any]:
        """
        Extension-aware router.
        """
        if filename.endswith('.py'):
            return self.python_specialist.chunk(text)
        raw_chunks = self._recursive_split(text, self.separators, max_size, overlap)
        return [CodeChunk(name=f'prose_chunk_{i}', type='text', content=c, start_line=0, end_line=0) for i, c in enumerate(raw_chunks)]

    def _recursive_split(self, text: str, separators: List[str], max_size: int, overlap: int) -> List[str]:
        final_chunks = []
        if len(text) <= max_size:
            return [text]
        if not separators:
            return self._hard_split(text, max_size, overlap)
        current_sep = separators[0]
        next_separators = separators[1:]
        if len(current_sep) > 1 and '(' in current_sep:
            splits = re.split(current_sep, text)
        else:
            splits = text.split(current_sep)
        current_doc = []
        current_length = 0
        for split in splits:
            if not split:
                continue
            if len(split) > max_size:
                if current_doc:
                    final_chunks.append(current_sep.join(current_doc))
                    current_doc = []
                    current_length = 0
                sub_chunks = self._recursive_split(split, next_separators, max_size, overlap)
                final_chunks.extend(sub_chunks)
                continue
            if current_length + len(split) + len(current_sep) > max_size:
                doc_text = current_sep.join(current_doc)
                final_chunks.append(doc_text)
                current_doc = [split]
                current_length = len(split)
            else:
                current_doc.append(split)
                current_length += len(split) + len(current_sep)
        if current_doc:
            final_chunks.append(current_sep.join(current_doc))
        return final_chunks

    def _hard_split(self, text: str, chunk_size: int, overlap: int) -> List[str]:
        """Last resort: naive character sliding window."""
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunks.append(text[start:end])
            start += chunk_size - overlap
        return chunks
if __name__ == '__main__':
    chunker = ChunkingRouterMS()
    print(f'Service ready: {chunker}')
    doc = '\n    # Intro to AI\n    Artificial Intelligence is great.\n    It helps us code.\n    \n    ## How it works\n    1. Ingestion: Reading data.\n    2. Processing: Thinking about data.\n    This is a very long paragraph that effectively serves as a stress test for the sentence splitter.\n    It should hopefully not break in the middle of a thought! We want to keep sentences whole.\n    '
    print('--- Testing Smart Chunking (Max 60 chars) ---')
    chunks = chunker.chunk_file(doc, 'test.md', max_size=60, overlap=0)
    for i, c in enumerate(chunks):
        print(f'[{i}] {repr(c)}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CodeChunkerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeChunkerMS
ENTRY_POINT: _CodeChunkerMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import re
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional
from microservice_std_lib import service_metadata, service_endpoint, BaseService

@service_metadata(name='CodeChunker', version='1.0.0', description='Splits code into semantic blocks (Classes, Functions) using indentation and regex heuristics.', tags=['parsing', 'chunking', 'code'], capabilities=['filesystem:read'], side_effects=['filesystem:read'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=[])
class CodeChunkerMS(BaseService):
    """
    The Surgeon (Pure Python Edition): Splits code into semantic blocks
    (Classes, Functions) using indentation and regex heuristics.
    
    Advantages: Zero dependencies. Works on any machine.
    Disadvantages: Slightly less precise than Tree-Sitter for messy code.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('CodeChunker')
        self.config = config or {}
        self.def_pattern = re.compile('^(\\s*)(?:async\\s+)?(?:class|def|function|func|var|const)\\s+([a-zA-Z0-9_]+)', re.MULTILINE)

    @service_endpoint(inputs={'file_path': 'str', 'max_chars': 'int'}, outputs={'chunks': 'List[Dict]'}, description='Reads a file and breaks it into logical blocks based on indentation.', tags=['parsing', 'chunking'], side_effects=['filesystem:read'])
    def chunk_file(self, file_path: str, max_chars: int=1500) -> List[Dict[str, Any]]:
        """
        Reads a file and breaks it into logical blocks based on indentation.
        """
        path = Path(file_path)
        try:
            code = path.read_text(encoding='utf-8', errors='ignore')
        except Exception as e:
            print(f'Error reading {file_path}: {e}')
            return []
        return self._chunk_by_indentation(code, max_chars)

    def _chunk_by_indentation(self, code: str, max_chars: int) -> List[Dict]:
        lines = code.splitlines()
        chunks = []
        current_chunk_lines = []
        current_start_line = 0
        current_indent = 0
        in_block = False
        for i, line in enumerate(lines):
            stripped = line.strip()
            if not stripped and (not in_block):
                continue
            indent_match = re.match('^(\\s*)', line)
            indent_level = len(indent_match.group(1)) if indent_match else 0
            match = self.def_pattern.match(line)
            is_def = match is not None and indent_level <= 4
            if is_def and current_chunk_lines:
                self._finalize_chunk(chunks, current_chunk_lines, current_start_line, max_chars)
                current_chunk_lines = []
                current_start_line = i + 1
                in_block = True
                current_indent = indent_level
            if in_block and stripped and (indent_level <= current_indent) and (not is_def):
                if not stripped.startswith('}'):
                    self._finalize_chunk(chunks, current_chunk_lines, current_start_line, max_chars)
                    current_chunk_lines = []
                    current_start_line = i + 1
                    in_block = False
            current_chunk_lines.append(line)
        if current_chunk_lines:
            self._finalize_chunk(chunks, current_chunk_lines, current_start_line, max_chars)
        return chunks

    def _finalize_chunk(self, chunks, lines, start_line, max_chars):
        """Recursively splits huge chunks if they exceed max_chars."""
        full_text = '\n'.join(lines)
        if not full_text.strip():
            return
        if len(full_text) > max_chars:
            self._split_large_block(chunks, lines, start_line, max_chars)
        else:
            chunks.append({'type': 'block', 'text': full_text, 'start_line': start_line, 'end_line': start_line + len(lines)})

    def _split_large_block(self, chunks, lines, start_line, max_chars):
        """Force split a large block while keeping line boundaries."""
        current_sub = []
        current_len = 0
        sub_start = start_line
        for i, line in enumerate(lines):
            if current_len + len(line) > max_chars:
                if current_sub:
                    chunks.append({'type': 'fragment', 'text': '\n'.join(current_sub), 'start_line': sub_start, 'end_line': sub_start + len(current_sub)})
                current_sub = []
                current_len = 0
                sub_start = start_line + i
            current_sub.append(line)
            current_len += len(line)
        if current_sub:
            chunks.append({'type': 'fragment', 'text': '\n'.join(current_sub), 'start_line': sub_start, 'end_line': sub_start + len(current_sub)})
if __name__ == '__main__':
    chunker = CodeChunkerMS()
    print(f'Service ready: {chunker}')
    py_code = '\nimport os\n\ndef small_helper():\n    return True\n\nclass DataProcessor:\n    def __init__(self):\n        self.data = []\n\n    def process(self, raw_input):\n        # This is a comment inside the function\n        if raw_input:\n            self.data.append(raw_input)\n        return True\n    '
    with tempfile.NamedTemporaryFile(suffix='.py', mode='w+', delete=False) as tmp:
        tmp.write(py_code)
        tmp_path = tmp.name
    try:
        print(f'--- Chunking {tmp_path} (Pure Python) ---')
        chunks = chunker.chunk_file(tmp_path)
        for i, c in enumerate(chunks):
            print(f"\n[Chunk {i}] Lines {c['start_line']}-{c['end_line']}")
            print(f"{'-' * 20}\n{c['text'].strip()}\n{'-' * 20}")
    finally:
        os.remove(tmp_path)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CodeFormatterMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeFormatterMS
ENTRY_POINT: _CodeFormatterMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import re
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('CodeFormatter')

class WhitespaceEngine:
    """
    Parses code into a granular map of (Indent + Content + Trailing).
    Can Normalize structure and generate 'Hunk' patches.
    """

    def __init__(self):
        self.raw_lines = []
        self.nodes = []
        self.normalized_text = ''
        self.patch_data = {'hunks': []}

    def load_source(self, text):
        self.raw_lines = text.splitlines()
        self.nodes = []
        indent_stack = [0]
        last_line_was_block_starter = False
        for i, line in enumerate(self.raw_lines):
            match = re.match('^([ \\t]*)(.*?)([ \\t]*)$', line)
            if not match:
                self.nodes.append({'id': i, 'indent': '', 'content': line, 'depth': 0, 'is_empty': True})
                continue
            indent, content, trailing = match.groups()
            is_empty = len(content) == 0
            current_width = 0
            for char in indent:
                current_width += 4 if char == '\t' else 1
            if is_empty:
                depth = len(indent_stack) - 1
            else:
                if current_width > indent_stack[-1]:
                    if last_line_was_block_starter:
                        indent_stack.append(current_width)
                    else:
                        pass
                while len(indent_stack) > 1 and current_width < indent_stack[-1]:
                    indent_stack.pop()
                depth = len(indent_stack) - 1
                clean_content = content.split('#')[0].strip()
                last_line_was_block_starter = clean_content.endswith(':')
            self.nodes.append({'id': i, 'raw_indent': indent, 'depth': depth, 'content': content, 'trailing': trailing, 'is_empty': is_empty})

    def normalize(self, use_tabs=False, space_count=4):
        """Reconstructs the code with strict indentation rules."""
        char = '\t' if use_tabs else ' ' * space_count
        clean_lines = []
        for node in self.nodes:
            if node['is_empty']:
                clean_lines.append('')
            else:
                new_indent = char * node['depth']
                clean_lines.append(f"{new_indent}{node['content']}")
        self.normalized_text = '\n'.join(clean_lines)
        return self.normalized_text

    def generate_patch(self):
        """Compares Raw vs Normalized and generates JSON Schema Hunks."""
        clean_lines = self.normalized_text.splitlines()
        if not clean_lines:
            return {'hunks': []}
        hunks = []
        current_hunk = None
        for i, (raw, clean) in enumerate(zip(self.raw_lines, clean_lines)):
            if raw != clean:
                if current_hunk is None:
                    current_hunk = {'start_line': i, 'raw_block': [raw], 'clean_block': [clean]}
                elif i == current_hunk['start_line'] + len(current_hunk['raw_block']):
                    current_hunk['raw_block'].append(raw)
                    current_hunk['clean_block'].append(clean)
                else:
                    self._finalize_hunk(hunks, current_hunk)
                    current_hunk = {'start_line': i, 'raw_block': [raw], 'clean_block': [clean]}
            elif current_hunk:
                self._finalize_hunk(hunks, current_hunk)
                current_hunk = None
        if current_hunk:
            self._finalize_hunk(hunks, current_hunk)
        self.patch_data = {'hunks': hunks}
        return self.patch_data

    def _finalize_hunk(self, hunks_list, hunk_data):
        search_txt = '\n'.join(hunk_data['raw_block'])
        replace_txt = '\n'.join(hunk_data['clean_block'])
        schema_hunk = {'description': f"Normalize indentation (Lines {hunk_data['start_line']}-{hunk_data['start_line'] + len(hunk_data['raw_block'])})", 'search_block': search_txt, 'replace_block': replace_txt}
        hunks_list.append(schema_hunk)

@service_metadata(name='CodeFormatter', version='1.0.0', description='The Architect: Intelligent whitespace normalization and structural repair engine.', tags=['formatting', 'code', 'utility'], capabilities=['compute', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class CodeFormatterMS:
    """
    The Architect.
    Uses the WhitespaceEngine to enforce strict indentation rules, 
    fixing 'staircase' formatting and mixed tabs/spaces.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'use_tabs': 'bool', 'spaces': 'int'}, outputs={'normalized': 'str', 'patch': 'Dict'}, description='Takes raw code and returns the normalized version plus a JSON patch of changes.', tags=['formatting', 'compute'], side_effects=[])
    def normalize_code(self, content: str, use_tabs: bool=False, spaces: int=4) -> Dict[str, Any]:
        """
        Pure logic endpoint: Takes string, returns string + patch.
        Does not touch the filesystem.
        """
        engine = WhitespaceEngine()
        engine.load_source(content)
        normalized = engine.normalize(use_tabs=use_tabs, space_count=spaces)
        patch = engine.generate_patch()
        return {'normalized': normalized, 'patch': patch}

    @service_endpoint(inputs={'file_path': 'str', 'use_tabs': 'bool', 'spaces': 'int'}, outputs={'status': 'str', 'changes': 'int'}, description='Reads a file, normalizes it, and overwrites it if changes are needed.', tags=['formatting', 'filesystem'], side_effects=['filesystem:read', 'filesystem:write'])
    def format_file(self, file_path: str, use_tabs: bool=False, spaces: int=4) -> Dict[str, Any]:
        """
        Filesystem endpoint: In-place repair of a file.
        """
        path = Path(file_path).resolve()
        if not path.exists():
            return {'status': 'error', 'message': 'File not found'}
        try:
            content = path.read_text(encoding='utf-8')
            engine = WhitespaceEngine()
            engine.load_source(content)
            normalized = engine.normalize(use_tabs=use_tabs, space_count=spaces)
            patch = engine.generate_patch()
            changes = len(patch['hunks'])
            if changes > 0:
                path.write_text(normalized, encoding='utf-8')
                logger.info(f'Formatted {path.name}: {changes} hunks applied.')
                return {'status': 'modified', 'changes': changes}
            else:
                return {'status': 'clean', 'changes': 0}
        except Exception as e:
            logger.error(f'Formatting failed for {path}: {e}')
            return {'status': 'error', 'message': str(e)}
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    svc = CodeFormatterMS()
    print('Service ready:', svc)
    broken_code = '\ndef hello():\n  print("Indented with 2 spaces")\n      print("Suddenly 6 spaces!")\n    '
    print('\n--- Processing Broken Code ---')
    result = svc.normalize_code(broken_code, spaces=4)
    print(f"Hunks Detected: {len(result['patch']['hunks'])}")
    print('\n--- Normalized Output ---')
    print(result['normalized'])

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CodeGrapherMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeGrapherMS
ENTRY_POINT: _CodeGrapherMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import ast
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional
from microservice_std_lib import service_metadata, service_endpoint, BaseService

class SurgicalVisitor(ast.NodeVisitor):
    """
    Extracts function definitions, calls, and class structures from AST.
    """

    def __init__(self, file_path: str):
        self.file_path = file_path
        self.symbols = []

    def visit_FunctionDef(self, node):
        self._handle_func(node, 'function')

    def visit_AsyncFunctionDef(self, node):
        self._handle_func(node, 'async_function')

    def visit_ClassDef(self, node):
        class_id = f'{self.file_path}::{node.name}'
        self.symbols.append({'id': class_id, 'file': self.file_path, 'name': node.name, 'type': 'class', 'line': node.lineno, 'calls': []})
        self.generic_visit(node)

    def _handle_func(self, node, type_name):
        calls = []
        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Name):
                    calls.append(child.func.id)
                elif isinstance(child.func, ast.Attribute):
                    calls.append(child.func.attr)
        unique_calls = list(set(calls))
        node_id = f'{self.file_path}::{node.name}'
        self.symbols.append({'id': node_id, 'file': self.file_path, 'name': node.name, 'type': type_name, 'line': node.lineno, 'calls': unique_calls})

@service_metadata(name='CodeGrapher', version='1.0.0', description='Parses Python code to extract symbols (nodes) and call relationships (edges).', tags=['parsing', 'graph', 'analysis'], capabilities=['filesystem:read'], side_effects=['filesystem:read'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=[])
class CodeGrapherMS(BaseService):
    """
    The Cartographer of Logic: Parses Python code to extract high-level 
    symbols (classes, functions) and maps their 'Call' relationships.
    
    Output: A graph structure (Nodes + Edges) suitable for visualization 
    or dependency analysis.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('CodeGrapher')
        self.config = config or {}
        self.nodes = []
        self.edges = []

    @service_endpoint(inputs={'root_path': 'str'}, outputs={'graph_data': 'Dict[str, Any]'}, description='Recursively scans a directory for .py files and builds the graph.', tags=['parsing', 'graph'], side_effects=['filesystem:read'])
    def scan_directory(self, root_path: str) -> Dict[str, Any]:
        """
        Recursively scans a directory for .py files and builds the graph.
        """
        root = Path(root_path).resolve()
        self.nodes = []
        self.edges = []
        if not root.exists():
            return {'error': f'Path {root} does not exist'}
        for path in root.rglob('*.py'):
            try:
                if any((p.startswith('.') for p in path.parts)) or 'venv' in path.parts:
                    continue
                with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                    source = f.read()
                rel_path = str(path.relative_to(root)).replace('\\', '/')
                file_symbols = self._parse_source(source, rel_path)
                self.nodes.extend(file_symbols)
            except Exception as e:
                print(f'Failed to parse {path.name}: {e}')
        self._build_edges()
        return {'root': str(root), 'node_count': len(self.nodes), 'edge_count': len(self.edges), 'nodes': self.nodes, 'edges': self.edges}

    def _parse_source(self, source: str, file_path: str) -> List[Dict]:
        """
        Uses Python's AST to extract surgical symbol info.
        """
        try:
            tree = ast.parse(source)
        except SyntaxError:
            return []
        visitor = SurgicalVisitor(file_path)
        visitor.visit(tree)
        return visitor.symbols

    def _build_edges(self):
        """
        Resolves 'calls' strings into explicit graph edges.
        """
        name_map = {n['name']: n['id'] for n in self.nodes}
        for node in self.nodes:
            source_id = node['id']
            calls = node.get('calls', [])
            for target_name in calls:
                if target_name in name_map:
                    target_id = name_map[target_name]
                    if source_id != target_id:
                        self.edges.append({'source': source_id, 'target': target_id, 'type': 'calls'})
if __name__ == '__main__':
    target_dir = sys.argv[1] if len(sys.argv) > 1 else '.'
    print(f'Mapping Logic in: {target_dir}')
    grapher = CodeGrapherMS()
    print(f'Service Ready: {grapher}')
    graph_data = grapher.scan_directory(target_dir)
    print(f'\n--- Scan Complete ---')
    print(f"Nodes Found: {graph_data.get('node_count', 0)}")
    print(f"Edges Built: {graph_data.get('edge_count', 0)}")
    out_file = 'code_graph_dump.json'
    with open(out_file, 'w') as f:
        json.dump(graph_data, f, indent=2)
    print(f'Graph saved to {out_file}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CodeJanitorMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeJanitorMS
ENTRY_POINT: _CodeJanitorMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import re
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('CodeJanitor')
RENAME_MAP = {'__AppShellMS': '_TkinterAppShellMS', '_AppShellMS': '_TkinterAppShellMS', '__ThemeManagerMS': '_TkinterThemeManagerMS', '_ThemeManagerMS': '_TkinterThemeManagerMS', '__SmartExplorerMS': '_TkinterSmartExplorerMS', '_SmartExplorerMS': '_TkinterSmartExplorerMS', '__UniButtonMS': '_TkinterUniButtonMS', '_UniButtonMS': '_TkinterUniButtonMS'}

@service_metadata(name='CodeJanitor', version='2.2.0', description='Fast version: Skips backup, high verbosity.', tags=['maintenance'], capabilities=['filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class CodeJanitorMS:

    def __init__(self):
        self.root = Path('.').resolve()

    def enforce_standards(self, dry_run: bool=True):
        print(f"--- üßπ JANITOR STARTED in {('DRY RUN' if dry_run else 'LIVE')} MODE ---")
        files = list(self.root.glob('*.py'))
        print(f'Found {len(files)} Python files to scan.\n')
        generic_import = re.compile('(from|import)\\s+__([A-Z])')
        generic_string = re.compile('["\\\']__([A-Z]\\w+MS)["\\\']')
        entry_point = re.compile('ENTRY_POINT:\\s*__([A-Z]\\w+MS\\.py)')
        for file_path in files:
            if file_path.name == '_CodeJanitorMS.py':
                continue
            try:
                original = file_path.read_text(encoding='utf-8')
                new = original
                new = entry_point.sub('ENTRY_POINT: _\\1', new)
                for old_name, new_name in RENAME_MAP.items():
                    pattern = re.compile(f'\\b{old_name}\\b')
                    if pattern.search(new):
                        new = pattern.sub(new_name, new)
                new = generic_import.sub('\\1 _\\2', new)
                new = generic_string.sub('"_\\1"', new)
                if new != original:
                    print(f'üõ†Ô∏è  PATCHING: {file_path.name}')
                    if not dry_run:
                        file_path.write_text(new, encoding='utf-8')
                else:
                    pass
            except Exception as e:
                print(f'‚ùå ERROR {file_path.name}: {e}')
        print('\n--- üèÅ JANITOR FINISHED ---')
if __name__ == '__main__':
    janitor = CodeJanitorMS()
    janitor.enforce_standards(dry_run=False)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CodeJanitorMS_OG.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CodeJanitorMS
ENTRY_POINT: _CodeJanitorMS.py
DEPENDENCIES: None
"""

import os
import re
import shutil
import datetime
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional

from microservice_std_lib import service_metadata, service_endpoint

# ==============================================================================
# CONFIGURATION
# ==============================================================================
logger = logging.getLogger("CodeJanitor")

# Files to ignore during mass operations
IGNORE_PATTERNS = {
    r"^\.",                # Hidden files
    r"^__pycache__",       # Python cache
    r"^venv",              # Virtual env
    r".*\.git.*",          # Git
    r".*\.db$",            # Databases
    r"_CodeJanitorMS\.py"  # Don't let the janitor scrub himself while running
}

# ==============================================================================
# MICROSERVICE CLASS
# ==============================================================================

@service_metadata(
    name="CodeJanitor",
    version="1.0.0",
    description="Automated maintenance service: Enforces file naming conventions, patches imports, and manages backups.",
    tags=["maintenance", "refactoring", "utility"],
    capabilities=["filesystem:write", "filesystem:read"]
)
class CodeJanitorMS:
    """
    The Custodian: Keeps the microservice ecosystem clean and standardized.
    Can rename files, patch source code, and create emergency backups.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.root = Path(self.config.get("root_path", ".")).resolve()

    @service_endpoint(
        inputs={"backup_name": "str"},
        outputs={"archive_path": "str"},
        description="Creates a timestamped ZIP archive of the entire project.",
        tags=["maintenance", "backup"],
        side_effects=["filesystem:write"]
    )
    def create_snapshot(self, backup_name: str = "auto_backup") -> str:
        """Creates a safety snapshot of the codebase."""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_name = f"{backup_name}_{timestamp}"
        
        # Create a _backups folder if it doesn't exist
        backup_dir = self.root / "_backups"
        backup_dir.mkdir(exist_ok=True)
        
        output_path = backup_dir / archive_name
        
        # We use shutil.make_archive
        # Note: We exclude _backups to prevent recursion if running from root
        def filter_func(path_str):
            p = Path(path_str)
            if "_backups" in p.parts: return False
            if "__pycache__" in p.parts: return False
            if ".git" in p.parts: return False
            return True

        # shutil doesn't have a native filter in older python versions, 
        # so we might just zip the root. 
        # For a robust implementation, we'd manually zip. 
        # Here we use the simple approach:
        
        archive = shutil.make_archive(
            str(output_path), 
            'zip', 
            root_dir=self.root
        )
        
        logger.info(f"‚úÖ Snapshot created: {archive}")
        return str(archive)

    @service_endpoint(
        inputs={"dry_run": "bool"},
        outputs={"renamed": "List[str]", "patched": "List[str]"},
        description="Scans the folder and enforces the '_NameMS.py' single-underscore convention.",
        tags=["maintenance", "refactoring"],
        side_effects=["filesystem:write"]
    )
    def enforce_standards(self, dry_run: bool = True) -> Dict[str, List[str]]:
        """
        The Migration Logic.
        1. Renames __Name.py -> _Name.py
        2. Patches imports (from _Name import) -> (from _Name import)
        """
        renamed_files = []
        patched_files = []
        
        files = [f for f in self.root.glob("*.py")]
        
        # Regex setup
        import_pattern = re.compile(r'(from|import)\s+__([A-Z])')
        string_pattern = re.compile(r'["\']__([A-Z]\w+MS)["\']')

        # 1. Patch Content First
        for file_path in files:
            if file_path.name == "_CodeJanitorMS.py": continue
            
            try:
                original_content = file_path.read_text(encoding="utf-8")
                new_content = original_content
                
                # Fix imports: "from _Auth" -> "from _Auth"
                new_content = import_pattern.sub(r'\1 _\2', new_content)
                # Fix strings: "_AuthMS" -> "_AuthMS"
                new_content = string_pattern.sub(r'"_\1"', new_content)
                
                # Special fix for Registry logic if it exists
                if "ServiceRegistry" in file_path.name:
                    new_content = new_content.replace('item.name.startswith("__")', 'item.name.startswith("_")')

                if new_content != original_content:
                    patched_files.append(file_path.name)
                    if not dry_run:
                        file_path.write_text(new_content, encoding="utf-8")
                        
            except Exception as e:
                logger.error(f"Failed to read {file_path}: {e}")

        # 2. Rename Files
        for file_path in files:
            name = file_path.name
            if name.startswith("__") and len(name) > 2 and name[2].isupper():
                new_name = "_" + name[2:]
                renamed_files.append(f"{name} -> {new_name}")
                
                if not dry_run:
                    try:
                        file_path.rename(self.root / new_name)
                    except OSError as e:
                        logger.error(f"Rename failed for {name}: {e}")

        status = "[DRY RUN] " if dry_run else "[LIVE] "
        logger.info(f"{status}Standards Enforcement Complete.")
        return {
            "renamed": renamed_files,
            "patched": patched_files
        }

    @service_endpoint(
        inputs={"find_pattern": "str", "replace_pattern": "str", "dry_run": "bool"},
        outputs={"affected_files": "List[str]"},
        description="Performs a regex Find & Replace across all Python files in the directory.",
        tags=["refactoring", "utility"],
        side_effects=["filesystem:write"]
    )
    def global_replace(self, find_pattern: str, replace_pattern: str, dry_run: bool = True) -> List[str]:
        """
        Global Search & Replace. 
        Useful if you rename a dependency or change a config key everywhere.
        """
        affected = []
        regex = re.compile(find_pattern)
        
        for file_path in self.root.glob("*.py"):
            if file_path.name == "_CodeJanitorMS.py": continue
            
            try:
                content = file_path.read_text(encoding="utf-8")
                if regex.search(content):
                    affected.append(file_path.name)
                    if not dry_run:
                        new_content = regex.sub(replace_pattern, content)
                        file_path.write_text(new_content, encoding="utf-8")
            except Exception:
                pass
                
        return affected

# --- Independent Test Block ---
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # We run in Dry Run mode by default to be safe
    janitor = CodeJanitorMS()
    print("Service ready:", janitor)
    
    print("\n--- Running Standards Check (Dry Run) ---")
    report = janitor.enforce_standards(dry_run=True)
    
    print(f"Files to Rename: {len(report['renamed'])}")
    for f in report['renamed']: print(f"  {f}")
    
    print(f"Files to Patch:  {len(report['patched'])}")
    for f in report['patched']: print(f"  {f}")

    # Uncomment to actually create a backup
    # janitor.create_snapshot("pre_migration_backup")
--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_CognitiveMemoryMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _CognitiveMemoryMS
ENTRY_POINT: _CognitiveMemoryMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: pydantic
"""
import importlib.util
import sys
REQUIRED = ['pydantic']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print(f"MISSING DEPENDENCIES: {' '.join(MISSING)}")
    print('Please run: pip install pydantic')
import datetime
import json
import logging
import uuid
import os
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional
from pydantic import BaseModel, Field
from microservice_std_lib import service_metadata, service_endpoint, BaseService
DEFAULT_MEMORY_FILE = Path('working_memory.jsonl')
FLUSH_THRESHOLD = 5
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('CognitiveMem')

class MemoryEntry(BaseModel):
    """Atomic unit of memory."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime.datetime = Field(default_factory=datetime.datetime.utcnow)
    role: str
    content: str
    metadata: Dict[str, Any] = Field(default_factory=dict)

@service_metadata(name='CognitiveMemory', version='1.0.0', description='Manages Short-Term (Working) Memory and orchestrates flushing to Long-Term Memory.', tags=['memory', 'history', 'context'], capabilities=['filesystem:read', 'filesystem:write'], side_effects=['filesystem:write'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['pydantic'])
class CognitiveMemoryMS(BaseService):
    """
    The Hippocampus: Manages Short-Term (Working) Memory and orchestrates 
    flushing to Long-Term Memory (Vector Store).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('CognitiveMemory')
        self.config = config or {}
        self.file_path = Path(self.config.get('persistence_path', DEFAULT_MEMORY_FILE))
        self.summarizer = self.config.get('summarizer_func')
        self.ingestor = self.config.get('long_term_ingest_func')
        self.working_memory: List[MemoryEntry] = []
        self._load_working_memory()

    @service_endpoint(inputs={'role': 'str', 'content': 'str', 'metadata': 'Dict'}, outputs={'entry': 'MemoryEntry'}, description='Adds an item to working memory and persists it.', tags=['memory', 'write'], side_effects=['filesystem:write'])
    def add_entry(self, role: str, content: str, metadata: Dict=None) -> MemoryEntry:
        """Adds an item to working memory and persists it."""
        entry = MemoryEntry(role=role, content=content, metadata=metadata or {})
        self.working_memory.append(entry)
        self._append_to_file(entry)
        log.info(f'Added memory: [{role}] {content[:30]}...')
        return entry

    @service_endpoint(inputs={'limit': 'int'}, outputs={'context': 'str'}, description='Returns the most recent conversation history formatted for an LLM.', tags=['memory', 'read', 'llm'], side_effects=['filesystem:read'])
    def get_context(self, limit: int=10) -> str:
        """
        Returns the most recent conversation history formatted for an LLM.
        """
        recent = self.working_memory[-limit:]
        return '\n'.join([f'{e.role.upper()}: {e.content}' for e in recent])

    def get_full_history(self) -> List[Dict]:
        """Returns the raw list of memory objects."""
        return [e.dict() for e in self.working_memory]

    @service_endpoint(inputs={}, outputs={}, description='Signals that a turn is complete; checks if memory flush is needed.', tags=['memory', 'maintenance'], side_effects=['filesystem:write'])
    def commit_turn(self):
        """
        Signal that a "Turn" (User + AI response) is complete.
        Checks if memory is full and triggers a flush if needed.
        """
        if len(self.working_memory) >= FLUSH_THRESHOLD:
            self._flush_to_long_term()

    def _flush_to_long_term(self):
        """
        Compresses working memory into a summary and moves it to Long-Term storage.
        """
        if not self.summarizer or not self.ingestor:
            log.warning('Flush triggered but Summarizer/Ingestor not configured. Skipping.')
            return
        log.info('üåÄ Flushing Working Memory to Long-Term Storage...')
        full_text = '\n'.join([f'{e.role}: {e.content}' for e in self.working_memory])
        try:
            summary = self.summarizer(full_text)
            log.info(f'Summary generated: {summary[:50]}...')
        except Exception as e:
            log.error(f'Summarization failed: {e}')
            return
        try:
            meta = {'source': 'cognitive_memory_flush', 'date': datetime.datetime.utcnow().isoformat(), 'original_entry_count': len(self.working_memory)}
            self.ingestor(summary, meta)
            log.info('‚úÖ Saved to Long-Term Memory.')
        except Exception as e:
            log.error(f'Ingestion failed: {e}')
            return
        self.working_memory.clear()
        self._rotate_log_file()

    def _load_working_memory(self):
        """Rehydrates memory from the JSONL file."""
        if not self.file_path.exists():
            return
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        self.working_memory.append(MemoryEntry.parse_raw(line))
            log.info(f'Loaded {len(self.working_memory)} items from {self.file_path}')
        except Exception as e:
            log.error(f'Corrupt memory file: {e}')

    def _append_to_file(self, entry: MemoryEntry):
        """Appends a single entry to the JSONL log."""
        with open(self.file_path, 'a', encoding='utf-8') as f:
            f.write(entry.json() + '\n')

    def _rotate_log_file(self):
        """Renames the current log to an archive timestamp."""
        if self.file_path.exists():
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            archive_name = self.file_path.with_name(f'memory_archive_{timestamp}.jsonl')
            self.file_path.rename(archive_name)
            log.info(f'Rotated memory log to {archive_name}')
if __name__ == '__main__':

    def mock_summarizer(text):
        return f'SUMMARY OF {len(text)} CHARS: The user and AI discussed AI architecture.'

    def mock_ingest(text, metadata):
        print(f"\n[VectorDB] Indexing: '{text}'\n[VectorDB] Meta: {metadata}")
    print('--- Initializing Cognitive Memory ---')
    mem = CognitiveMemoryMS({'summarizer_func': mock_summarizer, 'long_term_ingest_func': mock_ingest})
    print(f'Service ready: {mem}')
    print('\n--- Simulating Conversation ---')
    mem.add_entry('user', 'Hello, who are you?')
    mem.add_entry('assistant', 'I am a Cognitive Agent.')
    mem.add_entry('user', 'What is your memory capacity?')
    mem.add_entry('assistant', 'I have a tiered memory system.')
    mem.add_entry('user', 'That sounds complex.')
    print(f'\nCurrent Context:\n{mem.get_context()}')
    print('\n--- Triggering Memory Flush ---')
    mem.commit_turn()
    print(f'\nWorking Memory after flush: {len(mem.working_memory)} items')
    if Path('working_memory.jsonl').exists():
        os.remove('working_memory.jsonl')
    for p in Path('.').glob('memory_archive_*.jsonl'):
        os.remove(p)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ContentExtractorMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ContentExtractorMS
ENTRY_POINT: _ContentExtractorMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: beautifulsoup4, bs4, pypdf
"""
import io
import re
import time
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='ContentExtractorMS', version='1.0.0', description='The Decoder: A specialist service for extracting clean text from complex formats like PDF and HTML.', tags=['utility', 'extraction', 'nlp'], capabilities=['pdf-to-text', 'html-cleaning'], side_effects=['filesystem:read'], internal_dependencies=['microservice_std_lib'], external_dependencies=['beautifulsoup4', 'bs4', 'pypdf'])
class ContentExtractorMS:
    """
    The Decoder.
    A standalone utility microservice that separates the concern of 
    document parsing from ingestion logic.
    """

    def __init__(self):
        self.start_time = time.time()
        self._pdf_ready = False
        try:
            from pypdf import PdfReader
            self._pdf_ready = True
        except ImportError:
            pass
        self._html_ready = False
        try:
            from bs4 import BeautifulSoup
            self._html_ready = True
        except ImportError:
            pass

    @service_endpoint(inputs={}, outputs={'status': 'str', 'pdf_support': 'bool', 'html_support': 'bool'}, description='Health check to verify which extraction backends are installed.', tags=['diagnostic', 'health'])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status and library availability."""
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'pdf_support': self._pdf_ready, 'html_support': self._html_ready}

    @service_endpoint(inputs={'blob': 'bytes', 'mime_type': 'str'}, outputs={'text': 'str'}, description='Unified entry point for text extraction. Routes to the correct parser based on mime_type.', tags=['processing', 'extraction'])
    def extract_text(self, blob: bytes, mime_type: str) -> str:
        """
        Main routing logic for extraction. 
         logic is internalized here.
        """
        if 'pdf' in mime_type.lower():
            return self._extract_pdf(blob)
        elif 'html' in mime_type.lower():
            try:
                html_content = blob.decode('utf-8', errors='ignore')
                return self._extract_html(html_content)
            except:
                return ''
        return ''

    def _extract_pdf(self, file_bytes: bytes) -> str:
        """Extracts text from a PDF blob using pypdf. [cite: 96-97]"""
        if not self._pdf_ready:
            return ''
        from pypdf import PdfReader
        text_content = []
        try:
            stream = io.BytesIO(file_bytes)
            reader = PdfReader(stream)
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text_content.append(extracted)
            return '\n'.join(text_content)
        except Exception as e:
            return f'PDF Extraction Error: {e}'

    def _extract_html(self, html_content: str) -> str:
        """Cleans HTML to raw text using BeautifulSoup. [cite: 98-99]"""
        if not self._html_ready:
            return self._strip_tags_regex(html_content)
        from bs4 import BeautifulSoup
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            for script in soup(['script', 'style', 'meta', 'noscript']):
                script.decompose()
            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split('  '))
            return '\n'.join((chunk for chunk in chunks if chunk))
        except Exception:
            return self._strip_tags_regex(html_content)

    def _strip_tags_regex(self, html: str) -> str:
        """Fallback if BS4 is missing. [cite: 100]"""
        clean = re.compile('<.*?>')
        return re.sub(clean, '', html)
if __name__ == '__main__':
    svc = ContentExtractorMS()
    print('Service ready:', svc._service_info['name'])
    print('Health:', svc.get_health())

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ContextAggregatorMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ContextAggregatorMS
ENTRY_POINT: _ContextAggregatorMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import fnmatch
import datetime
import logging
from pathlib import Path
from typing import Set, Optional, Dict, Any
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_BINARY_EXTENSIONS = {'.tar.gz', '.gz', '.zip', '.rar', '.7z', '.bz2', '.xz', '.tgz', '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.webp', '.tif', '.tiff', '.mp3', '.wav', '.ogg', '.flac', '.mp4', '.mkv', '.avi', '.mov', '.webm', '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.exe', '.dll', '.so', '.db', '.sqlite', '.mdb', '.pyc', '.pyo', '.class', '.jar', '.wasm'}
DEFAULT_IGNORE_DIRS = {'node_modules', '.git', '__pycache__', '.venv', '.env', 'dist', 'build', 'coverage', '.idea', '.vscode'}
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('ContextAggregator')

@service_metadata(name='ContextAggregator', version='1.0.0', description='Flattens a project folder into a single readable text file.', tags=['filesystem', 'context', 'compilation'], capabilities=['filesystem:read', 'filesystem:write'], side_effects=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class ContextAggregatorMS:
    """
    The Context Builder: Flattens a project folder into a single readable text file.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        max_file_size_mb = self.config.get('max_file_size_mb', 1)
        self.max_file_size_bytes = max_file_size_mb * 1024 * 1024

    @service_endpoint(inputs={'root_path': 'str', 'output_file': 'str', 'extra_exclusions': 'Set[str]', 'use_default_exclusions': 'bool'}, outputs={'file_count': 'int'}, description='Aggregates project files into a single text dump.', tags=['filesystem', 'dump'], side_effects=['filesystem:read', 'filesystem:write'])
    def aggregate(self, root_path: str, output_file: str, extra_exclusions: Optional[Set[str]]=None, use_default_exclusions: bool=True) -> int:
        project_root = Path(root_path).resolve()
        out_path = Path(output_file).resolve()
        exclusions = set()
        if use_default_exclusions:
            exclusions.update(DEFAULT_IGNORE_DIRS)
        if extra_exclusions:
            exclusions.update(extra_exclusions)
        binary_exts = DEFAULT_BINARY_EXTENSIONS.copy()
        file_count = 0
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        try:
            with open(out_path, 'w', encoding='utf-8') as out_f:
                out_f.write(f"File Dump from Project: {project_root.name}\nGenerated: {timestamp}\n{'=' * 60}\n\n")
                for root, dirs, files in os.walk(project_root):
                    dirs[:] = [d for d in dirs if d not in exclusions]
                    for filename in files:
                        if self._should_exclude(filename, exclusions):
                            continue
                        file_path = Path(root) / filename
                        if file_path.resolve() == out_path:
                            continue
                        if self._is_safe_to_dump(file_path, binary_exts):
                            self._write_file_content(out_f, file_path, project_root)
                            file_count += 1
        except IOError as e:
            log.error(f'Error writing dump: {e}')
        return file_count

    def _should_exclude(self, filename: str, exclusions: Set[str]) -> bool:
        return any((fnmatch.fnmatch(filename, pattern) for pattern in exclusions))

    def _is_safe_to_dump(self, file_path: Path, binary_exts: Set[str]) -> bool:
        if ''.join(file_path.suffixes).lower() in binary_exts:
            return False
        try:
            if file_path.stat().st_size > self.max_file_size_bytes:
                return False
            with open(file_path, 'rb') as f:
                if b'\x00' in f.read(1024):
                    return False
        except (IOError, OSError):
            return False
        return True

    def _write_file_content(self, out_f, file_path: Path, project_root: Path):
        relative_path = file_path.relative_to(project_root)
        header = f"\n{'-' * 20} FILE: {relative_path} {'-' * 20}\n"
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as in_f:
                out_f.write(header + in_f.read() + f"\n{'-' * 60}\n")
        except Exception as e:
            out_f.write(f'\n[Error reading file: {e}]\n')
if __name__ == '__main__':
    svc = ContextAggregatorMS()
    print('Service ready:', svc)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ContextPackerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ContextPackerMS
ENTRY_POINT: _ContextPackerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_EXCLUDES = {'.git', '__pycache__', '.idea', '.vscode', 'node_modules', 'venv', '.venv', 'dist', 'build', '.DS_Store', 'file-dump.txt'}
logger = logging.getLogger('ContextPacker')

@service_metadata(name='ContextPacker', version='1.0.0', description='Flattens a directory of source code into a single text file (useful for LLM context stuffing).', tags=['filesystem', 'export', 'utility'], capabilities=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class ContextPackerMS:
    """
    The Packer: Walks a directory and dumps all text-readable files 
    into a single monolithic text file with delimiters.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'root_path': 'str', 'output_filename': 'str', 'additional_excludes': 'Set[str]'}, outputs={'output_path': 'str', 'file_count': 'int'}, description='Packs directory contents into a single text file.', tags=['export', 'dump'], side_effects=['filesystem:read', 'filesystem:write'])
    def pack_directory(self, root_path: str, output_filename: str='context_dump.txt', additional_excludes: Optional[Set[str]]=None) -> Dict[str, Any]:
        """
        Walks the directory and writes file contents to the output file.
        """
        root = Path(root_path).resolve()
        output_file = root / output_filename
        excludes = DEFAULT_EXCLUDES.copy()
        if additional_excludes:
            excludes.update(additional_excludes)
        excludes.add(output_filename)
        count = 0
        logger.info(f'Packing context from {root} into {output_filename}...')
        try:
            with open(output_file, 'w', encoding='utf-8') as out_f:
                out_f.write(f'CONTEXT PACKER DUMP\n')
                out_f.write(f'SOURCE: {root}\n')
                out_f.write('=' * 60 + '\n\n')
                for current_dir, dirs, files in os.walk(root):
                    dirs[:] = [d for d in dirs if d not in excludes and (not d.startswith('.'))]
                    for file in files:
                        if file in excludes or file.startswith('.'):
                            continue
                        file_path = Path(current_dir) / file
                        self._append_file(file_path, root, out_f)
                        count += 1
            return {'output_path': str(output_file), 'file_count': count}
        except Exception as e:
            logger.error(f'Packing failed: {e}')
            raise

    def _append_file(self, file_path: Path, root: Path, out_f):
        """Helper to append a single file's content to the dump."""
        rel_path = file_path.relative_to(root)
        try:
            content = file_path.read_text(encoding='utf-8')
            out_f.write(f'==================================================\n')
            out_f.write(f'FILE: {rel_path}\n')
            out_f.write(f'==================================================\n')
            out_f.write(content + '\n\n')
        except UnicodeDecodeError:
            out_f.write(f'==================================================\n')
            out_f.write(f'FILE: {rel_path} [SKIPPED - BINARY]\n')
            out_f.write(f'==================================================\n\n')
        except Exception as e:
            logger.warning(f'Could not read {rel_path}: {e}')
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    packer = ContextPackerMS()
    print('Service ready:', packer)
    print('\n--- Packing Current Directory ---')
    result = packer.pack_directory('.', 'test_dump.txt')
    print(f"Packed {result['file_count']} files to: {result['output_path']}")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_DiffEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _DiffEngineMS
ENTRY_POINT: _DiffEngineMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import sqlite3
import difflib
import datetime
import uuid
import logging
from pathlib import Path
from typing import Optional, Dict, List, Tuple, Any
from microservice_std_lib import service_metadata, service_endpoint
DB_PATH = Path(__file__).parent / 'diff_engine.db'
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('DiffEngine')

@service_metadata(name='DiffEngineMS', version='1.0.0', description='Implements hybrid versioning (Head + Diff History) for file content.', tags=['version-control', 'diff', 'db'], capabilities=['db:sqlite', 'filesystem:write'], side_effects=['db:read', 'db:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class DiffEngineMS:
    """
    The Timekeeper: Implements a 'Hybrid' versioning architecture.
    1. HEAD: Stores full current content for fast read access (UI/RAG).
    2. HISTORY: Stores diff deltas using difflib for audit trails.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.db_path = Path(self.config.get('db_path', DB_PATH))
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            conn.execute('\n                CREATE TABLE IF NOT EXISTS files (\n                    id TEXT PRIMARY KEY,\n                    path TEXT UNIQUE NOT NULL,\n                    content TEXT,\n                    last_updated TIMESTAMP\n                )\n            ')
            conn.execute("\n                CREATE TABLE IF NOT EXISTS diff_log (\n                    id TEXT PRIMARY KEY,\n                    file_id TEXT NOT NULL,\n                    timestamp TIMESTAMP,\n                    change_type TEXT,  -- 'CREATE', 'EDIT', 'DELETE'\n                    diff_blob TEXT,    -- The text output of difflib\n                    author TEXT,\n                    FOREIGN KEY(file_id) REFERENCES files(id)\n                )\n            ")

    @service_endpoint(inputs={'path': 'str', 'new_content': 'str', 'author': 'str'}, outputs={'status': 'str', 'file_id': 'str'}, description='Updates a file, creating a diff history entry and updating the head state.', tags=['version-control', 'write'], side_effects=['db:write'])
    def update_file(self, path: str, new_content: str, author: str='agent') -> Dict[str, Any]:
        """
        The Atomic Update Operation:
        1. Checks current state.
        2. Calculates Diff.
        3. Writes Diff to History.
        4. Updates Head to New Content.
        """
        path = str(Path(path).as_posix())
        now = datetime.datetime.utcnow()
        with self._get_conn() as conn:
            row = conn.execute('SELECT id, content FROM files WHERE path = ?', (path,)).fetchone()
            if not row:
                file_id = str(uuid.uuid4())
                conn.execute('INSERT INTO files (id, path, content, last_updated) VALUES (?, ?, ?, ?)', (file_id, path, new_content, now))
                self._log_diff(conn, file_id, 'CREATE', '[New File Created]', author, now)
                log.info(f'Created new file: {path}')
                return {'status': 'created', 'file_id': file_id}
            file_id = row['id']
            old_content = row['content'] or ''
            old_lines = old_content.splitlines(keepends=True)
            new_lines = new_content.splitlines(keepends=True)
            diff_gen = difflib.unified_diff(old_lines, new_lines, fromfile=f'a/{path}', tofile=f'b/{path}', lineterm='')
            diff_text = ''.join(diff_gen)
            if not diff_text:
                return {'status': 'unchanged', 'file_id': file_id}
            self._log_diff(conn, file_id, 'EDIT', diff_text, author, now)
            conn.execute('UPDATE files SET content = ?, last_updated = ? WHERE id = ?', (new_content, now, file_id))
            log.info(f'Updated file: {path}')
            return {'status': 'updated', 'file_id': file_id, 'diff_size': len(diff_text)}

    def _log_diff(self, conn, file_id, change_type, diff_text, author, timestamp):
        diff_id = str(uuid.uuid4())
        conn.execute('INSERT INTO diff_log (id, file_id, timestamp, change_type, diff_blob, author) VALUES (?, ?, ?, ?, ?, ?)', (diff_id, file_id, timestamp, change_type, diff_text, author))

    @service_endpoint(inputs={'path': 'str'}, outputs={'content': 'Optional[str]'}, description='Fast retrieval of current content.', tags=['version-control', 'read'], side_effects=['db:read'])
    def get_head(self, path: str) -> Optional[str]:
        """Fast retrieval of current content."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT content FROM files WHERE path = ?', (path,)).fetchone()
            return row['content'] if row else None

    @service_endpoint(inputs={'path': 'str'}, outputs={'history': 'List[Dict]'}, description='Retrieves the full evolution history of a file.', tags=['version-control', 'read'], side_effects=['db:read'])
    def get_history(self, path: str) -> List[Dict]:
        """Retrieves the full evolution history of a file."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT id FROM files WHERE path = ?', (path,)).fetchone()
            if not row:
                return []
            rows = conn.execute('SELECT timestamp, change_type, diff_blob, author FROM diff_log WHERE file_id = ? ORDER BY timestamp DESC', (row['id'],)).fetchall()
            return [dict(r) for r in rows]
if __name__ == '__main__':
    import os
    if DB_PATH.exists():
        os.remove(DB_PATH)
    engine = DiffEngineMS()
    print('Service ready:', engine)
    print('--- 1. Creating File ---')
    engine.update_file('notes.txt', 'Todo List:\n1. Buy Milk\n')
    print('\n--- 2. Updating File (The Rising Edge) ---')
    new_text = 'Todo List:\n1. Buy Eggs\n2. Code Python\n'
    res = engine.update_file('notes.txt', new_text, author='Jacob')
    print(f"Update Result: {res['status']}")
    print('\n--- 3. Inspecting History ---')
    history = engine.get_history('notes.txt')
    for event in history:
        print(f"\n[{event['timestamp']}] {event['change_type']} by {event['author']}")
        print(f"Diff Preview:\n{event['diff_blob'].strip()}")
    print('\n--- 4. Inspecting Head (Cache) ---')
    print(engine.get_head('notes.txt'))
    if DB_PATH.exists():
        os.remove(DB_PATH)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_EnvironmentManagerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _EnvironmentManagerMS
ENTRY_POINT: _EnvironmentManagerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import sys
import subprocess
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('EnvManager')

@service_metadata(name='EnvironmentManager', version='1.0.0', description='Manages Python runtime resolution and process execution.', tags=['runtime', 'python', 'venv', 'process'], capabilities=['os:shell', 'os:process'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class EnvironmentManagerMS:
    """
    The Operator.
    Finds the right Python interpreter (System vs Venv) and launches processes.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'project_path': 'str', 'config_override': 'str'}, outputs={'interpreter': 'str', 'source': 'str'}, description='Determines the absolute path to the Python interpreter for a given project.', tags=['runtime', 'resolve'])
    def resolve_python(self, project_path: str, config_override: Optional[str]=None) -> Dict[str, str]:
        """
        Priority:
        1. Explicit config override
        2. Local .venv
        3. System default (py or sys.executable)
        """
        path = Path(project_path).resolve()
        if config_override:
            if os.path.sep in config_override or '/' in config_override:
                return {'interpreter': str((path / config_override).resolve()), 'source': 'explicit'}
            return {'interpreter': config_override, 'source': 'command'}
        win_venv = path / '.venv' / 'Scripts' / 'python.exe'
        if win_venv.exists():
            return {'interpreter': str(win_venv), 'source': 'venv'}
        nix_venv = path / '.venv' / 'bin' / 'python'
        if nix_venv.exists():
            return {'interpreter': str(nix_venv), 'source': 'venv'}
        if os.name == 'nt':
            return {'interpreter': 'py', 'source': 'system_launcher'}
        return {'interpreter': sys.executable, 'source': 'system_default'}

    @service_endpoint(inputs={'project_path': 'str', 'script_rel_path': 'str', 'env_vars': 'Dict'}, outputs={'pid': 'int'}, description='Launches a python script in a subprocess using the resolved environment.', tags=['runtime', 'execute'], side_effects=['os:process'])
    def launch_script(self, project_path: str, script_rel_path: str='src/app.py', env_vars: Dict[str, str]=None) -> int:
        root = Path(project_path).resolve()
        script = root / script_rel_path
        if not script.exists():
            raise FileNotFoundError(f'Script not found: {script}')
        python_info = self.resolve_python(str(root))
        cmd = [python_info['interpreter'], str(script)]
        proc_env = os.environ.copy()
        if env_vars:
            proc_env.update(env_vars)
        logger.info(f"Launching {cmd} in {root} via {python_info['source']}")
        if os.name == 'nt':
            proc = subprocess.Popen(cmd, cwd=str(root), env=proc_env, creationflags=subprocess.CREATE_NEW_CONSOLE)
        else:
            proc = subprocess.Popen(cmd, cwd=str(root), env=proc_env)
        return proc.pid
if __name__ == '__main__':
    mgr = EnvironmentManagerMS()
    print('Resolved Self:', mgr.resolve_python('.'))

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ExplorerWidgetMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ExplorerWidgetMS
ENTRY_POINT: _ExplorerWidgetMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: ttk
"""
import importlib.util, sys
REQUIRED = ['microservice-std-lib>=1.0.0']
MISSING = []
for lib in REQUIRED:
    clean_lib = lib.split('>=')[0].split('==')[0].split('>')[0].replace('-', '_')
    if importlib.util.find_spec(clean_lib) is None:
        if clean_lib == 'pywebview':
            clean_lib = 'webview'
        if importlib.util.find_spec(clean_lib) is None:
            MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _ExplorerWidgetMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
import os
import queue
import threading
from pathlib import Path
from typing import Any, Dict, List, Optional
import tkinter as tk
from tkinter import ttk
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_EXCLUDED_FOLDERS = {'node_modules', '.git', '__pycache__', '.venv', '.mypy_cache', '_logs', 'dist', 'build', '.vscode', '.idea', 'target', 'out', 'bin', 'obj', 'Debug', 'Release', 'logs'}

@service_metadata(name='ExplorerWidgetMS', version='1.0.0', description='A standalone file system tree viewer widget.', tags=['ui', 'filesystem', 'widget'], capabilities=['ui:gui', 'filesystem:read'], side_effects=['ui:update', 'ui:read', 'filesystem:read'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['ttk'])
class ExplorerWidgetMS(BaseService):
    """
    A standalone file system tree viewer.
    """
    GLYPH_CHECKED = '[X]'
    GLYPH_UNCHECKED = '[ ]'

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('ExplorerWidgetMS')
        self.config_data: Dict[str, Any] = config or {}
        parent = self.config_data.get('parent')
        self.root_path: Path = Path(self.config_data.get('root_path', '.')).resolve()
        self.use_defaults: bool = self.config_data.get('use_default_exclusions', True)
        self.gui_queue: queue.Queue = queue.Queue()
        self.folder_item_states: Dict[str, str] = {}
        self.state_lock = threading.RLock()
        self._setup_styles()
        self._build_ui()
        self.process_gui_queue()
        self.refresh_tree()

    def _setup_styles(self) -> None:
        style = ttk.Style()
        if 'clam' in style.theme_names():
            style.theme_use('clam')
        style.configure('Explorer.Treeview', background='#252526', foreground='lightgray', fieldbackground='#252526', borderwidth=0, font=('Consolas', 10))
        style.map('Explorer.Treeview', background=[('selected', '#007ACC')], foreground=[('selected', 'white')])

    def _build_ui(self) -> None:
        self.columnconfigure(0, weight=1)
        self.rowconfigure(0, weight=1)
        self.tree = ttk.Treeview(self, show='tree', columns=('size',), selectmode='none', style='Explorer.Treeview')
        self.tree.column('size', width=80, anchor='e')
        ysb = ttk.Scrollbar(self, orient='vertical', command=self.tree.yview)
        xsb = ttk.Scrollbar(self, orient='horizontal', command=self.tree.xview)
        self.tree.configure(yscrollcommand=ysb.set, xscrollcommand=xsb.set)
        self.tree.grid(row=0, column=0, sticky='nsew')
        ysb.grid(row=0, column=1, sticky='ns')
        xsb.grid(row=1, column=0, sticky='ew')
        self.tree.bind('<ButtonRelease-1>', self._on_click)

    @service_endpoint(inputs={}, outputs={}, description='Rescans the directory and refreshes the tree view.', tags=['ui', 'refresh'], side_effects=['filesystem:read', 'ui:update'])
    def refresh_tree(self) -> None:
        for item in self.tree.get_children():
            self.tree.delete(item)
        with self.state_lock:
            self.folder_item_states.clear()
            self.folder_item_states[str(self.root_path)] = 'checked'
        root_id = str(self.root_path)
        tree_data: List[Dict[str, Any]] = [{'parent': '', 'iid': root_id, 'text': f' {self.root_path.name} (Root)', 'open': True}]
        self._scan_recursive(self.root_path, root_id, tree_data)
        for item in tree_data:
            self.tree.insert(item['parent'], 'end', iid=item['iid'], text=item['text'], open=item.get('open', False))
            self.tree.set(item['iid'], 'size', '...')
        self._refresh_visuals(root_id)
        threading.Thread(target=self._calc_sizes_thread, args=(root_id,), daemon=True).start()

    def _scan_recursive(self, current_path: Path, parent_id: str, data_list: List[Dict[str, Any]]) -> None:
        try:
            items = sorted(current_path.iterdir(), key=lambda x: (not x.is_dir(), x.name.lower()))
            for item in items:
                if not item.is_dir():
                    continue
                path_str = str(item.resolve())
                state = 'checked'
                if self.use_defaults and item.name in DEFAULT_EXCLUDED_FOLDERS:
                    state = 'unchecked'
                with self.state_lock:
                    self.folder_item_states[path_str] = state
                data_list.append({'parent': parent_id, 'iid': path_str, 'text': f' {item.name}'})
                self._scan_recursive(item, path_str, data_list)
        except (PermissionError, OSError):
            pass

    def _on_click(self, event: tk.Event) -> None:
        item_id = self.tree.identify_row(event.y)
        if not item_id:
            return
        with self.state_lock:
            curr = self.folder_item_states.get(item_id, 'unchecked')
            self.folder_item_states[item_id] = 'checked' if curr == 'unchecked' else 'unchecked'
        self._refresh_visuals(str(self.root_path))

    def _refresh_visuals(self, start_node: str) -> None:

        def _update(node_id: str) -> None:
            if not self.tree.exists(node_id):
                return
            with self.state_lock:
                state = self.folder_item_states.get(node_id, 'unchecked')
            glyph = self.GLYPH_CHECKED if state == 'checked' else self.GLYPH_UNCHECKED
            name = Path(node_id).name
            if node_id == str(self.root_path):
                name += ' (Root)'
            self.tree.item(node_id, text=f'{glyph} {name}')
            for child in self.tree.get_children(node_id):
                _update(child)
        _update(start_node)

    def _calc_sizes_thread(self, root_id: str) -> None:
        """
        Background worker for calculating folder sizes.

        Currently a stub so that the thread exits cleanly without errors.
        You can later extend this to walk the filesystem and push
        size updates via self.gui_queue.
        """
        return

    @service_endpoint(inputs={}, outputs={'selected_paths': 'List[str]'}, description='Returns a list of currently checked folder paths.', tags=['ui', 'read'], side_effects=['ui:read'])
    def get_selected_paths(self) -> List[str]:
        selected: List[str] = []
        with self.state_lock:
            for path, state in self.folder_item_states.items():
                if state == 'checked':
                    selected.append(path)
        return selected

    def process_gui_queue(self) -> None:
        while not self.gui_queue.empty():
            try:
                callback = self.gui_queue.get_nowait()
            except queue.Empty:
                break
            else:
                try:
                    callback()
                except Exception:
                    pass
        self.after(100, self.process_gui_queue)
if __name__ == '__main__':
    root = tk.Tk()
    root.title('ExplorerWidgetMS Test Harness')
    widget = ExplorerWidgetMS({'parent': root, 'root_path': os.getcwd()})
    widget.pack(fill='both', expand=True)
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_FingerprintScannerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _FingerprintScannerMS
ENTRY_POINT: _FingerprintScannerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import hashlib
import os
import logging
from pathlib import Path
from typing import Any, Dict, List, Set, Optional, Tuple
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_IGNORE_DIRS = {'node_modules', '.git', '__pycache__', '.venv', 'venv', 'env', '.mypy_cache', '.pytest_cache', '.idea', '.vscode', 'dist', 'build', 'coverage', 'target', 'out', 'bin', 'obj', '_project_library', '_sandbox', '_logs'}
DEFAULT_IGNORE_FILES = {'.DS_Store', 'Thumbs.db', '*.log', '*.tmp', '*.lock'}
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger('Fingerprint')

@service_metadata(name='FingerprintScannerMS', version='1.0.0', description='Scans a directory tree and generates a deterministic SHA-256 fingerprint.', tags=['scanning', 'integrity', 'hashing'], capabilities=['filesystem:read'], side_effects=['filesystem:read'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class FingerprintScannerMS:
    """
    The Detective: Scans a directory tree and generates a deterministic
    'Fingerprint' (SHA-256 Merkle Root) representing its exact state.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'root_path': 'str'}, outputs={'state': 'Dict[str, Any]'}, description='Scans the project and returns a comprehensive state object (hashes + Merkle root).', tags=['scanning', 'read'], side_effects=['filesystem:read'])
    def scan_project(self, root_path: str) -> Dict[str, Any]:
        """
        Scans the project and returns a comprehensive state object.
        """
        root = Path(root_path).resolve()
        if not root.exists():
            raise FileNotFoundError(f'Path not found: {root}')
        file_map = {}
        for path in sorted(root.rglob('*')):
            if path.is_file():
                if self._should_ignore(path, root):
                    continue
                rel_path = str(path.relative_to(root)).replace('\\', '/')
                file_hash = self._hash_file(path)
                if file_hash:
                    file_map[rel_path] = file_hash
        sorted_hashes = [file_map[p] for p in sorted(file_map.keys())]
        combined_data = ''.join(sorted_hashes).encode('utf-8')
        project_fingerprint = hashlib.sha256(combined_data).hexdigest()
        log.info(f'Scanned {len(file_map)} files. Fingerprint: {project_fingerprint[:8]}...')
        return {'root': str(root), 'project_fingerprint': project_fingerprint, 'file_hashes': file_map, 'file_count': len(file_map)}

    def _should_ignore(self, path: Path, root: Path) -> bool:
        """Checks path against exclusion lists."""
        try:
            rel_parts = path.relative_to(root).parts
            for part in rel_parts[:-1]:
                if part in DEFAULT_IGNORE_DIRS:
                    return True
            import fnmatch
            name = path.name
            if name in DEFAULT_IGNORE_FILES:
                return True
            if any((fnmatch.fnmatch(name, pat) for pat in DEFAULT_IGNORE_FILES)):
                return True
            return False
        except ValueError:
            return True

    def _hash_file(self, path: Path) -> Optional[str]:
        try:
            content = path.read_bytes()
            return hashlib.sha256(content).hexdigest()
        except (PermissionError, OSError):
            log.warning(f'Could not read/hash: {path}')
            return None
if __name__ == '__main__':
    import time
    test_dir = Path('test_fingerprint_proj')
    if test_dir.exists():
        import shutil
        shutil.rmtree(test_dir)
    test_dir.mkdir()
    (test_dir / 'main.py').write_text("print('hello')")
    scanner = FingerprintScannerMS()
    print('Service ready:', scanner)
    print('--- Scan 1 (Initial) ---')
    state_1 = scanner.scan_project(str(test_dir))
    print(f"Fingerprint 1: {state_1['project_fingerprint']}")
    if test_dir.exists():
        import shutil
        shutil.rmtree(test_dir)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_GitPilotMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _GitPilotMS
ENTRY_POINT: _GitPilotMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: git
"""
import os
import subprocess
import threading
import queue
import time
import tkinter as tk
from tkinter import ttk, messagebox, simpledialog
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple, Any, Callable, Dict
from microservice_std_lib import service_metadata, service_endpoint

def which(cmd: str) -> Optional[str]:
    for p in os.environ.get('PATH', '').split(os.pathsep):
        f = Path(p) / cmd
        if os.name == 'nt':
            for ext in ('.exe', '.cmd', '.bat'):
                if f.with_suffix(ext).exists():
                    return str(f.with_suffix(ext))
        if f.exists() and os.access(f, os.X_OK):
            return str(f)
    return None
USE_GH = which('gh') is not None

@dataclass
class GitStatusEntry:
    path: str
    index: str
    workdir: str

@dataclass
class GitStatus:
    repo_path: str
    branch: Optional[str]
    ahead: int
    behind: int
    entries: List[GitStatusEntry]

class GitCLI:
    """
    A robust wrapper around the git command line executable.
    """

    def __init__(self, repo_path: Path):
        self.root = self._resolve_repo_root(repo_path)

    def _run(self, args: List[str], *, cwd: Optional[Path]=None) -> Tuple[str, str]:
        cmd = ['git', *args]
        startupinfo = None
        if os.name == 'nt':
            startupinfo = subprocess.STARTUPINFO()
            startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        proc = subprocess.run(cmd, cwd=str(cwd or self.root), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8', startupinfo=startupinfo)
        if proc.returncode != 0:
            raise RuntimeError(proc.stderr.strip() or f"git {' '.join(args)} failed")
        return (proc.stdout, proc.stderr)

    @staticmethod
    def _resolve_repo_root(path: Path) -> Path:
        path = path.resolve()
        if (path / '.git').exists():
            return path
        p = path
        while True:
            if (p / '.git').exists():
                return p
            if p.parent == p:
                break
            p = p.parent
        return path

    def init(self) -> None:
        self._run(['init'])

    def status(self) -> GitStatus:
        try:
            out, _ = self._run(['rev-parse', '--abbrev-ref', 'HEAD'])
            branch = out.strip()
        except Exception:
            branch = None
        ahead = behind = 0
        try:
            out, _ = self._run(['rev-list', '--left-right', '--count', '@{upstream}...HEAD'])
            left, right = out.strip().split()
            behind, ahead = (int(left), int(right))
        except Exception:
            pass
        out, _ = self._run(['status', '--porcelain=v1'])
        entries = []
        for line in out.splitlines():
            if not line.strip():
                continue
            xy = line[:2]
            path = line[3:]
            index, work = (xy[0], xy[1])
            entries.append(GitStatusEntry(path=path, index=index, workdir=work))
        return GitStatus(str(self.root), branch, ahead, behind, entries)

    def stage(self, paths: List[str]) -> None:
        if paths:
            self._run(['add', '--'] + paths)

    def unstage(self, paths: List[str]) -> None:
        if paths:
            self._run(['reset', 'HEAD', '--'] + paths)

    def diff(self, file: Optional[str]=None) -> str:
        args = ['diff']
        if file:
            args += ['--', file]
        out, _ = self._run(args)
        return out

    def commit(self, message: str, author_name: str, author_email: str) -> str:
        env = os.environ.copy()
        if author_name:
            env['GIT_AUTHOR_NAME'] = author_name
            env['GIT_COMMITTER_NAME'] = author_name
        if author_email:
            env['GIT_AUTHOR_EMAIL'] = author_email
            env['GIT_COMMITTER_EMAIL'] = author_email
        proc = subprocess.run(['git', 'commit', '-m', message], cwd=str(self.root), capture_output=True, text=True, env=env)
        if proc.returncode != 0:
            raise RuntimeError(proc.stderr.strip() or proc.stdout.strip())
        out, _ = self._run(['rev-parse', 'HEAD'])
        return out.strip()

    def log(self, limit: int=100) -> List[Tuple[str, str, str, int]]:
        fmt = '%H%x1f%s%x1f%an%x1f%at'
        try:
            out, _ = self._run(['log', f'-n{limit}', f'--pretty=format:{fmt}'])
            items = []
            for line in out.splitlines():
                commit, summary, author, at = line.split('\x1f')
                items.append((commit, summary, author, int(at)))
            return items
        except Exception:
            return []

    def branches(self) -> List[Tuple[str, bool]]:
        try:
            out, _ = self._run(['branch'])
            res = []
            for line in out.splitlines():
                is_head = line.strip().startswith('*')
                name = line.replace('*', '', 1).strip()
                res.append((name, is_head))
            return res
        except Exception:
            return []

    def checkout(self, name: str, create: bool=False) -> None:
        if create:
            self._run(['checkout', '-B', name])
        else:
            self._run(['checkout', name])

    def push(self, remote: str='origin', branch: Optional[str]=None) -> str:
        args = ['push', remote]
        if branch:
            args.append(branch)
        out, _ = self._run(args)
        return out

    def pull(self, remote: str='origin', branch: Optional[str]=None) -> str:
        if branch:
            out, _ = self._run(['pull', remote, branch])
        else:
            out, _ = self._run(['pull', remote])
        return out

class Worker:

    def __init__(self, ui_callback):
        self.q = queue.Queue()
        self.ui_callback = ui_callback
        self.thread = threading.Thread(target=self._loop, daemon=True)
        self.thread.start()

    def submit(self, op: str, func, *args, **kwargs):
        self.q.put((op, func, args, kwargs))

    def _loop(self):
        while True:
            op, func, args, kwargs = self.q.get()
            try:
                result = (op, True, func(*args, **kwargs))
            except Exception as e:
                result = (op, False, e)
            finally:
                self.ui_callback(result)

@service_metadata(name='GitPilotMS', version='1.0.0', description='A Tkinter GUI panel for Git operations (Stage, Commit, Push, Pull).', tags=['ui', 'git', 'version-control', 'widget'], capabilities=['ui:gui', 'filesystem:read', 'filesystem:write', 'network:outbound'], side_effects=['filesystem:read', 'filesystem:write', 'network:outbound', 'ui:update'], internal_dependencies=['microservice_std_lib'], external_dependencies=['git'])
class GitPilotMS(ttk.Frame):

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        ttk.Frame.__init__(self, parent)
        initial_path = self.config.get('initial_path')
        self.repo_path = None
        self.git = None
        self.worker = Worker(self._on_worker_done)
        self._build_ui()
        if initial_path:
            self.set_repo(initial_path)

    @service_endpoint(inputs={'path': 'Path'}, outputs={}, description='Sets the active repository path and refreshes status.', tags=['git', 'config'], side_effects=['filesystem:read', 'ui:update'])
    def set_repo(self, path: Path):
        try:
            self.git = GitCLI(path)
            self.repo_path = self.git.root
            self.path_var.set(f'Repo: {self.repo_path}')
            self._refresh()
        except Exception as e:
            self.path_var.set(f'Error: {e}')

    def _build_ui(self):
        self.columnconfigure(0, weight=1)
        self.rowconfigure(1, weight=1)
        bar = ttk.Frame(self)
        bar.grid(row=0, column=0, sticky='ew')
        self.path_var = tk.StringVar(value='No Repo Selected')
        self.busy_var = tk.StringVar()
        ttk.Label(bar, textvariable=self.path_var).pack(side='left', padx=5)
        ttk.Label(bar, textvariable=self.busy_var, foreground='blue').pack(side='right', padx=5)
        self.nb = ttk.Notebook(self)
        self.nb.grid(row=1, column=0, sticky='nsew')
        self.tab_changes = self._build_changes_tab(self.nb)
        self.tab_log = self._build_log_tab(self.nb)
        self.nb.add(self.tab_changes, text='Changes')
        self.nb.add(self.tab_log, text='History')

    def _build_changes_tab(self, parent):
        frame = ttk.Frame(parent)
        paned = ttk.PanedWindow(frame, orient=tk.VERTICAL)
        paned.pack(fill='both', expand=True)
        top = ttk.Frame(paned)
        top.rowconfigure(1, weight=1)
        top.columnconfigure(0, weight=1)
        tb = ttk.Frame(top)
        tb.grid(row=0, column=0, sticky='ew')
        ttk.Button(tb, text='Refresh', command=self._refresh).pack(side='left')
        ttk.Button(tb, text='Stage', command=self._stage).pack(side='left')
        ttk.Button(tb, text='Unstage', command=self._unstage).pack(side='left')
        ttk.Button(tb, text='Diff', command=self._show_diff).pack(side='left')
        ttk.Button(tb, text='Push', command=self._push).pack(side='left', padx=10)
        ttk.Button(tb, text='Pull', command=self._pull).pack(side='left')
        self.tree = ttk.Treeview(top, columns=('path', 'idx', 'wd'), show='headings', selectmode='extended')
        self.tree.heading('path', text='Path')
        self.tree.heading('idx', text='Index')
        self.tree.heading('wd', text='Workdir')
        self.tree.column('path', width=400)
        self.tree.column('idx', width=50, anchor='center')
        self.tree.column('wd', width=50, anchor='center')
        self.tree.grid(row=1, column=0, sticky='nsew')
        paned.add(top, weight=3)
        bot = ttk.Frame(paned)
        bot.columnconfigure(1, weight=1)
        ttk.Label(bot, text='Message:').grid(row=0, column=0, sticky='nw')
        self.msg_text = tk.Text(bot, height=4)
        self.msg_text.grid(row=0, column=1, sticky='nsew')
        ttk.Button(bot, text='Commit', command=self._commit).grid(row=1, column=1, sticky='e', pady=5)
        paned.add(bot, weight=1)
        return frame

    def _build_log_tab(self, parent):
        frame = ttk.Frame(parent)
        self.log_tree = ttk.Treeview(frame, columns=('sha', 'msg', 'auth', 'time'), show='headings')
        self.log_tree.heading('sha', text='SHA')
        self.log_tree.heading('msg', text='Message')
        self.log_tree.heading('auth', text='Author')
        self.log_tree.heading('time', text='Time')
        self.log_tree.column('sha', width=80)
        self.log_tree.column('msg', width=400)
        self.log_tree.pack(fill='both', expand=True)
        return frame

    def _submit(self, label, func, *args):
        self.busy_var.set(f'{label}...')
        self.worker.submit(label, func, *args)

    def _on_worker_done(self, result):
        self.after(0, self._handle_result, result)

    def _handle_result(self, result):
        label, ok, data = result
        self.busy_var.set('')
        if not ok:
            messagebox.showerror('Error', str(data))
            return
        if label == 'refresh':
            status, logs = data
            self.tree.delete(*self.tree.get_children())
            for e in status.entries:
                self.tree.insert('', 'end', values=(e.path, e.index, e.workdir))
            self.log_tree.delete(*self.log_tree.get_children())
            for sha, msg, auth, ts in logs:
                t_str = time.strftime('%Y-%m-%d %H:%M', time.localtime(ts))
                self.log_tree.insert('', 'end', values=(sha[:7], msg, auth, t_str))
        if label == 'diff':
            top = tk.Toplevel(self)
            top.title('Diff')
            txt = tk.Text(top, font=('Consolas', 10))
            txt.pack(fill='both', expand=True)
            txt.insert('1.0', data)
        if label in ['stage', 'unstage', 'commit', 'push', 'pull']:
            self._refresh()

    def _refresh(self):
        if not self.git:
            return
        self._submit('refresh', lambda: (self.git.status(), self.git.log()))

    def _get_selection(self):
        return [self.tree.item(i)['values'][0] for i in self.tree.selection()]

    def _stage(self):
        paths = self._get_selection()
        if paths:
            self._submit('stage', self.git.stage, paths)

    def _unstage(self):
        paths = self._get_selection()
        if paths:
            self._submit('unstage', self.git.unstage, paths)

    def _commit(self):
        msg = self.msg_text.get('1.0', 'end').strip()
        if not msg:
            return
        self._submit('commit', self.git.commit, msg, 'GitPilot', 'pilot@local')
        self.msg_text.delete('1.0', 'end')

    def _push(self):
        self._submit('push', self.git.push)

    def _pull(self):
        self._submit('pull', self.git.pull)

    def _show_diff(self):
        sel = self._get_selection()
        file = sel[0] if sel else None
        self._submit('diff', self.git.diff, file)
if __name__ == '__main__':
    root = tk.Tk()
    root.title('Git Pilot Test')
    root.geometry('800x600')
    cwd = Path(os.getcwd())
    panel = GitPilotMS({'parent': root, 'initial_path': cwd})
    print('Service ready:', panel)
    panel.pack(fill='both', expand=True)
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_HeuristicSumMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _HeuristicSumMS
ENTRY_POINT: _HeuristicSumMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import re
from typing import Any, Dict, List, Optional
from microservice_std_lib import service_metadata, service_endpoint, BaseService
SIG_RE = re.compile('^\\s*(def|class|function|interface|struct|impl|func)\\s+([A-Za-z_][A-Za-z0-9_]*)')
MD_HDR_RE = re.compile('^\\s{0,3}(#{1,3})\\s+(.+)')
DOC_RE = re.compile('^\\s*("{3}|\\\'{3})(.*)', re.DOTALL)

@service_metadata(name='HeuristicSum', version='1.0.0', description='Generates quick summaries of code/text files using regex heuristics (No AI).', tags=['parsing', 'summary', 'heuristics'], capabilities=['compute'], side_effects=[], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=[])
class HeuristicSumMS(BaseService):
    """
    The Skimmer: Generates quick summaries of code/text files without AI.
    Scans for high-value lines (headers, signatures, docstrings) and concatenates them.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('HeuristicSum')
        self.config = config or {}

    @service_endpoint(inputs={'text': 'str', 'filename': 'str', 'max_chars': 'int'}, outputs={'summary': 'str'}, description='Generates a summary string from the provided text.', tags=['summary', 'parsing'])
    def summarize(self, text: str, filename: str='', max_chars: int=480) -> str:
        """
        Generates a summary string from the provided text.
        """
        lines = text.splitlines()
        picks = []
        for ln in lines[:20]:
            m = MD_HDR_RE.match(ln)
            if m:
                picks.append(f'Heading: {m.group(2).strip()}')
        for ln in lines[:40]:
            m = SIG_RE.match(ln)
            if m:
                picks.append(f'{m.group(1)} {m.group(2)}')
        if lines:
            joined = '\n'.join(lines[:80])
            m = DOC_RE.match(joined)
            if m:
                after = joined.splitlines()[1:3]
                if after:
                    clean_doc = ' '.join((s.strip() for s in after)).strip()
                    picks.append(f'Doc: {clean_doc}')
        if not picks:
            head = ' '.join((l.strip() for l in lines[:2] if l.strip()))
            if head:
                picks.append(head)
        if filename:
            picks.append(f'[{os.path.basename(filename)}]')
        seen = set()
        uniq = []
        for p in picks:
            if p and p not in seen:
                uniq.append(p)
                seen.add(p)
        summary = ' | '.join(uniq)
        if len(summary) > max_chars:
            summary = summary[:max_chars - 3] + '...'
        return summary.strip() if summary else '[No summary available]'
if __name__ == '__main__':
    skimmer = HeuristicSumMS()
    print(f'Service ready: {skimmer}')
    py_code = "\n    class DataProcessor:\n        '''\n        Handles the transformation of raw input data into structured formats.\n        '''\n        def process(self, data):\n            pass\n    "
    print(f"Python Summary: {skimmer.summarize(py_code, 'processor.py')}")
    md_text = '\n    # Project Roadmap\n    ## Phase 1\n    We begin with ingestion.\n    '
    print(f"Markdown Summary: {skimmer.summarize(md_text, 'README.md')}")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_IngestEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _IngestEngineMS
ENTRY_POINT: _IngestEngineMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: requests
"""
import importlib.util
import sys
REQUIRED = ['requests']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print(f"MISSING DEPENDENCIES: {' '.join(MISSING)}")
    print('Please run: pip install requests')
import json
import os
import re
import sqlite3
import time
from dataclasses import dataclass
from typing import Any, Dict, Generator, List, Optional
import requests
from microservice_std_lib import service_metadata, service_endpoint, BaseService
OLLAMA_API_URL = 'http://localhost:11434/api'

@dataclass
class IngestStatus:
    current_file: str
    progress_percent: float
    processed_files: int
    total_files: int
    log_message: str
    thought_frame: Optional[Dict] = None

class SynapseWeaver:
    """
    Parses source code to extract import dependencies.
    Used to generate the 'DEPENDS_ON' edges in the Knowledge Graph.
    """

    def __init__(self):
        self.py_pattern = re.compile('^\\s*(?:from|import)\\s+([\\w\\.]+)')
        self.js_pattern = re.compile('(?:import\\s+.*?from\\s+[\\\'"]|require\\([\\\'"])([\\.\\/\\w\\-_]+)[\\\'"]')

    def extract_dependencies(self, content: str, file_path: str) -> List[str]:
        dependencies = []
        ext = os.path.splitext(file_path)[1].lower()
        lines = content.split('\n')
        for line in lines:
            match = None
            if ext == '.py':
                match = self.py_pattern.match(line)
            elif ext in ['.js', '.ts', '.tsx', '.jsx']:
                match = self.js_pattern.search(line)
            if match:
                raw_dep = match.group(1)
                clean_dep = raw_dep.split('.')[-1].split('/')[-1]
                if clean_dep not in dependencies:
                    dependencies.append(clean_dep)
        return dependencies

@service_metadata(name='IngestEngine', version='1.0.0', description='Reads files, chunks text, fetches embeddings, and weaves graph edges.', tags=['ingest', 'rag', 'parsing', 'embedding'], capabilities=['filesystem:read', 'network:outbound', 'db:sqlite'], side_effects=['db:write', 'network:outbound'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['requests'])
class IngestEngineMS(BaseService):
    """
    The Heavy Lifter: Reads files, chunks text, fetches embeddings,
    populates the Graph Nodes, and weaves Graph Edges.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('IngestEngine')
        self.config = config or {}
        self.db_path = self.config.get('db_path', 'knowledge.db')
        self.stop_signal = False
        self.weaver = SynapseWeaver()
        self._init_db()

    def _init_db(self):
        """Ensures the target database has the required schema."""
        conn = sqlite3.connect(self.db_path)
        conn.execute('CREATE TABLE IF NOT EXISTS files (id INTEGER PRIMARY KEY, path TEXT, last_updated REAL)')
        conn.execute('CREATE TABLE IF NOT EXISTS chunks (id INTEGER PRIMARY KEY, file_id INT, chunk_index INT, content TEXT, embedding BLOB)')
        conn.execute('CREATE TABLE IF NOT EXISTS graph_nodes (id TEXT PRIMARY KEY, type TEXT, label TEXT, data_json TEXT)')
        conn.execute('CREATE TABLE IF NOT EXISTS graph_edges (source TEXT, target TEXT, weight REAL)')
        conn.close()

    def abort(self):
        self.stop_signal = True

    def check_ollama_connection(self) -> bool:
        try:
            requests.get(f'{OLLAMA_API_URL}/tags', timeout=2)
            return True
        except:
            return False

    def get_available_models(self) -> List[str]:
        try:
            res = requests.get(f'{OLLAMA_API_URL}/tags')
            if res.status_code == 200:
                data = res.json()
                return [m['name'] for m in data.get('models', [])]
        except:
            pass
        return []

    @service_endpoint(inputs={'file_paths': 'List[str]', 'model_name': 'str'}, outputs={'status': 'IngestStatus'}, description='Processes a list of files, ingesting them into the knowledge graph.', tags=['ingest', 'processing'], mode='generator', side_effects=['db:write', 'network:outbound'])
    def process_files(self, file_paths: List[str], model_name: str='none') -> Generator[IngestStatus, None, None]:
        total = len(file_paths)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('PRAGMA synchronous = OFF')
        cursor.execute('PRAGMA journal_mode = MEMORY')
        node_registry = {}
        file_contents = {}
        for idx, file_path in enumerate(file_paths):
            if self.stop_signal:
                yield IngestStatus(file_path, 0, idx, total, 'Ingestion Aborted.')
                break
            filename = os.path.basename(file_path)
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                file_contents[filename] = content
            except Exception as e:
                yield IngestStatus(file_path, idx / total * 100, idx, total, f'Error: {e}')
                continue
            try:
                cursor.execute('INSERT OR REPLACE INTO files (path, last_updated) VALUES (?, ?)', (file_path, time.time()))
                file_id = cursor.lastrowid
            except sqlite3.Error:
                continue
            cursor.execute('\n                INSERT OR REPLACE INTO graph_nodes (id, type, label, data_json)\n                VALUES (?, ?, ?, ?)\n            ', (filename, 'file', filename, json.dumps({'path': file_path})))
            node_registry[filename] = filename
            chunks = self._chunk_text(content)
            for i, chunk_text in enumerate(chunks):
                if self.stop_signal:
                    break
                embedding = None
                if model_name != 'none':
                    embedding = self._get_embedding(model_name, chunk_text)
                emb_blob = json.dumps(embedding).encode('utf-8') if embedding else None
                cursor.execute('\n                    INSERT INTO chunks (file_id, chunk_index, content, embedding)\n                    VALUES (?, ?, ?, ?)\n                ', (file_id, i, chunk_text, emb_blob))
                thought_frame = {'id': f'{file_id}_{i}', 'file': filename, 'chunk_index': i, 'content': chunk_text, 'vector_preview': embedding[:20] if embedding else [], 'concept_color': '#007ACC'}
                yield IngestStatus(current_file=filename, progress_percent=(idx + i / len(chunks)) / total * 100, processed_files=idx, total_files=total, log_message=f'Processing {filename}...', thought_frame=thought_frame)
            conn.commit()
        yield IngestStatus('Graph', 100, total, total, 'Weaving Knowledge Graph...')
        edge_count = 0
        for filename, content in file_contents.items():
            if self.stop_signal:
                break
            deps = self.weaver.extract_dependencies(content, filename)
            for dep in deps:
                target_id = None
                for potential_match in node_registry.keys():
                    if potential_match.startswith(dep + '.') or potential_match == dep:
                        target_id = potential_match
                        break
                if target_id and target_id != filename:
                    try:
                        cursor.execute('\n                            INSERT OR IGNORE INTO graph_edges (source, target, weight)\n                            VALUES (?, ?, 1.0)\n                        ', (filename, target_id))
                        edge_count += 1
                    except:
                        pass
        conn.commit()
        conn.close()
        yield IngestStatus(current_file='Complete', progress_percent=100, processed_files=total, total_files=total, log_message=f'Ingestion Complete. Created {edge_count} dependency edges.')

    def _chunk_text(self, text: str, chunk_size: int=1000, overlap: int=100) -> List[str]:
        if len(text) < chunk_size:
            return [text]
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunks.append(text[start:end])
            start += chunk_size - overlap
        return chunks

    def _get_embedding(self, model: str, text: str) -> Optional[List[float]]:
        try:
            res = requests.post(f'{OLLAMA_API_URL}/embeddings', json={'model': model, 'prompt': text}, timeout=30)
            if res.status_code == 200:
                return res.json().get('embedding')
        except:
            return None
if __name__ == '__main__':
    TEST_DB = 'test_ingest_v2.db'
    engine = IngestEngineMS({'db_path': TEST_DB})
    print(f'Service Ready: {engine}')
    target_file = '__IngestEngineMS.py'
    if not os.path.exists(target_file):
        with open(target_file, 'w') as f:
            f.write("import os\nimport json\nprint('Hello World')")
    print(f'Running Ingest on {target_file}...')
    files = [target_file]
    for status in engine.process_files(files, 'none'):
        print(f'[{status.progress_percent:.0f}%] {status.log_message}')
    conn = sqlite3.connect(TEST_DB)
    edges = conn.execute('SELECT * FROM graph_edges').fetchall()
    nodes = conn.execute('SELECT * FROM graph_nodes').fetchall()
    print(f'\nResult: {len(nodes)} Nodes, {len(edges)} Edges.')
    conn.close()
    if os.path.exists(TEST_DB):
        os.remove(TEST_DB)
    if os.path.exists(target_file) and 'Hello World' in open(target_file).read():
        os.remove(target_file)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_IntakeServiceMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _IntakeServiceMS
ENTRY_POINT: _IntakeServiceMS.py
INTERNAL_DEPENDENCIES: _CartridgeServiceMS, _ScannerMS, base_service, document_utils, microservice_std_lib
EXTERNAL_DEPENDENCIES: bs4, requests
"""
import os
import mimetypes
import requests
import fnmatch
import json
from pathlib import Path
from typing import Dict, Set, List, Any
from base_service import BaseService
from _CartridgeServiceMS import CartridgeServiceMS
from _ScannerMS import ScannerMS
import document_utils
from microservice_std_lib import service_metadata, service_endpoint
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

@service_metadata(name='IntakeServiceMS', version='1.2.0', description='The Vacuum: Handles two-phase ingestion by scanning sources and processing selected paths into the cartridge.', tags=['ingestion', 'scanner', 'vfs'], capabilities=['filesystem:read', 'web:crawl'], side_effects=['filesystem:read', 'cartridge:write'], internal_dependencies=['_CartridgeServiceMS', '_ScannerMS', 'base_service', 'document_utils', 'microservice_std_lib'], external_dependencies=['bs4', 'requests'])
class IntakeServiceMS(BaseService):
    """
    The Vacuum. 
    Now supports two-phase ingestion:
    1. Scan -> Build Tree (with .gitignore respect)
    2. Ingest -> Process selected paths
    """
    DEFAULT_IGNORE_DIRS = {'.git', '__pycache__', 'node_modules', 'venv', '.venv', 'env', '.env', '.idea', '.vscode', 'dist', 'build', 'target', 'bin', 'obj', '__cartridge__'}
    DEFAULT_IGNORE_EXTS = {'.pyc', '.pyd', '.exe', '.dll', '.so', '.db', '.sqlite', '.sqlite3', '.bin', '.iso', '.img', '.zip', '.tar', '.gz', '.7z', '.jpg', '.png'}

    def __init__(self, cartridge: CartridgeService):
        super().__init__('IntakeServiceMS')
        self.start_time = time.time()

    @service_endpoint(inputs={}, outputs={'status': 'str', 'uptime': 'float', 'cartridge_connected': 'bool'}, description='Standardized health check to verify service status and cartridge connectivity.', tags=['diagnostic', 'health'])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status of the IntakeServiceMS."""
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'cartridge_connected': self.cartridge is not None}
        self.cartridge = cartridge
        self.ignore_patterns: Set[str] = set()

    def ingest_source(self, source_path: str) -> Dict[str, int]:
        """Headless/CLI Entry point: Scans and Ingests in one go."""
        self.cartridge.initialize_manifest()
        self.cartridge.set_manifest('source_root', source_path)
        is_web = source_path.startswith('http')
        self.cartridge.set_manifest('source_type', 'web_root' if is_web else 'filesystem_dir')
        scanner = ScoutMS()
        tree_node = scanner.scan_directory(source_path, web_depth=1 if is_web else 0)
        if not tree_node:
            return {'error': 'Source not found'}
        files_to_ingest = scanner.flatten_tree(tree_node)
        self.cartridge.set_manifest('ingest_config', {'auto_flattened': True, 'count': len(files_to_ingest)})
        return self.ingest_selected(files_to_ingest, source_path)

    @service_endpoint(inputs={'root_path': 'str', 'web_depth': 'int'}, outputs={'tree': 'dict'}, description='Scans a local directory or URL to build a hierarchical tree structure of available files.', tags=['scan', 'discovery'])
    def scan_path(self, root_path: str, web_depth: int=0) -> Dict[str, Any]:
        """
        Unified Scanner Interface.
        Delegates to ScoutMS for both Web and Local FS to ensure consistent node structure.
        """
        scanner = ScannerMS()
        tree_root = scanner.scan_directory(root_path, web_depth=web_depth)
        if not tree_root:
            return None
        if not root_path.startswith('http'):
            saved_config = self._load_persistence(os.path.abspath(root_path))
            self._apply_persistence(tree_root, saved_config)
        return tree_root

    def _apply_persistence(self, node: Dict, saved_config: Dict):
        """Recursively applies checked state from saved config."""
        if 'rel_path' in node and node['rel_path'] in saved_config:
            node['checked'] = saved_config[node['rel_path']]
        elif 'children' in node:
            pass
        if 'children' in node:
            for child in node['children']:
                self._apply_persistence(child, saved_config)

    def _scan_recursive(self, current_path: str, root_path: str, saved_config: Dict) -> Dict:
        name = os.path.basename(current_path)
        is_dir = os.path.isdir(current_path)
        rel_path = os.path.relpath(current_path, root_path).replace('\\', '/')
        node = {'name': name, 'path': current_path, 'rel_path': rel_path, 'type': 'dir' if is_dir else 'file', 'children': [], 'checked': True}
        if saved_config and rel_path in saved_config:
            node['checked'] = saved_config[rel_path]
        elif self._is_ignored(name) or (not is_dir and self._is_binary_ext(name)):
            node['checked'] = False
        if is_dir:
            try:
                with os.scandir(current_path) as it:
                    entries = sorted(it, key=lambda e: (not e.is_dir(), e.name.lower()))
                    for entry in entries:
                        child = self._scan_recursive(entry.path, root_path, saved_config)
                        node['children'].append(child)
            except PermissionError:
                pass
        return node

    @service_endpoint(inputs={'file_list': 'list', 'root_path': 'str'}, outputs={'stats': 'dict'}, description='Processes a specific list of files into the cartridge storage, handling text extraction and VFS indexing.', tags=['ingest', 'write'], side_effects=['cartridge:write'])
    def ingest_selected(self, file_list: List[str], root_path: str) -> Dict[str, int]:
        """Ingests only the specific files passed in the list."""
        stats = {'added': 0, 'skipped': 0, 'errors': 0}
        for file_path in file_list:
            try:
                try:
                    vfs_path = os.path.relpath(file_path, root_path).replace('\\', '/')
                except ValueError:
                    vfs_path = os.path.basename(file_path)
                self._read_and_store(Path(file_path), vfs_path, 'filesystem', stats)
            except Exception as e:
                self.log_error(f'Error ingesting {file_path}: {e}')
                stats['errors'] += 1
        self._rebuild_directory_index()
        return stats

    def _rebuild_directory_index(self):
        """
        Scans 'files' table and populates 'directories' table.
        This creates the navigable VFS structure.
        """
        self.log_info('Rebuilding VFS Directory Index...')
        conn = self.cartridge._get_conn()
        try:
            rows = conn.execute('SELECT vfs_path FROM files').fetchall()
            seen_dirs = set()
            for r in rows:
                path = r[0]
                current = os.path.dirname(path).replace('\\', '/')
                while current and current != '.' and (current not in seen_dirs):
                    self.cartridge.ensure_directory(current)
                    seen_dirs.add(current)
                    current = os.path.dirname(current).replace('\\', '/')
        except Exception as e:
            self.log_error(f'Directory Index Error: {e}')
        finally:
            conn.close()

    def _load_persistence(self, root_path: str) -> Dict[str, bool]:
        """Loads config from DB Manifest (Portable) or fallback to local."""
        try:
            conn = self.cartridge._get_conn()
            row = conn.execute("SELECT value FROM manifest WHERE key='ingest_config'").fetchone()
            conn.close()
            if row:
                return json.loads(row[0])
        except:
            pass
        cfg_path = os.path.join(root_path, '.ragforge.json')
        if os.path.exists(cfg_path):
            try:
                with open(cfg_path, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_persistence(self, root_path: str, checked_map: Dict[str, bool]):
        """Saves user selections into the Cartridge Manifest (Portable)."""
        try:
            conn = self.cartridge._get_conn()
            conn.execute('INSERT OR REPLACE INTO manifest (key, value) VALUES (?, ?)', ('ingest_config', json.dumps(checked_map)))
            conn.commit()
            conn.close()
        except Exception as e:
            self.log_error(f'Failed to save persistence to DB: {e}')
        cfg_path = os.path.join(root_path, '.ragforge.json')
        try:
            with open(cfg_path, 'w') as f:
                json.dump(checked_map, f, indent=2)
        except:
            pass

    def _load_gitignore(self, root_path: str):
        gitignore_path = os.path.join(root_path, '.gitignore')
        self.ignore_patterns = self.DEFAULT_IGNORE_DIRS.copy()
        if os.path.exists(gitignore_path):
            try:
                with open(gitignore_path, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and (not line.startswith('#')):
                            if line.endswith('/'):
                                line = line[:-1]
                            self.ignore_patterns.add(line)
            except:
                pass

    def _is_ignored(self, name: str) -> bool:
        if name in self.ignore_patterns:
            return True
        for pattern in self.ignore_patterns:
            if fnmatch.fnmatch(name, pattern):
                return True
        return False

    def _is_binary_ext(self, name: str) -> bool:
        _, ext = os.path.splitext(name)
        return ext.lower() in self.DEFAULT_IGNORE_EXTS

    def _read_and_store(self, real_path: Path, vfs_path: str, origin_type: str, stats: Dict):
        mime_type, _ = mimetypes.guess_type(real_path)
        if not mime_type:
            mime_type = 'application/octet-stream'
        content = None
        blob = None
        try:
            with open(real_path, 'rb') as f:
                blob = f.read()
        except Exception as e:
            self.log_error(f'Read error {real_path}: {e}')
            stats['errors'] += 1
            return
        lower_path = str(real_path).lower()
        if lower_path.endswith('.pdf'):
            content = document_utils.extract_text_from_pdf(blob)
            if not content:
                mime_type = 'application/pdf'
        elif lower_path.endswith('.html') or lower_path.endswith('.htm'):
            try:
                raw_text = blob.decode('utf-8', errors='ignore')
                content = document_utils.extract_text_from_html(raw_text)
            except:
                pass
        else:
            try:
                content = blob.decode('utf-8')
            except UnicodeDecodeError:
                content = None
        success = self.cartridge.store_file(vfs_path, str(real_path), content=content, blob=blob, mime_type=mime_type, origin_type=origin_type)
        if success:
            stats['added'] += 1
        else:
            stats['errors'] += 1
        if __name__ == '__main__':
            from _CartridgeServiceMS import CartridgeService
            mock_cartridge = CartridgeService(':memory:')
            svc = IntakeServiceMS(mock_cartridge)
            print('Service ready:', svc._service_info['name'])

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_IsoProcessMS.py
--------------------------------------------------------------------------------
import multiprocessing as mp
import logging
import logging.handlers
import time
import queue
from typing import Any, Dict, Optional
from microservice_std_lib import service_metadata, service_endpoint

def _isolated_worker(result_queue: mp.Queue, log_queue: mp.Queue, payload: Any, config: Dict[str, Any]):
    """
    Entry point for the child process.
    Configures a logging handler to send records back to the parent.
    Note: Must remain top-level for multiprocessing pickling compatibility.
    """
    root = logging.getLogger()
    root.setLevel(logging.INFO)
    for h in root.handlers[:]:
        root.removeHandler(h)
    qh = logging.handlers.QueueHandler(log_queue)
    root.addHandler(qh)
    log = logging.getLogger('IsoWorker')
    try:
        log.info(f'Worker PID {mp.current_process().pid} started.')
        log.info('Loading heavy libraries (Torch/Transformers)...')
        time.sleep(0.2)
        model_name = config.get('model_name', 'default-model')
        log.info(f"Initializing model '{model_name}'...")
        for i in range(1, 4):
            time.sleep(0.3)
            log.info(f'Processing chunk {i}/3...')
        processed_data = f'Processed({payload}) via {model_name}'
        log.info('Work complete. Returning result.')
        result_queue.put({'success': True, 'data': processed_data})
    except Exception as e:
        log.exception('Critical failure in worker process.')
        result_queue.put({'success': False, 'error': str(e)})

@service_metadata(name='IsoProcess', version='1.0.0', description='Spawns isolated processes with real-time logging feedback.', tags=['process', 'isolation', 'safety'], capabilities=['process:spawn'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class IsoProcessMS:
    """
    The Safety Valve: Spawns isolated processes with real-time logging feedback.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.timeout = self.config.get('timeout_seconds', 60)
        self.log = logging.getLogger('IsoParent')
        if not self.log.handlers:
            logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(name)s] %(message)s', datefmt='%H:%M:%S')

    @service_endpoint(inputs={'payload': 'Any', 'config': 'Dict'}, outputs={'result': 'Any'}, description='Executes a payload in an isolated child process.', tags=['process', 'execution'], side_effects=['process:spawn'])
    def execute(self, payload: Any, config: Optional[Dict[str, Any]]=None) -> Any:
        config = config or {}
        ctx = mp.get_context('spawn')
        result_queue = ctx.Queue()
        log_queue = ctx.Queue()
        listener = logging.handlers.QueueListener(log_queue, *logging.getLogger().handlers)
        listener.start()
        process = ctx.Process(target=_isolated_worker, args=(result_queue, log_queue, payload, config))
        self.log.info('üöÄ Spawning isolated process...')
        process.start()
        try:
            result_packet = result_queue.get(timeout=self.timeout)
            process.join()
            if result_packet['success']:
                return result_packet['data']
            else:
                raise RuntimeError(f"Worker Error: {result_packet['error']}")
        except queue.Empty:
            self.log.error('‚è≥ Worker timed out! Terminating...')
            process.terminate()
            process.join()
            raise TimeoutError(f'Task exceeded {self.timeout}s limit.')
        finally:
            listener.stop()
if __name__ == '__main__':
    print('--- Testing IsoProcessMS with Live Logging ---')
    iso = IsoProcessMS({'timeout_seconds': 5})
    print('Service ready:', iso)
    try:
        result = iso.execute('Sensitive Data', {'model_name': 'DeepSeek-V3'})
        print(f'\n[Parent] Final Result: {result}')
    except Exception as e:
        print(f'\n[Parent] Failed: {e}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_LexicalSearchMS.py
--------------------------------------------------------------------------------
import sqlite3
import json
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='LexicalSearch', version='1.0.0', description='Lightweight BM25 keyword search using SQLite FTS5 (No AI required).', tags=['search', 'index', 'sqlite'], capabilities=['db:sqlite', 'filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class LexicalSearchMS:
    """
    The Librarian's Index: A lightweight, AI-free search engine.
    
    Uses SQLite's FTS5 extension to provide fast, ranked keyword search (BM25).
    Ideal for environments where installing PyTorch/Transformers is impossible
    or overkill.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        default_db = str(Path(__file__).parent / 'lexical_index.db')
        self.db_path = self.config.get('db_path', default_db)
        self._init_db()

    def _init_db(self):
        """
        Sets up the schema. 
        Uses Triggers to automatically keep the FTS index in sync with the main table.
        """
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        cur.execute('\n            CREATE TABLE IF NOT EXISTS documents (\n                id TEXT PRIMARY KEY,\n                content TEXT,\n                metadata TEXT  -- JSON blob for extra info (path, author, etc)\n            );\n        ')
        cur.execute("\n            CREATE VIRTUAL TABLE IF NOT EXISTS documents_fts USING fts5(\n                content,\n                content='documents',\n                content_rowid='rowid'  -- Internal SQLite mapping\n            );\n        ")
        cur.execute('\n            CREATE TRIGGER IF NOT EXISTS doc_ai AFTER INSERT ON documents BEGIN\n                INSERT INTO documents_fts(rowid, content) VALUES (new.rowid, new.content);\n            END;\n        ')
        cur.execute("\n            CREATE TRIGGER IF NOT EXISTS doc_ad AFTER DELETE ON documents BEGIN\n                INSERT INTO documents_fts(documents_fts, rowid, content) VALUES('delete', old.rowid, old.content);\n            END;\n        ")
        cur.execute("\n            CREATE TRIGGER IF NOT EXISTS doc_au AFTER UPDATE ON documents BEGIN\n                INSERT INTO documents_fts(documents_fts, rowid, content) VALUES('delete', old.rowid, old.content);\n                INSERT INTO documents_fts(rowid, content) VALUES (new.rowid, new.content);\n            END;\n        ")
        conn.commit()
        conn.close()

    @service_endpoint(inputs={'doc_id': 'str', 'text': 'str', 'metadata': 'Dict'}, outputs={}, description='Adds or updates a document in the FTS index.', tags=['search', 'write'], side_effects=['db:write'])
    def add_document(self, doc_id: str, text: str, metadata: Optional[Dict[str, Any]]=None):
        """
        Adds or updates a document in the index.
        """
        conn = sqlite3.connect(self.db_path)
        cur = conn.cursor()
        meta_json = json.dumps(metadata or {})
        cur.execute('\n            INSERT OR REPLACE INTO documents (id, content, metadata)\n            VALUES (?, ?, ?)\n        ', (doc_id, text, meta_json))
        conn.commit()
        conn.close()

    @service_endpoint(inputs={'query': 'str', 'top_k': 'int'}, outputs={'results': 'List[Dict]'}, description='Performs a BM25 ranked keyword search.', tags=['search', 'read'], side_effects=['db:read'])
    def search(self, query: str, top_k: int=20) -> List[Dict[str, Any]]:
        """
        Performs a BM25 Ranked Search.
        """
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        try:
            sql = "\n                SELECT \n                    d.id, \n                    d.content, \n                    d.metadata,\n                    snippet(documents_fts, 0, '<b>', '</b>', '...', 15) as preview,\n                    bm25(documents_fts) as score\n                FROM documents_fts \n                JOIN documents d ON d.rowid = documents_fts.rowid\n                WHERE documents_fts MATCH ? \n                ORDER BY score ASC\n                LIMIT ?\n            "
            safe_query = f'"{query}"'
            rows = cur.execute(sql, (safe_query, top_k)).fetchall()
            results = []
            for r in rows:
                results.append({'id': r['id'], 'score': round(r['score'], 4), 'preview': r['preview'], 'metadata': json.loads(r['metadata']), 'full_content': r['content']})
            return results
        except sqlite3.OperationalError as e:
            print(f'Search syntax error: {e}')
            return []
        finally:
            conn.close()
if __name__ == '__main__':
    import os
    db_name = 'test_lexical.db'
    engine = LexicalSearchMS({'db_path': db_name})
    print('Service ready:', engine)
    print('Ingesting test data...')
    engine.add_document('doc1', 'Python is a great language for data science.', {'category': 'coding'})
    engine.add_document('doc2', 'The snake python is a reptile found in jungles.', {'category': 'biology'})
    engine.add_document('doc3', 'Data science involves python, pandas, and SQL.', {'category': 'coding'})
    query = 'python data'
    print(f"\nSearching for: '{query}'")
    hits = engine.search(query)
    for hit in hits:
        print(f"[{hit['score']:.4f}] {hit['id']} ({hit['metadata']['category']})")
        print(f"   Preview: {hit['preview']}")
    if os.path.exists(db_name):
        os.remove(db_name)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_LibrarianMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _LibrarianMS
ENTRY_POINT: _LibrarianMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: requests
"""
import importlib.util
if importlib.util.find_spec('requests') is None:
    print('! MISSING DEPENDENCY: pip install requests')
import ast
import os
import datetime
import logging
import json
import requests
import concurrent.futures
from pathlib import Path
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
ENABLE_AI = True
OLLAMA_URL = 'http://localhost:11434/api/generate'
MODEL_WORKER = 'qwen2.5-coder:1.5b-cpu'
MODEL_ARCHITECT = 'qwen2.5-coder:3b-cpu'
MAX_WORKERS = 4
MAX_CONTEXT_CHARS = 16000
logger = logging.getLogger('Librarian')

@service_metadata(name='Librarian', version='3.0.0', description="Uses a swarm of local AI models to generate a 'Card Catalogue' of the microservice library.", tags=['documentation', 'ai', 'catalog', 'swarm'], capabilities=['filesystem:read', 'filesystem:write', 'network:outbound', 'compute:parallel'], internal_dependencies=['microservice_std_lib'], external_dependencies=['requests'])
class LibrarianMS:
    """
    The Swarm Librarian.
    Spawns concurrent AI workers to scan the codebase and create a system manifest.
    Optimized for Ryzen CPUs and 32GB RAM.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = Path(self.config.get('root_path', '.')).resolve()

    @service_endpoint(inputs={'output_file': 'str'}, outputs={'path': 'str', 'service_count': 'int'}, description='Unleashes the AI swarm to generate a catalog.', tags=['catalog', 'generate'], side_effects=['filesystem:write'])
    def generate_catalog(self, output_file: str='LIBRARY_CATALOGUE.md') -> Dict[str, Any]:
        """
        Main entry point. Uses ThreadPoolExecutor for parallel processing.
        """
        services = []
        logger.info(f'üöÄ Launching Swarm (Workers: {MAX_WORKERS}, Model: {MODEL_WORKER})...')
        ms_files = list(self.root.glob('*MS.py'))
        targets = [f for f in ms_files if f.name.startswith('_')]
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_file = {executor.submit(self._inspect_file, f): f for f in targets}
            for future in concurrent.futures.as_completed(future_to_file):
                f_path = future_to_file[future]
                try:
                    info = future.result()
                    if info:
                        services.append(info)
                        print(f'  [Worker Completed] {f_path.name}')
                except Exception as e:
                    logger.error(f'  [Worker Failed] {f_path.name}: {e}')
        services.sort(key=lambda x: x['name'])
        system_summary = self._generate_system_summary(services)
        content = self._format_markdown(services, system_summary)
        out_path = self.root / output_file
        out_path.write_text(content, encoding='utf-8')
        logger.info(f'‚úÖ Catalog generated: {out_path} ({len(services)} services)')
        return {'path': str(out_path), 'service_count': len(services)}

    def _inspect_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """
        Worker Task: AST Parse -> AI Enrichment.
        """
        try:
            source = file_path.read_text(encoding='utf-8')
            tree = ast.parse(source)
            meta = {'filename': file_path.name, 'name': file_path.stem, 'description': '', 'tags': [], 'endpoints': [], 'ai_enriched': False}
            target_node = None
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef) and 'MS' in node.name:
                    target_node = node
                    break
            if not target_node:
                return None
            meta['name'] = target_node.name
            meta['description'] = ast.get_docstring(target_node) or ''
            if ENABLE_AI and len(meta['description']) < 10:
                prompt = f'Read this Python class and write a 1-sentence description of its purpose. Be technical and concise.\n\nCode snippet:\n{source[:2000]}'
                ai_desc = self._query_ollama(MODEL_WORKER, prompt)
                if ai_desc:
                    meta['description'] = f'‚ú® {ai_desc}'
                    meta['ai_enriched'] = True
            for item in target_node.body:
                if isinstance(item, ast.FunctionDef) and (not item.name.startswith('_')):
                    args = [a.arg for a in item.args.args if a.arg != 'self']
                    doc = ast.get_docstring(item) or ''
                    meta['endpoints'].append({'name': item.name, 'args': args, 'doc': doc.split('\n')[0]})
            return meta
        except Exception as e:
            logger.warning(f'Failed to inspect {file_path.name}: {e}')
            return None

    def _generate_system_summary(self, services: List[Dict]) -> str:
        """
        Architect Task: Analyzes the entire system map using the larger model.
        """
        if not ENABLE_AI:
            return 'Auto-generated catalog of available microservices.'
        logger.info(f'üß† Architect ({MODEL_ARCHITECT}) is analyzing system structure...')
        service_list = '\n'.join([f"- {s['name']}: {s['description']}" for s in services])
        if len(service_list) > MAX_CONTEXT_CHARS:
            service_list = service_list[:MAX_CONTEXT_CHARS] + '\n...(truncated)...'
        prompt = f"You are a System Architect. Analyze this list of microservices. Write a brief 'Executive Summary' (max 150 words) that explains what this system is capable of. Group capabilities logically (e.g., 'UI Layer', 'Data Ingestion', 'Core Logic').\n\nService List:\n{service_list}"
        summary = self._query_ollama(MODEL_ARCHITECT, prompt)
        return summary or 'System analysis failed.'

    def _query_ollama(self, model: str, prompt: str) -> str:
        """Helper to hit local Ollama instance."""
        try:
            payload = {'model': model, 'prompt': prompt, 'stream': False, 'options': {'temperature': 0.2, 'num_ctx': 4096}}
            timeout = 60 if model == MODEL_ARCHITECT else 20
            res = requests.post(OLLAMA_URL, json=payload, timeout=timeout)
            if res.status_code == 200:
                return res.json().get('response', '').strip()
        except Exception:
            pass
        return ''

    def _format_markdown(self, services: List[Dict], summary: str) -> str:
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
        md = [f'# üìö Microservice Library Card Catalogue', f'> **Generated**: {timestamp}', f'> **Total Services**: {len(services)}', f'> **Swarm Configuration**: `{MAX_WORKERS}` Workers (`{MODEL_WORKER}`), 1 Architect (`{MODEL_ARCHITECT}`)', '', '## üß† System Architecture Overview', summary, '', '## üìá Index']
        for s in services:
            desc_short = s['description'].split('\n')[0][:80]
            md.append(f"- **[{s['name']}](#{s['name'].lower()})**: {desc_short}")
        md.append('\n---\n')
        for s in services:
            md.append(f"### {s['name']}")
            md.append(f"**File**: `{s['filename']}`")
            md.append(f"**Description**: {s['description']}")
            if s['endpoints']:
                md.append('\n| Endpoint | Inputs | Summary |')
                md.append('| :--- | :--- | :--- |')
                for ep in s['endpoints']:
                    args_str = ', '.join(ep['args']) or 'None'
                    md.append(f"| `{ep['name']}` | `{args_str}` | {ep['doc']} |")
            md.append('\n---\n')
        return '\n'.join(md)
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    lib = LibrarianMS()
    print('Service Ready:', lib)
    res = lib.generate_catalog()
    print(f"Catalog created at: {res['path']}")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_LibrarianServiceMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _LibrarianMS
ENTRY_POINT: _LibrarianMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: requests
"""
import importlib.util
if importlib.util.find_spec('requests') is None:
    print('! MISSING DEPENDENCY: pip install requests')
import ast
import os
import datetime
import logging
import requests
import concurrent.futures
from pathlib import Path
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
ENABLE_AI = True
OLLAMA_URL = 'http://localhost:11434/api/generate'
MODEL_WORKER = 'qwen2.5-coder:1.5b-cpu'
MODEL_ARCHITECT = 'qwen2.5-coder:3b-cpu'
MAX_WORKERS = 4
MAX_CONTEXT_CHARS = 16000
logger = logging.getLogger('Librarian')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

@service_metadata(name='Librarian', version='3.0.0', description="Uses a swarm of local AI models to generate a 'Card Catalogue'.", tags=['documentation', 'ai', 'catalog', 'swarm'], capabilities=['filesystem:read', 'filesystem:write', 'network:outbound', 'compute:parallel'], internal_dependencies=['microservice_std_lib'], external_dependencies=['requests'])
class LibrarianMS:

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = Path(self.config.get('root_path', '.')).resolve()

    @service_endpoint(inputs={'output_file': 'str'}, outputs={'path': 'str', 'service_count': 'int'}, description='Unleashes the AI swarm to generate a catalog.', tags=['catalog', 'generate'])
    def generate_catalog(self, output_file: str='LIBRARY_CATALOGUE.md') -> Dict[str, Any]:
        services = []
        print(f'\nüöÄ LAUNCHING SWARM (Workers: {MAX_WORKERS} | Model: {MODEL_WORKER})...')
        ms_files = list(self.root.glob('*MS.py'))
        targets = [f for f in ms_files if f.name.startswith('_')]
        print(f'üéØ Targets acquired: {len(targets)} microservices.\n')
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_file = {executor.submit(self._inspect_file, f): f for f in targets}
            for future in concurrent.futures.as_completed(future_to_file):
                f_path = future_to_file[future]
                try:
                    info = future.result()
                    if info:
                        services.append(info)
                        print(f'  ‚ú® Indexed: {f_path.name}')
                except Exception as e:
                    print(f'  ‚ùå Failed: {f_path.name} - {e}')
        services.sort(key=lambda x: x['name'])
        system_summary = self._generate_system_summary(services)
        content = self._format_markdown(services, system_summary)
        out_path = self.root / output_file
        out_path.write_text(content, encoding='utf-8')
        print(f'\n‚úÖ CATALOG GENERATED: {out_path}')
        return {'path': str(out_path), 'service_count': len(services)}

    def _inspect_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        try:
            source = file_path.read_text(encoding='utf-8')
            tree = ast.parse(source)
            meta = {'filename': file_path.name, 'name': file_path.stem, 'description': '', 'endpoints': [], 'ai_enriched': False}
            target_node = None
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef) and 'MS' in node.name:
                    target_node = node
                    break
            if not target_node:
                return None
            meta['name'] = target_node.name
            meta['description'] = ast.get_docstring(target_node) or ''
            if ENABLE_AI and len(meta['description']) < 10:
                prompt = f'Read this Python class. Write a 1-sentence technical description.\n\nCode:\n{source[:2000]}'
                ai_desc = self._query_ollama(MODEL_WORKER, prompt)
                if ai_desc:
                    meta['description'] = f'‚ú® {ai_desc}'
                    meta['ai_enriched'] = True
            for item in target_node.body:
                if isinstance(item, ast.FunctionDef) and (not item.name.startswith('_')):
                    args = [a.arg for a in item.args.args if a.arg != 'self']
                    doc = ast.get_docstring(item) or ''
                    meta['endpoints'].append({'name': item.name, 'args': args, 'doc': doc.split('\n')[0]})
            return meta
        except Exception:
            return None

    def _generate_system_summary(self, services: List[Dict]) -> str:
        if not ENABLE_AI:
            return 'Auto-generated catalog.'
        print(f'\nüß† Architect ({MODEL_ARCHITECT}) is analyzing system structure...')
        service_list = '\n'.join([f"- {s['name']}: {s['description']}" for s in services])
        if len(service_list) > MAX_CONTEXT_CHARS:
            service_list = service_list[:MAX_CONTEXT_CHARS] + '\n...(truncated)...'
        prompt = f"You are a System Architect. Analyze this microservice library. Write a brief 'Executive Summary' (max 150 words) grouping capabilities.\n\nServices:\n{service_list}"
        return self._query_ollama(MODEL_ARCHITECT, prompt) or 'Analysis failed.'

    def _query_ollama(self, model: str, prompt: str) -> str:
        try:
            res = requests.post(OLLAMA_URL, json={'model': model, 'prompt': prompt, 'stream': False, 'options': {'temperature': 0.2, 'num_ctx': 4096}}, timeout=60)
            if res.status_code == 200:
                return res.json().get('response', '').strip()
        except:
            pass
        return ''

    def _format_markdown(self, services: List[Dict], summary: str) -> str:
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
        md = [f'# üìö Microservice Library Codex', f'> **Generated**: {timestamp}', f'> **Services**: {len(services)}', '', '## üß† System Architecture', summary, '', '## üìá Index']
        for s in services:
            md.append(f"- **[{s['name']}](#{s['name'].lower()})**: {s['description'].split(chr(10))[0][:80]}")
        md.append('\n---\n')
        for s in services:
            md.append(f"### {s['name']}\n**File**: `{s['filename']}`\n\n{s['description']}\n")
            if s['endpoints']:
                md.append('| Endpoint | Inputs | Summary |\n|---|---|---|')
                for ep in s['endpoints']:
                    md.append(f"| `{ep['name']}` | `{', '.join(ep['args'])}` | {ep['doc']} |")
            md.append('\n---\n')
        return '\n'.join(md)
if __name__ == '__main__':
    lib = LibrarianMS()
    lib.generate_catalog()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_LogViewMS.py
--------------------------------------------------------------------------------
import tkinter as tk
from tkinter import scrolledtext, filedialog
import queue
import logging
import datetime
from typing import Any, Dict, Optional
from microservice_std_lib import service_metadata, service_endpoint

class QueueHandler(logging.Handler):
    """
    Sends log records to a thread-safe queue.
    Used to bridge the gap between Python's logging system and the Tkinter UI.
    """

    def __init__(self, log_queue: queue.Queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.log_queue.put(record)

@service_metadata(name='LogView', version='1.0.0', description='A thread-safe log viewer widget for Tkinter.', tags=['ui', 'logs', 'widget'], capabilities=['ui:gui', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class LogViewMS(tk.Frame):
    """
    The Console: A professional log viewer widget.
    Features:
    - Thread-safe (consumes from a Queue).
    - Message Consolidation ("Error occurred (x5)").
    - Level Filtering (Toggle INFO/DEBUG/ERROR).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        super().__init__(parent)
        self.log_queue: queue.Queue = self.config.get('log_queue')
        if self.log_queue is None:
            self.log_queue = queue.Queue()
        self.last_msg = None
        self.last_count = 0
        self.last_line_index = None
        self._build_ui()
        self._poll_queue()

    def _build_ui(self):
        toolbar = tk.Frame(self, bg='#2d2d2d', height=30)
        toolbar.pack(fill='x', side='top')
        self.filters = {'INFO': tk.BooleanVar(value=True), 'DEBUG': tk.BooleanVar(value=True), 'WARNING': tk.BooleanVar(value=True), 'ERROR': tk.BooleanVar(value=True)}
        for level, var in self.filters.items():
            cb = tk.Checkbutton(toolbar, text=level, variable=var, bg='#2d2d2d', fg='white', selectcolor='#444', activebackground='#2d2d2d', activeforeground='white')
            cb.pack(side='left', padx=5)
        tk.Button(toolbar, text='Clear', command=self.clear, bg='#444', fg='white', relief='flat').pack(side='right', padx=5)
        tk.Button(toolbar, text='Save', command=self.save, bg='#444', fg='white', relief='flat').pack(side='right')
        self.text = scrolledtext.ScrolledText(self, state='disabled', bg='#1e1e1e', fg='#d4d4d4', font=('Consolas', 10), insertbackground='white')
        self.text.pack(fill='both', expand=True)
        self.text.tag_config('INFO', foreground='#d4d4d4')
        self.text.tag_config('DEBUG', foreground='#569cd6')
        self.text.tag_config('WARNING', foreground='#ce9178')
        self.text.tag_config('ERROR', foreground='#f44747')
        self.text.tag_config('timestamp', foreground='#608b4e')

    def _poll_queue(self):
        """Pulls logs from the queue and updates UI."""
        try:
            while True:
                record = self.log_queue.get_nowait()
                self._display(record)
        except queue.Empty:
            pass
        finally:
            self.after(100, self._poll_queue)

    def _display(self, record):
        level = record.levelname
        if not self.filters.get(level, tk.BooleanVar(value=True)).get():
            return
        msg = record.getMessage()
        ts = datetime.datetime.fromtimestamp(record.created).strftime('%H:%M:%S')
        self.text.config(state='normal')
        if msg == self.last_msg:
            self.last_count += 1
        else:
            self.last_msg = msg
            self.last_count = 1
        self.text.insert('end', f'[{ts}] ', 'timestamp')
        self.text.insert('end', f'{msg}\n', level)
        self.text.see('end')
        self.text.config(state='disabled')

    @service_endpoint(inputs={}, outputs={}, description='Clears the log console.', tags=['ui', 'logs'], side_effects=['ui:update'])
    def clear(self):
        self.text.config(state='normal')
        self.text.delete('1.0', 'end')
        self.text.config(state='disabled')

    @service_endpoint(inputs={}, outputs={}, description='Opens a dialog to save logs to a file.', tags=['ui', 'filesystem'], side_effects=['filesystem:write', 'ui:dialog'])
    def save(self):
        path = filedialog.asksaveasfilename(defaultextension='.log', filetypes=[('Log Files', '*.log')])
        if path:
            try:
                with open(path, 'w', encoding='utf-8') as f:
                    f.write(self.text.get('1.0', 'end'))
            except Exception as e:
                print(f'Save failed: {e}')
if __name__ == '__main__':
    root = tk.Tk()
    root.title('Log View Test')
    root.geometry('600x400')
    q = queue.Queue()
    logger = logging.getLogger('TestApp')
    logger.setLevel(logging.DEBUG)
    logger.addHandler(QueueHandler(q))
    log_view = LogViewMS({'parent': root, 'log_queue': q})
    print('Service ready:', log_view)
    log_view.pack(fill='both', expand=True)

    def generate_noise():
        logger.info('System initializing...')
        logger.debug('Checking sensors...')
        logger.warning('Sensor 4 response slow.')
        logger.error('Connection failed!')
        root.after(2000, generate_noise)
    generate_noise()
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_MonacoHostMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import threading
import json
import logging
from typing import Any, Dict, Optional, Callable
REQUIRED = ['webview']
MISSING = []
if importlib.util.find_spec('webview') is None:
    MISSING.append('pywebview')
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _MonacoHostMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
import webview
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('MonacoHost')
MONACO_HTML = '\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset="UTF-8">\n    <title>Monaco Host</title>\n    <style>\n        html, body { margin: 0; padding: 0; width: 100%; height: 100%; overflow: hidden; background-color: #1e1e1e; font-family: sans-serif; }\n        #container { display: flex; flex-direction: column; height: 100%; }\n        #tabs { background: #252526; display: flex; overflow-x: auto; height: 35px; border-bottom: 1px solid #3e3e3e; }\n        .tab { \n            padding: 8px 15px; color: #969696; background: #2d2d2d; cursor: pointer; border-right: 1px solid #1e1e1e; font-size: 12px;\n            display: flex; align-items: center; white-space: nowrap;\n        }\n        .tab.active { background: #1e1e1e; color: #fff; border-top: 1px solid #007acc; }\n        .tab:hover { background: #323233; color: #fff; }\n        #editor { flex-grow: 1; }\n    </style>\n</head>\n<body>\n    <div id="container">\n        <div id="tabs"></div>\n        <div id="editor"></div>\n    </div>\n    <script src="https://cdn.jsdelivr.net/npm/monaco-editor@0.41.0/min/vs/loader.js"></script>\n    <script>\n        require.config({ paths: { \'vs\': \'https://cdn.jsdelivr.net/npm/monaco-editor@0.41.0/min/vs\' }});\n        let editor;\n        let models = {}; \n        let currentPath = null;\n\n        require([\'vs/editor/editor.main\'], function() {\n            editor = monaco.editor.create(document.getElementById(\'editor\'), {\n                value: "# Monaco Editor Ready\\n",\n                language: \'python\',\n                theme: \'vs-dark\',\n                automaticLayout: true,\n                fontSize: 14\n            });\n\n            if (window.pywebview) window.pywebview.api.signal_editor_ready();\n\n            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.KeyS, function() {\n                if (currentPath) {\n                    window.pywebview.api.save_file(currentPath, editor.getValue());\n                }\n            });\n        });\n\n        window.pywebview = window.pywebview || {};\n        window.pywebview.api = window.pywebview.api || {};\n\n        window.pywebview.api.open_in_tab = function(filepath, content) {\n            let ext = filepath.split(\'.\').pop();\n            let langMap = { \'py\': \'python\', \'js\': \'javascript\', \'html\': \'html\', \'json\': \'json\', \'css\': \'css\' };\n            let lang = langMap[ext] || \'plaintext\';\n\n            if (!models[filepath]) {\n                models[filepath] = monaco.editor.createModel(content, lang, monaco.Uri.file(filepath));\n                const tab = document.createElement(\'div\');\n                tab.className = \'tab\';\n                tab.innerText = filepath.split(/[\\\\/]/).pop();\n                tab.title = filepath;\n                tab.onclick = () => switchTo(filepath);\n                tab.dataset.path = filepath;\n                document.getElementById(\'tabs\').appendChild(tab);\n            }\n            switchTo(filepath);\n        };\n\n        window.pywebview.api.reveal_range = function(filepath, startLine, endLine) {\n            if (filepath !== currentPath) switchTo(filepath);\n            editor.revealLineInCenter(startLine);\n            editor.setSelection({ startLineNumber: startLine, startColumn: 1, endLineNumber: endLine, endColumn: 1000 });\n        };\n\n        function switchTo(filepath) {\n            if (!models[filepath]) return;\n            editor.setModel(models[filepath]);\n            currentPath = filepath;\n            document.querySelectorAll(\'.tab\').forEach(t => t.classList.toggle(\'active\', t.dataset.path === filepath));\n        }\n    </script>\n</body>\n</html>\n'

class MonacoApiBridge:
    """
    Acts as the bridge between Python and the JavaScript running inside the webview.
    Methods here are callable from JS via `window.pywebview.api.methodName()`.
    """

    def __init__(self):
        self._window = None
        self._ready_event = threading.Event()
        self.on_save_callback: Optional[Callable[[str, str], None]] = None

    def set_window(self, window):
        self._window = window

    def signal_editor_ready(self):
        """Called by JS when Monaco is fully loaded."""
        self._ready_event.set()
        logger.info('Monaco Editor reported ready.')

    def save_file(self, filepath: str, content: str):
        """Called by JS when Ctrl+S is pressed."""
        if self.on_save_callback:
            self.on_save_callback(filepath, content)
        else:
            logger.warning(f'Saved {filepath} (No callback registered)')

    def open_file_in_js(self, filepath: str, content: str):
        """Python helper to push data to JS."""
        self._ready_event.wait(timeout=10)
        if not self._window:
            return
        js = f'window.pywebview.api.open_in_tab({json.dumps(filepath)}, {json.dumps(content)})'
        self._window.evaluate_js(js)

@service_metadata(name='MonacoHost', version='1.1.0', description='Hosts an embedded Monaco Editor instance using PyWebview.', tags=['ui', 'editor', 'webview'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=['webview'])
class MonacoHostMS:
    """
    Hosts the Monaco Editor.
    This service spawns a GUI window and cannot be run in headless environments.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.api = MonacoApiBridge()
        self.window = None

    @service_endpoint(inputs={'title': 'str', 'width': 'int', 'height': 'int'}, outputs={}, description='Launches the editor window. Blocking call.', tags=['ui', 'launch'], side_effects=['ui:window'])
    def launch(self, title='Monaco Editor', width=1000, height=700, func=None):
        """
        Create and launch the window.
        :param func: Optional function to run in a separate thread after launch.
        """
        self.window = webview.create_window(title, html=MONACO_HTML, js_api=self.api, width=width, height=height)
        self.api.set_window(self.window)
        webview.start(func, debug=True) if func else webview.start(debug=True)

    def set_save_callback(self, callback: Callable[[str, str], None]):
        """Sets the function to trigger when Ctrl+S is pressed in the editor."""
        self.api.on_save_callback = callback

    def open_file(self, filepath: str, content: str):
        """Opens a file in the editor (must be called from a background thread or callback)."""
        self.api.open_file_in_js(filepath, content)
if __name__ == '__main__':
    host = MonacoHostMS()

    def background_actions():
        host.api._ready_event.wait()
        print('Opening demo file...')
        host.open_file('demo.py', "print('Hello World')\n# Try Ctrl+S to save!")
        host.set_save_callback(lambda p, c: print(f'File: {p} was saved with {len(c)} chars.'))
    print('Launching Monaco Host...')
    host.launch(func=background_actions)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_NetworkLayoutMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import logging
from typing import List, Dict, Any, Tuple, Optional
REQUIRED = ['networkx']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _NetworkLayoutMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
try:
    import networkx as nx
except ImportError:
    nx = None
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('NetLayout')

@service_metadata(name='NetworkLayout', version='1.0.0', description='Calculates visual (x,y) coordinates for graph nodes using NetworkX.', tags=['graph', 'layout', 'visualization'], capabilities=['compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=['networkx'])
class NetworkLayoutMS:
    """
    The Topologist: Calculates visual coordinates for graph nodes using
    server-side algorithms (NetworkX). 
    Useful for generating static map snapshots or pre-calculating positions 
    to offload client-side rendering.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        if nx is None:
            logger.error('NetworkX is not installed. Layout calculations will fail.')

    @service_endpoint(inputs={'nodes': 'List[str]', 'edges': 'List[Tuple]', 'algorithm': 'str'}, outputs={'positions': 'Dict[str, Tuple]'}, description='Computes (x, y) coordinates for the given graph nodes and edges.', tags=['graph', 'compute'], side_effects=[])
    def calculate_layout(self, nodes: List[str], edges: List[Tuple[str, str]], algorithm: str='spring', **kwargs) -> Dict[str, Tuple[float, float]]:
        """
        Computes (x, y) coordinates for the given graph.
        
        :param nodes: List of node IDs.
        :param edges: List of (source, target) tuples.
        :param algorithm: 'spring' (Force-directed) or 'circular'.
        :return: Dictionary {node_id: (x, y)}
        """
        if nx is None:
            return {}
        G = nx.DiGraph()
        G.add_nodes_from(nodes)
        G.add_edges_from(edges)
        logger.info(f"Computing layout for {len(nodes)} nodes, {len(edges)} edges using '{algorithm}'...")
        try:
            if algorithm == 'circular':
                pos = nx.circular_layout(G)
            else:
                k_val = kwargs.get('k', 0.15)
                iter_val = kwargs.get('iterations', 50)
                pos = nx.spring_layout(G, k=k_val, iterations=iter_val, seed=42)
            return {n: (float(p[0]), float(p[1])) for n, p in pos.items()}
        except Exception as e:
            logger.error(f'Layout calculation failed: {e}')
            return {}
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    layout = NetworkLayoutMS()
    print('Service ready:', layout)
    if nx:
        test_nodes = ['Main', 'Utils', 'Config', 'DB', 'Auth']
        test_edges = [('Main', 'Utils'), ('Main', 'Config'), ('Main', 'DB'), ('Main', 'Auth'), ('DB', 'Config'), ('Auth', 'DB')]
        positions = layout.calculate_layout(test_nodes, test_edges, k=0.5)
        print('--- Calculated Positions ---')
        for node, (x, y) in positions.items():
            print(f'{node:<10}: ({x: .4f}, {y: .4f})')
    else:
        print('Skipping test: NetworkX not found.')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_NeuralGraphEngineMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _NeuralGraphEngineMS
ENTRY_POINT: _NeuralGraphEngineMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: pygame
"""
import pygame
import math
import random
import time
from typing import Dict, Any
pygame.font.init()
from microservice_std_lib import service_metadata, service_endpoint
from base_service import BaseService

@service_metadata(name='NeuralGraphEngineMS', version='1.1.0', description='The Cartographer: A physics-driven rendering engine for visualizing complex neural relationships in a 2D force-directed graph.', tags=['visualization', 'graph', 'pygame'], capabilities=['force-directed-layout', 'real-time-rendering'], side_effects=['ui:update', 'render:write'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=['pygame'])
class NeuralGraphEngineMS(BaseService):

    def __init__(self, width, height, bg_color=(16, 16, 24)):
        super().__init__('NeuralGraphEngineMS')
        self.width = width
        self.start_time = time.time()
        self.height = height
        self.bg_color = bg_color
        self.surface = pygame.Surface((width, height))
        self.cam_x = 0
        self.cam_y = 0
        self.zoom = 1.0
        self.font = pygame.font.SysFont('Consolas', 12)
        self.nodes = []
        self.links = []
        self.dragged_node_idx = None
        self.hovered_node_idx = None
        self.settled = False

    @service_endpoint(inputs={}, outputs={'status': 'str', 'uptime': 'float', 'nodes': 'int', 'settled': 'bool'}, description='Standardized health check to verify the operational state of the graph renderer.', tags=['diagnostic', 'health'])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status of the NeuralGraphEngineMS."""
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'nodes': len(self.nodes), 'settled': self.settled}

    def resize(self, width, height):
        self.width = width
        self.height = height
        self.surface = pygame.Surface((width, height))

    @service_endpoint(inputs={'nodes': 'list', 'links': 'list'}, outputs={}, description='Injects new node and edge data into the engine and wakes up the physics simulation.', tags=['data', 'update'], side_effects=['graph:write'])
    def set_data(self, nodes, links):
        self.nodes = nodes
        self.links = links
        self.settled = False
        node_map = {node['id']: node for node in self.nodes}
        for n in self.nodes:
            if 'gnn_x' in n and 'gnn_y' in n:
                n['x'] = n['gnn_x'] * self.width
                n['y'] = n['gnn_y'] * self.height
            elif 'x' not in n:
                parent_id = n.get('meta', {}).get('parent')
                if parent_id and parent_id in node_map and ('x' in node_map[parent_id]):
                    p = node_map[parent_id]
                    angle = random.random() * 6.28
                    dist = 30
                    n['x'] = p['x'] + math.cos(angle) * dist
                    n['y'] = p['y'] + math.sin(angle) * dist
                else:
                    n['x'] = random.randint(int(self.width * 0.2), int(self.width * 0.8))
                    n['y'] = random.randint(int(self.height * 0.2), int(self.height * 0.8))
            if 'vx' not in n:
                n['vx'] = 0
            if 'vy' not in n:
                n['vy'] = 0
            if n.get('type') == 'file':
                n['_color'] = (0, 122, 204)
                n['_radius'] = 6
            elif n.get('type') == 'web':
                n['_color'] = (204, 0, 122)
                n['_radius'] = 7
            elif n.get('type') == 'chunk':
                n['_color'] = (100, 200, 100)
                n['_radius'] = 3
            else:
                n['_color'] = (160, 32, 240)
                n['_radius'] = 6

    def screen_to_world(self, sx, sy):
        cx, cy = (self.width / 2, self.height / 2)
        wx = (sx - cx) / self.zoom + cx - self.cam_x
        wy = (sy - cy) / self.zoom + cy - self.cam_y
        return (wx, wy)

    def get_node_at(self, sx, sy):
        wx, wy = self.screen_to_world(sx, sy)
        for n in self.nodes:
            dist = math.hypot(n['x'] - wx, n['y'] - wy)
            if dist < n['_radius'] * 2:
                return n
        return None

    def handle_mouse_down(self, x, y):
        wx, wy = self.screen_to_world(x, y)
        for i, n in enumerate(self.nodes):
            dist = math.hypot(n['x'] - wx, n['y'] - wy)
            if dist < n['_radius'] * 2:
                self.dragged_node_idx = i
                self.settled = False
                return True
        return False

    def handle_mouse_move(self, x, y, is_dragging):
        wx, wy = self.screen_to_world(x, y)
        if is_dragging and self.dragged_node_idx is not None:
            node = self.nodes[self.dragged_node_idx]
            node['x'] = wx
            node['y'] = wy
            node['vx'] = 0
            node['vy'] = 0
            self.settled = False
        else:
            prev_hover = self.hovered_node_idx
            self.hovered_node_idx = None
            for i, n in enumerate(self.nodes):
                dist = math.hypot(n['x'] - wx, n['y'] - wy)
                if dist < n['_radius'] * 2:
                    self.hovered_node_idx = i
                    break
            return prev_hover != self.hovered_node_idx

    def handle_mouse_up(self):
        self.dragged_node_idx = None

    def pan(self, dx, dy):
        self.cam_x += dx / self.zoom
        self.cam_y += dy / self.zoom

    def zoom_camera(self, amount, mouse_x, mouse_y):
        self.zoom *= amount
        self.zoom = max(0.1, min(self.zoom, 5.0))

    def highlight_nodes(self, node_ids):
        """Highlights specific nodes by ID."""
        for n in self.nodes:
            if n.get('type') == 'file':
                n['_color'] = (0, 122, 204)
                n['_radius'] = 6
            elif n.get('type') == 'web':
                n['_color'] = (204, 0, 122)
                n['_radius'] = 7
            elif n.get('type') == 'chunk':
                n['_color'] = (100, 200, 100)
                n['_radius'] = 3
            else:
                n['_color'] = (160, 32, 240)
                n['_radius'] = 6
            if n['id'] in node_ids:
                n['_color'] = (255, 255, 0)
                n['_radius'] = 12
        self.settled = False

    @service_endpoint(inputs={}, outputs={'settled': 'bool'}, description='Performs one iteration of the force-directed physics calculation.', tags=['physics', 'lifecycle'], mode='async', side_effects=['graph:update'])
    def step_physics(self):
        if not self.nodes or self.settled:
            return
        REPULSION = 1000
        ATTRACTION = 0.01
        CENTER_GRAVITY = 0.01
        DAMPING = 0.85
        cx, cy = (self.width / 2, self.height / 2)
        total_kinetic_energy = 0
        for i, a in enumerate(self.nodes):
            if i == self.dragged_node_idx:
                continue
            if self.zoom < 1.2 and a.get('type') == 'chunk':
                a['vx'] = 0
                a['vy'] = 0
                continue
            fx, fy = (0, 0)
            fx += (cx - a['x']) * CENTER_GRAVITY
            fy += (cy - a['y']) * CENTER_GRAVITY
            for j, b in enumerate(self.nodes):
                if i == j:
                    continue
                dx = a['x'] - b['x']
                dy = a['y'] - b['y']
                dist_sq = dx * dx + dy * dy
                if dist_sq < 0.1:
                    dist_sq = 0.1
                if dist_sq > 25000:
                    continue
                f = REPULSION / dist_sq
                dist = math.sqrt(dist_sq)
                fx += dx / dist * f
                fy += dy / dist * f
            a['vx'] = (a['vx'] + fx) * DAMPING
            a['vy'] = (a['vy'] + fy) * DAMPING
        for u, v in self.links:
            a = self.nodes[u]
            b = self.nodes[v]
            dx = b['x'] - a['x']
            dy = b['y'] - a['y']
            fx = dx * ATTRACTION
            fy = dy * ATTRACTION
            if u != self.dragged_node_idx:
                a['vx'] += fx
                a['vy'] += fy
            if v != self.dragged_node_idx:
                b['vx'] -= fx
                b['vy'] -= fy
        for i, n in enumerate(self.nodes):
            if i == self.dragged_node_idx:
                continue
            n['x'] += n['vx']
            n['y'] += n['vy']
            total_kinetic_energy += abs(n['vx']) + abs(n['vy'])
        if total_kinetic_energy < 0.5:
            self.settled = True

    @service_endpoint(inputs={}, outputs={'raw_data': 'bytes'}, description='Renders the current frame to a byte buffer for display in UI components.', tags=['render', 'output'], side_effects=['ui:update', 'render:write'])
    def get_image_bytes(self):
        self.surface.fill(self.bg_color)
        cx, cy = (self.width / 2, self.height / 2)

        def to_screen(x, y):
            sx = (x - cx + self.cam_x) * self.zoom + cx
            sy = (y - cy + self.cam_y) * self.zoom + cy
            return (int(sx), int(sy))
        for u, v in self.links:
            if self.zoom < 1.2:
                if self.nodes[u].get('type') == 'chunk' or self.nodes[v].get('type') == 'chunk':
                    continue
            start = to_screen(self.nodes[u]['x'], self.nodes[u]['y'])
            end = to_screen(self.nodes[v]['x'], self.nodes[v]['y'])
            pygame.draw.line(self.surface, (60, 60, 80), start, end, 1)
        for i, n in enumerate(self.nodes):
            if self.zoom < 1.2 and n.get('type') == 'chunk':
                continue
            sx, sy = to_screen(n['x'], n['y'])
            if sx < -20 or sx > self.width + 20 or sy < -20 or (sy > self.height + 20):
                continue
            rad = int(n['_radius'] * self.zoom)
            col = n['_color']
            if i == self.hovered_node_idx or i == self.dragged_node_idx:
                pygame.draw.circle(self.surface, (255, 255, 255), (sx, sy), rad + 2)
            pygame.draw.circle(self.surface, col, (sx, sy), rad)
            if self.zoom > 0.8 or i == self.hovered_node_idx:
                text = self.font.render(n['label'], True, (200, 200, 200))
                self.surface.blit(text, (sx + rad + 4, sy - 6))
        return pygame.image.tostring(self.surface, 'RGB')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_NeuralGraphViewerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _NeuralGraphViewerMS
ENTRY_POINT: _NeuralGraphViewerMS.py
INTERNAL_DEPENDENCIES: _NeuralGraphEngineMS, base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: PIL
"""
import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageTk
import sqlite3
import json
import os
from _NeuralGraphEngineMS import NeuralGraphEngineMS
from microservice_std_lib import service_metadata, service_endpoint
from base_service import BaseService

@service_metadata(name='NeuralGraphViewerMS', version='1.0.0', description='The Lens: A Tkinter-based UI component that hosts the neural graph engine and provides search/highlighting overlays.', tags=['ui', 'visualization', 'tkinter'], capabilities=['graph-rendering', 'search-highlighting'], side_effects=['ui:update', 'filesystem:read'], internal_dependencies=['_NeuralGraphEngineMS', 'base_service', 'microservice_std_lib'], external_dependencies=['PIL'])
class NeuralGraphViewerMS(BaseService, ttk.Frame):

    def __init__(self, parent):
        BaseService.__init__(self, 'NeuralGraphViewerMS')
        ttk.Frame.__init__(self, parent)
        self.pack(fill='both', expand=True)
        self.controls = tk.Frame(self, bg='#101018')
        self.controls.pack(fill='x', side='top', padx=5, pady=5)
        self.entry_search = tk.Entry(self.controls, bg='#252526', fg='white', insertbackground='white', font=('Consolas', 10))
        self.entry_search.pack(side='left', fill='x', expand=True, padx=(0, 5))
        self.entry_search.bind('<Return>', self.run_search)
        btn = tk.Button(self.controls, text='NEURAL TEST', command=self.run_search, bg='#007ACC', fg='white', relief='flat')
        btn.pack(side='right')
        self.canvas_lbl = tk.Label(self, bg='#101018', cursor='crosshair')
        self.canvas_lbl.pack(fill='both', expand=True)
        self.cartridge = None
        self.neural = None
        self.engine = NeuralGraphEngineMS(800, 600)
        self.photo = None
        self.last_mouse_x = 0
        self.last_mouse_y = 0
        self.is_dragging_node = False
        self.is_panning = False
        self.canvas_lbl.bind('<Button-1>', self.on_click)
        self.canvas_lbl.bind('<Double-Button-1>', self.on_double_click)
        self.canvas_lbl.bind('<ButtonRelease-1>', self.on_release)
        self.canvas_lbl.bind('<B1-Motion>', self.on_drag)
        self.canvas_lbl.bind('<Motion>', self.on_hover)
        self.canvas_lbl.bind('<Button-4>', lambda e: self.on_zoom(1.1))
        self.canvas_lbl.bind('<Button-5>', lambda e: self.on_zoom(0.9))
        self.canvas_lbl.bind('<MouseWheel>', self.on_windows_scroll)
        self.canvas_lbl.bind('<Configure>', self.on_resize)
        self.animate()

    def bind_services(self, cartridge, neural):
        self.cartridge = cartridge
        self.neural = neural

    @service_endpoint(inputs={'event': 'any'}, outputs={}, description='Triggers a neural search based on the entry field and highlights resulting nodes in the viewer.', tags=['ui-action', 'search'], side_effects=['ui:update', 'graph:highlight'])
    def run_search(self, event=None):
        if not self.cartridge or not self.neural:
            return
        query = self.entry_search.get().strip()
        if not query:
            return
        vec = self.neural.get_embedding(query)
        if not vec:
            return
        results = self.cartridge.search_embeddings(vec, limit=5)
        ids = set()
        for r in results:
            if 'vfs_path' in r and 'name' in r:
                ids.add(f"{r['vfs_path']}::{r['name']}")
        self.engine.highlight_nodes(ids)

    @service_endpoint(inputs={'db_path': 'str'}, outputs={}, description='Loads graph nodes and edges from a Cartridge database and triggers the physics engine.', tags=['data-load', 'sqlite'], side_effects=['filesystem:read'])
    def load_from_db(self, db_path):
        """
        Loads graph data from SQLite.
        Does NOT block the UI. The physics engine will settle the nodes frame-by-frame.
        """
        if not os.path.exists(db_path):
            return
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            db_nodes = cursor.execute('SELECT id, type, label, data_json FROM graph_nodes').fetchall()
            db_edges = cursor.execute('SELECT source, target FROM graph_edges').fetchall()
            conn.close()
        except Exception as e:
            print(f'Graph Load Error: {e}')
            return
        id_to_index = {}
        formatted_nodes = []
        for idx, row in enumerate(db_nodes):
            node_id, n_type, label, raw_json = row
            meta = {}
            try:
                if raw_json:
                    meta = json.loads(raw_json)
            except:
                pass
            id_to_index[node_id] = idx
            formatted_nodes.append({'id': node_id, 'type': n_type, 'label': label, 'meta': meta})
        formatted_links = []
        for src, tgt in db_edges:
            if src in id_to_index and tgt in id_to_index:
                formatted_links.append((id_to_index[src], id_to_index[tgt]))
        self.engine.set_data(formatted_nodes, formatted_links)

    def on_resize(self, event):
        if event.width > 1 and event.height > 1:
            self.engine.resize(event.width, event.height)

    def on_double_click(self, event):
        hit_node = self.engine.get_node_at(event.x, event.y)
        if hit_node:
            self.engine.cam_x = hit_node['x']
            self.engine.cam_y = hit_node['y']
            self.engine.zoom = 2.0
            self.engine.settled = False

    def on_click(self, event):
        self.last_mouse_x = event.x
        self.last_mouse_y = event.y
        hit = self.engine.handle_mouse_down(event.x, event.y)
        if hit:
            self.is_dragging_node = True
        else:
            self.is_panning = True

    def on_release(self, event):
        self.engine.handle_mouse_up()
        self.is_dragging_node = False
        self.is_panning = False

    def on_drag(self, event):
        if self.is_dragging_node:
            self.engine.handle_mouse_move(event.x, event.y, True)
        elif self.is_panning:
            dx = event.x - self.last_mouse_x
            dy = event.y - self.last_mouse_y
            self.engine.pan(dx, dy)
        self.last_mouse_x = event.x
        self.last_mouse_y = event.y

    def on_hover(self, event):
        if not self.is_dragging_node:
            self.engine.handle_mouse_move(event.x, event.y, False)

    def on_zoom(self, amount):
        self.engine.zoom_camera(amount, 0, 0)
        self.engine.settled = False

    def on_windows_scroll(self, event):
        if event.delta > 0:
            self.on_zoom(1.1)
        else:
            self.on_zoom(0.9)

    @service_endpoint(inputs={}, outputs={}, description='The primary heartbeat loop that orchestrates frame-by-frame physics steps and UI blitting.', tags=['lifecycle', 'rendering'], mode='async', side_effects=['ui:update', 'render:write'])
    def animate(self):
        """
        The Heartbeat Loop.
        Runs at ~30 FPS. Handles Physics + Rendering.
        """
        self.engine.step_physics()
        raw_data = self.engine.get_image_bytes()
        if raw_data:
            img = Image.frombytes('RGB', (self.engine.width, self.engine.height), raw_data)
            self.photo = ImageTk.PhotoImage(img)
            self.canvas_lbl.configure(image=self.photo)
        self.after(30, self.animate)
if __name__ == '__main__':
    root = tk.Tk()
    root.title('NeuralGraphViewerMS Test')
    view = NeuralGraphViewerMS(root)
    print('Service ready:', view._service_info['name'])
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_NeuralServiceMS.py
--------------------------------------------------------------------------------
import requests
import json
import concurrent.futures
import logging
from typing import Optional, Dict, Any, List
from microservice_std_lib import service_metadata, service_endpoint
OLLAMA_API_URL = 'http://localhost:11434/api'
logger = logging.getLogger('NeuralService')

@service_metadata(name='NeuralService', version='1.0.0', description='The Brain Interface: Orchestrates local AI operations via Ollama.', tags=['ai', 'neural', 'inference', 'ollama'], capabilities=['text-generation', 'embeddings', 'parallel-processing'], internal_dependencies=['microservice_std_lib'], external_dependencies=['requests'])
class NeuralServiceMS:
    """
    The Brain Interface: Orchestrates local AI operations via Ollama for inference and embeddings.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.max_workers = self.config.get('max_workers', 4)
        self.models = {'fast': 'qwen2.5-coder:1.5b-cpu', 'smart': 'qwen2.5:3b-cpu', 'embed': 'mxbai-embed-large:latest-cpu'}
        if 'models' in self.config:
            self.models.update(self.config['models'])

    @service_endpoint(inputs={'fast_model': 'str', 'smart_model': 'str', 'embed_model': 'str'}, outputs={'status': 'str'}, description='Updates the active model configurations on the fly.', tags=['config', 'write'], side_effects=['config:update'])
    def update_models(self, fast_model: str, smart_model: str, embed_model: str) -> Dict[str, str]:
        """Called by the UI Settings Modal to change models on the fly."""
        self.models['fast'] = fast_model
        self.models['smart'] = smart_model
        self.models['embed'] = embed_model
        logger.info(f'Models Updated: Fast={fast_model}, Smart={smart_model}')
        return {'status': 'success', 'config': str(self.models)}

    @service_endpoint(inputs={}, outputs={'models': 'List[str]'}, description='Fetches a list of available models from the local Ollama instance.', tags=['ai', 'read'], side_effects=['network:read'])
    def get_available_models(self) -> List[str]:
        """Fetches list from Ollama for the UI dropdown."""
        try:
            res = requests.get(f'{OLLAMA_API_URL}/tags', timeout=2)
            if res.status_code == 200:
                return [m['name'] for m in res.json().get('models', [])]
        except Exception as e:
            logger.error(f'Failed to fetch models: {e}')
            return []
        return []

    @service_endpoint(inputs={}, outputs={'is_alive': 'bool'}, description='Pings Ollama to verify connectivity.', tags=['health', 'read'], side_effects=['network:read'])
    def check_connection(self) -> bool:
        """Pings Ollama to see if it's alive."""
        try:
            requests.get(f'{OLLAMA_API_URL}/tags', timeout=2)
            return True
        except requests.RequestException:
            logger.error("Ollama connection failed. Is 'ollama serve' running?")
            return False

    @service_endpoint(inputs={'text': 'str'}, outputs={'embedding': 'list'}, description='Generates a vector embedding for the provided text.', tags=['nlp', 'vector', 'ai'], side_effects=['network:read'])
    def get_embedding(self, text: str) -> Optional[List[float]]:
        """Generates a vector using the configured embedding model."""
        try:
            res = requests.post(f'{OLLAMA_API_URL}/embeddings', json={'model': self.models['embed'], 'prompt': text}, timeout=30)
            if res.status_code == 200:
                return res.json().get('embedding')
        except Exception as e:
            logger.error(f'Embedding failed: {e}')
        return None

    @service_endpoint(inputs={'prompt': 'str', 'tier': 'str', 'format_json': 'bool'}, outputs={'response': 'str'}, description='Requests synchronous text generation from a local LLM.', tags=['llm', 'inference'], side_effects=['network:read'])
    def request_inference(self, prompt: str, tier: str='fast', format_json: bool=False) -> str:
        """
        Synchronous inference request.
        tier: 'fast', 'smart', or other keys in self.models
        """
        model = self.models.get(tier, self.models['fast'])
        payload = {'model': model, 'prompt': prompt, 'stream': False}
        if format_json:
            payload['format'] = 'json'
        try:
            res = requests.post(f'{OLLAMA_API_URL}/generate', json=payload, timeout=60)
            if res.status_code == 200:
                return res.json().get('response', '').strip()
        except Exception as e:
            logger.error(f'Inference ({tier}) failed: {e}')
        return ''

    def process_parallel(self, items: List[Any], worker_func) -> List[Any]:
        """
        Helper to run a function across many items using a ThreadPool.
        Useful for batch ingestion.
        Note: Not exposed as an endpoint as it takes a function as an argument.
        """
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(worker_func, item): item for item in items}
            for future in concurrent.futures.as_completed(futures):
                try:
                    results.append(future.result())
                except Exception as e:
                    logger.error(f'Worker task failed: {e}')
        return results
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    svc = NeuralServiceMS()
    print('Service ready:', svc)
    if svc.check_connection():
        print('Ollama Connection: OK')
        print(f'Models available: {svc.get_available_models()}')
        print('Testing Inference (Fast Tier)...')
        response = svc.request_inference('Why is the sky blue? Answer in 1 sentence.')
        print(f'Response: {response}')
    else:
        print('Ollama Connection: FAILED (Is Ollama running?)')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ProjectForgeMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ProjectForgeMS
ENTRY_POINT: _ProjectForgeMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import shutil
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('ProjectForge')

@service_metadata(name='ProjectForge', version='1.0.0', description='Scaffolding engine for creating new microservice projects or Python apps.', tags=['scaffolding', 'generator', 'filesystem'], capabilities=['filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class ProjectForgeMS:
    """
    The Blacksmith.
    Creates directory structures, stamps out boilerplate code, and injects dependencies.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.template_root = self.config.get('template_root')

    @service_endpoint(inputs={'parent_path': 'str', 'project_name': 'str', 'dependencies': 'List[str]', 'type': 'str'}, outputs={'path': 'str', 'status': 'str'}, description='Creates a new standardized Python project with the given specifications.', tags=['create', 'scaffold'], side_effects=['filesystem:write'])
    def forge_project(self, parent_path: str, project_name: str, dependencies: List[str]=None, project_type: str='microservice') -> Dict[str, Any]:
        """
        Stamps out a new project folder.
        """
        root = Path(parent_path).resolve()
        project_dir = root / project_name
        if project_dir.exists():
            raise FileExistsError(f'Directory already exists: {project_dir}')
        logger.info(f"Forging new project '{project_name}' at {project_dir}...")
        try:
            project_dir.mkdir(parents=True)
            (project_dir / 'src').mkdir()
            (project_dir / 'tests').mkdir()
            (project_dir / 'config').mkdir()
            self._create_readme(project_dir, project_name)
            self._create_requirements(project_dir, dependencies or [])
            self._create_gitignore(project_dir)
            if project_type == 'microservice':
                self._create_microservice_boilerplate(project_dir, project_name)
            else:
                self._create_standard_app_boilerplate(project_dir)
            return {'path': str(project_dir), 'status': 'created', 'name': project_name}
        except Exception as e:
            logger.error(f'Forge failed: {e}')
            raise e

    def _create_readme(self, root: Path, name: str):
        content = f'# {name}\n\nGenerated by ProjectForgeMS.\n\n## Overview\nTODO: Add description.\n'
        (root / 'README.md').write_text(content, encoding='utf-8')

    def _create_requirements(self, root: Path, deps: List[str]):
        base_deps = ['requests', 'logging']
        all_deps = sorted(list(set(base_deps + deps)))
        content = '\n'.join(all_deps)
        (root / 'requirements.txt').write_text(content, encoding='utf-8')

    def _create_gitignore(self, root: Path):
        content = '__pycache__/\n*.pyc\n.env\n.venv/\n.vscode/\n'
        (root / '.gitignore').write_text(content, encoding='utf-8')

    def _create_microservice_boilerplate(self, root: Path, name: str):
        content = f'"""\nSERVICE_NAME: _{name}MS\nENTRY_POINT: _{name}MS.py\nDEPENDENCIES: None\n"""\nfrom typing import Dict, Any, Optional\nfrom microservice_std_lib import service_metadata, service_endpoint\n\n@service_metadata(\n    name="{name}",\n    version="1.0.0",\n    description="Auto-generated microservice.",\n    tags=["new"],\n    capabilities=[]\n)\nclass {name}MS:\n    def __init__(self, config: Optional[Dict[str, Any]] = None):\n        self.config = config or {{}}\n\n    @service_endpoint(\n        inputs={{}},\n        outputs={{"message": "str"}},\n        description="Default endpoint.",\n        tags=["hello"]\n    )\n    def hello(self):\n        return {{"message": "Hello from {name}!"}}\n\nif __name__ == "__main__":\n    svc = {name}MS()\n    print("Service ready:", svc)\n'
        (root / 'src' / f'_{name}MS.py').write_text(content, encoding='utf-8')

    def _create_standard_app_boilerplate(self, root: Path):
        content = "def main():\n    print('Hello World')\n\nif __name__ == '__main__':\n    main()"
        (root / 'src' / 'app.py').write_text(content, encoding='utf-8')
if __name__ == '__main__':
    forge = ProjectForgeMS()
    try:
        forge.forge_project('.', 'TestForgedApp', ['pandas', 'numpy'])
        print('Test Project Created.')
        shutil.rmtree('TestForgedApp')
        print('Test Project Cleaned up.')
    except Exception as e:
        print(f'Test failed: {e}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_PromptOptimizerMS.py
--------------------------------------------------------------------------------
import json
import logging
from typing import List, Dict, Any, Callable, Optional
from microservice_std_lib import service_metadata, service_endpoint
REFINE_SYSTEM_PROMPT = 'You are a world-class prompt engineer. Given an original prompt and specific feedback, provide an improved, refined version of the prompt that incorporates the feedback. Return ONLY the refined prompt text, no preamble.'
VARIATION_SYSTEM_PROMPT = 'You are a creative AI assistant. Generate {num} innovative and diverse variations of the following prompt. Return the result as a valid JSON array of strings. Example: ["variation 1", "variation 2"]'
logger = logging.getLogger('PromptOpt')

@service_metadata(name='PromptOptimizer', version='1.0.0', description='Uses an LLM to refine prompts or generate variations.', tags=['llm', 'prompt-engineering', 'optimization'], capabilities=['network:outbound'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class PromptOptimizerMS:
    """
    The Tuner: Uses an LLM to refine prompts or generate variations.
    Requires an 'inference_func' to be passed in the config, which accepts a string
    and returns a string (simulating an LLM call).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.infer: Callable[[str], str] = self.config.get('inference_func', lambda x: 'Error: No inference function configured.')

    @service_endpoint(inputs={'draft_prompt': 'str', 'feedback': 'str'}, outputs={'refined_prompt': 'str'}, description='Rewrites a prompt based on feedback.', tags=['llm', 'refine'], side_effects=['network:outbound'])
    def refine_prompt(self, draft_prompt: str, feedback: str) -> str:
        """
        Rewrites a prompt based on feedback.
        """
        full_prompt = f'{REFINE_SYSTEM_PROMPT}\n\n[Original Prompt]:\n{draft_prompt}\n\n[Feedback]:\n{feedback}\n\n[Refined Prompt]:'
        logger.info('Refining prompt...')
        try:
            result = self.infer(full_prompt)
            return result.strip()
        except Exception as e:
            logger.error(f'Refinement failed: {e}')
            return draft_prompt

    @service_endpoint(inputs={'draft_prompt': 'str', 'num_variations': 'int', 'context_data': 'Dict'}, outputs={'variations': 'List[str]'}, description='Generates multiple versions of a prompt for testing.', tags=['llm', 'variations'], side_effects=['network:outbound'])
    def generate_variations(self, draft_prompt: str, num_variations: int=3, context_data: Optional[Dict[str, Any]]=None) -> List[str]:
        """
        Generates multiple versions of a prompt for testing.
        """
        meta_prompt = VARIATION_SYSTEM_PROMPT.format(num=num_variations)
        prompt_content = draft_prompt
        if context_data:
            prompt_content += f'\n\n--- Context ---\n{json.dumps(context_data, indent=2)}'
        full_prompt = f'{meta_prompt}\n\n[Original Prompt]:\n{prompt_content}\n\n[JSON Array of Variations]:'
        logger.info(f'Generating {num_variations} variations...')
        try:
            raw_response = self.infer(full_prompt)
            start = raw_response.find('[')
            end = raw_response.rfind(']') + 1
            if start == -1 or end == 0:
                logger.warning('No JSON array found in response. Returning raw response.')
                return [raw_response]
            clean_json = raw_response[start:end]
            variations = json.loads(clean_json)
            if isinstance(variations, list):
                return [str(v) for v in variations]
            return []
        except Exception as e:
            logger.error(f'Variation generation failed: {e}')
            return []
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

    def mock_llm(prompt: str) -> str:
        if '[Refined Prompt]' in prompt:
            return 'You are a helpful assistant who speaks like a pirate. How may I help ye?'
        if '[JSON Array]' in prompt:
            return '["Variation A: Pirate Mode", "Variation B: Formal Mode", "Variation C: Concise Mode"]'
        return 'Error'
    optimizer = PromptOptimizerMS({'inference_func': mock_llm})
    print('Service ready:', optimizer)
    print('--- Test: Refine ---')
    draft = 'Help me.'
    feedback = 'Make it sound like a pirate.'
    refined = optimizer.refine_prompt(draft, feedback)
    print(f'Original: {draft}')
    print(f'Refined:  {refined}')
    print('\n--- Test: Variations ---')
    vars = optimizer.generate_variations(draft, num_variations=3)
    for i, v in enumerate(vars):
        print(f' {i + 1}. {v}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_PromptVaultMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import sqlite3
import json
import uuid
import logging
import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
REQUIRED = ['pydantic', 'jinja2']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _PromptVaultMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
from pydantic import BaseModel
from jinja2 import Environment, BaseLoader
from microservice_std_lib import service_metadata, service_endpoint
DB_PATH = Path(__file__).parent / 'prompt_vault.db'
logger = logging.getLogger('PromptVault')

class PromptVersion(BaseModel):
    """A specific historical version of a prompt."""
    version_num: int
    content: str
    author: str
    timestamp: datetime.datetime
    embedding: Optional[List[float]] = None

class PromptTemplate(BaseModel):
    """The master record for a prompt."""
    id: str
    slug: str
    title: str
    description: Optional[str] = ''
    tags: List[str] = []
    latest_version_num: int
    versions: List[PromptVersion] = []

    @property
    def latest(self) -> PromptVersion:
        """Helper to get the most recent content."""
        if not self.versions:
            raise ValueError('No versions found.')
        return sorted(self.versions, key=lambda v: v.version_num)[-1]

@service_metadata(name='PromptVault', version='1.0.0', description='A persistent SQLite store for managing, versioning, and rendering AI prompts.', tags=['prompt', 'database', 'versioning', 'jinja'], capabilities=['db:sqlite', 'filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=['jinja2', 'pydantic'])
class PromptVaultMS:
    """
    The Vault: A persistent SQLite store for managing, versioning, 
    and rendering AI prompts.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.db_path = Path(self.config.get('db_path', DB_PATH))
        self._init_db()
        self.jinja_env = Environment(loader=BaseLoader())

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        """Bootstraps the schema."""
        with self._get_conn() as conn:
            conn.execute('\n                CREATE TABLE IF NOT EXISTS templates (\n                    id TEXT PRIMARY KEY,\n                    slug TEXT UNIQUE NOT NULL,\n                    title TEXT NOT NULL,\n                    description TEXT,\n                    tags_json TEXT,\n                    latest_version INTEGER DEFAULT 1,\n                    created_at TIMESTAMP,\n                    updated_at TIMESTAMP\n                )\n            ')
            conn.execute('\n                CREATE TABLE IF NOT EXISTS versions (\n                    id TEXT PRIMARY KEY,\n                    template_id TEXT,\n                    version_num INTEGER,\n                    content TEXT,\n                    author TEXT,\n                    timestamp TIMESTAMP,\n                    embedding_json TEXT,\n                    FOREIGN KEY(template_id) REFERENCES templates(id)\n                )\n            ')

    @service_endpoint(inputs={'slug': 'str', 'title': 'str', 'content': 'str', 'author': 'str', 'tags': 'List[str]'}, outputs={'template': 'Dict'}, description='Creates a new prompt template with an initial version.', tags=['prompt', 'create'], side_effects=['db:write'])
    def create_template(self, slug: str, title: str, content: str, author: str='system', tags: List[str]=None) -> Dict[str, Any]:
        """Creates a new prompt template with an initial version 1."""
        tags = tags or []
        now = datetime.datetime.utcnow()
        t_id = str(uuid.uuid4())
        v_id = str(uuid.uuid4())
        try:
            with self._get_conn() as conn:
                conn.execute('INSERT INTO templates (id, slug, title, description, tags_json, latest_version, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?)', (t_id, slug, title, '', json.dumps(tags), 1, now, now))
                conn.execute('INSERT INTO versions (id, template_id, version_num, content, author, timestamp) VALUES (?, ?, ?, ?, ?, ?)', (v_id, t_id, 1, content, author, now))
            logger.info(f'Created template: {slug}')
            tpl = self.get_template(slug)
            return tpl.dict() if tpl else {}
        except sqlite3.IntegrityError:
            raise ValueError(f"Template '{slug}' already exists.")

    @service_endpoint(inputs={'slug': 'str', 'content': 'str', 'author': 'str'}, outputs={'template': 'Dict'}, description='Adds a new version to an existing template.', tags=['prompt', 'update'], side_effects=['db:write'])
    def add_version(self, slug: str, content: str, author: str='user') -> Dict[str, Any]:
        """Adds a new version to an existing template."""
        current = self.get_template(slug)
        if not current:
            raise ValueError(f"Template '{slug}' not found.")
        new_ver = current.latest_version_num + 1
        now = datetime.datetime.utcnow()
        v_id = str(uuid.uuid4())
        with self._get_conn() as conn:
            conn.execute('INSERT INTO versions (id, template_id, version_num, content, author, timestamp) VALUES (?, ?, ?, ?, ?, ?)', (v_id, current.id, new_ver, content, author, now))
            conn.execute('UPDATE templates SET latest_version = ?, updated_at = ? WHERE id = ?', (new_ver, now, current.id))
        logger.info(f'Updated {slug} to v{new_ver}')
        tpl = self.get_template(slug)
        return tpl.dict() if tpl else {}

    @service_endpoint(inputs={'slug': 'str'}, outputs={'template': 'Optional[PromptTemplate]'}, description='Retrieves a full template with all history.', tags=['prompt', 'read'], side_effects=['db:read'])
    def get_template(self, slug: str) -> Optional[PromptTemplate]:
        """Retrieves a full template with all history."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT * FROM templates WHERE slug = ?', (slug,)).fetchone()
            if not row:
                return None
            v_rows = conn.execute('SELECT * FROM versions WHERE template_id = ? ORDER BY version_num ASC', (row['id'],)).fetchall()
            versions = []
            for v in v_rows:
                versions.append(PromptVersion(version_num=v['version_num'], content=v['content'], author=v['author'], timestamp=v['timestamp']))
            return PromptTemplate(id=row['id'], slug=row['slug'], title=row['title'], description=row['description'], tags=json.loads(row['tags_json']), latest_version_num=row['latest_version'], versions=versions)

    @service_endpoint(inputs={'slug': 'str', 'context': 'Dict'}, outputs={'rendered_text': 'str'}, description='Fetches the latest version and renders it with Jinja2.', tags=['prompt', 'render'], side_effects=['db:read'])
    def render(self, slug: str, context: Optional[Dict[str, Any]]=None) -> str:
        """Fetches the latest version and renders it with Jinja2."""
        template = self.get_template(slug)
        if not template:
            raise ValueError(f"Template '{slug}' not found.")
        raw_text = template.latest.content
        jinja_template = self.jinja_env.from_string(raw_text)
        return jinja_template.render(**context or {})

    @service_endpoint(inputs={}, outputs={'slugs': 'List[str]'}, description='Lists all available prompt slugs.', tags=['prompt', 'list'], side_effects=['db:read'])
    def list_slugs(self) -> List[str]:
        with self._get_conn() as conn:
            rows = conn.execute('SELECT slug FROM templates').fetchall()
            return [r[0] for r in rows]
if __name__ == '__main__':
    import os
    db_file = Path('test_prompt_vault.db')
    if db_file.exists():
        os.remove(db_file)
    vault = PromptVaultMS({'db_path': db_file})
    print('Service ready:', vault)
    print('--- Creating Prompt ---')
    vault.create_template(slug='greet_user', title='Greeting Protocol', content='Hello {{ name }}, welcome to the {{ system_name }}!', tags=['ui', 'onboarding'])
    print('--- Updating Prompt ---')
    vault.add_version('greet_user', 'Greetings, {{ name }}. System {{ system_name }} is online.')
    print('--- Rendering ---')
    final_text = vault.render('greet_user', {'name': 'Alice', 'system_name': 'Nexus'})
    print(f'Rendered Output: {final_text}')
    tpl = vault.get_template('greet_user')
    if tpl:
        print(f'Current Version: v{tpl.latest_version_num}')
        print(f'History: {[v.content for v in tpl.versions]}')
    if db_file.exists():
        os.remove(db_file)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_PythonChunkerMS.py
--------------------------------------------------------------------------------
import ast
import time
from dataclasses import dataclass, asdict
from typing import List, Dict, Any
from microservice_std_lib import service_metadata, service_endpoint

@dataclass
class CodeChunk:
    name: str
    type: str
    content: str
    start_line: int
    end_line: int
    docstring: str = ''

@service_metadata(name='PythonChunker', version='1.2.0', description='The Python Surgeon: Specialist in Abstract Syntax Tree (AST) parsing for Python source code.', tags=['chunking', 'python', 'ast'], capabilities=['python-ast'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class PythonChunkerMS:
    """
    Specialized Python AST Chunker.
    Focuses exclusively on identifying classes and functions to preserve code logic.
    """

    def __init__(self, config: Dict[str, Any]=None):
        self.config = config or {}
        self.start_time = time.time()

    @service_endpoint(inputs={}, outputs={'status': 'str', 'uptime': 'float', 'specialty': 'str'}, description='Standardized health check for the Python specialist service.', tags=['diagnostic', 'health'])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status of the PythonChunkerMS."""
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'specialty': 'python_ast'}

    @service_endpoint(inputs={'content': 'str'}, outputs={'chunks': 'List[Dict]'}, description='Primary entry point for high-fidelity Python-specific AST chunking.', tags=['processing', 'python'])
    def chunk(self, content: str) -> List[Dict[str, Any]]:
        """Parses Python source into semantic CodeChunks."""
        chunks = self._chunk_python(content)
        return [asdict(c) for c in chunks]

    def _chunk_python(self, source: str) -> List[CodeChunk]:
        chunks = []
        try:
            tree = ast.parse(source)
            lines = source.splitlines(keepends=True)

            def get_segment(node):
                start = node.lineno - 1
                end = node.end_lineno if hasattr(node, 'end_lineno') and node.end_lineno else start + 1
                return (''.join(lines[start:end]), start + 1, end)
            for node in tree.body:
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'def {node.name}', type='function', content=text, start_line=s, end_line=e, docstring=doc))
                elif isinstance(node, ast.ClassDef):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'class {node.name}', type='class', content=text, start_line=s, end_line=e, docstring=doc))
            if not chunks and source.strip():
                chunks.append(CodeChunk(name='module_level', type='text', content=source, start_line=1, end_line=len(lines)))
        except SyntaxError:
            chunks.append(CodeChunk(name='syntax_error_fallback', type='text', content=source, start_line=1, end_line=source.count('\n') + 1))
        return chunks
if __name__ == '__main__':
    svc = PythonChunkerMS()
    print('Service ready:', svc)
    test_code = 'class Test:\n    def run(self):\n        pass'
    results = svc.chunk(test_code)
    for c in results:
        print(f"[{c['type']}] {c['name']} (Lines {c['start_line']}-{c['end_line']})")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_RefineryServiceMS.py
--------------------------------------------------------------------------------
import json
import re
import os
import time
import ast
import concurrent.futures
import logging
from typing import Dict, List, Any, Optional, Tuple
try:
    from _CartridgeServiceMS import CartridgeServiceMS
    from _NeuralServiceMS import NeuralServiceMS
    from _ChunkingRouterMS import ChunkingRouterMS
except ImportError:
    CartridgeServiceMS = Any
    NeuralServiceMS = Any
    ChunkingRouterMS = Any
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('RefineryService')

@service_metadata(name='RefineryService', version='1.1.0', description="The Night Shift: Processes 'RAW' files into semantic chunks and weaves them into a knowledge graph.", tags=['processing', 'refinery', 'graph', 'RAG'], capabilities=['smart-chunking', 'graph-weaving', 'parallel-embedding'], internal_dependencies=['_CartridgeServiceMS', '_ChunkingRouterMS', '_NeuralServiceMS', 'microservice_std_lib'], external_dependencies=[])
class RefineryServiceMS:
    """
    The Night Shift.
    Polls the DB for 'RAW' files and processes them into Chunks and Graph Nodes.

    Graph Enrichment:
    - Code: function/class nodes, resolved import edges when possible.
    - Docs: section/chapter nodes for long-form text (md/txt/rst).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.cartridge = self.config.get('cartridge')
        self.neural = self.config.get('neural')
        self.chunker = ChunkingRouterMS() if ChunkingRouterMS != Any else None
        self.start_time = time.time()
        self.import_pattern = re.compile('(?:from|import)\\s+([\\w\\.]+)|require\\([\'"]([\\w\\.\\-/]+)[\'"]\\)')
        self._module_index: Dict[str, str] = {}
        self._path_index: Dict[str, str] = {}
        self._index_built: bool = False
        self._md_heading = re.compile('^(#{1,6})\\s+(.+?)\\s*$')
        self._chapter_heading = re.compile('^\\s*(chapter|CHAPTER)\\s+([0-9]+|[IVXLC]+)\\b\\s*[:\\-]?\\s*(.*)$')
        if self.cartridge and self.neural:
            self._stamp_specs()

    @service_endpoint(inputs={}, outputs={'status': 'str', 'uptime': 'float', 'cartridge_health': 'str'}, description='Standardized health check to verify the operational state of the Refinery service.', tags=['diagnostic', 'health'])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status of the RefineryServiceMS."""
        cart_status = 'UNKNOWN'
        if self.cartridge:
            cart_status = 'CONNECTED'
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'cartridge_health': cart_status}

    def _stamp_specs(self):
        """Writes the active Neural/Chunker configuration to the Manifest."""
        try:
            embed_model = getattr(self.neural, 'models', {}).get('embed', 'default')
            spec = {'provider': 'ollama', 'model': embed_model, 'dim': 1024, 'dtype': 'float32', 'distance': 'cosine'}
            if self.cartridge:
                self.cartridge.set_manifest('embedding_spec', spec)
        except Exception as e:
            logger.error(f'Failed to stamp specs: {e}')

    def _build_import_index(self):
        """Builds caches for resolving imports to VFS targets."""
        if self._index_built or not self.cartridge:
            return
        path_index: Dict[str, str] = {}
        module_index: Dict[str, str] = {}
        conn = self.cartridge._get_conn()
        try:
            rows = conn.execute('SELECT vfs_path FROM files').fetchall()
            for vp, in rows:
                if not vp:
                    continue
                vfs_path = str(vp).replace('\\', '/')
                path_index[vfs_path] = vfs_path
                if vfs_path.endswith('.py'):
                    mod = vfs_path[:-3].strip('/')
                    mod = mod.replace('/', '.')
                    if mod:
                        module_index[mod] = vfs_path
                    if vfs_path.endswith('/__init__.py'):
                        pkg = vfs_path[:-len('/__init__.py')].strip('/').replace('/', '.')
                        if pkg:
                            module_index[pkg] = vfs_path
        finally:
            conn.close()
        self._path_index = path_index
        self._module_index = module_index
        self._index_built = True

    @service_endpoint(inputs={'batch_size': 'int'}, outputs={'processed_count': 'int'}, description="Polls the database for files with 'RAW' status and processes them into chunks and graph nodes.", tags=['pipeline', 'batch'], side_effects=['cartridge:write', 'neural:inference'])
    def process_pending(self, batch_size: int=5) -> int:
        """Main loop. Returns number of files processed."""
        if not self.cartridge or not self.neural:
            logger.error('Refinery missing dependencies (Cartridge or Neural).')
            return 0
        pending = self.cartridge.get_pending_files(limit=batch_size)
        if not pending:
            return 0
        logger.info(f'Refining batch of {len(pending)} files...')
        for file_row in pending:
            self._refine_file(file_row)
        return len(pending)

    def _refine_file(self, row: Dict):
        file_id = row['id']
        vfs_path = row['vfs_path']
        content = row['content']
        if not content:
            self.cartridge.update_status(file_id, 'SKIPPED_BINARY')
            return
        try:
            chunks = self.chunker.chunk_file(content, vfs_path)
            chunk_texts = [c.content for c in chunks]
            pending_nodes: List[Tuple[str, str, str, Dict[str, Any]]] = []
            pending_edges: List[Tuple[str, str, str, float]] = []
            max_workers = getattr(self.neural, 'max_workers', 4)
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                vectors = list(executor.map(self.neural.get_embedding, chunk_texts))
            conn = self.cartridge._get_conn()
            try:
                cursor = conn.cursor()
                for i, chunk in enumerate(chunks):
                    vector = vectors[i]
                    vec_blob = json.dumps(vector).encode('utf-8') if vector else None
                    cursor.execute('\n                        INSERT INTO chunks (file_id, chunk_index, content, embedding, name, type, start_line, end_line)\n                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n                        ', (file_id, i, chunk.content, vec_blob, chunk.name, chunk.type, chunk.start_line, chunk.end_line))
                    chunk_row_id = cursor.lastrowid
                    if vector:
                        try:
                            cursor.execute('INSERT INTO vec_items(rowid, embedding) VALUES (?, ?)', (chunk_row_id, json.dumps(vector)))
                        except Exception as ve:
                            logger.error(f'Vector Index Insert Failed: {ve}')
                    if chunk.type in ['class', 'function']:
                        node_id = f'{vfs_path}::{chunk.name}'
                        pending_nodes.append((node_id, 'chunk', chunk.name, {'parent': vfs_path, 'file_id': file_id, 'chunk_row_id': chunk_row_id, 'chunk_type': chunk.type, 'start_line': chunk.start_line, 'end_line': chunk.end_line}))
                        pending_edges.append((node_id, vfs_path, 'defined_in', 1.0))
                conn.commit()
            finally:
                conn.close()
            pending_nodes.append((vfs_path, 'file', vfs_path.split('/')[-1], {'path': vfs_path, 'file_id': file_id}))
            self._weave_sections(vfs_path, content)
            self._weave_imports(vfs_path, content)
            for nid, ntype, label, data in pending_nodes:
                self.cartridge.add_node(nid, ntype, label, data)
            for src, tgt, rel, w in pending_edges:
                self.cartridge.add_edge(src, tgt, rel, w)
            self.cartridge.update_status(file_id, 'REFINED')
        except Exception as e:
            logger.error(f'Refining failed for {vfs_path}: {e}')
            self.cartridge.update_status(file_id, 'ERROR', {'error': str(e)})

    def _extract_imports_python(self, source_path: str, content: str) -> List[Tuple[str, int, int]]:
        """Returns list of (module_or_path, level, lineno)."""
        out: List[Tuple[str, int, int]] = []
        try:
            tree = ast.parse(content)
        except Exception:
            return out
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    if alias and alias.name:
                        out.append((alias.name, 0, getattr(node, 'lineno', 0)))
            elif isinstance(node, ast.ImportFrom):
                level = int(getattr(node, 'level', 0) or 0)
                mod = getattr(node, 'module', None) or ''
                if mod:
                    out.append((mod, level, getattr(node, 'lineno', 0)))
                else:
                    for alias in node.names:
                        if alias and alias.name:
                            out.append((alias.name, level, getattr(node, 'lineno', 0)))
        return out

    def _resolve_python_import(self, source_path: str, module: str, level: int) -> List[str]:
        """Resolve a python import to possible VFS target paths."""
        self._build_import_index()
        if level <= 0:
            if module in self._module_index:
                return [self._module_index[module]]
            return []
        src_dir = os.path.dirname(source_path).replace('\\', '/').strip('/')
        base_parts = src_dir.split('/') if src_dir else []
        pops = max(level - 1, 0)
        if pops > 0 and pops <= len(base_parts):
            base_parts = base_parts[:-pops]
        rel_base = '/'.join([p for p in base_parts if p])
        mod_path = module.replace('.', '/').strip('/')
        candidates: List[str] = []
        if rel_base:
            if mod_path:
                candidates.append(f'{rel_base}/{mod_path}.py')
                candidates.append(f'{rel_base}/{mod_path}/__init__.py')
            else:
                candidates.append(f'{rel_base}/__init__.py')
        elif mod_path:
            candidates.append(f'{mod_path}.py')
            candidates.append(f'{mod_path}/__init__.py')
        return [c for c in candidates if c in self._path_index]

    def _resolve_js_like_import(self, source_path: str, imp: str) -> List[str]:
        """Resolve require('./x') / import ... from './x' to VFS candidates."""
        self._build_import_index()
        sdir = os.path.dirname(source_path).replace('\\', '/').strip('/')
        raw = imp.strip().replace('\\', '/')
        if not (raw.startswith('.') or raw.startswith('/')):
            return []
        if raw.startswith('/'):
            rel = raw.lstrip('/')
        else:
            rel = os.path.normpath(os.path.join(sdir, raw)).replace('\\', '/').lstrip('./')
        ext_candidates = [rel]
        if not os.path.splitext(rel)[1]:
            ext_candidates.extend([rel + '.js', rel + '.ts', rel + '.json'])
            ext_candidates.extend([rel + '/index.js', rel + '/index.ts'])
        return [c for c in ext_candidates if c in self._path_index]

    def _weave_imports(self, source_path: str, content: str):
        """Scans content for imports and links them in the graph."""
        targets_resolved: List[str] = []
        if source_path.endswith('.py'):
            for mod, level, lineno in self._extract_imports_python(source_path, content):
                resolved = self._resolve_python_import(source_path, mod, level)
                if resolved:
                    for tgt in resolved:
                        self.cartridge.add_edge(source_path, tgt, 'imports_file', 1.0)
                        targets_resolved.append(tgt)
                else:
                    self.cartridge.add_edge(source_path, mod, 'imports_unresolved', 0.25)
            return
        for line in content.splitlines():
            match = self.import_pattern.search(line)
            if not match:
                continue
            imp = match.group(1) or match.group(2)
            if not imp:
                continue
            resolved = self._resolve_js_like_import(source_path, imp)
            if resolved:
                for tgt in resolved:
                    self.cartridge.add_edge(source_path, tgt, 'imports_file', 1.0)
                    targets_resolved.append(tgt)
            else:
                self.cartridge.add_edge(source_path, imp, 'imports_unresolved', 0.25)

    def _weave_sections(self, vfs_path: str, content: str):
        """Creates section/chapter nodes for long-form text and links them to the file node."""
        ext = os.path.splitext(vfs_path)[1].lower()
        if ext not in ('.md', '.markdown', '.txt', '.rst'):
            return
        lines = content.splitlines()
        for idx, line in enumerate(lines):
            lineno = idx + 1
            m = self._md_heading.match(line)
            if m:
                hashes = m.group(1)
                title = (m.group(2) or '').strip()
                level = len(hashes)
                if title:
                    node_id = f'{vfs_path}::section::{lineno}:{title}'
                    self.cartridge.add_node(node_id, 'section', title, {'parent': vfs_path, 'level': level, 'line': lineno})
                    self.cartridge.add_edge(node_id, vfs_path, 'in_file', 1.0)
                continue
            c = self._chapter_heading.match(line)
            if c:
                chap_num = (c.group(2) or '').strip()
                chap_title = (c.group(3) or '').strip()
                title = f'Chapter {chap_num}' + (f': {chap_title}' if chap_title else '')
                node_id = f'{vfs_path}::chapter::{lineno}:{chap_num}'
                self.cartridge.add_node(node_id, 'section', title, {'parent': vfs_path, 'level': 1, 'line': lineno})
                self.cartridge.add_edge(node_id, vfs_path, 'in_file', 1.0)
if __name__ == '__main__':
    try:
        from _CartridgeServiceMS import CartridgeServiceMS
        from _NeuralServiceMS import NeuralServiceMS
        print('Initializing Dependencies...')
        c = CartridgeServiceMS({'db_path': ':memory:'})
        n = NeuralServiceMS()
        svc = RefineryServiceMS({'cartridge': c, 'neural': n})
        print('Service ready:', svc)
        print('Health Check:', svc.get_health())
    except ImportError:
        print('Dependencies not found. Run in project context.')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_RegexWeaverMS.py
--------------------------------------------------------------------------------
import re
import logging
from typing import Any, Dict, List, Optional, Set
from microservice_std_lib import service_metadata, service_endpoint
PY_IMPORT = re.compile('^\\s*(?:from|import)\\s+([\\w\\.]+)')
JS_IMPORT = re.compile('(?:import\\s+.*?from\\s+[\\\'"]|require\\([\\\'"])([\\.\\/\\w\\-_]+)[\\\'"]')
logger = logging.getLogger('RegexWeaver')

@service_metadata(name='RegexWeaver', version='1.0.0', description='Fault-tolerant dependency extractor using Regex.', tags=['parsing', 'dependencies', 'regex'], capabilities=['compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class RegexWeaverMS:
    """
    The Weaver: A fault-tolerant dependency extractor.
    Uses Regex to find imports, making it faster and more permissive
    than AST parsers (works on broken code).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'language': 'str'}, outputs={'dependencies': 'List[str]'}, description='Scans code content for import statements.', tags=['parsing', 'dependencies'], side_effects=[])
    def extract_dependencies(self, content: str, language: str) -> List[str]:
        """
        Scans code content for import statements.
        :param language: 'python' or 'javascript' (includes ts/jsx).
        """
        dependencies: Set[str] = set()
        lines = content.splitlines()
        pattern = PY_IMPORT if language == 'python' else JS_IMPORT
        for line in lines:
            if line.strip().startswith(('#', '//')):
                continue
            if language == 'python':
                match = pattern.match(line)
            else:
                match = pattern.search(line)
            if match:
                raw_dep = match.group(1)
                clean_dep = raw_dep.split('.')[-1].split('/')[-1]
                dependencies.add(clean_dep)
        return sorted(list(dependencies))
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    weaver = RegexWeaverMS()
    print('Service ready:', weaver)
    py_code = '\n    import os\n    from backend.utils import helper\n    # from commented.out import ignore_me\n    import pandas as pd\n    '
    print(f"Python Deps: {weaver.extract_dependencies(py_code, 'python')}")
    js_code = "\n    import React from 'react';\n    const utils = require('./lib/utils');\n    // import hidden from 'hidden';\n    "
    print(f"JS Deps:     {weaver.extract_dependencies(js_code, 'javascript')}")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_RoleManagerMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import sqlite3
import json
import uuid
import logging
import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
REQUIRED = ['pydantic']
MISSING = []
for lib in REQUIRED:
    if importlib.util.find_spec(lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _RoleManagerMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
from pydantic import BaseModel
from microservice_std_lib import service_metadata, service_endpoint
DB_PATH = Path('roles.db')
logger = logging.getLogger('RoleManager')

class RoleModel(BaseModel):
    """Data model representing an Agent Persona."""
    id: str
    name: str
    description: Optional[str] = ''
    system_prompt: str
    knowledge_bases: List[str] = []
    memory_policy: str = 'scratchpad'
    created_at: datetime.datetime

@service_metadata(name='RoleManager', version='1.0.0', description='Manages Agent Personas (Roles), including System Prompts and Memory Settings.', tags=['roles', 'personas', 'db'], capabilities=['db:sqlite'], internal_dependencies=['microservice_std_lib'], external_dependencies=['pydantic'])
class RoleManagerMS:
    """
    The Casting Director: Manages Agent Personas (Roles).
    Persists configuration for System Prompts, Attached KBs, and Memory Settings.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.db_path = Path(self.config.get('db_path', DB_PATH))
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            conn.execute('\n                CREATE TABLE IF NOT EXISTS roles (\n                    id TEXT PRIMARY KEY,\n                    name TEXT UNIQUE NOT NULL,\n                    description TEXT,\n                    system_prompt TEXT NOT NULL,\n                    knowledge_bases_json TEXT,\n                    memory_policy TEXT,\n                    created_at TIMESTAMP\n                )\n            ')

    @service_endpoint(inputs={'name': 'str', 'system_prompt': 'str', 'description': 'str', 'kbs': 'List[str]'}, outputs={'role': 'Dict'}, description='Creates a new Agent Persona.', tags=['roles', 'create'], side_effects=['db:write'])
    def create_role(self, name: str, system_prompt: str, description: str='', kbs: List[str]=None) -> Dict[str, Any]:
        """Creates a new Agent Persona."""
        role_id = str(uuid.uuid4())
        now = datetime.datetime.utcnow()
        kbs_json = json.dumps(kbs or [])
        try:
            with self._get_conn() as conn:
                conn.execute('INSERT INTO roles (id, name, description, system_prompt, knowledge_bases_json, memory_policy, created_at) VALUES (?, ?, ?, ?, ?, ?, ?)', (role_id, name, description, system_prompt, kbs_json, 'scratchpad', now))
            logger.info(f'Created Role: {name}')
            role = self.get_role(name)
            return role.dict() if role else {}
        except sqlite3.IntegrityError:
            raise ValueError(f"Role '{name}' already exists.")

    @service_endpoint(inputs={'name_or_id': 'str'}, outputs={'role': 'Optional[RoleModel]'}, description='Retrieves a role by Name or ID.', tags=['roles', 'read'], side_effects=['db:read'])
    def get_role(self, name_or_id: str) -> Optional[RoleModel]:
        """Retrieves a role by Name or ID."""
        with self._get_conn() as conn:
            row = conn.execute('SELECT * FROM roles WHERE id = ?', (name_or_id,)).fetchone()
            if not row:
                row = conn.execute('SELECT * FROM roles WHERE name = ?', (name_or_id,)).fetchone()
            if not row:
                return None
            return RoleModel(id=row['id'], name=row['name'], description=row['description'], system_prompt=row['system_prompt'], knowledge_bases=json.loads(row['knowledge_bases_json']), memory_policy=row['memory_policy'], created_at=row['created_at'])

    @service_endpoint(inputs={}, outputs={'roles': 'List[Dict]'}, description='Lists all available roles.', tags=['roles', 'read'], side_effects=['db:read'])
    def list_roles(self) -> List[Dict[str, Any]]:
        with self._get_conn() as conn:
            rows = conn.execute('SELECT id, name, description FROM roles').fetchall()
            return [dict(r) for r in rows]

    @service_endpoint(inputs={'name': 'str'}, outputs={}, description='Deletes a role by name.', tags=['roles', 'delete'], side_effects=['db:write'])
    def delete_role(self, name: str):
        with self._get_conn() as conn:
            conn.execute('DELETE FROM roles WHERE name = ?', (name,))
        logger.info(f'Deleted Role: {name}')
if __name__ == '__main__':
    import os
    test_db = Path('test_roles.db')
    if test_db.exists():
        os.remove(test_db)
    logging.basicConfig(level=logging.INFO)
    mgr = RoleManagerMS({'db_path': test_db})
    print('Service ready:', mgr)
    mgr.create_role(name='SeniorDev', system_prompt='You are a senior Python developer. Prefer Clean Code principles.', description='Expert coding assistant', kbs=['python_docs', 'project_repo'])
    role = mgr.get_role('SeniorDev')
    if role:
        print(f'Role: {role.name}')
        print(f'Prompt: {role.system_prompt}')
        print(f'KBs: {role.knowledge_bases}')
    if test_db.exists():
        os.remove(test_db)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_SandboxManagerMS.py
--------------------------------------------------------------------------------
import shutil
import hashlib
import os
import logging
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple, Any
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_EXCLUDES = {'node_modules', '.git', '__pycache__', '.venv', '.mypy_cache', '_logs', 'dist', 'build', '.vscode', '.idea', '_sandbox', '_project_library'}
logger = logging.getLogger('SandboxMgr')

@service_metadata(name='SandboxManager', version='1.0.0', description="The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project for safe experimentation.", tags=['filesystem', 'safety', 'versioning'], capabilities=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class SandboxManagerMS:
    """
    The Safety Harness: Manages a 'Sandbox' mirror of a 'Live' project.
    Allows for safe experimentation, diffing, and atomic promotion of changes.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.live_root = Path(self.config.get('live_path', './project')).resolve()
        self.sandbox_root = Path(self.config.get('sandbox_path', './_sandbox')).resolve()

    @service_endpoint(inputs={'force': 'bool'}, outputs={}, description='Creates or resets the sandbox by mirroring the live project.', tags=['sandbox', 'reset'], side_effects=['filesystem:write'])
    def init_sandbox(self, force: bool=False):
        """
        Creates or resets the sandbox by mirroring the live project.
        """
        if self.sandbox_root.exists():
            if not force:
                raise FileExistsError(f'Sandbox already exists at {self.sandbox_root}')
            logger.info('Wiping existing sandbox...')
            shutil.rmtree(self.sandbox_root)
        logger.info(f'Cloning {self.live_root} -> {self.sandbox_root}...')
        self._mirror_tree(self.live_root, self.sandbox_root)
        logger.info('Sandbox initialized.')

    @service_endpoint(inputs={}, outputs={}, description='Discards all sandbox changes and re-syncs from live.', tags=['sandbox', 'reset'], side_effects=['filesystem:write'])
    def reset_sandbox(self):
        """
        Discards all sandbox changes and re-syncs from live.
        """
        self.init_sandbox(force=True)

    @service_endpoint(inputs={}, outputs={'diff': 'Dict[str, List[str]]'}, description='Compares Sandbox vs Live. Returns added, modified, and deleted files.', tags=['sandbox', 'diff'], side_effects=['filesystem:read'])
    def get_diff(self) -> Dict[str, List[str]]:
        """
        Compares Sandbox vs Live. Returns added, modified, and deleted files.
        """
        sandbox_files = self._scan_files(self.sandbox_root)
        live_files = self._scan_files(self.live_root)
        sandbox_paths = set(sandbox_files.keys())
        live_paths = set(live_files.keys())
        added = sorted(list(sandbox_paths - live_paths))
        deleted = sorted(list(live_paths - sandbox_paths))
        common = sandbox_paths.intersection(live_paths)
        modified = []
        for rel_path in common:
            if sandbox_files[rel_path] != live_files[rel_path]:
                modified.append(rel_path)
        modified.sort()
        return {'added': added, 'modified': modified, 'deleted': deleted}

    @service_endpoint(inputs={}, outputs={'added': 'int', 'modified': 'int', 'deleted': 'int'}, description='Applies changes from Sandbox to Live.', tags=['sandbox', 'promote'], side_effects=['filesystem:write'])
    def promote_changes(self) -> Tuple[int, int, int]:
        """
        Applies changes from Sandbox to Live.
        Returns (added_count, modified_count, deleted_count).
        """
        diff = self.get_diff()
        for rel_path in diff['added'] + diff['modified']:
            src = self.sandbox_root / rel_path
            dst = self.live_root / rel_path
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(src, dst)
        for rel_path in diff['deleted']:
            target = self.live_root / rel_path
            if target.exists():
                os.remove(target)
        logger.info(f"Promoted: {len(diff['added'])} added, {len(diff['modified'])} modified, {len(diff['deleted'])} deleted.")
        return (len(diff['added']), len(diff['modified']), len(diff['deleted']))

    def _mirror_tree(self, src_root: Path, dst_root: Path):
        """Recursive copy that respects the exclusion list."""
        if not dst_root.exists():
            dst_root.mkdir(parents=True, exist_ok=True)
        if not src_root.exists():
            return
        for item in src_root.iterdir():
            if item.name in DEFAULT_EXCLUDES:
                continue
            dst_path = dst_root / item.name
            if item.is_dir():
                self._mirror_tree(item, dst_path)
            else:
                shutil.copy2(item, dst_path)

    def _scan_files(self, root: Path) -> Dict[str, str]:
        """
        Scans directory and returns {relative_path: sha256_hash}.
        """
        file_map = {}
        if not root.exists():
            return {}
        for path in root.rglob('*'):
            if path.is_file() and (not self._is_excluded(path, root)):
                rel = str(path.relative_to(root)).replace('\\', '/')
                file_map[rel] = self._get_hash(path)
        return file_map

    def _is_excluded(self, path: Path, root: Path) -> bool:
        """Checks if any part of the path is in the exclusion list."""
        try:
            rel_parts = path.relative_to(root).parts
            return any((p in DEFAULT_EXCLUDES for p in rel_parts))
        except ValueError:
            return False

    def _get_hash(self, path: Path) -> str:
        """Fast SHA-256 for file content."""
        try:
            return hashlib.sha256(path.read_bytes()).hexdigest()
        except Exception:
            return 'read_error'
if __name__ == '__main__':
    base = Path('test_env')
    live = base / 'live_project'
    box = base / 'sandbox'
    if base.exists():
        shutil.rmtree(base)
    live.mkdir(parents=True)
    (live / 'main.py').write_text("print('v1')")
    (live / 'utils.py').write_text('def help(): pass')
    (live / 'node_modules').mkdir()
    (live / 'node_modules' / 'junk.js').write_text('junk')
    print('--- Initializing Sandbox ---')
    mgr = SandboxManagerMS({'live_path': str(live), 'sandbox_path': str(box)})
    mgr.init_sandbox()
    print('\n--- Modifying Sandbox ---')
    (box / 'main.py').write_text("print('v2')")
    (box / 'new_feature.py').write_text("print('new')")
    os.remove(box / 'utils.py')
    diff = mgr.get_diff()
    print(f"Diff Analysis:\n Added: {diff['added']}\n Modified: {diff['modified']}\n Deleted: {diff['deleted']}")
    print('\n--- Promoting Changes ---')
    mgr.promote_changes()
    print(f"Live 'main.py' content: {(live / 'main.py').read_text()}")
    print(f"Live 'utils.py' exists? {(live / 'utils.py').exists()}")
    if base.exists():
        shutil.rmtree(base)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ScannerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ScannerMS
ENTRY_POINT: _ScannerMS.py
INTERNAL_DEPENDENCIES: base_service, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import os
import time
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
from base_service import BaseService

@service_metadata(name='ScannerMS', version='1.0.0', description='Recursively scans directories, filters junk, and detects binaries.', tags=['filesystem', 'scanner', 'tree'], capabilities=['filesystem:read'], side_effects=['filesystem:read'], internal_dependencies=['base_service', 'microservice_std_lib'], external_dependencies=[])
class ScannerMS(BaseService):
    """
    The Scanner: Walks the file system, filters junk, and detects binary files.
    Generates the tree structure used by the UI.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        super().__init__('ScannerMS')
        self.config = config or {}
        self.IGNORE_DIRS = {'.git', '__pycache__', 'node_modules', 'venv', '.env', '.idea', '.vscode', 'dist', 'build', 'coverage'}
        self.BINARY_EXTENSIONS = {'.pyc', '.pyd', '.exe', '.dll', '.so', '.dylib', '.class', '.jpg', '.png', '.gif', '.ico', '.zip', '.tar', '.gz'}

    @service_endpoint(inputs={'path': 'str', 'depth': 'int'}, outputs={'tree': 'Dict'}, description='Scans the target directory and returns a nested dictionary tree of valid files.', tags=['filesystem', 'scan'], side_effects=['filesystem:read'])
    def scan_directory(self, path: str, depth: int=0) -> Dict[str, Any]:
        """
        Recursively scans a directory, building a tree.
        Excludes ignored directories and binary files.
        """
        if not os.path.exists(path):
            self.log_error(f'Path not found: {path}')
            return {}
        root_name = os.path.basename(path) or path
        tree = {'name': root_name, 'path': path, 'type': 'folder', 'children': []}
        try:
            with os.scandir(path) as it:
                entries = sorted(it, key=lambda e: (not e.is_dir(), e.name.lower()))
                for entry in entries:
                    if entry.name in self.IGNORE_DIRS:
                        continue
                    if entry.is_dir():
                        child_tree = self.scan_directory(entry.path, depth + 1)
                        if child_tree:
                            tree['children'].append(child_tree)
                    elif entry.is_file():
                        _, ext = os.path.splitext(entry.name)
                        if ext.lower() in self.BINARY_EXTENSIONS:
                            continue
                        tree['children'].append({'name': entry.name, 'path': entry.path, 'type': 'file', 'size': entry.stat().st_size})
        except PermissionError:
            self.log_warning(f'Permission denied: {path}')
        return tree

    @service_endpoint(inputs={'tree_node': 'Dict'}, outputs={'files': 'List[str]'}, description='Flattens a tree node into a list of file paths.', tags=['filesystem', 'utility'], side_effects=[])
    def flatten_tree(self, tree_node: Dict[str, Any]) -> List[str]:
        """
        Helper to extract all valid file paths from a tree node 
        (e.g., when the user clicks 'Start Ingest').
        """
        files = []
        if not tree_node:
            return []
        if tree_node.get('type') == 'file':
            files.append(tree_node['path'])
        elif tree_node.get('type') == 'folder' and 'children' in tree_node:
            for child in tree_node['children']:
                files.extend(self.flatten_tree(child))
        return files
if __name__ == '__main__':
    scanner = ScannerMS()
    print('Service ready:', scanner._service_info)
    cwd = os.getcwd()
    print(f'Scanning: {cwd} ...')
    start_time = time.time()
    tree = scanner.scan_directory(cwd)
    duration = time.time() - start_time
    if tree:
        file_count = len(scanner.flatten_tree(tree))
        print(f'Scan complete in {duration:.4f}s')
        print(f'Found {file_count} files.')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ScoutMS.py
--------------------------------------------------------------------------------
import os
import time
import requests
from urllib.parse import urljoin, urlparse
from typing import Dict, List, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

@service_metadata(name='Scout', version='1.0.0', description='The Scout: A depth-aware utility for recursively walking local file systems or crawling websites.', tags=['utility', 'scanner', 'crawler'], capabilities=['filesystem:read', 'web:crawl'], internal_dependencies=['microservice_std_lib'], external_dependencies=['bs4', 'requests'])
class ScoutMS:
    """
    The Scanner: Walks file systems OR crawls websites (Depth-Aware).
    """

    def __init__(self):
        self.IGNORE_DIRS = {'.git', '__pycache__', 'node_modules', 'venv', '.env', '.idea', '.vscode', 'dist', 'build', 'coverage', 'site-packages'}
        self.BINARY_EXTENSIONS = {'.pyc', '.pyd', '.exe', '.dll', '.so', '.dylib', '.class', '.jpg', '.jpeg', '.png', '.gif', '.ico', '.zip', '.tar', '.gz', '.docx', '.xlsx', '.db', '.sqlite', '.sqlite3'}
        self.visited_urls = set()

    def is_binary(self, file_path: str) -> bool:
        _, ext = os.path.splitext(file_path)
        if ext.lower() in self.BINARY_EXTENSIONS:
            return True
        return False

    @service_endpoint(inputs={'root_path': 'str', 'web_depth': 'int'}, outputs={'tree': 'dict'}, description='Main entry point to perform a recursive scan of a directory or a web crawl.', tags=['discovery', 'recursive'], side_effects=['filesystem:read', 'network:read'])
    def scan_directory(self, root_path: str, web_depth: int=0) -> Optional[Dict[str, Any]]:
        """
        Main Entry Point.
        :param root_path: File path or URL.
        :param web_depth: How many links deep to crawl (0 = single page).
        """
        if root_path.startswith('http://') or root_path.startswith('https://'):
            self.visited_urls.clear()
            return self._crawl_web_recursive(root_path, depth=web_depth, origin_domain=urlparse(root_path).netloc)
        target = os.path.abspath(root_path)
        if not os.path.exists(target):
            return None
        if not os.path.isdir(target):
            return self._create_node(target, is_dir=False)
        return self._scan_fs_recursive(target)

    def _crawl_web_recursive(self, url: str, depth: int, origin_domain: str) -> Dict[str, Any]:
        """
        Recursively fetches links.
        """
        parsed = urlparse(url)
        clean_path = parsed.path.strip('/')
        if not clean_path:
            clean_path = 'index.html'
        rel_path = f'web/{parsed.netloc}/{clean_path}'
        node = {'name': url, 'path': url, 'rel_path': rel_path, 'type': 'web', 'children': [], 'checked': True}
        if depth < 0 or url in self.visited_urls:
            return node
        self.visited_urls.add(url)
        if depth > 0 and BeautifulSoup:
            try:
                time.sleep(0.1)
                resp = requests.get(url, timeout=5)
                if resp.status_code == 200:
                    soup = BeautifulSoup(resp.content, 'html.parser')
                    for link in soup.find_all('a', href=True):
                        full_url = urljoin(url, link['href'])
                        parsed = urlparse(full_url)
                        if parsed.netloc == origin_domain and parsed.scheme in ['http', 'https']:
                            if full_url not in self.visited_urls:
                                child_node = self._crawl_web_recursive(full_url, depth - 1, origin_domain)
                                node['children'].append(child_node)
            except Exception as e:
                node['error'] = str(e)
        return node

    def _scan_fs_recursive(self, current_path: str, root_path: str=None) -> Dict[str, Any]:
        if root_path is None:
            root_path = current_path
        node = self._create_node(current_path, is_dir=True, root_path=root_path)
        node['children'] = []
        try:
            with os.scandir(current_path) as it:
                entries = sorted(it, key=lambda e: (not e.is_dir(), e.name.lower()))
                for entry in entries:
                    if entry.is_dir() and entry.name in self.IGNORE_DIRS:
                        continue
                    if entry.name.startswith('.'):
                        continue
                    if entry.is_dir():
                        child = self._scan_fs_recursive(entry.path, root_path=root_path)
                        if child:
                            node['children'].append(child)
                    else:
                        node['children'].append(self._create_node(entry.path, is_dir=False, root_path=root_path))
        except PermissionError:
            node['error'] = 'Access Denied'
        return node

    def _create_node(self, path: str, is_dir: bool, root_path: str=None) -> Dict[str, Any]:
        name = os.path.basename(path)
        rel_path = name
        if root_path:
            try:
                rel_path = os.path.relpath(path, root_path).replace('\\', '/')
            except ValueError:
                pass
        node = {'name': name, 'path': path, 'rel_path': rel_path, 'type': 'folder' if is_dir else 'file', 'children': [], 'checked': False}
        return node

    @service_endpoint(inputs={'tree_node': 'dict'}, outputs={'file_list': 'list'}, description='Flattens a hierarchical tree node structure into a simple list of paths.', tags=['utility', 'processing'])
    def flatten_tree(self, tree_node: Dict[str, Any]) -> List[str]:
        files = []
        if tree_node['type'] in ['file', 'web']:
            files.append(tree_node['path'])
        elif 'children' in tree_node:
            for child in tree_node['children']:
                files.extend(self.flatten_tree(child))
        return files
if __name__ == '__main__':
    svc = ScoutMS()
    print('Service ready:', svc)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    tree = svc.scan_directory(current_dir)
    if tree:
        print(f'Scanned {len(svc.flatten_tree(tree))} files in current directory.')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_SearchEngineMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import sqlite3
import json
import struct
import requests
import os
import logging
from typing import List, Dict, Any, Optional
REQUIRED = ['requests', 'sqlite_vec']
MISSING = []
for lib in REQUIRED:
    import_name = lib.replace('-', '_')
    if importlib.util.find_spec(import_name) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _SearchEngineMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_OLLAMA_URL = 'http://localhost:11434/api'
logger = logging.getLogger('SearchEngine')

@service_metadata(name='SearchEngine', version='1.0.0', description='The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching) on SQLite databases.', tags=['search', 'vector', 'hybrid', 'rag'], capabilities=['db:sqlite', 'network:outbound', 'compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=['requests', 'sqlite_vec'])
class SearchEngineMS:
    """
    The Oracle: Performs Hybrid Search (Vector Similarity + Keyword Matching).
    
    Architecture:
    1. Vector Search: Uses sqlite-vec (vec0) for fast nearest neighbor search.
    2. Keyword Search: Uses SQLite FTS5 for BM25-style text matching.
    3. Reranking: Combines scores using Reciprocal Rank Fusion (RRF).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.model_name = self.config.get('model_name', 'phi3:mini-128k')
        self.ollama_url = self.config.get('ollama_url', DEFAULT_OLLAMA_URL)

    @service_endpoint(inputs={'db_path': 'str', 'query': 'str', 'limit': 'int'}, outputs={'results': 'List[Dict]'}, description='Main entry point. Returns a list of results sorted by relevance (RRF).', tags=['search', 'query'], side_effects=['db:read', 'network:outbound'])
    def search(self, db_path: str, query: str, limit: int=10) -> List[Dict[str, Any]]:
        """
        Main entry point. Returns a list of results sorted by relevance.
        """
        if not os.path.exists(db_path):
            logger.warning(f'Database not found at: {db_path}')
            return []
        conn = sqlite3.connect(db_path)
        try:
            conn.enable_load_extension(True)
            import sqlite_vec
            sqlite_vec.load(conn)
        except Exception as e:
            logger.warning(f'Warning: sqlite_vec not loaded. Vector search may fail. Error: {e}')
        cursor = conn.cursor()
        query_vec = self._get_query_embedding(query)
        if not query_vec:
            logger.info('Vectorization failed. Falling back to keyword-only search.')
            conn.close()
            return self._keyword_search_only(db_path, query, limit)
        vec_bytes = struct.pack(f'{len(query_vec)}f', *query_vec)
        sql = '\n        WITH \n        vec_matches AS (\n            SELECT rowid, distance,\n            row_number() OVER (ORDER BY distance) as rank\n            FROM knowledge_vectors\n            WHERE embedding MATCH ? \n            AND k = 50\n        ),\n        fts_matches AS (\n            SELECT rowid, rank as fts_score,\n            row_number() OVER (ORDER BY rank) as rank\n            FROM documents_fts\n            WHERE documents_fts MATCH ?\n            ORDER BY rank\n            LIMIT 50\n        )\n        SELECT \n            kc.file_path,\n            kc.content,\n            (\n                -- RRF Formula: 1 / (k + rank)\n                COALESCE(1.0 / (60 + v.rank), 0.0) +\n                COALESCE(1.0 / (60 + f.rank), 0.0)\n            ) as rrf_score\n        FROM knowledge_chunks kc\n        LEFT JOIN vec_matches v ON kc.id = v.rowid\n        LEFT JOIN fts_matches f ON kc.id = f.rowid\n        WHERE v.rowid IS NOT NULL OR f.rowid IS NOT NULL\n        ORDER BY rrf_score DESC\n        LIMIT ?;\n        '
        try:
            fts_query = f'"{query}"'
            rows = cursor.execute(sql, (vec_bytes, fts_query, limit)).fetchall()
        except sqlite3.OperationalError as e:
            logger.error(f'Search Error (likely missing schema or sqlite-vec): {e}')
            return []
        finally:
            conn.close()
        results = []
        for r in rows:
            path, content, score = r
            snippet = self._extract_snippet(content, query)
            results.append({'path': path, 'score': round(score, 4), 'snippet': snippet})
        return results

    def _keyword_search_only(self, db_path: str, query: str, limit: int) -> List[Dict[str, Any]]:
        """Fallback if embeddings are offline."""
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        sql = '\n            SELECT file_path, content\n            FROM documents_fts\n            WHERE documents_fts MATCH ?\n            ORDER BY rank\n            LIMIT ?\n        '
        try:
            rows = cursor.execute(sql, (f'"{query}"', limit)).fetchall()
            return [{'path': r[0], 'score': 0.0, 'snippet': self._extract_snippet(r[1], query)} for r in rows]
        except sqlite3.OperationalError as e:
            logger.error(f'Keyword Search Error: {e}')
            return []
        finally:
            conn.close()

    def _get_query_embedding(self, text: str) -> Optional[List[float]]:
        """Call Ollama to get the vector for the search query."""
        try:
            res = requests.post(f'{self.ollama_url}/embeddings', json={'model': self.model_name, 'prompt': text}, timeout=5)
            if res.status_code == 200:
                return res.json().get('embedding')
        except Exception as e:
            logger.error(f'Embedding request failed: {e}')
            return None
        return None

    def _extract_snippet(self, content: str, query: str) -> str:
        """Finds the best window of text around the keyword."""
        if not content:
            return ''
        lower_content = content.lower()
        parts = query.lower().split()
        lower_query = parts[0] if parts else ''
        idx = lower_content.find(lower_query)
        if idx == -1:
            return content[:200].replace('\n', ' ') + '...'
        start = max(0, idx - 60)
        end = min(len(content), idx + 140)
        snippet = content[start:end].replace('\n', ' ')
        return f'...{snippet}...'
if __name__ == '__main__':
    print('Initializing Search Engine...')
    engine = SearchEngineMS({'model_name': 'phi3:mini-128k'})
    print('Service ready:', engine)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_SemanticChunkerMS.py
--------------------------------------------------------------------------------
import ast
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint

@dataclass
class CodeChunk:
    name: str
    type: str
    content: str
    start_line: int
    end_line: int
    docstring: str = ''

@service_metadata(name='SemanticChunker', version='1.0.0', description='The Surgeon: Intelligent Code Splitter that parses source code into logical semantic units (Classes, Functions) using AST.', tags=['utility', 'nlp', 'parser'], capabilities=['python-ast', 'semantic-chunking'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class SemanticChunkerMS:
    """
    Intelligent Code Splitter.
    Parses source code into logical units (Classes, Functions) 
    rather than arbitrary text windows.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'content': 'str', 'filename': 'str'}, outputs={'chunks': 'List[Dict]'}, description='Main entry point to split a file into semantic chunks based on its extension and content.', tags=['processing', 'chunking'], side_effects=[])
    def chunk_file(self, content: str, filename: str) -> List[Dict[str, Any]]:
        """
        Splits file content into chunks.
        Returns a list of dictionaries suitable for JSON response.
        """
        chunks: List[CodeChunk] = []
        if filename.endswith('.py'):
            chunks = self._chunk_python(content)
        elif filename.lower().endswith(('.md', '.txt', '.pdf', '.html', '.htm', '.rst')):
            chunks = self._chunk_generic(content, window_size=800)
        else:
            chunks = self._chunk_generic(content, window_size=1500)
        return [asdict(c) for c in chunks]

    def _chunk_python(self, source: str) -> List[CodeChunk]:
        chunks = []
        try:
            tree = ast.parse(source)
            lines = source.splitlines(keepends=True)

            def get_segment(node):
                start = node.lineno - 1
                end = node.end_lineno if hasattr(node, 'end_lineno') and node.end_lineno else start + 1
                return (''.join(lines[start:end]), start + 1, end)
            for node in tree.body:
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'def {node.name}', type='function', content=text, start_line=s, end_line=e, docstring=doc))
                elif isinstance(node, ast.ClassDef):
                    text, s, e = get_segment(node)
                    doc = ast.get_docstring(node) or ''
                    chunks.append(CodeChunk(name=f'class {node.name}', type='class', content=text, start_line=s, end_line=e, docstring=doc))
            if not chunks:
                return self._chunk_generic(source)
        except SyntaxError:
            return self._chunk_generic(source)
        return chunks

    def _chunk_generic(self, text: str, window_size: int=1500) -> List[CodeChunk]:
        """Sliding window for non-code files."""
        chunks = []
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        lines = text.splitlines(keepends=True)
        current_chunk = []
        current_size = 0
        chunk_idx = 1
        start_line = 1
        for i, line in enumerate(lines):
            current_chunk.append(line)
            current_size += len(line)
            if current_size >= window_size:
                chunks.append(CodeChunk(name=f'Chunk {chunk_idx}', type='text_block', content=''.join(current_chunk), start_line=start_line, end_line=i + 1))
                current_chunk = []
                current_size = 0
                chunk_idx += 1
                start_line = i + 2
        if current_chunk:
            chunks.append(CodeChunk(name=f'Chunk {chunk_idx}', type='text_block', content=''.join(current_chunk), start_line=start_line, end_line=len(lines)))
        return chunks
if __name__ == '__main__':
    svc = SemanticChunkerMS()
    print('Service ready:', svc)
    test_code = "def hello():\n    print('world')\n\nclass Test:\n    pass"
    results = svc.chunk_file(test_code, 'test.py')
    print(f'Extracted {len(results)} semantic chunks.')
    for c in results:
        print(f" - [{c['type']}] {c['name']} ({c['start_line']}-{c['end_line']})")
        print(f" - [{c['type']}] {c['name']} ({c['start_line']}-{c['end_line']})")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ServiceRegistryMS.py
--------------------------------------------------------------------------------
import ast
import json
import uuid
import os
import re
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
OUTPUT_FILE = 'registry.json'
logger = logging.getLogger('ServiceRegistry')

@service_metadata(name='ServiceRegistry', version='1.0.0', description='Scans a library of Python microservices and generates standardized JSON Service Tokens.', tags=['introspection', 'registry', 'parsing'], capabilities=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class ServiceRegistryMS:
    """
    The Tokenizer (v2): Scans a library of Python microservices and generates
    standardized JSON 'Service Tokens'.
    Feature: Hybrid AST/Regex parsing for maximum robustness.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = Path(self.config.get('root_path', '.')).resolve()
        self.registry = []

    @service_endpoint(inputs={'save_to': 'str'}, outputs={'registry': 'List[Dict]'}, description='Scans the file system for microservices and builds a registry.', tags=['introspection', 'scan'], side_effects=['filesystem:read', 'filesystem:write'])
    def scan(self, save_to: str=OUTPUT_FILE) -> List[Dict[str, Any]]:
        logger.info(f'Scanning for microservices in: {self.root}')
        self.registry = []
        if self.root.exists():
            for item in self.root.iterdir():
                if item.is_dir() and item.name.startswith('_') and item.name.endswith('MS'):
                    self._process_folder(item)
                elif item.is_file() and item.name.startswith('_') and item.name.endswith('MS.py'):
                    token = self._tokenize_file(item)
                    if token:
                        self.registry.append(token)
        try:
            with open(save_to, 'w', encoding='utf-8') as f:
                json.dump(self.registry, f, indent=2)
            logger.info(f'‚úÖ Registry built. Found {len(self.registry)} services. Saved to {save_to}')
        except Exception as e:
            logger.error(f'Failed to save registry: {e}')
        return self.registry

    def _process_folder(self, folder: Path):
        candidates = list(folder.glob('*.py'))
        for file in candidates:
            if file.name.startswith('__') or len(candidates) == 1:
                token = self._tokenize_file(file)
                if token:
                    self.registry.append(token)
                    logger.info(f"  + Tokenized: {token['name']}")
                    break

    def _tokenize_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source = f.read()
            try:
                return self._ast_parse(source, file_path)
            except Exception:
                return self._regex_parse(source, file_path)
        except Exception as e:
            logger.warning(f'  - Failed to read {file_path.name}: {e}')
            return None

    def _ast_parse(self, source: str, file_path: Path):
        tree = ast.parse(source)
        target_class = None
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef) and node.name.endswith('MS'):
                target_class = node
                break
        if not target_class:
            return None
        return self._build_token(name=target_class.name, doc=ast.get_docstring(target_class) or '', methods=[(n.name, [a.arg for a in n.args.args if a.arg != 'self'], ast.get_docstring(n) or '') for n in target_class.body if isinstance(n, ast.FunctionDef) and (not n.name.startswith('_'))], deps=self._extract_ast_imports(tree), file_path=file_path)

    def _regex_parse(self, source: str, file_path: Path):
        class_match = re.search('class\\s+(\\w+MS)', source)
        if not class_match:
            return None
        name = class_match.group(1)
        methods = []
        for match in re.finditer('def\\s+(\\w+)\\s*\\((.*?)\\):', source):
            m_name = match.group(1)
            if not m_name.startswith('_'):
                args = [a.strip().split(':')[0] for a in match.group(2).split(',') if a.strip() != 'self']
                methods.append((m_name, args, 'Regex extracted'))
        return self._build_token(name, 'Parsed via Regex', methods, [], file_path)

    def _build_token(self, name, doc, methods, deps, file_path):
        namespace = uuid.uuid5(uuid.NAMESPACE_DNS, 'microservice.library')
        token_id = f'MS_{uuid.uuid5(namespace, name).hex[:8].upper()}'
        method_dict = {m_name: {'args': m_args, 'doc': m_doc.strip()} for m_name, m_args, m_doc in methods}
        try:
            rel_path = str(file_path.relative_to(self.root)).replace('\\', '/')
        except ValueError:
            rel_path = file_path.name
        return {'token_id': token_id, 'name': name, 'path': rel_path, 'description': doc.strip(), 'methods': method_dict, 'dependencies': sorted(deps)}

    def _extract_ast_imports(self, tree):
        deps = set()
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for n in node.names:
                    deps.add(n.name.split('.')[0])
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    deps.add(node.module.split('.')[0])
        return list(deps)
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    svc = ServiceRegistryMS()
    print('Service ready:', svc)
    svc.scan()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_SpinnerThingyMaBobberMS.py
--------------------------------------------------------------------------------
import tkinter as tk
import math
import colorsys
import time
from typing import Optional, Dict, Any
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='SpinnerTHINGYMABOBBER', version='1.0.0', description='Interactive visual spinner widget for OBS/UI overlays.', tags=['ui', 'widget', 'visuals'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class SpinnerThingyMaBobberMS:
    """
    The Visualizer: An interactive spinner widget.
    Useful for "Processing..." screens or OBS overlays.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = tk.Tk()
        self.root.title('OBS Interactive Spinner')
        self.root.configure(bg='black')
        self.root.geometry('600x600')
        self.canvas = tk.Canvas(self.root, bg='black', highlightthickness=0)
        self.canvas.pack(fill='both', expand=True)
        self.angle_1 = 0
        self.angle_2 = 0
        self.angle_3 = 0
        self.hue = 0
        self.user_text = 'PROCESSING'
        self.cursor_visible = True
        self.last_cursor_toggle = time.time()
        self.root.bind('<Key>', self.handle_keypress)
        self.animate()

    @service_endpoint(inputs={}, outputs={}, description='Launches the GUI main loop.', tags=['ui', 'execution'], mode='sync', side_effects=['ui:block'])
    def launch(self):
        """Starts the Tkinter main event loop."""
        self.root.mainloop()

    def handle_keypress(self, event):
        if event.keysym == 'BackSpace':
            self.user_text = self.user_text[:-1]
        elif event.keysym == 'Escape':
            self.user_text = 'PROCESSING'
        elif len(event.char) == 1 and ord(event.char) >= 32:
            if len(self.user_text) < 25:
                self.user_text += event.char.upper()

    def get_neon_color(self, offset=0):
        h = (self.hue + offset) % 1.0
        r, g, b = colorsys.hsv_to_rgb(h, 1.0, 1.0)
        return f'#{int(r * 255):02x}{int(g * 255):02x}{int(b * 255):02x}'

    def draw_arc(self, cx, cy, radius, width, start, extent, color):
        x0 = cx - radius
        y0 = cy - radius
        x1 = cx + radius
        y1 = cy + radius
        self.canvas.create_arc(x0, y0, x1, y1, start=start, extent=extent, outline=color, width=width, style='arc')

    def animate(self):
        self.canvas.delete('all')
        w = self.canvas.winfo_width()
        h = self.canvas.winfo_height()
        if w < 10 or h < 10:
            self.root.after(50, self.animate)
            return
        cx, cy = (w / 2, h / 2)
        base_size = min(w, h) / 2
        self.hue += 0.005
        if self.hue > 1:
            self.hue = 0
        c1 = self.get_neon_color(0.0)
        c2 = self.get_neon_color(0.3)
        c3 = self.get_neon_color(0.6)
        r1 = base_size * 0.85
        self.angle_1 -= 3
        for i in range(3):
            self.draw_arc(cx, cy, r1, base_size * 0.08, self.angle_1 + i * 120, 80, c1)
        r2 = base_size * 0.65
        self.angle_2 += 5
        self.draw_arc(cx, cy, r2, base_size * 0.05, self.angle_2, 160, c2)
        self.draw_arc(cx, cy, r2, base_size * 0.05, self.angle_2 + 180, 160, c2)
        r3 = base_size * 0.45
        self.angle_3 -= 8
        self.draw_arc(cx, cy, r3, base_size * 0.04, self.angle_3, 300, c3)
        if time.time() - self.last_cursor_toggle > 0.5:
            self.cursor_visible = not self.cursor_visible
            self.last_cursor_toggle = time.time()
        display_text = self.user_text + ('_' if self.cursor_visible else ' ')
        text_len = max(len(self.user_text), 1)
        scaling_factor = 1.0
        if text_len > 8:
            scaling_factor = 8 / text_len
        font_size = int(base_size * 0.15 * scaling_factor)
        font_size = max(font_size, 10)
        self.canvas.create_text(cx, cy, text=display_text, fill='white', font=('Courier', font_size, 'bold'))
        self.root.after(30, self.animate)
if __name__ == '__main__':
    print('Launching Spinner ThingyMaBobber...')
    svc = SpinnerThingyMaBobberMS()
    svc.launch()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_SysInspectorMS.py
--------------------------------------------------------------------------------
import platform
import subprocess
import sys
import datetime
import logging
from typing import Any, Dict, List, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('SysInspector')

@service_metadata(name='SysInspector', version='1.0.0', description='Gathers hardware and environment statistics via shell commands.', tags=['system', 'audit', 'hardware'], capabilities=['os:shell', 'compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class SysInspectorMS:
    """
    The Auditor: Gathers hardware and environment statistics.
    Supports: Windows (WMIC), Linux (lscpu/lspci), and macOS (sysctl/system_profiler).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={}, outputs={'report': 'str'}, description='Runs the full audit and returns a formatted string report.', tags=['system', 'report'], side_effects=['os:read'])
    def generate_report(self) -> str:
        """
        Runs the full audit and returns a formatted string report.
        """
        system_os = platform.system()
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        report = [f'System Audit Report', f'Generated: {timestamp}', f'OS: {system_os} {platform.release()} ({platform.machine()})', '-' * 40, '']
        report.append('--- Hardware Information ---')
        if system_os == 'Windows':
            report.extend(self._audit_windows())
        elif system_os == 'Linux':
            report.extend(self._audit_linux())
        elif system_os == 'Darwin':
            report.extend(self._audit_mac())
        else:
            report.append('Unsupported Operating System for detailed hardware audit.')
        report.append('\n--- Software Environment ---')
        report.append(f'Python Version: {platform.python_version()}')
        report.append(f'Python Executable: {sys.executable}')
        return '\n'.join(report)

    def _run_cmd(self, cmd: str) -> str:
        """Helper to run shell commands safely."""
        try:
            result = subprocess.run(cmd, text=True, capture_output=True, check=False, shell=True, timeout=5)
            if result.returncode == 0 and result.stdout:
                return result.stdout.strip()
            elif result.stderr:
                return f'[Cmd Error]: {result.stderr.strip()}'
            return '[No Output]'
        except Exception as e:
            return f'[Execution Error]: {e}'

    def _audit_windows(self) -> List[str]:
        data = []
        data.append('CPU: ' + self._run_cmd('wmic cpu get name'))
        data.append('GPU: ' + self._run_cmd('wmic path win32_videocontroller get name'))
        try:
            mem_str = self._run_cmd('wmic computersystem get totalphysicalmemory').splitlines()[-1]
            mem_bytes = int(mem_str)
            data.append(f'Memory: {mem_bytes / 1024 ** 3:.2f} GB')
        except:
            data.append('Memory: Could not retrieve total physical memory.')
        data.append('\nDisks:')
        data.append(self._run_cmd('wmic diskdrive get model,size'))
        return data

    def _audit_linux(self) -> List[str]:
        data = []
        data.append('CPU: ' + self._run_cmd("lscpu | grep 'Model name'"))
        data.append('GPU: ' + self._run_cmd('lspci | grep -i vga'))
        data.append('Memory:\n' + self._run_cmd('free -h'))
        data.append('\nDisks:\n' + self._run_cmd('lsblk -o NAME,SIZE,MODEL'))
        return data

    def _audit_mac(self) -> List[str]:
        data = []
        data.append('CPU: ' + self._run_cmd('sysctl -n machdep.cpu.brand_string'))
        data.append('GPU:\n' + self._run_cmd("system_profiler SPDisplaysDataType | grep -E 'Chipset Model|VRAM'"))
        data.append('Memory Details:\n' + self._run_cmd("system_profiler SPMemoryDataType | grep -E 'Size|Type|Speed'"))
        try:
            mem_bytes = int(self._run_cmd('sysctl -n hw.memsize'))
            data.append(f'Total Memory: {mem_bytes / 1024 ** 3:.2f} GB')
        except:
            pass
        data.append('\nDisks:\n' + self._run_cmd('diskutil list physical'))
        return data
if __name__ == '__main__':
    inspector = SysInspectorMS()
    print('Service ready:', inspector)
    print('Running System Inspector...')
    print('\n' + inspector.generate_report())

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TasklistVaultMS.py
--------------------------------------------------------------------------------
import sqlite3
import uuid
import logging
import datetime
import json
from pathlib import Path
from typing import List, Optional, Dict, Any, Literal
from microservice_std_lib import service_metadata, service_endpoint
DB_PATH = Path(__file__).parent / 'task_vault.db'
logger = logging.getLogger('TaskVault')
TaskStatus = Literal['Pending', 'Running', 'Complete', 'Error', 'Awaiting-Approval']

@service_metadata(name='TaskVault', version='1.0.0', description='Persistent SQLite engine for hierarchical task management.', tags=['tasks', 'db', 'project-management'], capabilities=['db:sqlite', 'filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TasklistVaultMS:
    """
    The Taskmaster: A persistent SQLite engine for hierarchical task management.
    Supports infinite nesting of sub-tasks and status tracking.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.db_path = self.config.get('db_path', DB_PATH)
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            conn.execute('\n                CREATE TABLE IF NOT EXISTS task_lists (\n                    id TEXT PRIMARY KEY,\n                    name TEXT NOT NULL,\n                    created_at TIMESTAMP\n                )\n            ')
            conn.execute("\n                CREATE TABLE IF NOT EXISTS tasks (\n                    id TEXT PRIMARY KEY,\n                    list_id TEXT NOT NULL,\n                    parent_id TEXT,\n                    content TEXT NOT NULL,\n                    status TEXT DEFAULT 'Pending',\n                    result TEXT,\n                    created_at TIMESTAMP,\n                    updated_at TIMESTAMP,\n                    FOREIGN KEY(list_id) REFERENCES task_lists(id) ON DELETE CASCADE,\n                    FOREIGN KEY(parent_id) REFERENCES tasks(id) ON DELETE CASCADE\n                )\n            ")

    @service_endpoint(inputs={'name': 'str'}, outputs={'list_id': 'str'}, description='Creates a new task list and returns its ID.', tags=['tasks', 'create'], side_effects=['db:write'])
    def create_list(self, name: str) -> str:
        """Creates a new task list and returns its ID."""
        list_id = str(uuid.uuid4())
        now = datetime.datetime.utcnow()
        with self._get_conn() as conn:
            conn.execute('INSERT INTO task_lists (id, name, created_at) VALUES (?, ?, ?)', (list_id, name, now))
        logger.info(f"Created Task List: '{name}' ({list_id})")
        return list_id

    @service_endpoint(inputs={}, outputs={'lists': 'List[Dict]'}, description='Returns metadata for all task lists.', tags=['tasks', 'read'], side_effects=['db:read'])
    def get_lists(self) -> List[Dict[str, Any]]:
        """Returns metadata for all task lists."""
        with self._get_conn() as conn:
            rows = conn.execute('SELECT * FROM task_lists ORDER BY created_at DESC').fetchall()
            return [dict(r) for r in rows]

    @service_endpoint(inputs={'list_id': 'str', 'content': 'str', 'parent_id': 'Optional[str]'}, outputs={'task_id': 'str'}, description='Adds a task (or sub-task) to a list.', tags=['tasks', 'write'], side_effects=['db:write'])
    def add_task(self, list_id: str, content: str, parent_id: Optional[str]=None) -> str:
        """Adds a task (or sub-task) to a list."""
        task_id = str(uuid.uuid4())
        now = datetime.datetime.utcnow()
        with self._get_conn() as conn:
            conn.execute('INSERT INTO tasks (id, list_id, parent_id, content, status, created_at, updated_at) \n                   VALUES (?, ?, ?, ?, ?, ?, ?)', (task_id, list_id, parent_id, content, 'Pending', now, now))
        return task_id

    @service_endpoint(inputs={'task_id': 'str', 'content': 'str', 'status': 'str', 'result': 'str'}, outputs={}, description="Updates a task's details.", tags=['tasks', 'update'], side_effects=['db:write'])
    def update_task(self, task_id: str, content: str=None, status: TaskStatus=None, result: str=None):
        """Updates a task's details."""
        updates = []
        params = []
        if content:
            updates.append('content = ?')
            params.append(content)
        if status:
            updates.append('status = ?')
            params.append(status)
        if result:
            updates.append('result = ?')
            params.append(result)
        if not updates:
            return
        updates.append('updated_at = ?')
        params.append(datetime.datetime.utcnow())
        params.append(task_id)
        sql = f"UPDATE tasks SET {', '.join(updates)} WHERE id = ?"
        with self._get_conn() as conn:
            conn.execute(sql, params)
        logger.info(f'Updated task {task_id}')

    @service_endpoint(inputs={'list_id': 'str'}, outputs={'tree': 'Dict[str, Any]'}, description='Fetches a list and reconstructs the full hierarchy of tasks.', tags=['tasks', 'read'], side_effects=['db:read'])
    def get_full_tree(self, list_id: str) -> Dict[str, Any]:
        """
        Fetches a list and reconstructs the full hierarchy of tasks.
        """
        with self._get_conn() as conn:
            list_row = conn.execute('SELECT * FROM task_lists WHERE id = ?', (list_id,)).fetchone()
            if not list_row:
                return {}
            task_rows = conn.execute('SELECT * FROM tasks WHERE list_id = ?', (list_id,)).fetchall()
        tasks_by_id = {}
        for r in task_rows:
            t = dict(r)
            t['sub_tasks'] = []
            tasks_by_id[t['id']] = t
        root_tasks = []
        for t_id, task in tasks_by_id.items():
            parent_id = task['parent_id']
            if parent_id and parent_id in tasks_by_id:
                tasks_by_id[parent_id]['sub_tasks'].append(task)
            else:
                root_tasks.append(task)
        return {'id': list_row['id'], 'name': list_row['name'], 'tasks': root_tasks}

    @service_endpoint(inputs={'list_id': 'str'}, outputs={}, description='Deletes a task list and all its tasks.', tags=['tasks', 'delete'], side_effects=['db:write'])
    def delete_list(self, list_id: str):
        with self._get_conn() as conn:
            conn.execute('DELETE FROM task_lists WHERE id = ?', (list_id,))
        logger.info(f'Deleted list {list_id}')
if __name__ == '__main__':
    import os
    test_db = Path('test_task_vault.db')
    if test_db.exists():
        os.remove(test_db)
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    vault = TasklistVaultMS({'db_path': test_db})
    print('Service ready:', vault)
    plan_id = vault.create_list('System Upgrade Plan')
    t1 = vault.add_task(plan_id, 'Backup Database')
    t2 = vault.add_task(plan_id, 'Update Server')
    t2_1 = vault.add_task(plan_id, 'Stop Services', parent_id=t2)
    t2_2 = vault.add_task(plan_id, 'Run Installer', parent_id=t2)
    vault.update_task(t1, status='Complete', result='Backup saved to /tmp/bk.tar')
    vault.update_task(t2_1, status='Running')
    tree = vault.get_full_tree(plan_id)
    print(f"\n--- {tree.get('name')} ---")

    def print_node(node, indent=0):
        status_icon = '‚úì' if node['status'] == 'Complete' else '‚óã'
        print(f"{'  ' * indent}{status_icon} {node['content']} [{node['status']}]")
        for child in node['sub_tasks']:
            print_node(child, indent + 1)
    if 'tasks' in tree:
        for task in tree['tasks']:
            print_node(task)
    if test_db.exists():
        os.remove(test_db)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TelemetryServiceMS.py
--------------------------------------------------------------------------------
import logging
import queue
import time
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('TelemetryService')

class QueueHandler(logging.Handler):
    """
    Custom logging handler that pushes log records into a thread-safe queue.
    """

    def __init__(self, log_queue: queue.Queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.format(record)
        self.log_queue.put(record)

@service_metadata(name='TelemetryService', version='1.0.0', description='The Nervous System: Watches the thread-safe LogQueue and updates GUI components with real-time status.', tags=['utility', 'logging', 'telemetry'], capabilities=['log-redirection', 'real-time-updates'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TelemetryServiceMS:
    """
    The Nervous System.
    Watches the thread-safe LogQueue and updates the GUI Panels.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = self.config.get('root')
        self.panels = self.config.get('panels')
        self.log_queue = queue.Queue()
        self.start_time = time.time()
        self._heartbeat_count = 0
        self._setup_logging_hook()

    @service_endpoint(inputs={}, outputs={'status': 'str', 'uptime': 'float', 'queue_depth': 'int'}, description='Standardized health check to verify the operational state of the telemetry pipeline.', tags=['diagnostic', 'health'], side_effects=[])
    def get_health(self) -> Dict[str, Any]:
        """Returns the operational status of the TelemetryServiceMS."""
        return {'status': 'online', 'uptime': time.time() - self.start_time, 'queue_depth': self.log_queue.qsize()}

    def _setup_logging_hook(self):
        """Redirects Python's standard logging to our Queue."""
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        q_handler = QueueHandler(self.log_queue)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%H:%M:%S')
        q_handler.setFormatter(formatter)
        root_logger.addHandler(q_handler)

    @service_endpoint(inputs={}, outputs={}, description='Initiates the telemetry service and begins the asynchronous GUI log-polling loop.', tags=['lifecycle', 'event-loop'], mode='async', side_effects=['ui:update'])
    def start(self):
        """Begins the GUI update loop."""
        logger.info('Telemetry Service starting...')
        self._poll_queue()

    @service_endpoint(inputs={}, outputs={'alive': 'bool', 'heartbeat': 'int'}, description='Verifies that the GUI polling loop is actively processing the log queue.', tags=['diagnostic', 'heartbeat'], side_effects=[])
    def ping(self) -> Dict[str, Any]:
        """Allows an agent to verify the pulse of the UI loop."""
        return {'alive': True, 'heartbeat': self._heartbeat_count}

    def _poll_queue(self):
        """The heartbeat that drains the queue into the GUI."""
        if not self.root or not self.panels:
            return
        self._heartbeat_count += 1
        try:
            while True:
                record = self.log_queue.get_nowait()
                msg = f'[{record.levelname}] {record.message}'
                if hasattr(self.panels, 'log'):
                    self.panels.log(msg)
        except queue.Empty:
            pass
        finally:
            if hasattr(self.root, 'after'):
                self.root.after(100, self._poll_queue)
if __name__ == '__main__':

    class MockRoot:

        def after(self, ms, func):
            pass

    class MockPanels:

        def log(self, msg):
            print(f'[UI LOG]: {msg}')
    svc = TelemetryServiceMS({'root': MockRoot(), 'panels': MockPanels()})
    print('Service ready:', svc)
    logger.info('Internal test message')
    svc._poll_queue()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TextChunkerMS.py
--------------------------------------------------------------------------------
import logging
from typing import Any, Dict, List, Optional, Tuple
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('TextChunker')

@service_metadata(name='TextChunker', version='1.0.0', description='Splits text into chunks using various strategies (chars, lines).', tags=['chunking', 'nlp', 'rag'], capabilities=['compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TextChunkerMS:
    """
    The Butcher: A unified service for splitting text into digestible chunks
    for RAG (Retrieval Augmented Generation).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'text': 'str', 'chunk_size': 'int', 'chunk_overlap': 'int'}, outputs={'chunks': 'List[str]'}, description='Standard sliding window split by character count.', tags=['chunking', 'chars'], side_effects=[])
    def chunk_by_chars(self, text: str, chunk_size: int=500, chunk_overlap: int=50) -> List[str]:
        """
        Standard Sliding Window. Best for prose/documentation.
        Splits purely by character count.
        """
        if chunk_size <= 0:
            raise ValueError('chunk_size must be positive')
        chunks = []
        start = 0
        text_length = len(text)
        while start < text_length:
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            if end >= text_length:
                break
            start += chunk_size - chunk_overlap
        return chunks

    @service_endpoint(inputs={'text': 'str', 'max_lines': 'int', 'max_chars': 'int'}, outputs={'chunks': 'List[Dict]'}, description='Line-preserving chunker, best for code.', tags=['chunking', 'lines', 'code'], side_effects=[])
    def chunk_by_lines(self, text: str, max_lines: int=200, max_chars: int=4000) -> List[Dict[str, Any]]:
        """
        Line-Preserving Chunker. Best for Code.
        Respects line boundaries and returns metadata about line numbers.
        """
        lines = text.splitlines()
        chunks = []
        start = 0
        while start < len(lines):
            end = min(start + max_lines, len(lines))
            chunk_str = '\n'.join(lines[start:end])
            while len(chunk_str) > max_chars and end > start + 1:
                end -= 1
                chunk_str = '\n'.join(lines[start:end])
            chunks.append({'text': chunk_str, 'start_line': start + 1, 'end_line': end})
            start = end
        return chunks
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    chunker = TextChunkerMS()
    print('Service ready:', chunker)
    print('--- Prose Chunking ---')
    lorem = 'A' * 100
    result = chunker.chunk_by_chars(lorem, chunk_size=40, chunk_overlap=10)
    for i, c in enumerate(result):
        print(f'Chunk {i}: len={len(c)}')
    print('\n--- Code Chunking ---')
    code = '\n'.join([f"print('Line {i}')" for i in range(1, 10)])
    result_code = chunker.chunk_by_lines(code, max_lines=3, max_chars=100)
    for i, c in enumerate(result_code):
        print(f"Chunk {i}: Lines {c['start_line']}-{c['end_line']}")

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_ThoughtStreamMS.py
--------------------------------------------------------------------------------
import tkinter as tk
from tkinter import ttk
import datetime
from typing import Any, Dict, Optional, List
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='ThoughtStream', version='1.0.0', description='A UI widget for displaying a stream of AI thoughts/logs.', tags=['ui', 'stream', 'logs', 'widget'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class ThoughtStreamMS(ttk.Frame):
    """
    The Neural Inspector: A UI widget for displaying a stream of AI thoughts/logs
    visualized as 'bubbles' with sparklines.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        super().__init__(parent)
        self.header = ttk.Label(self, text='NEURAL INSPECTOR', font=('Consolas', 10, 'bold'))
        self.header.pack(fill='x', padx=5, pady=5)
        self.canvas = tk.Canvas(self, bg='#13131f', highlightthickness=0)
        self.scrollbar = ttk.Scrollbar(self, orient='vertical', command=self.canvas.yview)
        self.scrollable_frame = tk.Frame(self.canvas, bg='#13131f')
        self.scrollable_frame.bind('<Configure>', lambda e: self.canvas.configure(scrollregion=self.canvas.bbox('all')))
        self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor='nw', width=340)
        self.canvas.configure(yscrollcommand=self.scrollbar.set)
        self.canvas.pack(side='left', fill='both', expand=True)
        self.scrollbar.pack(side='right', fill='y')

    @service_endpoint(inputs={'filename': 'str', 'chunk_id': 'int', 'content': 'str', 'vector_preview': 'List[float]', 'color': 'str'}, outputs={}, description='Adds a new thought bubble to the visual stream.', tags=['ui', 'update'], side_effects=['ui:update'])
    def add_thought_bubble(self, filename: str, chunk_id: int, content: str, vector_preview: List[float], color: str):
        """
        Mimics the 'InspectorFrame' from your React code.
        """
        bubble = tk.Frame(self.scrollable_frame, bg='#1a1a25', highlightbackground='#444', highlightthickness=1)
        bubble.pack(fill='x', padx=5, pady=5)
        ts = datetime.datetime.now().strftime('%H:%M:%S')
        header_lbl = tk.Label(bubble, text=f'{filename} #{chunk_id} [{ts}]', fg='#007ACC', bg='#1a1a25', font=('Consolas', 8))
        header_lbl.pack(anchor='w', padx=5, pady=2)
        snippet = content[:400] + '...' if len(content) > 400 else content
        content_lbl = tk.Label(bubble, text=snippet, fg='#ccc', bg='#10101a', font=('Consolas', 8), justify='left', wraplength=300)
        content_lbl.pack(fill='x', padx=5, pady=2)
        self._draw_sparkline(bubble, vector_preview, color)

    def _draw_sparkline(self, parent, vector: List[float], color: str):
        """
        Recreates the 'vector_preview' visual from React using a micro-canvas.
        """
        h = 30
        w = 300
        cv = tk.Canvas(parent, height=h, width=w, bg='#1a1a25', highlightthickness=0)
        cv.pack(padx=5, pady=2)
        if not vector:
            return
        bar_w = w / len(vector) if len(vector) > 0 else 0
        for i, val in enumerate(vector):
            mag = abs(val)
            bar_h = mag * h
            x0 = i * bar_w
            y0 = h - bar_h
            x1 = x0 + bar_w
            y1 = h
            cv.create_rectangle(x0, y0, x1, y1, fill=color, outline='')
if __name__ == '__main__':
    import random
    root = tk.Tk()
    root.title('Thought Stream Test')
    root.geometry('400x600')
    stream = ThoughtStreamMS({'parent': root})
    print('Service ready:', stream)
    stream.pack(fill='both', expand=True)
    fake_vector = [random.uniform(-1, 1) for _ in range(20)]
    stream.add_thought_bubble('ExplorerView.tsx', 1, "import React from 'react'...", fake_vector, '#FF00FF')
    fake_vector_2 = [random.uniform(-1, 1) for _ in range(20)]
    stream.add_thought_bubble('Backend.py', 42, 'def process_data(self): pass', fake_vector_2, '#00FF00')
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TkinterAppShellMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterAppShellMS
ENTRY_POINT: _TkinterAppShellMS.py
INTERNAL_DEPENDENCIES: _TkinterThemeManagerMS, microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import tkinter as tk
from tkinter import ttk
import logging
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
try:
    from _TkinterThemeManagerMS import TkinterThemeManagerMS
except ImportError:
    TkinterThemeManagerMS = None
logger = logging.getLogger('AppShell')

@service_metadata(name='TkinterAppShell', version='2.0.0', description='The Application Container. Manages the root window, main loop, and global layout.', tags=['ui', 'core', 'lifecycle'], capabilities=['ui:root', 'ui:gui'], internal_dependencies=['_TkinterThemeManagerMS', 'microservice_std_lib'], external_dependencies=[])
class TkinterAppShellMS:
    """
    The Mother Ship.
    Owns the Tkinter Root. All other UI microservices dock into this.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.root = tk.Tk()
        self.root.withdraw()
        self.theme_svc = self.config.get('theme_manager')
        if not self.theme_svc and TkinterThemeManagerMS:
            self.theme_svc = TkinterThemeManagerMS()
        self.colors = self.theme_svc.get_theme() if self.theme_svc else {}
        self._configure_root()

    def _configure_root(self):
        self.root.title(self.config.get('title', 'Microservice OS'))
        self.root.geometry(self.config.get('geometry', '1200x800'))
        bg = self.colors.get('background', '#1e1e1e')
        self.root.configure(bg=bg)
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('TFrame', background=bg)
        style.configure('TLabel', background=bg, foreground=self.colors.get('foreground', '#ccc'))
        style.configure('TButton', background=self.colors.get('panel_bg', '#333'), foreground='white')
        self.main_container = tk.Frame(self.root, bg=bg)
        self.main_container.pack(fill='both', expand=True, padx=5, pady=5)

    @service_endpoint(inputs={}, outputs={}, description='Starts the GUI Main Loop.', tags=['lifecycle', 'start'], mode='sync', side_effects=['ui:block'])
    def launch(self):
        """Ignition sequence start."""
        self.root.deiconify()
        logger.info('AppShell Launched.')
        self.root.mainloop()

    @service_endpoint(inputs={}, outputs={'container': 'tk.Frame'}, description='Returns the main content area for other services to dock into.', tags=['ui', 'layout'])
    def get_main_container(self):
        """Other services call this to know where to .pack() themselves."""
        return self.main_container

    @service_endpoint(inputs={}, outputs={}, description='Gracefully shuts down the application.', tags=['lifecycle', 'stop'], side_effects=['ui:close'])
    def shutdown(self):
        self.root.quit()
if __name__ == '__main__':
    shell = TkinterAppShellMS({'title': 'Test Shell'})
    shell.launch()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TkinterBootstrap.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterBootstrap
ENTRY_POINT: _TkinterBootstrap.py
DEPENDENCIES: None
"""
# --- 1. Import The UI Fabric ---
from _TkinterThemeManagerMS import TkinterThemeManagerMS
from _TkinterAppShellMS import TkinterAppShellMS
from _TkinterSmartExplorerMS import TkinterSmartExplorerMS

# --- 2. Import Capabilities (The Brains) ---
# Assuming you have these from previous steps
try:
    from _ScoutMS import ScoutMS
except ImportError:
    ScoutMS = None

def main():
    print("--- BOOTING MICROSERVICE UI ---")

    # A. Initialize Theme
    theme_mgr = TkinterThemeManagerMS()
    
    # B. Initialize Shell (Pass the theme manager so it knows the colors)
    app = TkinterAppShellMS({
        "theme_manager": theme_mgr, 
        "title": "Neural Command Center",
        "geometry": "1000x700"
    })
    
    # C. Initialize Logic Services
    scout = ScoutMS() if ScoutMS else None

    # --- D. COMPOSE THE UI ---
    # Get the docking bay
    main_deck = app.get_main_container()

    # 1. Dock the Explorer on the Left
    explorer = TkinterSmartExplorerMS({
        "parent": main_deck, 
        "theme": theme_mgr.get_theme()
    })
    explorer.pack(side="left", fill="y", padx=2, pady=2)

    # 2. Load Data (If Scout is available)
    if scout:
        print("Scanning current directory...")
        data = scout.scan_directory(".") # Scan root
        explorer.load_data(data)
    else:
        # Fallback data if Scout isn't found
        explorer.load_data({"name": "No Scout Found", "type": "error", "children": []})

    # --- E. LAUNCH ---
    app.launch()

if __name__ == "__main__":
    main()
--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TkinterSmartExplorerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterSmartExplorerMS
ENTRY_POINT: _TkinterSmartExplorerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import tkinter as tk
from tkinter import ttk
from typing import Dict, Any, Optional, List
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='TkinterSmartExplorer', version='1.0.0', description='A hierarchical tree viewer capable of displaying file systems or JSON data structures.', tags=['ui', 'widget', 'explorer'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TkinterSmartExplorerMS(tk.Frame):
    """
    The Navigator.
    A TreeView widget that expects standard 'Node' dictionaries (name, type, children).
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        theme = self.config.get('theme', {})
        super().__init__(parent, bg=theme.get('panel_bg', '#252526'))
        self.tree = ttk.Treeview(self, show='tree headings', selectmode='browse')
        self.tree.heading('#0', text='Explorer', anchor='w')
        vsb = ttk.Scrollbar(self, orient='vertical', command=self.tree.yview)
        hsb = ttk.Scrollbar(self, orient='horizontal', command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.pack(side='left', fill='both', expand=True)
        vsb.pack(side='right', fill='y')
        self.icons = {'folder': 'üìÅ', 'file': 'üìÑ', 'web': 'üåê', 'unknown': '‚ùì'}

    @service_endpoint(inputs={'data': 'Dict'}, outputs={}, description="Populates the tree view with a nested dictionary structure (Standard 'Node' format).", tags=['ui', 'update'], side_effects=['ui:update'])
    def load_data(self, data: Dict[str, Any]):
        """
        Ingests a dictionary tree (like from _ScoutMS or _TreeMapperMS).
        """
        for item in self.tree.get_children():
            self.tree.delete(item)
        self._build_node('', data)

    def _build_node(self, parent_id, node_data):
        ntype = node_data.get('type', 'unknown')
        icon = self.icons.get(ntype, self.icons['unknown'])
        text = f"{icon} {node_data.get('name', '???')}"
        item_id = self.tree.insert(parent_id, 'end', text=text, open=True)
        for child in node_data.get('children', []):
            self._build_node(item_id, child)
if __name__ == '__main__':
    root = tk.Tk()
    explorer = TkinterSmartExplorerMS({'parent': root})
    explorer.pack(fill='both', expand=True)
    dummy_data = {'name': 'Project Root', 'type': 'folder', 'children': [{'name': 'src', 'type': 'folder', 'children': []}, {'name': 'README.md', 'type': 'file'}]}
    explorer.load_data(dummy_data)
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TkinterThemeManagerMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _TkinterThemeManagerMS
ENTRY_POINT: _TkinterThemeManagerMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
from typing import Dict, Any, Optional
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_THEME = {'background': '#1e1e1e', 'foreground': '#d4d4d4', 'panel_bg': '#252526', 'border': '#3c3c3c', 'accent': '#007acc', 'error': '#f48771', 'success': '#89d185', 'font_main': ('Segoe UI', 10), 'font_mono': ('Consolas', 10)}

@service_metadata(name='TkinterThemeManager', version='1.0.0', description='Centralized configuration for UI colors and fonts.', tags=['ui', 'config', 'theme'], capabilities=['ui:style'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TkinterThemeManagerMS:
    """
    The Stylist: Holds the color palette and font settings.
    All UI components query this service to decide how to draw themselves.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.theme = DEFAULT_THEME.copy()
        if 'overrides' in self.config:
            self.theme.update(self.config['overrides'])

    @service_endpoint(inputs={}, outputs={'theme': 'Dict'}, description='Returns the current active theme dictionary.', tags=['ui', 'read'])
    def get_theme(self) -> Dict[str, Any]:
        return self.theme

    @service_endpoint(inputs={'key': 'str', 'value': 'Any'}, outputs={}, description='Updates a specific theme attribute (e.g., changing accent color).', tags=['ui', 'write'], side_effects=['ui:refresh'])
    def update_key(self, key: str, value: Any):
        self.theme[key] = value
if __name__ == '__main__':
    svc = TkinterThemeManagerMS()
    print('Theme Ready:', svc.get_theme()['accent'])

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TkinterUniButtonMS.py
--------------------------------------------------------------------------------
import tkinter as tk
from dataclasses import dataclass
from typing import Any, Dict, Optional, Callable
from microservice_std_lib import service_metadata, service_endpoint

@dataclass
class ButtonConfig:
    text: str
    command: Callable[[], None]
    bg_color: str
    active_bg_color: str
    fg_color: str = '#FFFFFF'

@dataclass
class LinkConfig:
    """Configuration for the 'Linked' state (The Trap)"""
    trap_bg: str = '#7C3AED'
    btn_bg: str = '#8B5CF6'
    text_color: str = '#FFFFFF'

@service_metadata(name='LockingDualBtn', version='1.0.0', description='A unified button group (Left/Right/Link) where linking merges the actions.', tags=['ui', 'widget', 'button'], capabilities=['ui:gui'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TkinterUniButtonMS(tk.Frame):
    """
    A generic button group that can merge ANY two actions.
    Pass the visual/functional definitions in via the config objects.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        parent = self.config.get('parent')
        super().__init__(parent)
        self.left_cfg: Optional[ButtonConfig] = self.config.get('left_btn')
        self.right_cfg: Optional[ButtonConfig] = self.config.get('right_btn')
        self.link_cfg: LinkConfig = self.config.get('link_config') or LinkConfig()
        self.is_linked = False
        try:
            self.default_bg = parent.cget('bg')
        except AttributeError:
            self.default_bg = '#f0f0f0'
        if not self.left_cfg or not self.right_cfg:
            print('Warning: TkinterUniButtonMS initialized without button configs.')
            return
        self._setup_ui()
        self._update_state()

    def _setup_ui(self):
        self.configure(padx=4, pady=4)
        common_style = {'relief': 'flat', 'font': ('Segoe UI', 10, 'bold'), 'bd': 0, 'cursor': 'hand2'}
        self.btn_left = tk.Button(self, command=lambda: self._execute('left'), **common_style)
        self.btn_left.pack(side='left', fill='y', padx=(0, 2))
        self.btn_link = tk.Button(self, text='&', width=3, command=self._toggle_link, **common_style)
        self.btn_link.pack(side='left', fill='y', padx=(0, 2))
        self.btn_right = tk.Button(self, command=lambda: self._execute('right'), **common_style)
        self.btn_right.pack(side='left', fill='y')

    def _toggle_link(self):
        self.is_linked = not self.is_linked
        self._update_state()

    def _update_state(self):
        if self.is_linked:
            self.configure(bg=self.link_cfg.trap_bg)
            for btn in (self.btn_left, self.btn_right, self.btn_link):
                btn.configure(bg=self.link_cfg.btn_bg, fg=self.link_cfg.text_color, activebackground=self.link_cfg.trap_bg)
            self.btn_left.configure(text=self.left_cfg.text)
            self.btn_right.configure(text=self.right_cfg.text)
        else:
            try:
                self.configure(bg=self.default_bg)
            except:
                self.configure(bg='#f0f0f0')
            self.btn_left.configure(text=self.left_cfg.text, bg=self.left_cfg.bg_color, fg=self.left_cfg.fg_color, activebackground=self.left_cfg.active_bg_color)
            self.btn_right.configure(text=self.right_cfg.text, bg=self.right_cfg.bg_color, fg=self.right_cfg.fg_color, activebackground=self.right_cfg.active_bg_color)
            self.btn_link.configure(bg='#E5E7EB', fg='#374151', activebackground='#D1D5DB')

    def _execute(self, source):
        if self.is_linked:
            self.left_cfg.command()
            self.right_cfg.command()
        elif source == 'left':
            self.left_cfg.command()
        elif source == 'right':
            self.right_cfg.command()
if __name__ == '__main__':
    root = tk.Tk()
    root.title('UniButton Test')
    root.geometry('300x100')

    def on_validate():
        print('Validating Data...')

    def on_apply():
        print('Applying Changes...')
    btn1 = ButtonConfig('Validate', on_validate, '#3b82f6', '#2563eb')
    btn2 = ButtonConfig('Apply', on_apply, '#10b981', '#059669')
    svc = TkinterUniButtonMS({'parent': root, 'left_btn': btn1, 'right_btn': btn2})
    print('Service ready:', svc)
    svc.pack(pady=20)
    root.mainloop()

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_TreeMapperMS.py
--------------------------------------------------------------------------------
import os
import datetime
import logging
from pathlib import Path
from typing import Any, Dict, List, Set, Optional
from microservice_std_lib import service_metadata, service_endpoint
DEFAULT_EXCLUDES = {'.git', '__pycache__', '.idea', '.vscode', 'node_modules', '.venv', 'env', 'venv', 'dist', 'build', '.DS_Store'}
logger = logging.getLogger('TreeMapper')

@service_metadata(name='TreeMapper', version='1.0.0', description='Generates ASCII-art style directory maps of the file system.', tags=['filesystem', 'map', 'visualization'], capabilities=['filesystem:read'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class TreeMapperMS:
    """
    The Cartographer: Generates ASCII-art style directory maps.
    Useful for creating context snapshots for LLMs.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'root_path': 'str', 'additional_exclusions': 'Set[str]', 'use_default_exclusions': 'bool'}, outputs={'tree_map': 'str'}, description='Generates an ASCII tree map of the directory.', tags=['filesystem', 'visualization'], side_effects=['filesystem:read'])
    def generate_tree(self, root_path: str, additional_exclusions: Optional[Set[str]]=None, use_default_exclusions: bool=True) -> str:
        start_path = Path(root_path).resolve()
        if not start_path.exists():
            return f"Error: Path '{root_path}' does not exist."
        exclusions = set()
        if use_default_exclusions:
            exclusions.update(DEFAULT_EXCLUDES)
        if additional_exclusions:
            exclusions.update(additional_exclusions)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        lines = [f'Project Map: {start_path.name}', f'Generated: {timestamp}', '-' * 40, f'üìÅ {start_path.name}/']
        logger.info(f'Mapping directory: {start_path}')
        self._walk(start_path, '', lines, exclusions)
        return '\n'.join(lines)

    def _walk(self, directory: Path, prefix: str, lines: List[str], exclusions: Set[str]):
        try:
            children = sorted([p for p in directory.iterdir() if p.name not in exclusions], key=lambda x: (not x.is_dir(), x.name.lower()))
        except PermissionError:
            lines.append(f'{prefix}‚îî‚îÄ‚îÄ üö´ [Permission Denied]')
            return
        count = len(children)
        for index, path in enumerate(children):
            is_last = index == count - 1
            connector = '‚îî‚îÄ‚îÄ ' if is_last else '‚îú‚îÄ‚îÄ '
            if path.is_dir():
                lines.append(f'{prefix}{connector}üìÅ {path.name}/')
                extension = '    ' if is_last else '‚îÇ   '
                self._walk(path, prefix + extension, lines, exclusions)
            else:
                lines.append(f'{prefix}{connector}üìÑ {path.name}')
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    svc = TreeMapperMS()
    print('Service ready:', svc)
    print('\n--- Map of Current Dir ---')
    tree = svc.generate_tree('.', additional_exclusions={'__pycache__'})
    print(tree)

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_VectorFactoryMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import os
import uuid
import logging
import shutil
from typing import List, Dict, Any, Optional, Protocol, Union
from pathlib import Path
REQUIRED = ['chromadb', 'faiss-cpu', 'numpy']
MISSING = []
for lib in REQUIRED:
    clean_lib = lib.split('>=')[0].replace('-', '_')
    if clean_lib == 'faiss_cpu':
        clean_lib = 'faiss'
    if importlib.util.find_spec(clean_lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _VectorFactoryMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
from microservice_std_lib import service_metadata, service_endpoint
logger = logging.getLogger('VectorFactory')

class VectorStore(Protocol):
    """The contract that all vector backends must fulfill."""

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]) -> None:
        ...

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        ...

    def count(self) -> int:
        ...

    def clear(self) -> None:
        ...

class FaissVectorStore:
    """Local, RAM-heavy, fast vector store using FAISS."""

    def __init__(self, index_path: str, dimension: int):
        import numpy as np
        import faiss
        self.np = np
        self.faiss = faiss
        self.index_path = index_path
        self.dim = dimension
        self.metadata_store = []
        if os.path.exists(index_path):
            try:
                self.index = faiss.read_index(index_path)
                meta_path = index_path + '.meta.json'
                if os.path.exists(meta_path):
                    import json
                    with open(meta_path, 'r') as f:
                        self.metadata_store = json.load(f)
            except Exception as e:
                logger.error(f'Failed to load FAISS index: {e}')
                self.index = faiss.IndexFlatL2(dimension)
        else:
            self.index = faiss.IndexFlatL2(dimension)

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]):
        if not embeddings:
            return
        vecs = self.np.array(embeddings).astype('float32')
        self.index.add(vecs)
        self.metadata_store.extend(metadatas)
        self._save()

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        if self.index.ntotal == 0:
            return []
        q_vec = self.np.array([query_vector]).astype('float32')
        distances, indices = self.index.search(q_vec, k)
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx != -1 and idx < len(self.metadata_store):
                entry = self.metadata_store[idx].copy()
                entry['score'] = float(dist)
                results.append(entry)
        return results

    def count(self) -> int:
        return self.index.ntotal

    def clear(self):
        self.index.reset()
        self.metadata_store = []
        self._save()

    def _save(self):
        self.faiss.write_index(self.index, self.index_path)
        import json
        with open(self.index_path + '.meta.json', 'w') as f:
            json.dump(self.metadata_store, f)

class ChromaVectorStore:
    """Persistent, feature-rich vector store using ChromaDB."""

    def __init__(self, persist_dir: str, collection_name: str):
        import chromadb
        logging.getLogger('chromadb').setLevel(logging.ERROR)
        self.client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.client.get_or_create_collection(collection_name)

    def add(self, embeddings: List[List[float]], metadatas: List[Dict[str, Any]]):
        if not embeddings:
            return
        ids = [str(uuid.uuid4()) for _ in embeddings]
        clean_metas = [{k: str(v) if isinstance(v, (list, dict)) else v for k, v in m.items()} for m in metadatas]
        docs = [m.get('content', '') for m in metadatas]
        self.collection.add(ids=ids, embeddings=embeddings, metadatas=clean_metas, documents=docs)

    def search(self, query_vector: List[float], k: int) -> List[Dict[str, Any]]:
        results = self.collection.query(query_embeddings=[query_vector], n_results=k)
        output = []
        if not results['ids']:
            return []
        for i in range(len(results['ids'][0])):
            meta = results['metadatas'][0][i]
            if meta:
                entry = meta.copy()
                entry['score'] = results['distances'][0][i] if results['distances'] else 0.0
                entry['id'] = results['ids'][0][i]
                output.append(entry)
        return output

    def count(self) -> int:
        return self.collection.count()

    def clear(self):
        name = self.collection.name
        self.client.delete_collection(name)
        self.collection = self.client.get_or_create_collection(name)

@service_metadata(name='VectorFactory', version='1.0.0', description='Factory for creating VectorStore instances (FAISS, Chroma).', tags=['vector', 'factory', 'db'], capabilities=['filesystem:read', 'filesystem:write'], internal_dependencies=['microservice_std_lib'], external_dependencies=['chromadb', 'faiss', 'numpy'])
class VectorFactoryMS:
    """
    The Switchboard: Returns the appropriate VectorStore implementation
    based on configuration.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}

    @service_endpoint(inputs={'backend': 'str', 'config': 'Dict'}, outputs={'store': 'VectorStore'}, description='Creates and returns a configured VectorStore instance.', tags=['vector', 'create'], side_effects=[])
    def create(self, backend: str, config: Dict[str, Any]) -> VectorStore:
        """
        :param backend: 'faiss' or 'chroma'
        :param config: Dict containing 'path', 'dim' (for FAISS), or 'collection' (for Chroma)
        """
        logger.info(f'Initializing Vector Store: {backend.upper()}')
        if backend == 'faiss':
            path = config.get('path', 'vector_index.bin')
            dim = config.get('dim', 384)
            return FaissVectorStore(path, dim)
        elif backend == 'chroma':
            path = config.get('path', './chroma_db')
            name = config.get('collection', 'default_collection')
            return ChromaVectorStore(path, name)
        else:
            raise ValueError(f'Unknown backend: {backend}')
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    print('--- Testing VectorFactoryMS ---')
    mock_vec = [0.1, 0.2, 0.3, 0.4]
    mock_meta = {'text': 'Hello World', 'source': 'test'}
    factory = VectorFactoryMS()
    print('Service ready:', factory)
    print('\n[Testing FAISS]')
    try:
        faiss_store = factory.create('faiss', {'path': 'test_faiss.index', 'dim': 4})
        faiss_store.add([mock_vec], [mock_meta])
        print(f'Count: {faiss_store.count()}')
        res = faiss_store.search(mock_vec, 1)
        if res:
            print(f"Search Result: {res[0]['text']}")
        if os.path.exists('test_faiss.index'):
            os.remove('test_faiss.index')
        if os.path.exists('test_faiss.index.meta.json'):
            os.remove('test_faiss.index.meta.json')
    except ImportError:
        print('Skipping FAISS test (library not installed)')
    except Exception as e:
        print(f'FAISS Test Failed: {e}')
    print('\n[Testing Chroma]')
    try:
        chroma_store = factory.create('chroma', {'path': './test_chroma_db', 'collection': 'test_col'})
        chroma_store.add([mock_vec], [mock_meta])
        print(f'Count: {chroma_store.count()}')
        res = chroma_store.search(mock_vec, 1)
        if res:
            print(f"Search Result: {res[0]['text']}")
        if os.path.exists('./test_chroma_db'):
            shutil.rmtree('./test_chroma_db')
    except ImportError:
        print('Skipping Chroma test (library not installed)')
    except Exception as e:
        print(f'Chroma Test Failed: {e}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_WebScraperMS.py
--------------------------------------------------------------------------------
import importlib.util
import sys
import httpx
import logging
import asyncio
import re
from typing import Optional, Dict, Any
REQUIRED = ['httpx', 'readability-lxml']
MISSING = []
for lib in REQUIRED:
    clean_lib = lib.split('>=')[0].replace('-', '_')
    if clean_lib == 'readability_lxml':
        clean_lib = 'readability'
    if importlib.util.find_spec(clean_lib) is None:
        MISSING.append(lib)
if MISSING:
    print('\n' + '!' * 60)
    print(f'MISSING DEPENDENCIES for _WebScraperMS:')
    print(f"Run:  pip install {' '.join(MISSING)}")
    print('!' * 60 + '\n')
try:
    from readability import Document
except ImportError:
    Document = None
from microservice_std_lib import service_metadata, service_endpoint
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
TIMEOUT_SECONDS = 15.0
logger = logging.getLogger('WebScraper')

@service_metadata(name='WebScraper', version='1.0.0', description='Fetches URLs and extracts main content using Readability (stripping ads/nav).', tags=['scraper', 'web', 'readability'], capabilities=['network:outbound', 'compute'], internal_dependencies=['microservice_std_lib'], external_dependencies=['httpx', 'readability'])
class WebScraperMS:
    """
    The Reader: Fetches URLs and extracts the main content using Readability.
    Strips ads, navbars, and boilerplate to return clean text for LLMs.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        self.config = config or {}
        self.headers = {'User-Agent': USER_AGENT}

    @service_endpoint(inputs={'url': 'str'}, outputs={'data': 'Dict[str, Any]'}, description='Fetches and cleans a URL.', tags=['scraper', 'read'], side_effects=['network:outbound'])
    def scrape(self, url: str) -> Dict[str, Any]:
        """
        Synchronous wrapper for fetching and cleaning a URL.
        Returns: {
            "url": str,
            "title": str,
            "content": str (The main body text),
            "html": str (The raw HTML of the main content area)
        }
        """
        return asyncio.run(self._scrape_async(url))

    async def _scrape_async(self, url: str) -> Dict[str, Any]:
        if Document is None:
            raise ImportError('readability-lxml is missing.')
        logger.info(f'Fetching: {url}')
        async with httpx.AsyncClient(headers=self.headers, follow_redirects=True, timeout=TIMEOUT_SECONDS) as client:
            try:
                response = await client.get(url)
                response.raise_for_status()
            except httpx.HTTPStatusError as e:
                logger.error(f'HTTP Error {e.response.status_code}: {e}')
                raise
            except httpx.RequestError as e:
                logger.error(f'Request failed: {e}')
                raise
        try:
            doc = Document(response.text)
            title = doc.title()
            clean_html = doc.summary()
            clean_text = self._strip_tags(clean_html)
            logger.info(f"Successfully scraped '{title}' ({len(clean_text)} chars)")
            return {'url': url, 'title': title, 'content': clean_text, 'html': clean_html}
        except Exception as e:
            logger.error(f'Parsing failed: {e}')
            raise

    def _strip_tags(self, html: str) -> str:
        """
        Removes HTML tags to leave only the readable text.
        """
        html = re.sub('<(script|style).*?>.*?</\\1>', '', html, flags=re.DOTALL)
        text = re.sub('<[^>]+>', ' ', html)
        text = re.sub('\\s+', ' ', text).strip()
        return text
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    scraper = WebScraperMS()
    print('Service ready:', scraper)
    target_url = 'https://peps.python.org/pep-0008/'
    print(f'--- Scraping {target_url} ---')
    try:
        data = scraper.scrape(target_url)
        print(f"\nTitle: {data['title']}")
        print(f"Content Preview:\n{data['content'][:500]}...")
        print(f"\nTotal Length: {len(data['content'])} characters")
    except Exception as e:
        print(f'Scrape failed: {e}')

--------------------------------------------------------------------------------
FILE: _MicroserviceLIBRARY\_WorkbenchLayoutMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _WorkbenchLayoutMS
ENTRY_POINT: _WorkbenchLayoutMS.py
INTERNAL_DEPENDENCIES: microservice_std_lib
EXTERNAL_DEPENDENCIES: None
"""
import tkinter as tk
from tkinter import ttk
from typing import Dict, Any, Optional, Callable
from microservice_std_lib import service_metadata, service_endpoint

@service_metadata(name='WorkbenchLayout', version='1.0.0', description='A declarative layout engine that builds resizable, nested Workbenches (Rows/Cols) from a config dictionary.', tags=['ui', 'layout', 'framework'], capabilities=['ui:construct'], internal_dependencies=['microservice_std_lib'], external_dependencies=[])
class WorkbenchLayoutMS(tk.Frame):
    """
    The Architect.
    Recursively builds a UI based on a 'Layout Manifest'.
    Uses ttk.PanedWindow to allow user resizing of areas.
    """

    def __init__(self, config: Optional[Dict[str, Any]]=None):
        parent = config.get('parent')
        super().__init__(parent)
        self.config = config or {}
        self.panel_registry: Dict[str, tk.Widget] = {}

    @service_endpoint(inputs={'manifest': 'Dict'}, outputs={}, description='Builds the UI structure based on the provided dictionary layout.', tags=['ui', 'build'])
    def build_from_manifest(self, manifest: Dict[str, Any]):
        """
        Manifest Schema:
        {
            "type": "row" | "col",
            "weight": int,  # 1 = expands, 0 = fixed
            "children": [
                { "type": "panel", "id": "my_panel_id", "weight": 1 },
                { "type": "row", "weight": 2, "children": [...] }
            ]
        }
        """
        for widget in self.winfo_children():
            widget.destroy()
        self._build_recursive(self, manifest)

    def get_panel(self, panel_id: str) -> Optional[tk.Widget]:
        """Retrieve a specific container by ID to pack widgets into."""
        return self.panel_registry.get(panel_id)

    def _build_recursive(self, parent_widget, node: Dict[str, Any]):
        node_type = node.get('type', 'panel')
        weight = node.get('weight', 1)
        if node_type in ['row', 'col']:
            orient = tk.HORIZONTAL if node_type == 'col' else tk.VERTICAL
            container = ttk.PanedWindow(parent_widget, orient=orient)
            if isinstance(parent_widget, ttk.PanedWindow):
                parent_widget.add(container, weight=weight)
            else:
                container.pack(fill='both', expand=True)
            for child in node.get('children', []):
                self._build_recursive(container, child)
        elif node_type == 'panel':
            p_id = node.get('id', 'unknown')
            frame = ttk.Frame(parent_widget, padding=2)
            self.panel_registry[p_id] = frame
            if isinstance(parent_widget, ttk.PanedWindow):
                parent_widget.add(frame, weight=weight)
            else:
                frame.pack(fill='both', expand=True)

--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\Iterative App Refactor Tasklist.md
--------------------------------------------------------------------------------
This mechanical task list breaks the upgrade down into iterative steps. We will move through the files by establishing the structural fixes first, then the interaction logic, and finally the advanced UX features.

### **Phase 1: Structural Integrity & Standard Fixes**

**Goal:** Prevent UI collapse, fix the layout of the right-hand buttons, and enable the double-click launch.

* **Step 1.1: src/app.pyw**  
  * **Action:** Add self.root.minsize(900, 600\) to \_\_init\_\_.

  * **Action:** Refactor btn\_row (in \_build\_widgets) to use pack(side=tk.RIGHT) with specific padding or a nested frame to prevent truncation.

* **Step 1.2: src/app.pyw**  
  * **Action:** Bind \<Double-1\> on self.app\_listbox and self.archive\_listbox to self.\_on\_launch\_clicked.

* **Step 1.3: src/app.pyw**  
  * **Action:** Implement the \_on\_mousewheel helper method and bind it to all scrollable widgets.

* **THE PATCH FOR PHASE 1** *
{
  "hunks": [
    {
      "description": "Add window constraints and double-click bindings in __init__",
      "search_block": "        self.root.title(\"Useful Helper Apps Launcher\")\n        self.root.geometry(\"900x600\")\n        self._setup_styles()\n        self._build_widgets()\n        self._refresh_all()",
      "replace_block": "        self.root.title(\"Useful Helper Apps Launcher\")\n        self.root.geometry(\"900x600\")\n        self.root.minsize(900, 600)\n        self._setup_styles()\n        self._build_widgets()\n        self._refresh_all()\n\n        # Double-click launch bindings\n        self.app_listbox.bind(\"<Double-1>\", self._on_double_click)\n        self.archive_listbox.bind(\"<Double-1>\", self._on_double_click)",
      "use_patch_indent": false
    },
    {
      "description": "Refactor btn_row to prevent button truncation and add right-alignment",
      "search_block": "        btn_row = ttk.Frame(right_frame)\n        btn_row.pack(fill=tk.X, pady=(15, 0))\n        \n        ttk.Button(btn_row, text=\"Launch\", command=self._on_launch_clicked).pack(side=tk.LEFT)\n        ttk.Button(btn_row, text=\"Create New...\", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)\n        ttk.Button(btn_row, text=\"Refresh\", command=self._refresh_all).pack(side=tk.LEFT)\n\n        ttk.Button(btn_row, text=\"VENV\", width=5, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(btn_row, text=\"PS\", width=3, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(btn_row, text=\"CMD\", width=4, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(btn_row, text=\"Folder\", command=self._on_open_folder).pack(side=tk.RIGHT)",
      "replace_block": "        btn_row = ttk.Frame(right_frame)\n        btn_row.pack(fill=tk.X, pady=(15, 0))\n\n        # Action Group (Left)\n        left_btn_grp = ttk.Frame(btn_row)\n        left_btn_grp.pack(side=tk.LEFT)\n        \n        ttk.Button(left_btn_grp, text=\"Launch\", command=self._on_launch_clicked).pack(side=tk.LEFT)\n        ttk.Button(left_btn_grp, text=\"Create New...\", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)\n        ttk.Button(left_btn_grp, text=\"Refresh\", command=self._refresh_all).pack(side=tk.LEFT)\n\n        # Utility Group (Right)\n        right_btn_grp = ttk.Frame(btn_row)\n        right_btn_grp.pack(side=tk.RIGHT)\n\n        ttk.Button(right_btn_grp, text=\"VENV\", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(right_btn_grp, text=\"PS\", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(right_btn_grp, text=\"CMD\", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)\n        ttk.Button(right_btn_grp, text=\"Folder\", command=self._on_open_folder).pack(side=tk.RIGHT)",
      "use_patch_indent": false
    },
    {
      "description": "Add Mousewheel helper and double-click handler",
      "search_block": "    def _on_launch_clicked(self):\n        if hasattr(self, 'selected_app'): launch_app(self.selected_app)",
      "replace_block": "    def _on_mousewheel(self, event):\n        \"\"\"Universal scroll handler for listboxes and text widgets.\"\"\"\n        direction = -1 if event.delta > 0 else 1\n        event.widget.yview_scroll(direction * 3, \"units\")\n\n    def _on_double_click(self, event=None):\n        self._on_launch_clicked()\n\n    def _on_launch_clicked(self):\n        if hasattr(self, 'selected_app'): launch_app(self.selected_app)",
      "use_patch_indent": false
    }
  ]
}

### ---

**Phase 2: Navigation & Contextual Control**

**Goal:** Add real-time searching and the ability to control apps via right-click.

* **Step 2.1: src/app.pyw**  
  * **Action:** Insert a ttk.Entry (Search Bar) above the "Available Apps" label.

  * **Action:** Create a self.search\_var with a .trace\_add("write", ...) callback to filter self.active\_apps.

* **Step 2.2: src/app.pyw**  
  * **Action:** Define a \_show\_context\_menu method.  
  * **Action:** Bind \<Button-3\> (Right Click) on the listboxes to trigger a tk.Menu containing Launch, Folder, CMD, PS, and VENV actions.

* **THE PATCH FOR PHASE 2** *
{
  "hunks": [
    {
      "description": "Initialize search variable and context menu in __init__",
      "search_block": "        self._setup_styles()\n        self._build_widgets()\n        self._refresh_all()",
      "replace_block": "        self._setup_styles()\n        self.search_var = tk.StringVar()\n        self.search_var.trace_add(\"write\", lambda *args: self._refresh_listbox_only())\n        self._build_widgets()\n        self._refresh_all()\n        self._build_context_menu()",
      "use_patch_indent": false
    },
    {
      "description": "Insert Search Bar and bind Right-Click to listboxes",
      "search_block": "        # 1. Available Apps (The \"Expander\")\n        ttk.Label(left_frame, text=\"Available Apps\", font=(\"Segoe UI\", 9, \"bold\")).pack(anchor=\"w\")\n        self.app_listbox = tk.Listbox(left_frame, bg=self.widget_colors[\"bg\"], ",
      "replace_block": "        # 1. Search and Available Apps\n        ttk.Label(left_frame, text=\"Search Apps\", font=(\"Segoe UI\", 8)).pack(anchor=\"w\")\n        search_entry = ttk.Entry(left_frame, textvariable=self.search_var)\n        search_entry.pack(fill=tk.X, pady=(0, 10))\n\n        ttk.Label(left_frame, text=\"Available Apps\", font=(\"Segoe UI\", 9, \"bold\")).pack(anchor=\"w\")\n        self.app_listbox = tk.Listbox(left_frame, bg=self.widget_colors[\"bg\"], ",
      "use_patch_indent": false
    },
    {
      "description": "Bind Button-3 for Context Menu on both listboxes",
      "search_block": "        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))\n        self.app_listbox.bind(\"<<ListboxSelect>>\", lambda e: self._on_select(self.app_listbox))",
      "replace_block": "        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))\n        self.app_listbox.bind(\"<<ListboxSelect>>\", lambda e: self._on_select(self.app_listbox))\n        self.app_listbox.bind(\"<Button-3>\", self._show_context_menu)",
      "use_patch_indent": false
    },
    {
      "description": "Bind Button-3 for Archive listbox",
      "search_block": "        self.archive_listbox.pack(fill=tk.X, expand=False) # Only fills width, height is fixed\n        self.archive_listbox.bind(\"<<ListboxSelect>>\", lambda e: self._on_select(self.archive_listbox))",
      "replace_block": "        self.archive_listbox.pack(fill=tk.X, expand=False) # Only fills width, height is fixed\n        self.archive_listbox.bind(\"<<ListboxSelect>>\", lambda e: self._on_select(self.archive_listbox))\n        self.archive_listbox.bind(\"<Button-3>\", self._show_context_menu)",
      "use_patch_indent": false
    },
    {
      "description": "Implement filtering logic and context menu methods",
      "search_block": "    def _refresh_all(self):\n        self.active_apps = discover_apps(ROOT_DIR)\n        self.archived_apps = discover_apps(ROOT_DIR / \"__ARCHIVES__\")\n        \n        self.app_listbox.delete(0, tk.END)\n        for a in self.active_apps: self.app_listbox.insert(tk.END, a.name)\n        \n        self.archive_listbox.delete(0, tk.END)\n        for a in self.archived_apps: self.archive_listbox.insert(tk.END, a.name)",
      "replace_block": "    def _refresh_all(self):\n        self.active_apps = discover_apps(ROOT_DIR)\n        self.archived_apps = discover_apps(ROOT_DIR / \"__ARCHIVES__\")\n        self._refresh_listbox_only()\n\n    def _refresh_listbox_only(self):\n        search_query = self.search_var.get().lower()\n        \n        self.app_listbox.delete(0, tk.END)\n        for a in self.active_apps:\n            if search_query in a.name.lower():\n                self.app_listbox.insert(tk.END, a.name)\n        \n        self.archive_listbox.delete(0, tk.END)\n        for a in self.archived_apps:\n            if search_query in a.name.lower():\n                self.archive_listbox.insert(tk.END, a.name)\n\n    def _build_context_menu(self):\n        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors[\"bg\"], fg=\"white\")\n        self.context_menu.add_command(label=\"üöÄ Launch\", command=self._on_launch_clicked)\n        self.context_menu.add_separator()\n        self.context_menu.add_command(label=\"üìÇ Open Folder\", command=self._on_open_folder)\n        self.context_menu.add_command(label=\"üíª CMD Terminal\", command=self._on_open_cmd)\n        self.context_menu.add_command(label=\"üêö PowerShell\", command=self._on_open_ps)\n        self.context_menu.add_command(label=\"üêç VENV Terminal\", command=self._on_open_venv)\n\n    def _show_context_menu(self, event):\n        # Select the item under the mouse first\n        widget = event.widget\n        index = widget.nearest(event.y)\n        widget.selection_clear(0, tk.END)\n        widget.selection_set(index)\n        widget.activate(index)\n        self._on_select(widget)\n        \n        self.context_menu.post(event.x_root, event.y_root)",
      "use_patch_indent": false
    }
  ]
}

### ---

**Phase 3: Feedback & Visual Polish**

**Goal:** Improve communication with the user and add visual distinction to the app list.

* **Step 3.1: src/app.pyw**  
  * **Action:** Add a ttk.Label (Status Bar) at the very bottom of the root window.

  * **Action:** Create a \_set\_status(text) method to update this label and replace generic print statements or non-critical messagebox alerts.

* **Step 3.2: src/app.pyw**  
  * **Action:** Modify \_refresh\_all to prepend symbols (e.g., üêç  for Python apps) to the names inserted into the listboxes.

* **Step 3.3: src/app.pyw**  
  * **Action:** Wrap the left and right columns in a ttk.PanedWindow to allow user-adjustable sidebar width.

* **THE PATCH FOR PHASE 3** *
{
  "hunks": [
    {
      "description": "Initialize Status Bar and PanedWindow in _build_widgets",
      "search_block": "    def _build_widgets(self):\n        main_frame = ttk.Frame(self.root, padding=10)\n        main_frame.pack(fill=tk.BOTH, expand=True)\n\n        # --- LEFT COLUMN ---",
      "replace_block": "    def _build_widgets(self):\n        # Status Bar at the bottom\n        self.status_bar = ttk.Label(self.root, text=\" Ready\", relief=tk.SUNKEN, anchor=tk.W)\n        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n\n        # PanedWindow to allow resizing columns\n        self.paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)\n        self.paned.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n\n        # --- LEFT COLUMN ---",
      "use_patch_indent": false
    },
    {
      "description": "Add left and right frames to PanedWindow instead of packing directly",
      "search_block": "        # --- LEFT COLUMN ---\n        left_frame = ttk.Frame(main_frame)\n        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)",
      "replace_block": "        # --- LEFT COLUMN ---\n        left_frame = ttk.Frame(self.paned)\n        self.paned.add(left_frame, weight=1)",
      "use_patch_indent": false
    },
    {
      "description": "Add right frame to PanedWindow",
      "search_block": "        # RIGHT DETAILS\n        right_frame = ttk.Frame(main_frame, padding=(15, 0))\n        right_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)",
      "replace_block": "        # RIGHT DETAILS\n        right_frame = ttk.Frame(self.paned, padding=(15, 0))\n        self.paned.add(right_frame, weight=2)",
      "use_patch_indent": false
    },
    {
      "description": "Implement _set_status and update listbox icons",
      "search_block": "    def _refresh_listbox_only(self):\n        search_query = self.search_var.get().lower()\n        \n        self.app_listbox.delete(0, tk.END)\n        for a in self.active_apps:\n            if search_query in a.name.lower():\n                self.app_listbox.insert(tk.END, a.name)\n        \n        self.archive_listbox.delete(0, tk.END)\n        for a in self.archived_apps:\n            if search_query in a.name.lower():\n                self.archive_listbox.insert(tk.END, a.name)",
      "replace_block": "    def _set_status(self, text):\n        \"\"\"Updates the status bar with a timestamped message.\"\"\"\n        import datetime\n        ts = datetime.datetime.now().strftime(\"%H:%M:%S\")\n        self.status_bar.config(text=f\" [{ts}] {text}\")\n\n    def _refresh_listbox_only(self):\n        search_query = self.search_var.get().lower()\n        \n        self.app_listbox.delete(0, tk.END)\n        for a in self.active_apps:\n            if search_query in a.name.lower():\n                icon = \"üêç \" if a.has_src_app else \"‚≠ï \"\n                self.app_listbox.insert(tk.END, f\"{icon}{a.name}\")\n        \n        self.archive_listbox.delete(0, tk.END)\n        for a in self.archived_apps:\n            if search_query in a.name.lower():\n                self.archive_listbox.insert(tk.END, f\"üì¶ {a.name}\")\n        \n        self._set_status(f\"Refreshed list ({len(self.active_apps)} active, {len(self.archived_apps)} archived)\")",
      "use_patch_indent": false
    },
    {
      "description": "Update launch and folder actions to use status bar",
      "search_block": "    def _on_launch_clicked(self):\n        if hasattr(self, 'selected_app'): launch_app(self.selected_app)\n\n    def _on_open_venv(self):\n        if hasattr(self, 'selected_app'):\n            act = self.selected_app.folder / \".venv\" / \"Scripts\" / \"activate.bat\"\n            if act.exists(): subprocess.Popen([\"cmd.exe\", \"/k\", str(act)], cwd=str(self.selected_app.folder))\n            else: self._on_open_cmd()",
      "replace_block": "    def _on_launch_clicked(self):\n        if hasattr(self, 'selected_app'): \n            self._set_status(f\"Launching {self.selected_app.name}...\")\n            launch_app(self.selected_app)\n\n    def _on_open_venv(self):\n        if hasattr(self, 'selected_app'):\n            self._set_status(f\"Opening VENV for {self.selected_app.name}\")\n            act = self.selected_app.folder / \".venv\" / \"Scripts\" / \"activate.bat\"\n            if act.exists(): subprocess.Popen([\"cmd.exe\", \"/k\", str(act)], cwd=str(self.selected_app.folder))\n            else: self._on_open_cmd()",
      "use_patch_indent": false
    }
  ]
}

### ---

**Phase 4: Scaffolding Enhancements**

**Goal:** Ensure the Microservice Selector is as robust as the main menu.

* **Step 4.1: src/app.pyw (Inside MicroserviceSelector Class)**  
  * **Action:** Add mousewheel support to the scrollable\_frame.

  * **Action:** Add a "Project Name" Entry directly into this modal so all creation data is in one window.

* **Step 4.2: src/app.pyw**  
  * **Action:** Update \_on\_create\_clicked to validate that the project name is safe and the target path is writable before proceeding.

* **THE PATCH FOR PHASE 4** *
{
  "hunks": [
    {
      "description": "Add Project Name entry and mousewheel binding to MicroserviceSelector",
      "search_block": "    def _build_ui(self):\n        # Folder Picker Row\n        frame_folder = ttk.LabelFrame(self, text=\"Step 1: Target Location\", padding=10)\n        frame_folder.pack(fill=\"x\", padx=10, pady=10)\n        self.lbl_path = ttk.Label(frame_folder, text=\"No folder selected...\", foreground=\"#ff6666\", wraplength=450)\n        self.lbl_path.pack(side=\"left\", padx=5)\n        ttk.Button(frame_folder, text=\"Browse...\", command=self._on_browse).pack(side=\"right\")\n\n        # Microservice Selection",
      "replace_block": "    def _build_ui(self):\n        # Step 1: Project Name\n        frame_name = ttk.LabelFrame(self, text=\"Step 1: Project Name\", padding=10)\n        frame_name.pack(fill=\"x\", padx=10, pady=5)\n        self.ent_name = ttk.Entry(frame_name)\n        self.ent_name.pack(fill=\"x\")\n\n        # Step 2: Folder Picker Row\n        frame_folder = ttk.LabelFrame(self, text=\"Step 2: Target Location\", padding=10)\n        frame_folder.pack(fill=\"x\", padx=10, pady=5)\n        self.lbl_path = ttk.Label(frame_folder, text=\"No folder selected...\", foreground=\"#ff6666\", wraplength=450)\n        self.lbl_path.pack(side=\"left\", padx=5)\n        ttk.Button(frame_folder, text=\"Browse...\", command=self._on_browse).pack(side=\"right\")\n\n        # Step 3: Microservice Selection",
      "use_patch_indent": false
    },
    {
      "description": "Bind Mousewheel to the canvas in MicroserviceSelector",
      "search_block": "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n        scrollbar.pack(side=\"right\", fill=\"y\")",
      "replace_block": "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n        scrollbar.pack(side=\"right\", fill=\"y\")\n\n        # Mousewheel support\n        canvas.bind_all(\"<MouseWheel>\", lambda e: canvas.yview_scroll(int(-1*(e.delta/120)), \"units\"))",
      "use_patch_indent": false
    },
    {
      "description": "Add name validation and cleanup mousewheel binding on confirm",
      "search_block": "    def _on_confirm(self):\n        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]\n        self.confirmed = True\n        self.destroy()",
      "replace_block": "    def _on_confirm(self):\n        name = self.ent_name.get().strip()\n        if not name:\n            messagebox.showerror(\"Error\", \"Project name is required.\")\n            return\n        \n        self.safe_name = \"\".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()\n        if not self.target_path:\n            messagebox.showerror(\"Error\", \"Target location is required.\")\n            return\n\n        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]\n        self.confirmed = True\n        self.unbind_all(\"<MouseWheel>\")\n        self.destroy()",
      "use_patch_indent": false
    },
    {
      "description": "Update _on_create_clicked to use unified selector data and validate path",
      "search_block": "    def _on_create_clicked(self):\n        name = simpledialog.askstring(\"New App\", \"Enter project name:\")\n        if not name: return\n        safe_name = \"\".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()\n        \n        selector = MicroserviceSelector(self.root)\n        self.root.wait_window(selector)\n        if not selector.confirmed or not selector.target_path: return\n\n        target_dir = selector.target_path / safe_name\n        self._write_boilerplate(target_dir, selector.selected_files)\n        self._refresh_all()\n        messagebox.showinfo(\"Success\", f\"App {safe_name} created.\")",
      "replace_block": "    def _on_create_clicked(self):\n        selector = MicroserviceSelector(self.root)\n        self.root.wait_window(selector)\n        \n        if not selector.confirmed: \n            return\n\n        target_dir = selector.target_path / selector.safe_name\n        \n        # Path Validation\n        if target_dir.exists():\n            messagebox.showerror(\"Error\", f\"Directory already exists:\\n{target_dir}\")\n            return\n        \n        try:\n            # Test writability\n            target_dir.mkdir(parents=True, exist_ok=True)\n            self._write_boilerplate(target_dir, selector.selected_files)\n            self._refresh_all()\n            self._set_status(f\"Created app: {selector.safe_name}\")\n            messagebox.showinfo(\"Success\", f\"App {selector.safe_name} created.\")\n        except Exception as e:\n            messagebox.showerror(\"Creation Failed\", f\"Could not create project:\\n{e}\")",
      "use_patch_indent": false
    }
  ]
}

### ---

**Phase 5: Boilerplate & Template Sync**

**Goal:** Align the "stamped out" apps with the new microservice standards.

* **Step 5.1: \_BoilerPlatePythonTEMPLATE/src/app.py**  
  * **Action:** Update the boilerplate imports and main() structure to match the microservice injection logic.

* **Step 5.2: src/microservices/\_ContextAggregatorMS.py**  
  * **Action:** Update the default ignore list to include the newly created \_logs and \_\_ARCHIVES\_\_ directories.

* **THE PATCH FOR PHASE 5** *
{
  "hunks": [
    {
      "description": "Update boilerplate to match microservice injection logic",
      "search_block": "import sys\nimport os\nimport argparse  # For parsing command-line arguments\n\n# Third-party imports (if any)\n# e.g., import requests\n\n# Local/application imports (if any)\n# e.g., from . import my_other_module",
      "replace_block": "import sys\nimport os\n\n# Note: This file is designed to be overwritten by the Launcher's injection logic.\n# It provides the entry point for loaded microservices.",
      "use_patch_indent": false
    },
    {
      "description": "Align boilerplate main() with microservice boot sequence",
      "search_block": "def main():\n    \"\"\"\n    Main function to run the script from the command line.\n    It parses arguments, calls core functions, and handles CLI-specific\n    input/output and error handling.\n    \"\"\"\n    \n    # --- Argument Parsing ---\n    # Set up the argument parser\n    # TODO: Update the description to match your tool.\n    parser = argparse.ArgumentParser(\n        description=\"A generic CLI tool. TODO: Describe your tool here.\",\n        epilog=\"Example: python generic_module.py my_input.txt -o my_output.txt -v\"\n    )",
      "replace_block": "def main():\n    \"\"\"\n    Main entry point for the microservice-enabled application.\n    \"\"\"\n    print('--- Booting Microservice App ---')\n    # Injection point for service instances\n    print('--- System Ready ---')",
      "use_patch_indent": false
    },
    {
      "description": "Update ContextAggregator ignore list to include logs and archives",
      "search_block": "DEFAULT_IGNORE_DIRS = {\n    \"node_modules\", \".git\", \"__pycache__\", \".venv\", \".env\", \n    \"dist\", \"build\", \"coverage\", \".idea\", \".vscode\"\n}",
      "replace_block": "DEFAULT_IGNORE_DIRS = {\n    \"node_modules\", \".git\", \"__pycache__\", \".venv\", \".env\", \n    \"dist\", \"build\", \"coverage\", \".idea\", \".vscode\",\n    \"_logs\", \"__ARCHIVES__\"\n}",
      "use_patch_indent": false
    }
  ]
}



--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\requirements.txt
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\setup_env.bat
--------------------------------------------------------------------------------
@echo off
echo [SYSTEM] Initializing new project environment...

:: 1. Create the venv if it doesn't exist
if not exist .venv (
    echo [SYSTEM] Creating .venv...
    py -m venv .venv
)

:: 2. Upgrade pip and install requirements
echo [SYSTEM] Installing dependencies...
.venv\Scripts\python.exe -m pip install --upgrade pip
if exist requirements.txt (
    .venv\Scripts\pip install -r requirements.txt
)

echo.
echo [SUCCESS] Environment ready!
echo You can now open this folder in VS Code or launch via scripts_menu.py
pause
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
import datetime
import ast
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.safe_name = ""
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        # --- ttk dark styling for this dialog (prevents OS theme grey/white bleed) ---
        BG = "#1e1e2f"
        PANEL = "#151521"
        FG = "#d1d1e0"
        BORDER = "#33334d"

        style = ttk.Style(self)
        # On Windows, default themes often ignore background colors; clam is predictable.
        try:
            style.theme_use("clam")
        except tk.TclError:
            pass

        style.configure("Dark.TFrame", background=BG)
        style.configure("Dark.TLabelframe", background=BG, bordercolor=BORDER)
        style.configure("Dark.TLabelframe.Label", background=BG, foreground=FG)
        style.configure("Dark.TLabel", background=BG, foreground=FG)
        style.configure("Dark.TEntry", fieldbackground=PANEL, foreground=FG)

        # --- Project Name ---
        frame_name = ttk.LabelFrame(self, text="Project Name", padding=10, style="Dark.TLabelframe")
        frame_name.pack(fill="x", padx=10, pady=5)
        self.ent_name = ttk.Entry(frame_name, style="Dark.TEntry")
        self.ent_name.pack(fill="x")

        # --- Project Location ---
        frame_folder = ttk.LabelFrame(self, text="Project Location", padding=10, style="Dark.TLabelframe")
        frame_folder.pack(fill="x", padx=10, pady=5)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", style="Dark.TLabel", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        # --- Microservices ---
        frame_ms = ttk.LabelFrame(self, text="Microservices to Include", padding=10, style="Dark.TLabelframe")
        frame_ms.pack(fill="both", expand=True, padx=10, pady=5)

        # Core libs are always vendored (not MS files)
        self.core_libs = ["microservice_std_lib.py", "base_service.py", "document_utils.py"]
        core_txt = "Core libs (always included): " + ", ".join(self.core_libs)
        ttk.Label(frame_ms, text=core_txt, style="Dark.TLabel", wraplength=560).pack(anchor="w", pady=(0, 8))

        # Horizontal split: list (left) + info panel (right)
        split = tk.PanedWindow(frame_ms, orient=tk.HORIZONTAL, bg=BG, sashwidth=4, borderwidth=0)
        split.pack(fill="both", expand=True)

        # Left: scrollable MS list
        frame_list = tk.Frame(split, bg=BG, highlightthickness=0)
        split.add(frame_list, width=330)

        self.canvas = tk.Canvas(frame_list, bg=BG, highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = tk.Frame(self.canvas, bg=BG)
        self.scrollable_frame.bind("<Configure>", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        self.canvas.configure(yscrollcommand=scrollbar.set)

        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        self.canvas.bind_all("<MouseWheel>", self._on_canvas_scroll)

        # Right: info panel (always shows last selected)
        frame_info = tk.Frame(split, bg=BG, highlightthickness=0)
        split.add(frame_info)

        ttk.Label(frame_info, text="Microservice Info", style="Dark.TLabel", font=("Segoe UI", 10, "bold")).pack(anchor="w")
        self.info_text = tk.Text(
            frame_info,
            wrap="word",
            height=20,
            state="disabled",
            bg=PANEL,
            fg=FG,
            borderwidth=0,
            padx=10,
            pady=10,
            highlightthickness=1,
            highlightbackground=BORDER,
        )
        self.info_text.pack(fill="both", expand=True, pady=(6, 0))

        # Build MS rows
        self.check_vars = {}
        self.check_btns = {}
        self.required_paths = set()
        self.ms_meta_cache = {}
        self.last_selected_ms = None

        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        for f in unique_paths:
            var = tk.BooleanVar(value=False)
            row = tk.Frame(self.scrollable_frame, bg=BG)
            row.pack(fill="x", padx=5, pady=2)

            cb = ttk.Checkbutton(
                row,
                text="",
                variable=var,
                style="TCheckbutton",
                command=lambda p=f: self._on_check_changed(p),
            )
            cb.pack(side="left")

            lbl = tk.Label(
                row,
                text=f.name,
                bg=BG,
                fg=FG,
                anchor="w",
                cursor="hand2",
            )
            lbl.pack(side="left", fill="x", expand=True, padx=(6, 0))

            # Single click: show info (do NOT toggle)
            lbl.bind("<Button-1>", lambda e, p=f: self._on_ms_select(p))
            # Double click: toggle checkbox
            lbl.bind("<Double-1>", lambda e, p=f: self._toggle_ms(p))

            self.check_vars[f] = var
            self.check_btns[f] = cb

        # Seed info panel with instructions
        self._set_info_text("Single-click a microservice name to view details.\nDouble-click to toggle include.")

        btn_frame = ttk.Frame(self, style="Dark.TFrame")
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(
            btn_frame,
            text="CREATE APP",
            bg="#444444",
            fg="gray",
            state="disabled",
            command=self._on_confirm,
            borderwidth=0,
            padx=15,
        )
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _set_info_text(self, text: str) -> None:
        self.info_text.config(state="normal")
        self.info_text.delete("1.0", tk.END)
        self.info_text.insert("1.0", text)
        self.info_text.config(state="disabled")

    def _extract_meta_from_ast(self, path: Path) -> Dict[str, object]:
        """Extracts a light metadata object from @service_metadata(...) on the first class found."""
        src = path.read_text(encoding="utf-8", errors="replace")
        try:
            tree = ast.parse(src, filename=str(path))
        except SyntaxError:
            return {
                "name": path.stem,
                "description": "(SyntaxError while parsing file)",
                "internal": [],
                "external": [],
            }

        def _lit(val):
            try:
                return ast.literal_eval(val)
            except Exception:
                return None

        for node in tree.body:
            if not isinstance(node, ast.ClassDef):
                continue
            for dec in node.decorator_list:
                if not isinstance(dec, ast.Call):
                    continue
                fn = dec.func
                if not (isinstance(fn, ast.Name) and fn.id == "service_metadata"):
                    continue

                kw = {k.arg: k.value for k in dec.keywords if k.arg}
                desc = _lit(kw.get("description")) if "description" in kw else None
                internal = _lit(kw.get("internal_dependencies")) if "internal_dependencies" in kw else None
                external = _lit(kw.get("external_dependencies")) if "external_dependencies" in kw else None

                return {
                    "name": path.stem,
                    "class": node.name,
                    "description": desc or "(No description)",
                    "internal": internal or [],
                    "external": external or [],
                }

        # Fallback if decorator not found
        return {
            "name": path.stem,
            "description": "(No @service_metadata decorator found)",
            "internal": [],
            "external": [],
        }

    def _get_ms_meta(self, path: Path) -> Dict[str, object]:
        if path in self.ms_meta_cache:
            return self.ms_meta_cache[path]
        meta = self._extract_meta_from_ast(path)
        self.ms_meta_cache[path] = meta
        return meta

    def _on_ms_select(self, path: Path) -> None:
        self.last_selected_ms = path
        meta = self._get_ms_meta(path)

        # Resolve any internal deps that correspond to MS files in the library
        required_ms = []
        for dep in (meta.get("internal") or []):
            # internal deps are module-like names; try to map to known MS files
            # e.g. "ArchiveBotMS" or "_ArchiveBotMS" or filename keys
            if dep in self.available_files:
                p = self.available_files[dep]
                if p.name.endswith("MS.py"):
                    required_ms.append(p.name)

        text = (
            f"File: {path.name}\n"
            f"Class: {meta.get('class', '(unknown)')}\n\n"
            f"Description:\n  {meta.get('description')}\n\n"
            f"Internal deps (vendor):\n  {', '.join(meta.get('internal') or []) or 'None'}\n\n"
            f"External deps (requirements):\n  {', '.join(meta.get('external') or []) or 'None'}\n\n"
            f"Required microservices (auto-include when resolvable):\n  {', '.join(required_ms) or 'None'}\n"
        )
        self._set_info_text(text)

    def _toggle_ms(self, path: Path) -> None:
        var = self.check_vars.get(path)
        if not var:
            return
        var.set(not var.get())
        self._on_check_changed(path)

    def _on_check_changed(self, changed_path: Path) -> None:
        """When a checkbox changes, auto-include resolvable required MS deps."""
        # Always keep info panel synced to last click target
        self._on_ms_select(changed_path)

        # Recompute required set from all checked items
        required = set()
        for p, var in self.check_vars.items():
            if not var.get():
                continue
            meta = self._get_ms_meta(p)
            for dep in (meta.get("internal") or []):
                if dep in self.available_files:
                    dep_path = self.available_files[dep]
                    if dep_path.name.endswith("MS.py"):
                        required.add(dep_path)

        self.required_paths = required

        # Apply required paths: force checked + disable checkbox so users know it's required
        for p, cb in self.check_btns.items():
            if p in self.required_paths:
                self.check_vars[p].set(True)
                cb.state(["disabled"])
            else:
                cb.state(["!disabled"])

    def _on_canvas_scroll(self, event):
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        name = self.ent_name.get().strip()
        if not name:
            messagebox.showerror("Error", "Project name is required.")
            return
        self.safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        if not self.target_path:
            messagebox.showerror("Error", "Target location is required.")
            return
        chosen = {f for f, var in self.check_vars.items() if var.get()}
        chosen |= set(getattr(self, "required_paths", set()))
        self.selected_files = sorted(list(chosen), key=lambda p: p.name.lower())
        self.confirmed = True
        self.unbind_all("<MouseWheel>")
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("1100x700")
        self.root.minsize(900, 600)
        self.root.resizable(True, True)
        self.last_selected_name = None
        self.colors = {
            "bg_main": "#1e1e2f",    
            "bg_dark": "#151521",    
            "bg_status": "#252538",  
            "accent": "#007ACC",     
            "border": "#33334d",     
            "fg": "#d1d1e0"          
        }
        self.root.configure(bg=self.colors["bg_main"])
        self._setup_styles()
        self.search_var = tk.StringVar()
        self.search_var.trace_add("write", lambda *args: self._refresh_listbox_only())
        
        self._build_widgets()
        self._refresh_all()
        self._build_context_menu()

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        
        style.configure("TFrame", background=self.colors["bg_main"])
        style.configure("TLabel", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.configure("Status.TLabel", background=self.colors["bg_status"], foreground=self.colors["fg"], padding=5)
        
        style.configure("TCheckbutton", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.map("TCheckbutton", background=[('active', self.colors["bg_main"])], foreground=[('active', 'white')])

        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", self.colors["accent"])])
        
        self.widget_colors = {"bg": self.colors["bg_dark"], "fg": self.colors["fg"], "selectbg": self.colors["accent"]}

    def _build_widgets(self):
        # 1. STATUS BAR
        self.status_bar = ttk.Label(self.root, text=" Ready", style="Status.TLabel", anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # 2. MAIN CONTENT WRAPPER
        content_wrapper = tk.Frame(self.root, bg=self.colors["bg_main"], highlightthickness=0)
        content_wrapper.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # 3. PANED WINDOW - Surgical Fix: tk.PanedWindow does not support 'highlightthickness'
        self.paned = tk.PanedWindow(
            content_wrapper, 
            orient=tk.HORIZONTAL, 
            bg=self.colors["bg_main"],
            borderwidth=0, 
            sashwidth=4,
            sashpad=0
        )
        self.paned.pack(fill=tk.BOTH, expand=True)

        # LEFT PANEL
        left_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(left_panel, width=300)

        left_inner = ttk.Frame(left_panel)
        left_inner.pack(fill=tk.BOTH, expand=True, padx=(5, 15), pady=5)

        search_container = ttk.Frame(left_inner)
        search_container.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(search_container, text="Search Apps", font=("Segoe UI", 8)).pack(anchor="w")
        ttk.Entry(search_container, textvariable=self.search_var).pack(fill=tk.X)

        ttk.Label(left_inner, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(
            left_inner, 
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"], 
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))
        self.app_listbox.bind("<Button-3>", self._show_context_menu)
        self.app_listbox.bind("<Double-1>", self._on_double_click)

        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            left_inner, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        self.archive_frame = ttk.Frame(left_inner)
        self.archive_listbox = tk.Listbox(
            self.archive_frame, 
            height=8, 
            bg=self.widget_colors["bg"],
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"],
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.archive_listbox.pack(fill=tk.X, expand=False)
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))
        self.archive_listbox.bind("<Button-3>", self._show_context_menu)
        self.archive_listbox.bind("<Double-1>", self._on_double_click)

        # RIGHT PANEL
        right_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(right_panel)

        right_inner = ttk.Frame(right_panel)
        right_inner.pack(fill=tk.BOTH, expand=True, padx=(15, 5), pady=5)
        
        self.details_text = tk.Text(
            right_inner, 
            height=10, 
            wrap="word", 
            state="disabled",
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            borderwidth=0, 
            padx=10, 
            pady=10, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.details_text.pack(fill=tk.BOTH, expand=True)

        btn_row = ttk.Frame(right_inner)
        btn_row.pack(fill=tk.X, pady=(15, 0))

        left_btn_grp = ttk.Frame(btn_row)
        left_btn_grp.pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(left_btn_grp, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        right_btn_grp = ttk.Frame(btn_row)
        right_btn_grp.pack(side=tk.RIGHT)
        ttk.Button(right_btn_grp, text="VENV", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="PS", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="CMD", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _on_double_click(self, event=None):
        self._on_launch_clicked()

    def _toggle_archives(self):
        if self.archive_var.get():
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            self.archive_frame.pack_forget()

    def _set_status(self, text):
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        self.status_bar.config(text=f" [{ts}] {text}")

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        self._refresh_listbox_only()

    def _refresh_listbox_only(self):
        query = self.search_var.get().lower()
        targets = [
            (self.app_listbox, self.active_apps, 'üêç '), 
            (self.archive_listbox, self.archived_apps, 'üì¶ ')
        ]
        
        for lb, app_list, default_icon in targets:
            lb.delete(0, tk.END)
            for a in app_list:
                if query in a.name.lower():
                    if default_icon == 'üì¶ ':
                        icon = 'üì¶ '
                    else:
                        icon = 'üêç ' if a.has_src_app else '‚≠ï '
                    lb.insert(tk.END, f"{icon}{a.name}")
            
            if self.last_selected_name:
                all_items = lb.get(0, tk.END)
                for idx, display_val in enumerate(all_items):
                    if display_val[2:] == self.last_selected_name:
                        lb.selection_set(idx)
                        lb.activate(idx)
                        lb.see(idx) 
                        break

        self._set_status(f"Refreshed list ({len(self.active_apps)} active, {len(self.archived_apps)} archived)")

    def _on_select(self, listbox):
        sel = listbox.curselection()
        if not sel: return
        
        raw_val = listbox.get(sel[0])
        self.last_selected_name = raw_val[2:]
        
        app = next((a for a in self.active_apps + self.archived_apps if a.name == self.last_selected_name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _build_context_menu(self):
        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors["bg"], fg="white")
        self.context_menu.add_command(label="üöÄ Launch", command=self._on_launch_clicked)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üìÇ Open Folder", command=self._on_open_folder)
        self.context_menu.add_command(label="üíª CMD Terminal", command=self._on_open_cmd)
        self.context_menu.add_command(label="üêö PowerShell", command=self._on_open_ps)
        self.context_menu.add_command(label="üêç VENV Terminal", command=self._on_open_venv)

    def _show_context_menu(self, event):
        widget = event.widget
        index = widget.nearest(event.y)
        widget.selection_clear(0, tk.END)
        widget.selection_set(index)
        self._on_select(widget)
        self.context_menu.post(event.x_root, event.y_root)

    def _on_create_clicked(self):
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        if selector.confirmed:
            target = selector.target_path / selector.safe_name
            try:
                target.mkdir(parents=True, exist_ok=True)
                self._write_boilerplate(target, selector.selected_files)
                self._refresh_all()
                self._set_status(f"Created: {selector.safe_name}")
                messagebox.showinfo("Success", f"App {selector.safe_name} created.")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to create app: {e}")

    def _write_boilerplate(self, root_path, services):
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            subprocess.Popen(["cmd.exe", "/k", str(act)] if act.exists() else ["start", "cmd"], cwd=str(self.selected_app.folder))

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()


--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app_workingBACKUP_v1.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"
CONFIG_FILE = ROOT_DIR / "helper_apps.json"

GLOBAL_IGNORE_PATTERNS = [
    ".git", ".gitignore", ".gitattributes", ".vscode", ".idea",
    "__pycache__", "*.pyc", "*.pyo", ".DS_Store", "Thumbs.db",
    ".venv", "venv", "env", "node_modules",
    "_logs", "*.log", "*.tmp", "dist", "build",
    "*.exe", "*.dll", "*.so", "*.bin", "*.iso", "*.zip", "*.tar", "*.gz",
    "package-lock.json", "yarn.lock" 
]

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

# ---------- Discovery & Launch Logic ----------

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        self.colors = getattr(parent, 'widget_colors', {"bg": "#151521", "fg": "white", "selectbg": "#007ACC"})
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        # Folder Picker Row
        frame_folder = ttk.LabelFrame(self, text="Step 1: Target Location", padding=10)
        frame_folder.pack(fill="x", padx=10, pady=10)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", foreground="#ff6666", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        # Microservice Selection
        ttk.Label(self, text="Step 2: Select Microservices:", font=("Segoe UI", 10, "bold")).pack(pady=5)
        
        frame_list = ttk.Frame(self)
        frame_list.pack(fill="both", expand=True, padx=10, pady=5)
        canvas = tk.Canvas(frame_list, bg="#1e1e2f", highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=canvas.yview)
        scrollable_frame = tk.Frame(canvas, bg="#1e1e2f")
        scrollable_frame.bind("<Configure>", lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        self.check_vars = {}
        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        style = ttk.Style()
        style.configure("TCheckbutton", background="#1e1e2f", foreground="white")

        for f in unique_paths:
            var = tk.BooleanVar()
            cb = ttk.Checkbutton(scrollable_frame, text=f.name, variable=var, style="TCheckbutton")
            cb.pack(anchor="w", padx=5, pady=2)
            self.check_vars[f] = var

        # Footer
        btn_frame = ttk.Frame(self)
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(btn_frame, text="CREATE APP", bg="#444444", fg="gray", 
                                   state="disabled", command=self._on_confirm, borderwidth=0, padx=15)
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]
        self.confirmed = True
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("900x600")
        self._setup_styles()
        self._build_widgets()
        self._refresh_all()

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        bg_main, bg_dark, accent = "#1e1e2f", "#151521", "#007ACC"
        self.root.configure(bg=bg_main)
        style.configure("TFrame", background=bg_main)
        style.configure("TLabel", background=bg_main, foreground="white")
        style.configure("TLabelframe", background=bg_main, foreground="white")
        style.configure("TLabelframe.Label", background=bg_main, foreground="white")
        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", accent)])
        self.widget_colors = {"bg": bg_dark, "fg": "lightgray", "selectbg": accent}

    def _build_widgets(self):
        main_frame = ttk.Frame(self.root, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        # --- LEFT COLUMN ---
        left_frame = ttk.Frame(main_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # 1. Available Apps (The "Expander")
        ttk.Label(left_frame, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(left_frame, bg=self.widget_colors["bg"], 
                                      fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"], 
                                      borderwidth=0, highlightthickness=1, highlightbackground="#333333")
        # fill=BOTH and expand=True makes this fill the column by default
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))

        # 2. Archives Control (Checkbutton)
        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            left_frame, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        # 3. Archives Listbox (The "Contractor")
        self.archive_frame = ttk.Frame(left_frame)
        # Note: We do NOT pack archive_frame yet.
        
        self.archive_listbox = tk.Listbox(self.archive_frame, height=8, width=40, bg=self.widget_colors["bg"],
                                          fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"],
                                          borderwidth=0, highlightthickness=1, highlightbackground="#333333")
        self.archive_listbox.pack(fill=tk.X, expand=False) # Only fills width, height is fixed
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))

        # RIGHT DETAILS
        right_frame = ttk.Frame(main_frame, padding=(15, 0))
        right_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        self.details_text = tk.Text(right_frame, height=10, wrap="word", state="disabled",
                                    bg=self.widget_colors["bg"], fg=self.widget_colors["fg"], 
                                    borderwidth=0, padx=10, pady=10)
        self.details_text.pack(fill=tk.BOTH, expand=True)

        btn_row = ttk.Frame(right_frame)
        btn_row.pack(fill=tk.X, pady=(15, 0))
        
        ttk.Button(btn_row, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(btn_row, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_row, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        ttk.Button(btn_row, text="VENV", width=5, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(btn_row, text="PS", width=3, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(btn_row, text="CMD", width=4, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(btn_row, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _toggle_archives(self):
        if self.archive_var.get():
            # Show Archives: Pack at the bottom, don't let it expand
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            # Hide Archives: Remove from layout
            self.archive_frame.pack_forget()

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        
        self.app_listbox.delete(0, tk.END)
        for a in self.active_apps: self.app_listbox.insert(tk.END, a.name)
        
        self.archive_listbox.delete(0, tk.END)
        for a in self.archived_apps: self.archive_listbox.insert(tk.END, a.name)

    def _on_select(self, listbox):
        selection = listbox.curselection()
        if not selection: return
        name = listbox.get(selection[0])
        app = next((a for a in self.active_apps + self.archived_apps if a.name == name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _on_create_clicked(self):
        name = simpledialog.askstring("New App", "Enter project name:")
        if not name: return
        safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        if not selector.confirmed or not selector.target_path: return

        target_dir = selector.target_path / safe_name
        self._write_boilerplate(target_dir, selector.selected_files)
        self._refresh_all()
        messagebox.showinfo("Success", f"App {safe_name} created.")

    def _write_boilerplate(self, root_path: Path, services: List[Path]):
        root_path.mkdir(parents=True, exist_ok=True)
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            if act.exists(): subprocess.Popen(["cmd.exe", "/k", str(act)], cwd=str(self.selected_app.folder))
            else: self._on_open_cmd()

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app_workingBACKUP_v2.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"
CONFIG_FILE = ROOT_DIR / "helper_apps.json"

GLOBAL_IGNORE_PATTERNS = [
    ".git", ".gitignore", ".gitattributes", ".vscode", ".idea",
    "__pycache__", "*.pyc", "*.pyo", ".DS_Store", "Thumbs.db",
    ".venv", "venv", "env", "node_modules",
    "_logs", "*.log", "*.tmp", "dist", "build",
    "*.exe", "*.dll", "*.so", "*.bin", "*.iso", "*.zip", "*.tar", "*.gz",
    "package-lock.json", "yarn.lock" 
]

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

# ---------- Discovery & Launch Logic ----------

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        self.colors = getattr(parent, 'widget_colors', {"bg": "#151521", "fg": "white", "selectbg": "#007ACC"})
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.safe_name = ""
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        # Step 1: Project Name
        frame_name = ttk.LabelFrame(self, text="Step 1: Project Name", padding=10)
        frame_name.pack(fill="x", padx=10, pady=5)
        self.ent_name = ttk.Entry(frame_name)
        self.ent_name.pack(fill="x")

        # Step 2: Folder Picker Row
        frame_folder = ttk.LabelFrame(self, text="Step 2: Target Location", padding=10)
        frame_folder.pack(fill="x", padx=10, pady=5)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", foreground="#ff6666", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        # Step 3: Microservice Selection
        ttk.Label(self, text="Step 3: Select Microservices:", font=("Segoe UI", 10, "bold")).pack(pady=5)
        
        frame_list = ttk.Frame(self)
        frame_list.pack(fill="both", expand=True, padx=10, pady=5)
        canvas = tk.Canvas(frame_list, bg="#1e1e2f", highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=canvas.yview)
        scrollable_frame = tk.Frame(canvas, bg="#1e1e2f")
        scrollable_frame.bind("<Configure>", lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        # Mousewheel support
        canvas.bind_all("<MouseWheel>", lambda e: canvas.yview_scroll(int(-1*(e.delta/120)), "units"))

        self.check_vars = {}
        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        style = ttk.Style()
        style.configure("TCheckbutton", background="#1e1e2f", foreground="white")

        for f in unique_paths:
            var = tk.BooleanVar()
            cb = ttk.Checkbutton(scrollable_frame, text=f.name, variable=var, style="TCheckbutton")
            cb.pack(anchor="w", padx=5, pady=2)
            self.check_vars[f] = var

        # Footer
        btn_frame = ttk.Frame(self)
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(btn_frame, text="CREATE APP", bg="#444444", fg="gray", 
                                   state="disabled", command=self._on_confirm, borderwidth=0, padx=15)
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        name = self.ent_name.get().strip()
        if not name:
            messagebox.showerror("Error", "Project name is required.")
            return
        
        self.safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        if not self.target_path:
            messagebox.showerror("Error", "Target location is required.")
            return

        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]
        self.confirmed = True
        self.unbind_all("<MouseWheel>")
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("900x600")
        self.root.minsize(900, 600)
        
        self._setup_styles()
        self.search_var = tk.StringVar()
        self.search_var.trace_add("write", lambda *args: self._refresh_listbox_only())
        
        self._build_widgets()
        self._refresh_all()
        self._build_context_menu()

        # Double-click launch bindings
        self.app_listbox.bind("<Double-1>", self._on_double_click)
        self.archive_listbox.bind("<Double-1>", self._on_double_click)

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        bg_main, bg_dark, accent = "#1e1e2f", "#151521", "#007ACC"
        self.root.configure(bg=bg_main)
        style.configure("TFrame", background=bg_main)
        style.configure("TLabel", background=bg_main, foreground="white")
        style.configure("TLabelframe", background=bg_main, foreground="white")
        style.configure("TLabelframe.Label", background=bg_main, foreground="white")
        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", accent)])
        self.widget_colors = {"bg": bg_dark, "fg": "lightgray", "selectbg": accent}

    def _build_widgets(self):
        # Status Bar at the bottom
        self.status_bar = ttk.Label(self.root, text=" Ready", relief=tk.SUNKEN, anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # PanedWindow to allow resizing columns
        self.paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        self.paned.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # --- LEFT COLUMN ---
        left_frame = ttk.Frame(self.paned)
        self.paned.add(left_frame, weight=1)

        # Search and Available Apps
        ttk.Label(left_frame, text="Search Apps", font=("Segoe UI", 8)).pack(anchor="w")
        search_entry = ttk.Entry(left_frame, textvariable=self.search_var)
        search_entry.pack(fill=tk.X, pady=(0, 10))

        ttk.Label(left_frame, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(left_frame, bg=self.widget_colors["bg"], 
                                      fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"], 
                                      borderwidth=0, highlightthickness=1, highlightbackground="#333333")
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))
        self.app_listbox.bind("<Button-3>", self._show_context_menu)
        self.app_listbox.bind("<MouseWheel>", self._on_mousewheel)

        # Archives Control
        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            left_frame, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        self.archive_frame = ttk.Frame(left_frame)
        self.archive_listbox = tk.Listbox(self.archive_frame, height=8, width=40, bg=self.widget_colors["bg"],
                                          fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"],
                                          borderwidth=0, highlightthickness=1, highlightbackground="#333333")
        self.archive_listbox.pack(fill=tk.X, expand=False)
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))
        self.archive_listbox.bind("<Button-3>", self._show_context_menu)
        self.archive_listbox.bind("<MouseWheel>", self._on_mousewheel)

        # RIGHT DETAILS
        right_frame = ttk.Frame(self.paned, padding=(15, 0))
        self.paned.add(right_frame, weight=2)
        
        self.details_text = tk.Text(right_frame, height=10, wrap="word", state="disabled",
                                    bg=self.widget_colors["bg"], fg=self.widget_colors["fg"], 
                                    borderwidth=0, padx=10, pady=10)
        self.details_text.pack(fill=tk.BOTH, expand=True)
        self.details_text.bind("<MouseWheel>", self._on_mousewheel)

        btn_row = ttk.Frame(right_frame)
        btn_row.pack(fill=tk.X, pady=(15, 0))

        # Action Group (Left)
        left_btn_grp = ttk.Frame(btn_row)
        left_btn_grp.pack(side=tk.LEFT)
        
        ttk.Button(left_btn_grp, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(left_btn_grp, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        # Utility Group (Right)
        right_btn_grp = ttk.Frame(btn_row)
        right_btn_grp.pack(side=tk.RIGHT)

        ttk.Button(right_btn_grp, text="VENV", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="PS", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="CMD", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _on_mousewheel(self, event):
        """Universal scroll handler for listboxes and text widgets."""
        direction = -1 if event.delta > 0 else 1
        event.widget.yview_scroll(direction * 3, "units")

    def _on_double_click(self, event=None):
        self._on_launch_clicked()

    def _toggle_archives(self):
        if self.archive_var.get():
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            self.archive_frame.pack_forget()

    def _set_status(self, text):
        """Updates the status bar with a timestamped message."""
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        self.status_bar.config(text=f" [{ts}] {text}")

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        self._refresh_listbox_only()

    def _refresh_listbox_only(self):
        search_query = self.search_var.get().lower()
        
        self.app_listbox.delete(0, tk.END)
        for a in self.active_apps:
            if search_query in a.name.lower():
                icon = "üêç " if a.has_src_app else "‚≠ï "
                self.app_listbox.insert(tk.END, f"{icon}{a.name}")
        
        self.archive_listbox.delete(0, tk.END)
        for a in self.archived_apps:
            if search_query in a.name.lower():
                self.archive_listbox.insert(tk.END, f"üì¶ {a.name}")
        
        self._set_status(f"Refreshed list ({len(self.active_apps)} active, {len(self.archived_apps)} archived)")

    def _build_context_menu(self):
        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors["bg"], fg="white")
        self.context_menu.add_command(label="üöÄ Launch", command=self._on_launch_clicked)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üìÇ Open Folder", command=self._on_open_folder)
        self.context_menu.add_command(label="üíª CMD Terminal", command=self._on_open_cmd)
        self.context_menu.add_command(label="üêö PowerShell", command=self._on_open_ps)
        self.context_menu.add_command(label="üêç VENV Terminal", command=self._on_open_venv)

    def _show_context_menu(self, event):
        widget = event.widget
        index = widget.nearest(event.y)
        widget.selection_clear(0, tk.END)
        widget.selection_set(index)
        widget.activate(index)
        self._on_select(widget)
        self.context_menu.post(event.x_root, event.y_root)

    def _on_select(self, listbox):
        selection = listbox.curselection()
        if not selection: return
        raw_name = listbox.get(selection[0])
        # Strip icons to find original app name
        name = raw_name.replace("üêç ", "").replace("‚≠ï ", "").replace("üì¶ ", "")
        app = next((a for a in self.active_apps + self.archived_apps if a.name == name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _on_create_clicked(self):
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        
        if not selector.confirmed: 
            return

        target_dir = selector.target_path / selector.safe_name
        
        if target_dir.exists():
            messagebox.showerror("Error", f"Directory already exists:\n{target_dir}")
            return
        
        try:
            target_dir.mkdir(parents=True, exist_ok=True)
            self._write_boilerplate(target_dir, selector.selected_files)
            self._refresh_all()
            self._set_status(f"Created app: {selector.safe_name}")
            messagebox.showinfo("Success", f"App {selector.safe_name} created.")
        except Exception as e:
            messagebox.showerror("Creation Failed", f"Could not create project:\n{e}")

    def _write_boilerplate(self, root_path: Path, services: List[Path]):
        root_path.mkdir(parents=True, exist_ok=True)
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): 
            self._set_status(f"Launching {self.selected_app.name}...")
            launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            self._set_status(f"Opening VENV for {self.selected_app.name}")
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            if act.exists(): subprocess.Popen(["cmd.exe", "/k", str(act)], cwd=str(self.selected_app.folder))
            else: self._on_open_cmd()

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app_workingBackup_v3.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.safe_name = ""
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        frame_name = ttk.LabelFrame(self, text="Step 1: Project Name", padding=10)
        frame_name.pack(fill="x", padx=10, pady=5)
        self.ent_name = ttk.Entry(frame_name)
        self.ent_name.pack(fill="x")

        frame_folder = ttk.LabelFrame(self, text="Step 2: Target Location", padding=10)
        frame_folder.pack(fill="x", padx=10, pady=5)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", foreground="#ff6666", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        ttk.Label(self, text="Step 3: Select Microservices:", font=("Segoe UI", 10, "bold")).pack(pady=5)
        
        frame_list = ttk.Frame(self)
        frame_list.pack(fill="both", expand=True, padx=10, pady=5)
        self.canvas = tk.Canvas(frame_list, bg="#1e1e2f", highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=self.canvas.yview)
        scrollable_frame = tk.Frame(self.canvas, bg="#1e1e2f")
        scrollable_frame.bind("<Configure>", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        self.canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        self.canvas.bind_all("<MouseWheel>", self._on_canvas_scroll)

        self.check_vars = {}
        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        
        for f in unique_paths:
            var = tk.BooleanVar()
            cb = ttk.Checkbutton(scrollable_frame, text=f.name, variable=var, style="TCheckbutton")
            cb.pack(anchor="w", padx=5, pady=2)
            self.check_vars[f] = var

        btn_frame = ttk.Frame(self)
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(btn_frame, text="CREATE APP", bg="#444444", fg="gray", 
                                   state="disabled", command=self._on_confirm, borderwidth=0, padx=15)
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _on_canvas_scroll(self, event):
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        name = self.ent_name.get().strip()
        if not name:
            messagebox.showerror("Error", "Project name is required.")
            return
        self.safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        if not self.target_path:
            messagebox.showerror("Error", "Target location is required.")
            return
        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]
        self.confirmed = True
        self.unbind_all("<MouseWheel>")
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("1100x700")
        self.root.minsize(900, 600)
        self.root.resizable(True, True)
        
        # --- COLOR PALETTE ---
        self.colors = {
            "bg_main": "#1e1e2f",    # Medium-dark blue
            "bg_dark": "#151521",    # Darkest blue (inner textboxes)
            "bg_status": "#252538",  # Status bar brightness
            "accent": "#007ACC",     # Selection Blue
            "border": "#33334d",     # Subtle border color
            "fg": "#d1d1e0"          # Soft text
        }

        self._setup_styles()
        self.search_var = tk.StringVar()
        self.search_var.trace_add("write", lambda *args: self._refresh_listbox_only())
        
        self._build_widgets()
        self._refresh_all()
        self._build_context_menu()

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        
        style.configure("TFrame", background=self.colors["bg_main"])
        style.configure("TLabel", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.configure("TLabelframe", background=self.colors["bg_main"], foreground=self.colors["fg"], bordercolor=self.colors["border"])
        style.configure("TLabelframe.Label", background=self.colors["bg_main"], foreground=self.colors["fg"])
        
        # Status Bar - Zeroing out internal padding and relief 
        style.configure("Status.TLabel", background=self.colors["bg_status"], foreground=self.colors["fg"], padding=5)
        
        # Paned Window - Clean borders 
        style.configure("TPanedwindow", background=self.colors["border"])
        
        style.configure("TCheckbutton", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.map("TCheckbutton", background=[('active', self.colors["bg_main"])], foreground=[('active', 'white')])

        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", self.colors["accent"])])
        
        self.widget_colors = {"bg": self.colors["bg_dark"], "fg": self.colors["fg"], "selectbg": self.colors["accent"]}

    def _build_widgets(self):
        # 1. STATUS BAR (BOTTOM)
        self.status_bar = ttk.Label(self.root, text=" Ready", style="Status.TLabel", anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # 2. MAIN CONTENT WRAPPER (CENTER)
        # This frame provides the padding that keeps everything away from the window edges
        content_wrapper = tk.Frame(self.root, bg=self.colors["bg_main"], highlightthickness=0)
        content_wrapper.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # 3. PANED WINDOW (Within Content)
        # highlightthickness=0 removes that abrasive grey/white border 
        self.paned = ttk.PanedWindow(content_wrapper, orient=tk.HORIZONTAL)
        self.paned.pack(fill=tk.BOTH, expand=True)

        # --- LEFT COLUMN ---
        # Add internal padding so widgets don't collide with the sash 
        left_frame = ttk.Frame(self.paned)
        self.paned.add(left_frame, weight=1)

        # Search - Left Panel Padding
        search_container = ttk.Frame(left_frame)
        search_container.pack(fill=tk.X, padx=(5, 15), pady=(5, 10))
        
        ttk.Label(search_container, text="Search Apps", font=("Segoe UI", 8)).pack(anchor="w")
        search_entry = ttk.Entry(search_container, textvariable=self.search_var)
        search_entry.pack(fill=tk.X)

        # Listboxes - Left Panel Padding
        list_container = ttk.Frame(left_frame)
        list_container.pack(fill=tk.BOTH, expand=True, padx=(5, 15))

        ttk.Label(list_container, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(list_container, bg=self.widget_colors["bg"], 
                                      fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"], 
                                      borderwidth=0, highlightthickness=1, highlightbackground=self.colors["border"])
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))
        self.app_listbox.bind("<Button-3>", self._show_context_menu)
        self.app_listbox.bind("<Double-1>", self._on_double_click)

        # Archives with styled checkbox
        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            list_container, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        self.archive_frame = ttk.Frame(list_container)
        self.archive_listbox = tk.Listbox(self.archive_frame, height=8, bg=self.widget_colors["bg"],
                                          fg=self.widget_colors["fg"], selectbackground=self.widget_colors["selectbg"],
                                          borderwidth=0, highlightthickness=1, highlightbackground=self.colors["border"])
        self.archive_listbox.pack(fill=tk.X, expand=False)
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))
        self.archive_listbox.bind("<Button-3>", self._show_context_menu)
        self.archive_listbox.bind("<Double-1>", self._on_double_click)

        # --- RIGHT COLUMN ---
        right_frame = ttk.Frame(self.paned, padding=(15, 5, 5, 5))
        self.paned.add(right_frame, weight=2)
        
        self.details_text = tk.Text(right_frame, height=10, wrap="word", state="disabled",
                                    bg=self.widget_colors["bg"], fg=self.widget_colors["fg"], 
                                    borderwidth=0, padx=10, pady=10, highlightthickness=1, highlightbackground=self.colors["border"])
        self.details_text.pack(fill=tk.BOTH, expand=True)

        btn_row = ttk.Frame(right_frame)
        btn_row.pack(fill=tk.X, pady=(15, 0))

        # Buttons
        left_btn_grp = ttk.Frame(btn_row)
        left_btn_grp.pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(left_btn_grp, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        right_btn_grp = ttk.Frame(btn_row)
        right_btn_grp.pack(side=tk.RIGHT)
        ttk.Button(right_btn_grp, text="VENV", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="PS", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="CMD", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _on_double_click(self, event=None):
        self._on_launch_clicked()

    def _toggle_archives(self):
        if self.archive_var.get():
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            self.archive_frame.pack_forget()

    def _set_status(self, text):
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        self.status_bar.config(text=f" [{ts}] {text}")

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        self._refresh_listbox_only()

    def _refresh_listbox_only(self):
        query = self.search_var.get().lower()
        self.app_listbox.delete(0, tk.END)
        for a in self.active_apps:
            if query in a.name.lower():
                self.app_listbox.insert(tk.END, f"{'üêç ' if a.has_src_app else '‚≠ï '}{a.name}")
        
        self.archive_listbox.delete(0, tk.END)
        for a in self.archived_apps:
            if query in a.name.lower():
                self.archive_listbox.insert(tk.END, f"üì¶ {a.name}")
        self._set_status(f"Refreshed list ({len(self.active_apps)} active)")

    def _build_context_menu(self):
        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors["bg"], fg="white")
        self.context_menu.add_command(label="üöÄ Launch", command=self._on_launch_clicked)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üìÇ Open Folder", command=self._on_open_folder)
        self.context_menu.add_command(label="üíª CMD Terminal", command=self._on_open_cmd)
        self.context_menu.add_command(label="üêö PowerShell", command=self._on_open_ps)
        self.context_menu.add_command(label="üêç VENV Terminal", command=self._on_open_venv)

    def _show_context_menu(self, event):
        widget = event.widget
        index = widget.nearest(event.y)
        widget.selection_clear(0, tk.END)
        widget.selection_set(index)
        self._on_select(widget)
        self.context_menu.post(event.x_root, event.y_root)

    def _on_select(self, listbox):
        sel = listbox.curselection()
        if not sel: return
        name = listbox.get(sel[0])[2:] # Strip icon
        app = next((a for a in self.active_apps + self.archived_apps if a.name == name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _on_create_clicked(self):
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        if selector.confirmed:
            target = selector.target_path / selector.safe_name
            target.mkdir(parents=True, exist_ok=True)
            self._write_boilerplate(target, selector.selected_files)
            self._refresh_all()
            self._set_status(f"Created: {selector.safe_name}")

    def _write_boilerplate(self, root_path, services):
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            subprocess.Popen(["cmd.exe", "/k", str(act)] if act.exists() else ["start", "cmd"], cwd=str(self.selected_app.folder))

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app_workingBACKUP_v4.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.safe_name = ""
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        frame_name = ttk.LabelFrame(self, text="Step 1: Project Name", padding=10)
        frame_name.pack(fill="x", padx=10, pady=5)
        self.ent_name = ttk.Entry(frame_name)
        self.ent_name.pack(fill="x")

        frame_folder = ttk.LabelFrame(self, text="Step 2: Target Location", padding=10)
        frame_folder.pack(fill="x", padx=10, pady=5)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", foreground="#ff6666", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        ttk.Label(self, text="Step 3: Select Microservices:", font=("Segoe UI", 10, "bold")).pack(pady=5)
        
        frame_list = ttk.Frame(self)
        frame_list.pack(fill="both", expand=True, padx=10, pady=5)
        self.canvas = tk.Canvas(frame_list, bg="#1e1e2f", highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=self.canvas.yview)
        scrollable_frame = tk.Frame(self.canvas, bg="#1e1e2f")
        scrollable_frame.bind("<Configure>", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        self.canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        self.canvas.bind_all("<MouseWheel>", self._on_canvas_scroll)

        self.check_vars = {}
        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        
        for f in unique_paths:
            var = tk.BooleanVar()
            cb = ttk.Checkbutton(scrollable_frame, text=f.name, variable=var, style="TCheckbutton")
            cb.pack(anchor="w", padx=5, pady=2)
            self.check_vars[f] = var

        btn_frame = ttk.Frame(self)
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(btn_frame, text="CREATE APP", bg="#444444", fg="gray", 
                                   state="disabled", command=self._on_confirm, borderwidth=0, padx=15)
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _on_canvas_scroll(self, event):
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        name = self.ent_name.get().strip()
        if not name:
            messagebox.showerror("Error", "Project name is required.")
            return
        self.safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        if not self.target_path:
            messagebox.showerror("Error", "Target location is required.")
            return
        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]
        self.confirmed = True
        self.unbind_all("<MouseWheel>")
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("1100x700")
        self.root.minsize(900, 600)
        self.root.resizable(True, True)
        self.last_selected_name = None
        self.colors = {
            "bg_main": "#1e1e2f",    
            "bg_dark": "#151521",    
            "bg_status": "#252538",  
            "accent": "#007ACC",     
            "border": "#33334d",     
            "fg": "#d1d1e0"          
        }
        self.root.configure(bg=self.colors["bg_main"])
        self._setup_styles()
        self.search_var = tk.StringVar()
        self.search_var.trace_add("write", lambda *args: self._refresh_listbox_only())
        
        self._build_widgets()
        self._refresh_all()
        self._build_context_menu()

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        
        style.configure("TFrame", background=self.colors["bg_main"])
        style.configure("TLabel", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.configure("Status.TLabel", background=self.colors["bg_status"], foreground=self.colors["fg"], padding=5)
        
        style.configure("TCheckbutton", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.map("TCheckbutton", background=[('active', self.colors["bg_main"])], foreground=[('active', 'white')])

        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", self.colors["accent"])])
        
        self.widget_colors = {"bg": self.colors["bg_dark"], "fg": self.colors["fg"], "selectbg": self.colors["accent"]}

    def _build_widgets(self):
        # 1. STATUS BAR
        self.status_bar = ttk.Label(self.root, text=" Ready", style="Status.TLabel", anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # 2. MAIN CONTENT WRAPPER
        content_wrapper = tk.Frame(self.root, bg=self.colors["bg_main"], highlightthickness=0)
        content_wrapper.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # 3. PANED WINDOW - Surgical Fix: tk.PanedWindow does not support 'highlightthickness'
        self.paned = tk.PanedWindow(
            content_wrapper, 
            orient=tk.HORIZONTAL, 
            bg=self.colors["bg_main"],
            borderwidth=0, 
            sashwidth=4,
            sashpad=0
        )
        self.paned.pack(fill=tk.BOTH, expand=True)

        # LEFT PANEL
        left_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(left_panel, width=300)

        left_inner = ttk.Frame(left_panel)
        left_inner.pack(fill=tk.BOTH, expand=True, padx=(5, 15), pady=5)

        search_container = ttk.Frame(left_inner)
        search_container.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(search_container, text="Search Apps", font=("Segoe UI", 8)).pack(anchor="w")
        ttk.Entry(search_container, textvariable=self.search_var).pack(fill=tk.X)

        ttk.Label(left_inner, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(
            left_inner, 
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"], 
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))
        self.app_listbox.bind("<Button-3>", self._show_context_menu)
        self.app_listbox.bind("<Double-1>", self._on_double_click)

        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            left_inner, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        self.archive_frame = ttk.Frame(left_inner)
        self.archive_listbox = tk.Listbox(
            self.archive_frame, 
            height=8, 
            bg=self.widget_colors["bg"],
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"],
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.archive_listbox.pack(fill=tk.X, expand=False)
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))
        self.archive_listbox.bind("<Button-3>", self._show_context_menu)
        self.archive_listbox.bind("<Double-1>", self._on_double_click)

        # RIGHT PANEL
        right_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(right_panel)

        right_inner = ttk.Frame(right_panel)
        right_inner.pack(fill=tk.BOTH, expand=True, padx=(15, 5), pady=5)
        
        self.details_text = tk.Text(
            right_inner, 
            height=10, 
            wrap="word", 
            state="disabled",
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            borderwidth=0, 
            padx=10, 
            pady=10, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.details_text.pack(fill=tk.BOTH, expand=True)

        btn_row = ttk.Frame(right_inner)
        btn_row.pack(fill=tk.X, pady=(15, 0))

        left_btn_grp = ttk.Frame(btn_row)
        left_btn_grp.pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(left_btn_grp, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        right_btn_grp = ttk.Frame(btn_row)
        right_btn_grp.pack(side=tk.RIGHT)
        ttk.Button(right_btn_grp, text="VENV", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="PS", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="CMD", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _on_double_click(self, event=None):
        self._on_launch_clicked()

    def _toggle_archives(self):
        if self.archive_var.get():
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            self.archive_frame.pack_forget()

    def _set_status(self, text):
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        self.status_bar.config(text=f" [{ts}] {text}")

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        self._refresh_listbox_only()

    def _refresh_listbox_only(self):
        query = self.search_var.get().lower()
        targets = [
            (self.app_listbox, self.active_apps, 'üêç '), 
            (self.archive_listbox, self.archived_apps, 'üì¶ ')
        ]
        
        for lb, app_list, default_icon in targets:
            lb.delete(0, tk.END)
            for a in app_list:
                if query in a.name.lower():
                    if default_icon == 'üì¶ ':
                        icon = 'üì¶ '
                    else:
                        icon = 'üêç ' if a.has_src_app else '‚≠ï '
                    lb.insert(tk.END, f"{icon}{a.name}")
            
            if self.last_selected_name:
                all_items = lb.get(0, tk.END)
                for idx, display_val in enumerate(all_items):
                    if display_val[2:] == self.last_selected_name:
                        lb.selection_set(idx)
                        lb.activate(idx)
                        lb.see(idx) 
                        break

        self._set_status(f"Refreshed list ({len(self.active_apps)} active, {len(self.archived_apps)} archived)")

    def _on_select(self, listbox):
        sel = listbox.curselection()
        if not sel: return
        
        raw_val = listbox.get(sel[0])
        self.last_selected_name = raw_val[2:]
        
        app = next((a for a in self.active_apps + self.archived_apps if a.name == self.last_selected_name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _build_context_menu(self):
        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors["bg"], fg="white")
        self.context_menu.add_command(label="üöÄ Launch", command=self._on_launch_clicked)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üìÇ Open Folder", command=self._on_open_folder)
        self.context_menu.add_command(label="üíª CMD Terminal", command=self._on_open_cmd)
        self.context_menu.add_command(label="üêö PowerShell", command=self._on_open_ps)
        self.context_menu.add_command(label="üêç VENV Terminal", command=self._on_open_venv)

    def _show_context_menu(self, event):
        widget = event.widget
        index = widget.nearest(event.y)
        widget.selection_clear(0, tk.END)
        widget.selection_set(index)
        self._on_select(widget)
        self.context_menu.post(event.x_root, event.y_root)

    def _on_create_clicked(self):
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        if selector.confirmed:
            target = selector.target_path / selector.safe_name
            try:
                target.mkdir(parents=True, exist_ok=True)
                self._write_boilerplate(target, selector.selected_files)
                self._refresh_all()
                self._set_status(f"Created: {selector.safe_name}")
                messagebox.showinfo("Success", f"App {selector.safe_name} created.")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to create app: {e}")

    def _write_boilerplate(self, root_path, services):
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            subprocess.Popen(["cmd.exe", "/k", str(act)] if act.exists() else ["start", "cmd"], cwd=str(self.selected_app.folder))

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\app_workingBACKUP_v5.pyw
--------------------------------------------------------------------------------
import json
import os
import shutil
import subprocess
import sys
import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import tkinter as tk
from tkinter import ttk, messagebox, simpledialog

# ==============================================================================
# CONFIGURATION
# ==============================================================================
ROOT_DIR = Path(__file__).resolve().parent.parent.parent
MICROSERVICE_LIB_PATH = ROOT_DIR / "_MicroserviceLIBRARY"

@dataclass
class AppConfig:
    name: str
    folder: Path
    python_cmd: Optional[str] = None
    env: Dict[str, str] = field(default_factory=dict)

    @property
    def has_src_app(self) -> bool:
        return (self.folder / "src" / "app.py").is_file()

    def resolve_python(self) -> List[str]:
        if self.python_cmd:
            cmd = self.python_cmd
            if os.path.sep in cmd or "/" in cmd:
                return [str((self.folder / cmd).resolve())]
            return [cmd]

        win_candidate = self.folder / ".venv" / "Scripts" / "pythonw.exe"
        win_fallback = self.folder / ".venv" / "Scripts" / "python.exe"
        
        if win_candidate.is_file(): return [str(win_candidate.resolve())]
        if win_fallback.is_file(): return [str(win_fallback.resolve())]
        
        return ["pyw"] if os.name == "nt" else [sys.executable]

def discover_apps(base_dir: Path) -> List[AppConfig]:
    apps = []
    if base_dir.is_dir():
        for child in base_dir.iterdir():
            if child.is_dir() and (child / "src" / "app.py").is_file():
                apps.append(AppConfig(name=child.name, folder=child))
    return sorted(apps, key=lambda a: a.name.lower())

def launch_app(app_cfg: AppConfig):
    if not app_cfg.has_src_app:
        messagebox.showerror("Error", f"Missing src/app.py in:\n{app_cfg.folder}")
        return
    cmd = app_cfg.resolve_python() + ["-m", "src.app"]
    env = os.environ.copy()
    env.update(app_cfg.env)
    try:
        subprocess.Popen(cmd, cwd=str(app_cfg.folder), env=env)
    except Exception as e:
        messagebox.showerror("Launch failed", f"Failed to launch {app_cfg.name}:\n{e}")

# ==============================================================================
# UI COMPONENTS
# ==============================================================================

class MicroserviceSelector(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title("Scaffolding Details")
        self.geometry("600x800")
        self.configure(bg="#1e1e2f")
        
        self.confirmed = False
        self.selected_files = []
        self.target_path = None
        self.safe_name = ""
        self.available_files = {}

        if MICROSERVICE_LIB_PATH.exists():
            for f in MICROSERVICE_LIB_PATH.glob("*MS.py"):
                self.available_files[f.name] = f
                self.available_files[f.stem.lstrip("_")] = f

        self._build_ui()
        self.transient(parent)
        self.grab_set()

    def _build_ui(self):
        frame_name = ttk.LabelFrame(self, text="Step 1: Project Name", padding=10)
        frame_name.pack(fill="x", padx=10, pady=5)
        self.ent_name = ttk.Entry(frame_name)
        self.ent_name.pack(fill="x")

        frame_folder = ttk.LabelFrame(self, text="Step 2: Target Location", padding=10)
        frame_folder.pack(fill="x", padx=10, pady=5)
        self.lbl_path = ttk.Label(frame_folder, text="No folder selected...", foreground="#ff6666", wraplength=450)
        self.lbl_path.pack(side="left", padx=5)
        ttk.Button(frame_folder, text="Browse...", command=self._on_browse).pack(side="right")

        ttk.Label(self, text="Step 3: Select Microservices:", font=("Segoe UI", 10, "bold")).pack(pady=5)
        
        frame_list = ttk.Frame(self)
        frame_list.pack(fill="both", expand=True, padx=10, pady=5)
        self.canvas = tk.Canvas(frame_list, bg="#1e1e2f", highlightthickness=0)
        scrollbar = ttk.Scrollbar(frame_list, orient="vertical", command=self.canvas.yview)
        scrollable_frame = tk.Frame(self.canvas, bg="#1e1e2f")
        scrollable_frame.bind("<Configure>", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        self.canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")

        self.canvas.bind_all("<MouseWheel>", self._on_canvas_scroll)

        self.check_vars = {}
        unique_paths = sorted(list(set(self.available_files.values())), key=lambda p: p.name)
        
        for f in unique_paths:
            var = tk.BooleanVar()
            cb = ttk.Checkbutton(scrollable_frame, text=f.name, variable=var, style="TCheckbutton")
            cb.pack(anchor="w", padx=5, pady=2)
            self.check_vars[f] = var

        btn_frame = ttk.Frame(self)
        btn_frame.pack(fill="x", pady=10, padx=10)
        self.btn_create = tk.Button(btn_frame, text="CREATE APP", bg="#444444", fg="gray", 
                                   state="disabled", command=self._on_confirm, borderwidth=0, padx=15)
        self.btn_create.pack(side="right", padx=5)
        ttk.Button(btn_frame, text="Cancel", command=self.destroy).pack(side="right")

    def _on_canvas_scroll(self, event):
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")

    def _on_browse(self):
        from tkinter import filedialog
        path = filedialog.askdirectory(title="Select Target Location", initialdir=str(ROOT_DIR))
        if path:
            self.target_path = Path(path)
            self.lbl_path.config(text=str(self.target_path), foreground="#00FF00")
            self.btn_create.config(state="normal", bg="#007ACC", fg="white")

    def _on_confirm(self):
        name = self.ent_name.get().strip()
        if not name:
            messagebox.showerror("Error", "Project name is required.")
            return
        self.safe_name = "".join(c for c in name if c.isalnum() or c in ('_', '-')).strip()
        if not self.target_path:
            messagebox.showerror("Error", "Target location is required.")
            return
        self.selected_files = [f for f, var in self.check_vars.items() if var.get()]
        self.confirmed = True
        self.unbind_all("<MouseWheel>")
        self.destroy()

class AppLauncherUI:
    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("Useful Helper Apps Launcher")
        self.root.geometry("1100x700")
        self.root.minsize(900, 600)
        self.root.resizable(True, True)
        self.last_selected_name = None
        self.colors = {
            "bg_main": "#1e1e2f",    
            "bg_dark": "#151521",    
            "bg_status": "#252538",  
            "accent": "#007ACC",     
            "border": "#33334d",     
            "fg": "#d1d1e0"          
        }
        self.root.configure(bg=self.colors["bg_main"])
        self._setup_styles()
        self.search_var = tk.StringVar()
        self.search_var.trace_add("write", lambda *args: self._refresh_listbox_only())
        
        self._build_widgets()
        self._refresh_all()
        self._build_context_menu()

    def _setup_styles(self):
        style = ttk.Style()
        style.theme_use("clam")
        
        style.configure("TFrame", background=self.colors["bg_main"])
        style.configure("TLabel", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.configure("Status.TLabel", background=self.colors["bg_status"], foreground=self.colors["fg"], padding=5)
        
        style.configure("TCheckbutton", background=self.colors["bg_main"], foreground=self.colors["fg"])
        style.map("TCheckbutton", background=[('active', self.colors["bg_main"])], foreground=[('active', 'white')])

        style.configure("TButton", background="#2a2a3f", foreground="white", borderwidth=0)
        style.map("TButton", background=[("active", self.colors["accent"])])
        
        self.widget_colors = {"bg": self.colors["bg_dark"], "fg": self.colors["fg"], "selectbg": self.colors["accent"]}

    def _build_widgets(self):
        # 1. STATUS BAR
        self.status_bar = ttk.Label(self.root, text=" Ready", style="Status.TLabel", anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # 2. MAIN CONTENT WRAPPER
        content_wrapper = tk.Frame(self.root, bg=self.colors["bg_main"], highlightthickness=0)
        content_wrapper.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # 3. PANED WINDOW - Surgical Fix: tk.PanedWindow does not support 'highlightthickness'
        self.paned = tk.PanedWindow(
            content_wrapper, 
            orient=tk.HORIZONTAL, 
            bg=self.colors["bg_main"],
            borderwidth=0, 
            sashwidth=4,
            sashpad=0
        )
        self.paned.pack(fill=tk.BOTH, expand=True)

        # LEFT PANEL
        left_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(left_panel, width=300)

        left_inner = ttk.Frame(left_panel)
        left_inner.pack(fill=tk.BOTH, expand=True, padx=(5, 15), pady=5)

        search_container = ttk.Frame(left_inner)
        search_container.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(search_container, text="Search Apps", font=("Segoe UI", 8)).pack(anchor="w")
        ttk.Entry(search_container, textvariable=self.search_var).pack(fill=tk.X)

        ttk.Label(left_inner, text="Available Apps", font=("Segoe UI", 9, "bold")).pack(anchor="w")
        self.app_listbox = tk.Listbox(
            left_inner, 
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"], 
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.app_listbox.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.app_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.app_listbox))
        self.app_listbox.bind("<Button-3>", self._show_context_menu)
        self.app_listbox.bind("<Double-1>", self._on_double_click)

        self.archive_var = tk.BooleanVar(value=False)
        self.archive_check = ttk.Checkbutton(
            left_inner, text="Show Archives", variable=self.archive_var, command=self._toggle_archives
        )
        self.archive_check.pack(anchor="w", pady=5)

        self.archive_frame = ttk.Frame(left_inner)
        self.archive_listbox = tk.Listbox(
            self.archive_frame, 
            height=8, 
            bg=self.widget_colors["bg"],
            fg=self.widget_colors["fg"], 
            selectbackground=self.widget_colors["selectbg"],
            borderwidth=0, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.archive_listbox.pack(fill=tk.X, expand=False)
        self.archive_listbox.bind("<<ListboxSelect>>", lambda e: self._on_select(self.archive_listbox))
        self.archive_listbox.bind("<Button-3>", self._show_context_menu)
        self.archive_listbox.bind("<Double-1>", self._on_double_click)

        # RIGHT PANEL
        right_panel = tk.Frame(self.paned, bg=self.colors["bg_main"], highlightthickness=0)
        self.paned.add(right_panel)

        right_inner = ttk.Frame(right_panel)
        right_inner.pack(fill=tk.BOTH, expand=True, padx=(15, 5), pady=5)
        
        self.details_text = tk.Text(
            right_inner, 
            height=10, 
            wrap="word", 
            state="disabled",
            bg=self.widget_colors["bg"], 
            fg=self.widget_colors["fg"], 
            borderwidth=0, 
            padx=10, 
            pady=10, 
            highlightthickness=1, 
            highlightbackground=self.colors["border"]
        )
        self.details_text.pack(fill=tk.BOTH, expand=True)

        btn_row = ttk.Frame(right_inner)
        btn_row.pack(fill=tk.X, pady=(15, 0))

        left_btn_grp = ttk.Frame(btn_row)
        left_btn_grp.pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Launch", command=self._on_launch_clicked).pack(side=tk.LEFT)
        ttk.Button(left_btn_grp, text="Create New...", command=self._on_create_clicked).pack(side=tk.LEFT, padx=5)
        ttk.Button(left_btn_grp, text="Refresh", command=self._refresh_all).pack(side=tk.LEFT)

        right_btn_grp = ttk.Frame(btn_row)
        right_btn_grp.pack(side=tk.RIGHT)
        ttk.Button(right_btn_grp, text="VENV", width=6, command=self._on_open_venv).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="PS", width=4, command=self._on_open_ps).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="CMD", width=5, command=self._on_open_cmd).pack(side=tk.RIGHT, padx=2)
        ttk.Button(right_btn_grp, text="Folder", command=self._on_open_folder).pack(side=tk.RIGHT)

    def _on_double_click(self, event=None):
        self._on_launch_clicked()

    def _toggle_archives(self):
        if self.archive_var.get():
            self.archive_frame.pack(side=tk.BOTTOM, fill=tk.X, before=self.archive_check)
        else:
            self.archive_frame.pack_forget()

    def _set_status(self, text):
        ts = datetime.datetime.now().strftime("%H:%M:%S")
        self.status_bar.config(text=f" [{ts}] {text}")

    def _refresh_all(self):
        self.active_apps = discover_apps(ROOT_DIR)
        self.archived_apps = discover_apps(ROOT_DIR / "__ARCHIVES__")
        self._refresh_listbox_only()

    def _refresh_listbox_only(self):
        query = self.search_var.get().lower()
        targets = [
            (self.app_listbox, self.active_apps, 'üêç '), 
            (self.archive_listbox, self.archived_apps, 'üì¶ ')
        ]
        
        for lb, app_list, default_icon in targets:
            lb.delete(0, tk.END)
            for a in app_list:
                if query in a.name.lower():
                    if default_icon == 'üì¶ ':
                        icon = 'üì¶ '
                    else:
                        icon = 'üêç ' if a.has_src_app else '‚≠ï '
                    lb.insert(tk.END, f"{icon}{a.name}")
            
            if self.last_selected_name:
                all_items = lb.get(0, tk.END)
                for idx, display_val in enumerate(all_items):
                    if display_val[2:] == self.last_selected_name:
                        lb.selection_set(idx)
                        lb.activate(idx)
                        lb.see(idx) 
                        break

        self._set_status(f"Refreshed list ({len(self.active_apps)} active, {len(self.archived_apps)} archived)")

    def _on_select(self, listbox):
        sel = listbox.curselection()
        if not sel: return
        
        raw_val = listbox.get(sel[0])
        self.last_selected_name = raw_val[2:]
        
        app = next((a for a in self.active_apps + self.archived_apps if a.name == self.last_selected_name), None)
        if app:
            self.selected_app = app
            self.details_text.config(state="normal")
            self.details_text.delete("1.0", tk.END)
            self.details_text.insert("1.0", f"Name: {app.name}\nFolder: {app.folder}\nPython: {' '.join(app.resolve_python())}")
            self.details_text.config(state="disabled")

    def _build_context_menu(self):
        self.context_menu = tk.Menu(self.root, tearoff=0, bg=self.widget_colors["bg"], fg="white")
        self.context_menu.add_command(label="üöÄ Launch", command=self._on_launch_clicked)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üìÇ Open Folder", command=self._on_open_folder)
        self.context_menu.add_command(label="üíª CMD Terminal", command=self._on_open_cmd)
        self.context_menu.add_command(label="üêö PowerShell", command=self._on_open_ps)
        self.context_menu.add_command(label="üêç VENV Terminal", command=self._on_open_venv)

    def _show_context_menu(self, event):
        widget = event.widget
        index = widget.nearest(event.y)
        widget.selection_clear(0, tk.END)
        widget.selection_set(index)
        self._on_select(widget)
        self.context_menu.post(event.x_root, event.y_root)

    def _on_create_clicked(self):
        selector = MicroserviceSelector(self.root)
        self.root.wait_window(selector)
        if selector.confirmed:
            target = selector.target_path / selector.safe_name
            try:
                target.mkdir(parents=True, exist_ok=True)
                self._write_boilerplate(target, selector.selected_files)
                self._refresh_all()
                self._set_status(f"Created: {selector.safe_name}")
                messagebox.showinfo("Success", f"App {selector.safe_name} created.")
            except Exception as e:
                messagebox.showerror("Error", f"Failed to create app: {e}")

    def _write_boilerplate(self, root_path, services):
        (root_path / "src").mkdir(exist_ok=True)
        ms_dir = root_path / "src" / "microservices"
        ms_dir.mkdir(exist_ok=True)
        for dep in ["microservice_std_lib.py", "base_service.py", "document_utils.py"]:
            src = MICROSERVICE_LIB_PATH / dep
            if src.exists(): shutil.copy2(src, ms_dir / dep)
        for s in services: shutil.copy2(s, ms_dir / s.name)

    def _on_launch_clicked(self):
        if hasattr(self, 'selected_app'): launch_app(self.selected_app)

    def _on_open_venv(self):
        if hasattr(self, 'selected_app'):
            act = self.selected_app.folder / ".venv" / "Scripts" / "activate.bat"
            subprocess.Popen(["cmd.exe", "/k", str(act)] if act.exists() else ["start", "cmd"], cwd=str(self.selected_app.folder))

    def _on_open_folder(self):
        if hasattr(self, 'selected_app'): os.startfile(self.selected_app.folder)

    def _on_open_cmd(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "cmd"], shell=True, cwd=self.selected_app.folder)

    def _on_open_ps(self):
        if hasattr(self, 'selected_app'): subprocess.Popen(["start", "powershell"], shell=True, cwd=self.selected_app.folder)

if __name__ == "__main__":
    root = tk.Tk()
    AppLauncherUI(root)
    root.mainloop()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\__init__.py
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\microservices\_ContextAggregatorMS.py
--------------------------------------------------------------------------------
"""
SERVICE_NAME: _ContextAggregatorMS
ENTRY_POINT: _ContextAggregatorMS.py
DEPENDENCIES: None
"""

import os
import fnmatch
import datetime
import logging
from pathlib import Path
from typing import Set, Optional, Dict, Any
from microservice_std_lib import service_metadata, service_endpoint

# ==============================================================================
# USER CONFIGURATION: DEFAULTS
# ==============================================================================
# Extensions known to be binary/non-text (Images, Archives, Executables)
DEFAULT_BINARY_EXTENSIONS = {
    ".tar.gz", ".gz", ".zip", ".rar", ".7z", ".bz2", ".xz", ".tgz",
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".ico", ".webp", ".tif", ".tiff",
    ".mp3", ".wav", ".ogg", ".flac", ".mp4", ".mkv", ".avi", ".mov", ".webm",
    ".pdf", ".doc", ".docx", ".xls", ".xlsx", ".ppt", ".pptx", ".exe", ".dll", ".so",
    ".db", ".sqlite", ".mdb", ".pyc", ".pyo", ".class", ".jar", ".wasm"
}

# Folders to ignore by default
DEFAULT_IGNORE_DIRS = {
    "node_modules", ".git", "__pycache__", ".venv", ".env", 
    "dist", "build", "coverage", ".idea", ".vscode"
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger("ContextAggregator")
# ==============================================================================

@service_metadata(
    name="ContextAggregator",
    version="1.0.0",
    description="Flattens a project folder into a single readable text file.",
    tags=["filesystem", "context", "compilation"],
    capabilities=["filesystem:read", "filesystem:write"],
    dependencies=["os", "fnmatch", "datetime"],
    side_effects=["filesystem:read", "filesystem:write"]
)
class ContextAggregatorMS:
    """
    The Context Builder: Flattens a project folder into a single readable text file.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        max_file_size_mb = self.config.get("max_file_size_mb", 1)
        self.max_file_size_bytes = max_file_size_mb * 1024 * 1024

    @service_endpoint(
        inputs={"root_path": "str", "output_file": "str", "extra_exclusions": "Set[str]", "use_default_exclusions": "bool"},
        outputs={"file_count": "int"},
        description="Aggregates project files into a single text dump.",
        tags=["filesystem", "dump"],
        side_effects=["filesystem:read", "filesystem:write"]
    )
    def aggregate(self, 
                  root_path: str, 
                  output_file: str, 
                  extra_exclusions: Optional[Set[str]] = None,
                  use_default_exclusions: bool = True) -> int:
        
        project_root = Path(root_path).resolve()
        out_path = Path(output_file).resolve()
        
        # Build Exclusions
        exclusions = set()
        if use_default_exclusions:
            exclusions.update(DEFAULT_IGNORE_DIRS)
        if extra_exclusions:
            exclusions.update(extra_exclusions)

        # Build Binary List
        binary_exts = DEFAULT_BINARY_EXTENSIONS.copy()
        
        file_count = 0
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        try:
            with open(out_path, "w", encoding="utf-8") as out_f:
                out_f.write(f"File Dump from Project: {project_root.name}\nGenerated: {timestamp}\n{'='*60}\n\n")

                for root, dirs, files in os.walk(project_root):
                    # In-place filtering of directories
                    dirs[:] = [d for d in dirs if d not in exclusions]
                    
                    for filename in files:
                        if self._should_exclude(filename, exclusions): continue

                        file_path = Path(root) / filename
                        if file_path.resolve() == out_path: continue

                        if self._is_safe_to_dump(file_path, binary_exts):
                            self._write_file_content(out_f, file_path, project_root)
                            file_count += 1                            
        except IOError as e:
            log.error(f"Error writing dump: {e}")
            
        return file_count

    def _should_exclude(self, filename: str, exclusions: Set[str]) -> bool:
        return any(fnmatch.fnmatch(filename, pattern) for pattern in exclusions)

    def _is_safe_to_dump(self, file_path: Path, binary_exts: Set[str]) -> bool:
        if "".join(file_path.suffixes).lower() in binary_exts: return False
        try:
            if file_path.stat().st_size > self.max_file_size_bytes: return False
            with open(file_path, 'rb') as f:
                if b'\0' in f.read(1024): return False
        except (IOError, OSError): return False
        return True

    def _write_file_content(self, out_f, file_path: Path, project_root: Path):
        relative_path = file_path.relative_to(project_root)
        header = f"\n{'-'*20} FILE: {relative_path} {'-'*20}\n"
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as in_f:
                out_f.write(header + in_f.read() + f"\n{'-'*60}\n")
        except Exception as e:
            out_f.write(f"\n[Error reading file: {e}]\n")

if __name__ == "__main__":
    svc = ContextAggregatorMS()
    print("Service ready:", svc)
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\src\microservices\_TreeMapperMS.py
--------------------------------------------------------------------------------
import os
import datetime
import logging
from pathlib import Path
from typing import Any, Dict, List, Set, Optional

from microservice_std_lib import service_metadata, service_endpoint

# ==============================================================================
# CONFIGURATION
# ==============================================================================
DEFAULT_EXCLUDES = {
    '.git', '__pycache__', '.idea', '.vscode', 'node_modules', 
    '.venv', 'env', 'venv', 'dist', 'build', '.DS_Store'
}
logger = logging.getLogger("TreeMapper")

# ==============================================================================
# MICROSERVICE CLASS
# ==============================================================================

@service_metadata(
    name="TreeMapper",
    version="1.0.0",
    description="Generates ASCII-art style directory maps of the file system.",
    tags=["filesystem", "map", "visualization"],
    capabilities=["filesystem:read"]
)
class TreeMapperMS:
    """
    The Cartographer: Generates ASCII-art style directory maps.
    Useful for creating context snapshots for LLMs.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}

    @service_endpoint(
        inputs={"root_path": "str", "additional_exclusions": "Set[str]", "use_default_exclusions": "bool"},
        outputs={"tree_map": "str"},
        description="Generates an ASCII tree map of the directory.",
        tags=["filesystem", "visualization"],
        side_effects=["filesystem:read"]
    )
    def generate_tree(self, 
                      root_path: str, 
                      additional_exclusions: Optional[Set[str]] = None,
                      use_default_exclusions: bool = True) -> str:
        
        start_path = Path(root_path).resolve()
        if not start_path.exists(): 
            return f"Error: Path '{root_path}' does not exist."

        exclusions = set()
        if use_default_exclusions:
            exclusions.update(DEFAULT_EXCLUDES)
        if additional_exclusions:
            exclusions.update(additional_exclusions)

        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        lines = [
            f"Project Map: {start_path.name}",
            f"Generated: {timestamp}",
            "-" * 40,
            f"üìÅ {start_path.name}/"
        ]

        logger.info(f"Mapping directory: {start_path}")
        self._walk(start_path, "", lines, exclusions)
        return "\n".join(lines)

    def _walk(self, directory: Path, prefix: str, lines: List[str], exclusions: Set[str]):
        try:
            # Sort: Directories first, then files (alphabetical)
            children = sorted(
                [p for p in directory.iterdir() if p.name not in exclusions],
                key=lambda x: (not x.is_dir(), x.name.lower())
            )
        except PermissionError:
            lines.append(f"{prefix}‚îî‚îÄ‚îÄ üö´ [Permission Denied]")
            return

        count = len(children)
        for index, path in enumerate(children):
            is_last = (index == count - 1)
            connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            
            if path.is_dir():
                lines.append(f"{prefix}{connector}üìÅ {path.name}/")
                extension = "    " if is_last else "‚îÇ   "
                self._walk(path, prefix + extension, lines, exclusions)
            else:
                lines.append(f"{prefix}{connector}üìÑ {path.name}")


# --- Independent Test Block ---
if __name__ == "__main__":
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

    svc = TreeMapperMS()
    print("Service ready:", svc)
    
    # Map the current directory
    print("\n--- Map of Current Dir ---")
    tree = svc.generate_tree(".", additional_exclusions={"__pycache__"})
    print(tree)
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\LICENSE.md
--------------------------------------------------------------------------------
MIT License

Copyright (c) 2025 Jacob Lambert

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\README.md
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\requirements.txt
--------------------------------------------------------------------------------
# Standard Library dependencies only:
# tkinter, argparse, json, ast, threading, os, sys
#
# No external pip packages required.
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\setup_env.bat
--------------------------------------------------------------------------------
@echo off
echo [SYSTEM] Initializing new project environment...

:: 1. Create the venv if it doesn't exist
if not exist .venv (
    echo [SYSTEM] Creating .venv...
    py -m venv .venv
)

:: 2. Upgrade pip and install requirements
echo [SYSTEM] Installing dependencies...
.venv\Scripts\python.exe -m pip install --upgrade pip
if exist requirements.txt (
    .venv\Scripts\pip install -r requirements.txt
)

echo.
echo [SUCCESS] Environment ready!
echo You can now open this folder in VS Code or launch via scripts_menu.py
pause
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\src\app.py
--------------------------------------------------------------------------------
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
== Generic Python Module/CLI Boilerplate ==

This is a generic template for a Python file that can be:
1.  Imported as a module by other scripts (e.g., `import generic_module`).
2.  Run as a standalone command-line script (e.g., `$ python generic_module.py --input data.txt`).

How to use this template:
1.  Rename this file to match your new tool (e.g., `my_data_processor.py`).
2.  Update this docstring to describe what your tool does.
3.  Fill in the "CORE FUNCTIONALITY" section with your app's logic.
4.  Go to the `main()` function to define your CLI arguments.
5.  In `main()`, add the code to call your core functions using the parsed arguments.
"""

# 1. IMPORTS
# Standard library imports
import sys
import os
import argparse  # For parsing command-line arguments

# Third-party imports (if any)
# e.g., import requests

# Local/application imports (if any)
# e.g., from . import my_other_module


# 2. CONSTANTS
# TODO: Define any constants your application needs.
SOME_DEFAULT_SETTING = "default_value"


# 3. CORE FUNCTIONALITY (The "Importable" Module)
#
# These functions make up the "core logic" of your application.
# They can be imported and used by other Python scripts.
# They should be self-contained and not rely on command-line arguments.

def core_logic_function(data: any, setting: str = SOME_DEFAULT_SETTING) -> any:
    """
    TODO: Replace this with your main logic function.
    
    This function should perform the primary task of your module.
    
    Args:
        data (any): The input data to process.
        setting (str, optional): An example of an optional setting.
                                 Defaults to SOME_DEFAULT_SETTING.

    Returns:
        any: The processed data.
    """
    print(f"[Core Logic] Processing data with setting: {setting}")
    
    # --- TODO: Your actual logic goes here ---
    # Example:
    try:
        processed_data = f"Processed data: {str(data).upper()}"
        print("[Core Logic] Processing complete.")
        return processed_data
    except Exception as e:
        print(f"[Core Logic] Error during processing: {e}", file=sys.stderr)
        # Re-raise the exception to be handled by the caller
        raise


def helper_function(value: int) -> str:
    """
    TODO: Add any helper functions your core logic needs.
    
    This is an example of a helper that might be called by
    core_logic_function or also be importable.
    
    Args:
        value (int): An input value.

    Returns:
        str: A formatted string.
    """
    return f"Helper processed value: {value * 2}"


# 4. CLI (Command-Line Interface) LOGIC
#
# This code only runs when the script is executed directly.
# It should handle parsing arguments and calling the core functions.

def main():
    """
    Main function to run the script from the command line.
    
    It parses arguments, calls core functions, and handles CLI-specific
    input/output and error handling.
    """
    
    # --- Argument Parsing ---
    # Set up the argument parser
    # TODO: Update the description to match your tool.
    parser = argparse.ArgumentParser(
        description="A generic CLI tool. TODO: Describe your tool here.",
        epilog="Example: python generic_module.py my_input.txt -o my_output.txt -v"
    )
    
    # --- TODO: Define your arguments ---
    
    # Example of a required positional argument
    parser.add_argument(
        "input_path",  # The name of the argument
        type=str,
        help="TODO: Describe this required input (e.g., path to an input file)."
    )
    
    # Example of an optional argument (e.g., -o or --output)
    parser.add_argument(
        "-o", "--output",
        type=str,
        default=None,  # Default to None if not provided
        help="TODO: Describe this optional argument (e.g., path to an output file)."
    )
    
    # Example of a "flag" argument (stores True if present)
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",  # This makes it a boolean flag
        help="Enable verbose output."
    )
    
    # Parse the arguments from the command line (e.g., sys.argv)
    args = parser.parse_args()

    # --- Main Application Flow ---
    
    # Use the 'verbose' flag to control print statements
    if args.verbose:
        print("Verbose mode enabled.", file=sys.stderr)
        print(f"Arguments received: {args}", file=sys.stderr)

    try:
        # 1. Load data (CLI-specific task)
        #    TODO: Replace this with your actual data loading
        if args.verbose:
            print(f"Loading data from {args.input_path}...", file=sys.stderr)
        # This is just an example. You'd likely load a file here.
        input_data = f"Content of {args.input_path}" 

        # 2. Call core logic (the "importable" part)
        if args.verbose:
            print("Calling core logic...", file=sys.stderr)
        
        # Here we pass the CLI arguments to the core function
        processed_data = core_logic_function(input_data)
        
        # 3. Handle output (CLI-specific task)
        if args.output:
            # Save to a file
            if args.verbose:
                print(f"Saving processed data to {args.output}...", file=sys.stderr)
            # TODO: Add file-saving logic here
            # with open(args.output, 'w') as f:
            #     f.write(processed_data)
            print(f"Success: Output saved to {args.output}")
        else:
            # Print to standard output
            if args.verbose:
                print("Printing processed data to stdout:", file=sys.stderr)
            print(processed_data)
        
        # Exit with a success code
        sys.exit(0)

    except FileNotFoundError as e:
        print(f"\nError: Input file not found.", file=sys.stderr)
        print(f"Details: {e}", file=sys.stderr)
        sys.exit(1) # Exit with a non-zero error code
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}", file=sys.stderr)
        sys.exit(1)


# This "magic" line is the key to the whole pattern:
#
# - If you run `python generic_module.py ...`, Python sets
#   __name__ = "__main__", and the main() function is called.
#
# - If you `import generic_module` in another script, __name__
#   is "generic_module", so this block is SKIPPED.
#
if __name__ == "__main__":
    main()
--------------------------------------------------------------------------------
FILE: _UsefulHelperScriptsMENU\_BoilerPlatePythonTEMPLATE\src\__init__.py
--------------------------------------------------------------------------------

{
  "system_prompts": {
    "registry_lookup": "You are the Library Registry Manager. You have a strict list of available microservices above.\n1. Answer ONLY based on this list.\n2. If the user asks for a list, output the names exactly as they appear here.\n3. Do NOT invent, guess, or hallucinate service names that are not in the list.\n4. If a requested tool is not in the list, say 'I do not see that service'.",
    "deep_analysis": "You are a Senior Python Architect. You have been given the source code for specific microservices below. Your job is to answer the user's technical questions based ONLY on this code. If the code does not support the answer, state that. Do not invent features."
  },
  "context_templates": {
    "registry_header": "AVAILABLE SERVICES LIST:\n",
    "code_header": "SOURCE CODE CONTEXT:\n",
    "file_block": "\n=== BEGIN FILE: {filename} ===\n{content}\n=== END FILE ===\n"
  },
  "ui_messages": {
    "ollama_check": "Checking Ollama connection...",
    "ollama_connected": "Ollama connected. Found {count} models.",
    "ollama_error": "Ollama Error: {status}",
    "reading_files": "Reading {count} selected files...",
    "analyzing_files": "Analyzing {count} selected source files...",
    "connection_failed": "Connection Failed: {error}"
  },
  "inference_options": {
    "temperature": 0.1,
    "timeout_seconds": 120
  }
}
